[{"content":"安装 在https://www.python.org/downloads/source/上找到合适的安装包 在linux上curl -O https://www.python.org/ftp/python/3.7.14/Python-3.7.14.tgz 解压tar -zxvf python/3.7.14/Python-3.7.14.tgz 修改解压目录下的Modules/Setup按需自定义 在解压目录下的bin目录下执行./configure 执行make 执行make install 输入py按tab看是否有提示验证是否安装成功 申明 在编写的python脚本文件中，可以在第一行申明#!/usr/bin/python标识默认改脚本的执行程序(路径未pythen可执行文件的具体路径)，如果使用./xxx.py时就会使用该程序执行脚本，如果未申明默认会当做shell脚本进行执行\n#!/usr/bin/python print(\u0026#34;ok\u0026#34;) 中文编码 如果在执行程序时遇到中文乱码问题，可以在脚本文件中申明# -*- coding: UTF-8 -*-或# coding=utf-8\n#!/usr/bin/python # coding=utf-8 print(\u0026#34;你好！\u0026#34;) 变量 #赋值 x, y = 1, 2 #交换 x, y = y, x 条件语句 num = 3 if num \u0026gt; 2: pass else: pass if num \u0026gt; 2: pass elif num \u0026lt; 0: pass else: pass 条件成立时执行的语句 if cond else 条件不成立时执行的语句 num=3 print(\u0026#34;num\u0026gt;5\u0026#34;) if num\u0026gt;5 else print(\u0026#34;num\u0026lt;=5\u0026#34;) 循环 for item in iterable: pass for item in iterable: pass else: pass #range函数可以用于生成一个数字可迭代对象 range(stop) #默认start为0,生成的数组序列不包含stop range(start, stop) range(start, stop, step) num = 3 while num \u0026gt; 0: pass #使用break跳出循环并不会执行else里面的代码 num = 3 while num \u0026gt; 0: pass else: pass 逻辑运算符 and:操作符左右为Ture才是True，相当于\u0026amp;\u0026amp; or:操作符左右任意一边为True就为True，相当于|| not:取反，相当于 ! 运算符优先级：not \u0026gt; and \u0026gt; or\nand/or遵循逻辑短路运算，即当第一个操作数的逻辑无法确定值时才运算第二个\n3 and 4 4 3 or 4 3 (not 1) or (0 and 1) or (3 and 4) or (5 and 6) or (7 and 8 and 9) =\u0026gt; False or 0 or 4 or 6 or 9 =\u0026gt; 4 not 1 or 0 and 1 or 3 and 4 or 5 and 6 or 7 and 8 and 9 =\u0026gt; False or 0 and 1 or 3 and 4 or 5 and 6 or 7 and 8 and 9 =\u0026gt; False or 0 or 4 or 6 or 9 =\u0026gt; 4 数据类型 内置函数type(var)可以返回var的数据类型\n数值类型 数值类型是不可变的数据类型，也就是说如果对数值类型进行改变将会产生一个新的对象\npython支持四种不同的数值类型：\nint(有符号整型) long(长整型，使用l或L标识,在3.x版本中已被废弃) float(浮点数) complex(复数，使用a+bj标识或者complex(a,b)) 布尔类型 定义为False的对象：None和False 转换为False的对象：0，0.0，oj，Decimal(0)，Fraction(0,1),\u0026quot;\u0026quot;,(),[],{},set(),range(0) 字符串 #字符串内包含单引号 str1 = \u0026#34;let\u0026#39;s go!\u0026#34; #字符串内包含双引号 str2 = \u0026#39;\u0026#34;life is short\u0026#34;\u0026#39; #字符串内既包含单引号也包含双引号 str3 = \u0026#34;let\u0026#39;s go! \\\u0026#34;life is short\\\u0026#34;\u0026#34; str4 = \u0026#39;let\\\u0026#39;s go! \u0026#34;life is short\u0026#34;\u0026#39; #原始字符串 str1 = \u0026#34;D:\\one\\two\\three\u0026#34; print(str1) D:\\one wo hree # r表示后面的字符串是原始字符串，字符串中的反斜杠不转义 str2 = r\u0026#34;D:\\one\\two\\three\u0026#34; print(str2) D:\\one\\two\\three #多行文本 str1 = \u0026#34;\u0026#34;\u0026#34;this is line1 this is line2 this is line3\u0026#34;\u0026#34;\u0026#34; print(str1) this is line1 this is line2 this is line3 str2 = \u0026#34;\u0026#34;\u0026#34;this is line1 let\u0026#39;s go! \u0026#34;life is short\u0026#34; \u0026#34;\u0026#34;\u0026#34; print(str2) this is line1 let\u0026#39;s go! \u0026#34;life is short\u0026#34; python字符串索引方式：\n从左到右，下标从0开始递增 从右往左，小标从-1开始递减 python 012345 -6-5-4-3-2-1 s=\u0026#34;python\u0026#34; print(s) #python #字符串截取使用[idx1:idx2],其中idx2不包含在内 print(s[1:3]) #yt print(s[:3]) #pyt print(s[3:]) #hon print(s[:]) #python print(s[:-1]) #pytho print(s[-5:]) #ython print(s[-5:-1]) #ytho #指定截取步长 print(s[1:6:1]) #ython print(s[1:6:2]) #yhn #字符串运算 print(s*2) #pythonpython print(s+2) #报错can only concatenate str (not \u0026#34;int\u0026#34;) to str #字符串拼接 print(s+\u0026#34;ok\u0026#34;) #pythonok 自身函数:\nstr1 = \u0026#34;I love python\u0026#34; #首字母大写 print(str1.capitalize()) #单词首字母大写 print(str1.title()) #所有字母大小写转换 print(str1.swapcase()) #全部小写 print(str1.lower()) #全部大写 print(str1.upper()) #字符串居中，如果指定的width小于字符串长度，那么原字符串输出 print(str1.center(5)) #I love python print(str1.center(20)) # I love python #左对齐 print(str1.ljust(20)) #I love python 有空格 #右对齐 print(str1.rjust(20)) # I love python #空白部分0填充 print(str1.zfill(20)) #0000000I love python str1 = \u0026#34;上海自来水来自海上\u0026#34; #str.count(sub[, start[, end]]) str1.count(\u0026#34;海\u0026#34;) #2 str1.count(\u0026#34;海\u0026#34;, 5) #1 str1.count(\u0026#34;海\u0026#34;, 0, 5) #1 #str.find(sub[, start[, end]]) str1.find(\u0026#34;海\u0026#34;) #1 str1.find(\u0026#34;海\u0026#34;, 5) #7 str1.find(\u0026#34;海\u0026#34;, 5, 7) #-1 找不到 #str.rfind(sub[, start[, end]]) str1.rfind(\u0026#34;海\u0026#34;) #7 str1.rfind(\u0026#34;海\u0026#34;, 5) #7 str1.find(\u0026#34;海\u0026#34;, 5, 7) #-1 #str.index(sub[, start[, end]]) 如果找不到就抛出异常 str1.index(\u0026#34;海\u0026#34;) #1 str1.index(\u0026#34;海\u0026#34;, 3, 6) Traceback (most recent call last): File \u0026#34;\u0026lt;stdin\u0026gt;\u0026#34;, line 1, in \u0026lt;module\u0026gt; ValueError: substring not found #str.expandtabs([tabsize]) tab替换空格 str2 = \u0026#34;\\thello\u0026#34; print(str2) # hello str3 = str2.expandtabs(2) print(str3) # hello #str.replace(old, new, count=-1) str2 = str1.replace(\u0026#34;海\u0026#34;, \u0026#34;hai\u0026#34;) print(str2) #上hai自来水来自hai上 str2 = str1.replace(\u0026#34;海\u0026#34;, \u0026#34;hai\u0026#34;, 1) print(str2) #上hai自来水来自海上 #str.plit(sep=None, maxsplit=-1)分割字符串 #sep参数自定分隔符，默认未None，如果未指定那么会按照\\n \\r \\t \\f 空格 进行分割 #maxsplit指定最大分割次数 str1=\u0026#34;123:abc:ABC:True:False\u0026#34; str1.split(\u0026#34;:\u0026#34;) #[\u0026#39;123\u0026#39;, \u0026#39;abc\u0026#39;, \u0026#39;ABC\u0026#39;, \u0026#39;True\u0026#39;, \u0026#39;False\u0026#39;] str1.split(\u0026#34;:\u0026#34;, 2) #[\u0026#39;123\u0026#39;, \u0026#39;abc\u0026#39;, \u0026#39;ABC:True:False\u0026#39;] #str.startswith(prefix[, start[, end]]) -\u0026gt; bool 判断字符串是否以指定字符串开头 str1 = \u0026#34;http://www/baidu.com\u0026#34; str1.startswith(\u0026#34;http\u0026#34;) #True str1.startswith(\u0026#34;https\u0026#34;) #False str1.startswith(\u0026#34;http\u0026#34;, 1) #False str1.startswith(\u0026#34;http\u0026#34;, 0, 3) #Flase end不包括 str1.startswith((\u0026#34;http\u0026#34;, \u0026#34;ftp\u0026#34;)) #True #str.endswith(suffix[, start[, end]]) 判断字符串是否以指定字符结尾 str1.endswith(\u0026#34;.com\u0026#34;) #True #str.isupper() str1.isupper() #False #str.islower() str1.islower() #True #str.isalpha() 判断字符串是不是纯字母组成 str1.isalpha() #False 包含标点符号不是纯字符 #str.lstrip(chars=None) 去除字符串左侧的指定字符,按字符判断，凡是在chars里的字符都去掉 str1 = \u0026#34; hello,python! \u0026#34; print(str1.lstrip()) #hello,python! 右侧有空格 str1 = \u0026#34;www.baidu.com\u0026#34; print(str1.lstrip(\u0026#34;www.\u0026#34;)) #baidu.com #str.rstrip(chars=None) 去除字符串右侧的指定字符 str1 = \u0026#34; hello,python! \u0026#34; print(str1.rstrip()) # hello,python! str1 = \u0026#34;www.baidu.com\u0026#34; print(str1.rstrip(\u0026#34;.com\u0026#34;)) #www.baidu #str.strip(chars=None) str1 = \u0026#34; hello,python! \u0026#34; print(str1.strip()) #hello,python! str1 = \u0026#34;www.baidu.com\u0026#34; print(str1.strip(\u0026#34;www..com\u0026#34;)) #baidu #str.removeprefix() 去除字符串指定前缀字符串 str1 = \u0026#34;www.baidu.com\u0026#34; print(str1.removeprefix(\u0026#34;www.\u0026#34;)) #baidu.com #str.removesuffix() 去除字符串指定后缀字符串 str1 = \u0026#34;www.baidu.com\u0026#34; print(str1.removesuffix(\u0026#34;.com\u0026#34;)) #www.baidu #str.partition(sep) 通过指定分隔符把字符串分割为三部分,从左往右找第一个分隔符进行分割 str1 = \u0026#34;www.baidu.com\u0026#34; print(str1.partition(\u0026#34;.\u0026#34;)) #(\u0026#39;www\u0026#39;, \u0026#39;.\u0026#39;, \u0026#39;baidu.com\u0026#39;) print(str1.partition(\u0026#34;/\u0026#34;)) #(\u0026#39;www.baidu.com\u0026#39;, \u0026#39;\u0026#39;, \u0026#39;\u0026#39;) 找不到分隔符的话元祖后两个字符为空 #str.rpartition(sep) str1 = \u0026#34;www.baidu.com\u0026#34; print(str1.rpartition(\u0026#34;.\u0026#34;)) #(\u0026#39;www.baidu\u0026#39;, \u0026#39;.\u0026#39;, \u0026#39;com\u0026#39;) #str.split(sep=None, maxsplit=-1) 默认以空格分割 str1 = \u0026#34;www.baidu.com\u0026#34; print(str1.split(\u0026#34;.\u0026#34;)) #[\u0026#39;www\u0026#39;, \u0026#39;baidu\u0026#39;, \u0026#39;com\u0026#39;] print(str1.split(\u0026#34;.\u0026#34;, 1)) #[\u0026#39;www\u0026#39;, \u0026#39;baidu.com\u0026#39;] #str.rsplit(sep=None, maxsplit=-1) str1 = \u0026#34;www.baidu.com\u0026#34; print(str1.rsplit(\u0026#34;.\u0026#34;)) #[\u0026#39;www\u0026#39;, \u0026#39;baidu\u0026#39;, \u0026#39;com\u0026#39;] print(str1.rsplit(\u0026#34;.\u0026#34;, 1)) #[\u0026#39;www.baidu\u0026#39;, \u0026#39;com\u0026#39;] #str.splitlines(keepends=False) 按换行符分割字符串，可以处理不同操作系统下换行符不同的问题 #在linux换行符是\\n 在mac下换行符是\\r 在windows下换行符是\\r\\n str1 = \u0026#34;line1\\nline2\\rline3\\r\\n\u0026#34; print(str1.splitlines()) #[\u0026#39;line1\u0026#39;, \u0026#39;line2\u0026#39;, \u0026#39;line3\u0026#39;] print(str1.splitlines(keepends=True)) #[\u0026#39;line1\\n\u0026#39;, \u0026#39;line2\\r\u0026#39;, \u0026#39;line3\\r\\n\u0026#39;] #str.join(iterable) 使用指定分隔符连接列表返回字符串 cat_str = \u0026#34;,\u0026#34; print(cat_str.join([\u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;, \u0026#34;c\u0026#34;])) #a,b,c 格式化字符串 https://blog.csdn.net/ex_6450/article/details/125031543\n#1. str.format() str1 = \u0026#34;hello, i am {}\u0026#34; print(str1.format(\u0026#34;tom\u0026#34;)) #hello, i am tom str1 = \u0026#34;hello, i am {}, {} years old\u0026#34; print(str1.format(\u0026#34;tom\u0026#34;, 20)) #hello, i am tom, 20 years old str1 = \u0026#34;hello, i am {0}, {1} years old\u0026#34; print(str1.format(\u0026#34;tom\u0026#34;, 20)) #hello, i am tom, 20 years old str1 = \u0026#34;hello, i am {name}, {age} years old\u0026#34; print(str1.format(name=\u0026#34;tom\u0026#34;, age=20)) #hello, i am tom, 20 years old str1 = \u0026#34;hello, i am {0}, {age} years old\u0026#34; print(str1.format(\u0026#34;tom\u0026#34;, age=20)) #hello, i am tom, 20 years old #在字符串里有原始的大括号用双大括号 或 用单大括号然后format的时候传入大括号 str1 = \u0026#34;{{}}hello, i am {0}, {age} years old\u0026#34; print(str1.format(\u0026#34;tom\u0026#34;, age=20)) #{}hello, i am tom, 20 years old str1 = \u0026#34;{0}hello, i am {1}, {age} years old\u0026#34; print(str1.format(\u0026#34;{}\u0026#34;, \u0026#34;tom\u0026#34;, age=20)) #{}hello, i am tom, 20 years old #2. % str1 = \u0026#34;hello, i am %s\u0026#34; print(str1 % (\u0026#34;tom\u0026#34;)) #hello, i am tom str1 = \u0026#34;hello, i am %s, %d years old\u0026#34; print(str1 % (\u0026#34;tom\u0026#34;, 20)) #hello, i am tom, 20 years old str1 = \u0026#34;{}hello, i am %s, %d years old\u0026#34; print(str1 % (\u0026#34;tom\u0026#34;, 20)) #{}hello, i am tom, 20 years old #3. f name = \u0026#34;tom\u0026#34; str1 = f\u0026#34;hello, i am {name}\u0026#34; print(str1) #hello, i am tom name = \u0026#34;tom\u0026#34; age = 20 str1 = f\u0026#34;hello, i am {name}, {age} years old\u0026#34; print(str1) #hello, i am tom, 20 years old name = \u0026#34;tom\u0026#34; age = 20 str1 = f\u0026#34;{{}}hello, i am {name}, {age} years old\u0026#34; print(str1) #{}hello, i am tom, 20 years old 列表 列表可以包含数值、字符串、布尔、列表等类型，甚至一个列表可以包含多种数据类型\n列表的索引和字符串一样\narr = [1,\u0026#39;a\u0026#39;,True,[3.14]] #列表可以包含多种数据类型 print(arr) #[1, \u0026#39;a\u0026#39;, True, [3.14]] print(arr[1]) #\u0026#39;a\u0026#39; print(arr[1:]) #[\u0026#39;a\u0026#39;, True, [3.14]] print(arr[:-1]) #[1, \u0026#39;a\u0026#39;, True] print(arr[::2]) #[1, True] #计算 print(arr*2) #[1, \u0026#39;a\u0026#39;, True, [3.14], 1, \u0026#39;a\u0026#39;, True, [3.14]] print(arr[::2] + arr[1::2]) #[1, \u0026#39;a\u0026#39;, True, [3.14]] arr2 = [1,2,3] arr3 = [1] print(arr2-arr3) #报错unsupported operand type(s) for -: \u0026#39;list\u0026#39; and \u0026#39;list\u0026#39; #判断列表中是否存在某个元素 2 in arr2 #True 相关内置函数：\n#cmp(list1, list2)比较两个列表,3.x版本已经废弃 list1=[1,2,3] list2=[1,2,3] cmp(list1, list2) #len(list)获取列表的直接子元素个数 list1=[1,2,3] len(list1) #3 list2=[1,2,[\u0026#39;a\u0026#39;,\u0026#39;b\u0026#39;]] len(list2) #3 #max(list)获取列表大最大元素 list1=[1,2,3] max(list1) #3 list2=[1,\u0026#39;a\u0026#39;,\u0026#39;A\u0026#39;,True,False] max(list2) #报错 TypeError: \u0026#39;\u0026gt;\u0026#39; not supported between instances of \u0026#39;str\u0026#39; and \u0026#39;int\u0026#39; list3=[1,True,False] max(list3) #1 list4=[True,False,\u0026#34;a\u0026#34;,\u0026#34;A\u0026#34;] max(list4) #报错 TypeError: \u0026#39;\u0026gt;\u0026#39; not supported between instances of \u0026#39;str\u0026#39; and \u0026#39;bool\u0026#39; #min(list)获取列表的最小元素 list1=[1,2,3] min(list1) #1 list2=[1,\u0026#39;a\u0026#39;,\u0026#39;A\u0026#39;,True,False] min(list2) #报错 TypeError: \u0026#39;\u0026lt;\u0026#39; not supported between instances of \u0026#39;str\u0026#39; and \u0026#39;int\u0026#39; list3=[1,True,False] min(list3) #False list4=[True,False,\u0026#34;a\u0026#34;,\u0026#34;A\u0026#34;] min(list4) #报错 TypeError: \u0026#39;\u0026lt;\u0026#39; not supported between instances of \u0026#39;str\u0026#39; and \u0026#39;bool\u0026#39; #list(tuple)姜元组转化为列表 tup1=(1,2,3) list(tup1) #[1, 2, 3] 自带方法：\n#list.append(obj)在列表的末尾追加一个元素 list1=[1,2,3] list1.append(\u0026#39;a\u0026#39;) print(list1) #[1, 2, 3, \u0026#39;a\u0026#39;] #list.count(obj)统计某个元素在列表中出现的次数 list2=[1,2,3] list2.count(1) #1 list2.count(\u0026#39;a\u0026#39;) #0 #list.extend(iterable)使用另一个可迭代列表扩展本列表 #等同于 list[len(list):] = list2 list3=[1,2,3] list4=[\u0026#39;a\u0026#39;,\u0026#39;b\u0026#39;] list3.extend(list4) print(list3) #[1, 2, 3, \u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;] tup1=(\u0026#39;A\u0026#39;,\u0026#39;B\u0026#39;) list3.extend(tup1) print(list3) #[1, 2, 3, \u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;, \u0026#39;A\u0026#39;, \u0026#39;B\u0026#39;] dict1={\u0026#39;k1\u0026#39;: \u0026#39;v1\u0026#39;, \u0026#39;k2\u0026#39;:\u0026#39;v2\u0026#39;} list3.extend(dict1) print(list3) #[1, 2, 3, \u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;, \u0026#39;A\u0026#39;, \u0026#39;B\u0026#39;, \u0026#39;k1\u0026#39;, \u0026#39;k2\u0026#39;] #list.index(obj, start, end)从列表这种找到第一个匹配元素的索引,包含start不包含end list1=[1,2,3,1,2,3] list1.index(1) #0 list2=[1,2,3,[\u0026#39;a\u0026#39;,\u0026#39;b\u0026#39;]] list2.index([\u0026#39;a\u0026#39;,\u0026#39;b\u0026#39;]) #3 #list.insert(idx, obj)将元素插入到指定位置,该位置及其之后的元素一次往后移 list1=[1,2,3] list1.insert(1,\u0026#39;a\u0026#39;) print(list1) #[1, \u0026#39;a\u0026#39;, 2, 3] #list.pop(idx=-1)移除列表中指定位置(默认最后一个)的元素并返回 list1=[1,2,3] list1.pop() #3 list2=[1,2,3] list2.pop(1) #2 list3=[] list3.pop() #报错 IndexError: pop from empty list #list.remove(obj)移除列表中元素的第一个匹配项 list1=[1,2,3] list1.remove(2) print(list1) [1, 3] list2=[1,2,3] list2.remove(5) #报错 ValueError: list.remove(x): x not in list #list.reverse()反转列表,并不会反转列表中的列表元素(非递归) list1=[1,2,3] list1.reverse() print(list1) #[3, 2, 1] list2=[1,2,3,[\u0026#39;a\u0026#39;,\u0026#39;b\u0026#39;]] list2.reverse() print(list2) #[[\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;], 3, 2, 1] #list.sort(cmp=None,key=None,reverse=False)杜列表进行排序 #key参数指定使用元素的键进行比较 #reverse参数指定排序的升降序，False升序，True降序 list1=[2,1,4,3] list1.sort() print(list1) #[1, 2, 3, 4] list2=[ {\u0026#34;name\u0026#34;: \u0026#34;tom\u0026#34;, \u0026#34;age\u0026#34;: 20}, {\u0026#34;name\u0026#34;: \u0026#34;jack\u0026#34;, \u0026#34;age\u0026#34;: 18}, {\u0026#34;name\u0026#34;: \u0026#34;jarry\u0026#34;, \u0026#34;age\u0026#34;: 25}, ] def sortFunc(p): return p[\u0026#34;age\u0026#34;] list2.sort(key=sortFunc) print(list2) #[{\u0026#39;name\u0026#39;: \u0026#39;jack\u0026#39;, \u0026#39;age\u0026#39;: 18}, {\u0026#39;name\u0026#39;: \u0026#39;tom\u0026#39;, \u0026#39;age\u0026#39;: 20}, {\u0026#39;name\u0026#39;: \u0026#39;jarry\u0026#39;, \u0026#39;age\u0026#39;: 25}] #list.clear()清空列表 list1 = [1,2,3] print(list1) #[1, 2, 3] list1.clear() print(list1) #[] 变量的定义还在 #list.copy()浅拷贝一个列表 同 list2 = list1[:] 同 list2 = copy.copy(list1) list1=[1,2,3] list2=[\u0026#39;a\u0026#39;,\u0026#39;b\u0026#39;,\u0026#39;c\u0026#39;,list1] print(list2) # [\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;, \u0026#39;c\u0026#39;, [1, 2, 3]] list3 = l2.copy() print(list3) # [\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;, \u0026#39;c\u0026#39;, [1, 2, 3]] list4 = list2[:] import copy list5 = copy.copy(list2) list1[1]=20 print(list2) # [\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;, \u0026#39;c\u0026#39;, [1, 20, 3]] print(list3) # [\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;, \u0026#39;c\u0026#39;, [1, 20, 3]] #深拷贝 list1=[1,2,3] list2=[\u0026#39;a\u0026#39;,\u0026#39;b\u0026#39;,\u0026#39;c\u0026#39;,list1] print(list2) # [\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;, \u0026#39;c\u0026#39;, [1, 2, 3]] import copy list3 = copy.deepcopy(list2) print(list3) # [\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;, \u0026#39;c\u0026#39;, [1, 2, 3]] list1[1] = 20 print(list3) # [\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;, \u0026#39;c\u0026#39;, [1, 2, 3]] 列表推导式\nlist1 = [1,2,3] list1 = [item*2 for item in list1] even = [num for num in range(10) if num%2 == 0] print(even) #[0, 2, 4, 6, 8] list1 = [[1,2,3], [4,5,6], [7,8,9]] flatten = [col for row in list1 for col in row] print(flatten) #[1, 2, 3, 4, 5, 6, 7, 8, 9] list1 = [[x,y] for x in range(10) if x%2 == 0 for y in range(10) if y%3 == 0] print(list1) #[[0, 0], [0, 3], [0, 6], [0, 9], [2, 0], [2, 3], [2, 6], [2, 9], [4, 0], [4, 3], [4, 6], [4, 9], [6, 0], [6, 3], [6, 6], [6, 9], [8, 0], [8, 3], [8, 6], [8, 9]] 元组 元组与列表类似，只是元组中的元素不能修改\nt1 = (1,2,3) t2 = () t3 = (1,) #创建只带有一个元素的元组需要在元素后面加逗号 t4 = 1,2,3 #如果元祖的元素是列表，那么可以对该列表的元素进行修改 t5 = ([1,2,3], [\u0026#39;a\u0026#39;,\u0026#39;b\u0026#39;,\u0026#39;c\u0026#39;]) print(t5) #([1, 2, 3], [\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;, \u0026#39;c\u0026#39;]) t5[0][0] = 10 t5[1][0] = \u0026#39;A\u0026#39; print(t5) #([10, 2, 3], [\u0026#39;A\u0026#39;, \u0026#39;b\u0026#39;, \u0026#39;c\u0026#39;]) #判断元组中是否存在某个元素 3 in t1 #True 元素的访问、截取、复制、连接的用法和列表相同\n内置函数：\n#tuple(list)把列表转化为元组 list1 = [1,2,3] tup1 = tuple(list1) print(tup1) #(1, 2, 3) 解包\nt1 = (1,2,3) print(t1) #(1, 2, 3) a,b,c = t1 print(a, b, c) #1 2 3 dict字典 字段使用kv形式保存键值对，如果有多个相同的键，那么后一个键的值会覆盖前一个\ndict1={\u0026#34;k1\u0026#34;: 1, \u0026#34;k2\u0026#34;: 2, \u0026#34;k3\u0026#34;: 3} print(dict1) #{\u0026#39;k1\u0026#39;: 1, \u0026#39;k2\u0026#39;: 2, \u0026#39;k3\u0026#39;: 3} dict1 = dict(k1=1, k2=2, k3=3) dict1 = dict({\u0026#34;k1\u0026#34;: 1, \u0026#34;k2\u0026#34;: 2, \u0026#34;k3\u0026#34;: 3}) dict1 = dict([(\u0026#34;k1\u0026#34;, 1), (\u0026#34;k2\u0026#34;, 2), (\u0026#34;k3\u0026#34;, 3)]) dict2={\u0026#34;k1\u0026#34;: 1, \u0026#34;k2\u0026#34;: 2, \u0026#34;k3\u0026#34;: 3, \u0026#34;k1\u0026#34;: -1} print(dict2) #{\u0026#39;k1\u0026#39;: -1, \u0026#39;k2\u0026#39;: 2, \u0026#39;k3\u0026#39;: 3} dict3={\u0026#34;k1\u0026#34;: 1, \u0026#34;k2\u0026#34;: 2, \u0026#34;k3\u0026#34;: 3} #访问不存在的键会报错 dict3[\u0026#34;k5\u0026#34;] #KeyError: \u0026#39;k5\u0026#39; #增加/更新键值对 dict4={\u0026#34;k1\u0026#34;: 1, \u0026#34;k2\u0026#34;: 2, \u0026#34;k3\u0026#34;: 3} dict4[\u0026#34;k2\u0026#34;] = \u0026#34;v2\u0026#34; print(dict4) #{\u0026#39;k1\u0026#39;: 1, \u0026#39;k2\u0026#39;: \u0026#39;v2\u0026#39;, \u0026#39;k3\u0026#39;: 3} dict4[\u0026#34;k4\u0026#34;] = 4 print(dict4) #{\u0026#39;k1\u0026#39;: 1, \u0026#39;k2\u0026#39;: \u0026#39;v2\u0026#39;, \u0026#39;k3\u0026#39;: 3, \u0026#39;k4\u0026#39;: 4} #删除键值对/清空字典/删除字典 del dict4[\u0026#34;k4\u0026#34;] print(dict4) #{\u0026#39;k1\u0026#39;: 1, \u0026#39;k2\u0026#39;: \u0026#39;v2\u0026#39;, \u0026#39;k3\u0026#39;: 3} dict4.clear() print(dict4) #{} del dict4 print(dict4) #NameError: name \u0026#39;dict4\u0026#39; is not defined. Did you mean: \u0026#39;dict1\u0026#39;? 注意：字典的键必须是不可变的，所以可以使用数值、字符串、元组作为键，但是不能使用列表、字典作为键。\n字典的键必须是不可变的即可以对对象使用hash函数\ndict1 = {(1,2,3):\u0026#34;ok\u0026#34;} dict2 = {[1,2,3]:\u0026#34;not ok\u0026#34;} #TypeError: unhashable type: \u0026#39;list\u0026#39; dict3 = {{\u0026#34;k1\u0026#34;:\u0026#34;v1\u0026#34;}:\u0026#34;not ok\u0026#34;} #TypeError: unhashable type: \u0026#39;dict\u0026#39; 内置函数：\n#len(dict)获取字典键值对个数 dict1={\u0026#34;k1\u0026#34;: 1, \u0026#34;k2\u0026#34;: 2, \u0026#34;k3\u0026#34;: 3} len(dict1) #3 #str(dict)输出字符串形式的字典表示 dict1={\u0026#34;k1\u0026#34;: 1, \u0026#34;k2\u0026#34;: 2, \u0026#34;k3\u0026#34;: 3} str(dict1) #\u0026#34;{\u0026#39;k1\u0026#39;: 1, \u0026#39;k2\u0026#39;: 2, \u0026#39;k3\u0026#39;: 3}\u0026#34; #keyName in dict 判断键是否在字典中 dict1={\u0026#34;k1\u0026#34;: 1, \u0026#34;k2\u0026#34;: 2, \u0026#34;k3\u0026#34;: 3} \u0026#34;k1\u0026#34; in dict1 #True \u0026#34;k11\u0026#34; in dict1 #False #keyName not in dict 判断键是否不在字典中 dict1={\u0026#34;k1\u0026#34;: 1, \u0026#34;k2\u0026#34;: 2, \u0026#34;k3\u0026#34;: 3} \u0026#34;k1\u0026#34; not in dict1 #False \u0026#34;k11\u0026#34; not in dict1 #True 自带方法：\n#dict.clear()清空字典 dict1={\u0026#34;k1\u0026#34;: 1, \u0026#34;k2\u0026#34;: 2, \u0026#34;k3\u0026#34;: 3} dict1.clear() #dict.copy()浅拷贝一个字典 list1 = [1,2,3] dict1 = {\u0026#34;k1\u0026#34;: \u0026#34;v1\u0026#34;, \u0026#34;k2\u0026#34;:list1} dict2 = dict1.copy() print(dict2) #{\u0026#39;k1\u0026#39;: \u0026#39;v1\u0026#39;, \u0026#39;k2\u0026#39;: [1, 2, 3]} list1.append(\u0026#34;ok\u0026#34;) print(dict1) #{\u0026#39;k1\u0026#39;: \u0026#39;v1\u0026#39;, \u0026#39;k2\u0026#39;: [1, 2, 3, \u0026#39;ok\u0026#39;]} print(dict2) #{\u0026#39;k1\u0026#39;: \u0026#39;v1\u0026#39;, \u0026#39;k2\u0026#39;: [1, 2, 3, \u0026#39;ok\u0026#39;]} #dict.fromkeys(seq[,value]) dict1 = dict.fromkeys(\u0026#34;python\u0026#34;, 520) #使用序列创建字典 print(dict1) #{\u0026#39;p\u0026#39;: 520, \u0026#39;y\u0026#39;: 520, \u0026#39;t\u0026#39;: 520, \u0026#39;h\u0026#39;: 520, \u0026#39;o\u0026#39;: 520, \u0026#39;n\u0026#39;: 520} #dict1.pop(k[,d]) remove specified key and return the corresponding value dict1 = {\u0026#34;k1\u0026#34;: 1, \u0026#34;k2\u0026#34;: 2, \u0026#34;k3\u0026#34;: 3} print(dict1.pop(\u0026#34;k2\u0026#34;)) #2 print(dict1) #{\u0026#39;k1\u0026#39;: 1, \u0026#39;k3\u0026#39;: 3} print(dict1.pop(\u0026#34;k4\u0026#34;)) Traceback (most recent call last): File \u0026#34;\u0026lt;stdin\u0026gt;\u0026#34;, line 1, in \u0026lt;module\u0026gt; KeyError: \u0026#39;k4\u0026#39; print(dict1.pop(\u0026#34;k4\u0026#34;, \u0026#34;not found\u0026#34;)) #not found #dict1.popitem() Pairs are returned in LIFO (last-in, first-out) order Raises KeyError if the dict is empty dict1 = {\u0026#34;k1\u0026#34;: 1, \u0026#34;k2\u0026#34;: 2, \u0026#34;k3\u0026#34;: 3} print(dict1.popitem()) #(\u0026#39;k3\u0026#39;, 3) dict1[\u0026#34;k4\u0026#34;] = 4 print(dict1.popitem()) #(\u0026#39;k4\u0026#39;, 4) #dict1.update() 批量更新dict dict1 = {\u0026#34;k1\u0026#34;: 1, \u0026#34;k2\u0026#34;: 2, \u0026#34;k3\u0026#34;: 3} dict1.update({\u0026#34;k3\u0026#34;: 33, \u0026#34;k4\u0026#34;: 44}) print(dict1) #{\u0026#39;k1\u0026#39;: 1, \u0026#39;k2\u0026#39;: 2, \u0026#39;k3\u0026#39;: 33, \u0026#39;k4\u0026#39;: 44} #dict1.get(key, default=None) dict1 = {\u0026#34;k1\u0026#34;: 1, \u0026#34;k2\u0026#34;: 2, \u0026#34;k3\u0026#34;: 3} print(dict1.get(\u0026#34;k1\u0026#34;)) #1 print(dict1.get(\u0026#34;k4\u0026#34;)) #None print(dict1.get(\u0026#34;k4\u0026#34;, \u0026#34;not found\u0026#34;)) #not found #dict1.setdefault(key, default=None) 如果key不在dict中则设置值，并返回该key的value dict1 = {\u0026#34;k1\u0026#34;: 1, \u0026#34;k2\u0026#34;: 2, \u0026#34;k3\u0026#34;: 3} print(dict1.setdefault(\u0026#34;k2\u0026#34;)) #2 print(dict1.setdefault(\u0026#34;k4\u0026#34;, 4)) #4 print(dict1) #{\u0026#39;k1\u0026#39;: 1, \u0026#39;k2\u0026#39;: 2, \u0026#39;k3\u0026#39;: 3, \u0026#39;k4\u0026#39;: 4} #dict1.items() dict1 = {\u0026#34;k1\u0026#34;: 1, \u0026#34;k2\u0026#34;: 2, \u0026#34;k3\u0026#34;: 3} items = dict1.items() print(items) #dict_items([(\u0026#39;k1\u0026#39;, 1), (\u0026#39;k2\u0026#39;, 2), (\u0026#39;k3\u0026#39;, 3)]) dict1[\u0026#34;k4\u0026#34;] = 4 print(items) #dict_items([(\u0026#39;k1\u0026#39;, 1), (\u0026#39;k2\u0026#39;, 2), (\u0026#39;k3\u0026#39;, 3), (\u0026#39;k4\u0026#39;, 4)]) #dict1.keys() dict1 = {\u0026#34;k1\u0026#34;: 1, \u0026#34;k2\u0026#34;: 2, \u0026#34;k3\u0026#34;: 3} keys = dict1.keys() print(keys) #dict_keys([\u0026#39;k1\u0026#39;, \u0026#39;k2\u0026#39;, \u0026#39;k3\u0026#39;]) dict1[\u0026#34;k4\u0026#34;] = 4 print(keys) #dict_keys([\u0026#39;k1\u0026#39;, \u0026#39;k2\u0026#39;, \u0026#39;k3\u0026#39;, \u0026#39;k4\u0026#39;]) #dict.values() dict1 = {\u0026#34;k1\u0026#34;: 1, \u0026#34;k2\u0026#34;: 2, \u0026#34;k3\u0026#34;: 3} values = dict1.values() print(values) #dict_values([1, 2, 3]) dict1[\u0026#34;k4\u0026#34;] = 4 print(values) #dict_values([1, 2, 3, 4]) #key1 in dict1 dict1 = {\u0026#34;k1\u0026#34;: 1, \u0026#34;k2\u0026#34;: 2, \u0026#34;k3\u0026#34;: 3} \u0026#34;k1\u0026#34; in dict1 #True \u0026#34;k4\u0026#34; in dict1 #False #key1 not in dict1 dict1 = {\u0026#34;k1\u0026#34;: 1, \u0026#34;k2\u0026#34;: 2, \u0026#34;k3\u0026#34;: 3} \u0026#34;k1\u0026#34; not in dict1 #False \u0026#34;k4\u0026#34; not in dict1 #True #list(dict1) dict1 = {\u0026#34;k1\u0026#34;: 1, \u0026#34;k2\u0026#34;: 2, \u0026#34;k3\u0026#34;: 3} list(dict1) #[\u0026#39;k1\u0026#39;, \u0026#39;k2\u0026#39;, \u0026#39;k3\u0026#39;] #iter(dict1) dict1 = {\u0026#34;k1\u0026#34;: 1, \u0026#34;k2\u0026#34;: 2, \u0026#34;k3\u0026#34;: 3} d = iter(dict1) next(d) #\u0026#39;k1\u0026#39; next(d) #\u0026#39;k2\u0026#39; next(d) #\u0026#39;k3\u0026#39; next(d) Traceback (most recent call last): File \u0026#34;\u0026lt;stdin\u0026gt;\u0026#34;, line 1, in \u0026lt;module\u0026gt; StopIteration set集合 集合中所有元素应该是不重复的，而且是无序的\nset1 = {\u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;, \u0026#34;c\u0026#34;} set1 = {s for s in \u0026#34;abc\u0026#34;} set1 = set(\u0026#34;abc\u0026#34;) set1[0] #集合不可索引 Traceback (most recent call last): File \u0026#34;\u0026lt;stdin\u0026gt;\u0026#34;, line 1, in \u0026lt;module\u0026gt; TypeError: \u0026#39;set\u0026#39; object is not subscriptable #set1.copy() #set1.isdisjoint(set2) #判断两个集合是否毫不相干 #set1.issubset(set2) \u0026lt;= #检测一个集合是不是另一个集合的子集 #set1.issuperset() \u0026gt;= #检测一个集合是不是另一个集合的超集 #set1.union(set2) | #set1.intersection(set1) \u0026amp; 集合交集 #set1.difference(set2) - 差集 可变集合(set) \u0026amp; 不可变集合(frozenset)\nset1 = {\u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;, \u0026#34;c\u0026#34;} set1.update([1,1], \u0026#34;23\u0026#34;) #以可迭代的方式处理参数 print(set1) #{1, \u0026#39;b\u0026#39;, \u0026#39;a\u0026#39;, \u0026#39;c\u0026#39;, \u0026#39;3\u0026#39;, \u0026#39;2\u0026#39;} set1.add(\u0026#34;23\u0026#34;) #添加单个元素到set print(set1) #{1, \u0026#39;23\u0026#39;, \u0026#39;b\u0026#39;, \u0026#39;a\u0026#39;, \u0026#39;c\u0026#39;, \u0026#39;3\u0026#39;, \u0026#39;2\u0026#39;} p = set1.pop() #Remove and return an arbitrary set element. Raises KeyError if the set is empty print(p) #1 set1.clear() print(set1) #set() fs = frozenset({\u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;, \u0026#34;c\u0026#34;}) fs.update(\u0026#34;abc\u0026#34;) Traceback (most recent call last): File \u0026#34;\u0026lt;stdin\u0026gt;\u0026#34;, line 1, in \u0026lt;module\u0026gt; AttributeError: \u0026#39;frozenset\u0026#39; object has no attribute \u0026#39;update\u0026#39; fs.add(1) Traceback (most recent call last): File \u0026#34;\u0026lt;stdin\u0026gt;\u0026#34;, line 1, in \u0026lt;module\u0026gt; AttributeError: \u0026#39;frozenset\u0026#39; object has no attribute \u0026#39;add\u0026#39; 时间 时间戳都以自从1970年1月1日午夜经过了多长秒来表示\n#时间戳 import time t1 = time.time() print(t1) #1665641987.3554833 秒的浮点数 #本地时间 import time localtime = time.localtime(time.time()) print(localtime) #time.struct_time(tm_year=2022, tm_mon=10, tm_mday=13, tm_hour=6, tm_min=22, tm_sec=58, tm_wday=3, tm_yday=286, tm_isdst=0) localtime = time.localtime() print(localtime) #可读时间 import time localtime = time.asctime(time.localtime(time.time())) print(localtime) #Thu Oct 13 06:25:30 2022 #格式化 import time time_str = time.strftime(\u0026#34;%Y-%m-%d %H:%M:%S\u0026#34;, time.localtime()) print(time_str) #2022-10-13 06:27:39 time_str = time.strftime(\u0026#34;%Y-%m-%d %H:%M:%S\u0026#34;) print(time_str) #2022-10-13 06:28:04 异常 处理异常 python3: num = 1 num / 0 Traceback (most recent call last): File \u0026#34;\u0026lt;stdin\u0026gt;\u0026#34;, line 1, in \u0026lt;module\u0026gt; ZeroDivisionError: division by zero try: 1/0 except: print(\u0026#34;出错\u0026#34;) 出错 try: 1/0 except ZeroDivisionError: print(\u0026#34;除数不能为0\u0026#34;) 除数不能为0 try: 1/0 except ZeroDivisionError as e: print(e) division by zero try: 1/0 except (ZeroDivisionError, ValueError, TypeError): print(\u0026#34;出错啦\u0026#34;) 出错啦 try: 1/0 except (ZeroDivisionError, ValueError, TypeError) as err: print(\u0026#34;出错啦\u0026#34;, err) 出错啦 division by zero try: 1/0 except ZeroDivisionError: print(\u0026#34;ZeroDivisionError\u0026#34;) except ValueError: print(\u0026#34;ValueError\u0026#34;) except TypeError: print(\u0026#34;TypeError\u0026#34;) ZeroDivisionError def myfunc(arg): try: int(arg) except Exception as err: print(\u0026#34;出错啦\u0026#34;, err) else: print(\u0026#34;没有任何问题\u0026#34;) finally: print(\u0026#34;finally语句\u0026#34;) myfunc(\u0026#34;abc\u0026#34;) 出错啦 invalid literal for int() with base 10: \u0026#39;abc\u0026#39; finally语句 myfunc(\u0026#34;123\u0026#34;) 没有任何问题 finally语句 抛出异常 def myfunc(level): if level == 1: pass elif level == 2: pass else: raise Exception(\u0026#34;invalid level\u0026#34;) myfunc(1) myfunc(3) Traceback (most recent call last): File \u0026#34;\u0026lt;stdin\u0026gt;\u0026#34;, line 1, in \u0026lt;module\u0026gt; File \u0026#34;\u0026lt;stdin\u0026gt;\u0026#34;, line 7, in myfunc Exception: invalid level def myfunc(arg): try: int(arg) except ValueError as err: raise Exception(\u0026#34;出错啦\u0026#34;) from err myfunc(\u0026#34;123\u0026#34;) myfunc(\u0026#34;abc\u0026#34;) Traceback (most recent call last): File \u0026#34;\u0026lt;stdin\u0026gt;\u0026#34;, line 3, in myfunc ValueError: invalid literal for int() with base 10: \u0026#39;abc\u0026#39; The above exception was the direct cause of the following exception: Traceback (most recent call last): File \u0026#34;\u0026lt;stdin\u0026gt;\u0026#34;, line 1, in \u0026lt;module\u0026gt; File \u0026#34;\u0026lt;stdin\u0026gt;\u0026#34;, line 5, in myfunc Exception: 出错啦 函数 函数定义 #定义 def functionname( parameters ): \u0026#34;函数_文档字符串\u0026#34; function_suite return [expression] import time def printtime(): \u0026#34;打印本地时间\u0026#34; print(time.localtime()) printtime() #time.struct_time(tm_year=2022, tm_mon=10, tm_mday=13, tm_hour=7, tm_min=11, tm_sec=50, tm_wday=3, tm_yday=286, tm_isdst=0) 可变对象和不可变对象\n在python中数值类型、字符串类型、元组类型是不可变的(可hash)\n列表、字典、对象是可变的(不可hash)\n在python中变量都是指向实际类型的指针\ndef change_number(num): num = 10 num = 1 change_number(num) print(num) #1 def change_list(l): l.append(\u0026#39;a\u0026#39;) l1 = [1,2,3] change_list(l1) print(l1) #[1, 2, 3, \u0026#39;a\u0026#39;] 在change_number函数中num是指向数值类型的指针，由于数值类型是不可变类型，在函数内对该值进行修改会生成一个新的数值类型，然后num指向它\n在change_list函数中l变量和调用函数是的l1变量都指向同一个列表，由于列表是可变对象，所以会在该对象上追加元素，并不会生成新的对象，所以函数内的修改函数外也能看见\n函数参数 位置参数,函数调用时参数的个数必须和定义的个数相同\ndef greet(name, welcome_str): print(f\u0026#34;{welcome_str},{name}!\u0026#34;) greet(\u0026#34;python\u0026#34;, \u0026#34;hello\u0026#34;) #hello,python! 关键字参数,使用关键字参数后可以不按函数定义的参数位置给各个参数传值,但是位置参数之前不能有关键字参数，关键字参数必须完全放在位置参数之后\ndef greet(name, welcome_str): print(f\u0026#34;{welcome_str},{name}!\u0026#34;) greet(\u0026#34;python\u0026#34;, \u0026#34;hello\u0026#34;) greet(name=\u0026#34;python\u0026#34;, welcome_str=\u0026#34;hello\u0026#34;) greet(welcome_str=\u0026#34;hello\u0026#34;, name=\u0026#34;python\u0026#34;) greet(\u0026#34;python\u0026#34;, welcome_str=\u0026#34;hello\u0026#34;) greet(name=\u0026#34;python\u0026#34;, \u0026#34;hello\u0026#34;) #SyntaxError: positional argument follows keyword argument 在使用help()查看函数的帮助文档时，许多内置函数如sum()在函数的定义中都有/ 意味着/左侧的参数只能是位置参数 /右侧的参数可以是关键字参数\nhelp(sum) sum(iterable, /, start=0) Return the sum of a \u0026#39;start\u0026#39; value (default: 0) plus an iterable of numbers sum([1,2,3]) #6 sum(iterable=[1,2,3]) Traceback (most recent call last): File \u0026#34;\u0026lt;stdin\u0026gt;\u0026#34;, line 1, in \u0026lt;module\u0026gt; TypeError: sum() takes at least 1 positional argument (0 given) sum([1,2,3], 6) #12 sum([1,2,3], start=6) #12 def greet(name, /, welcome_str): print(f\u0026#34;{welcome_str},{name}!\u0026#34;) greet(\u0026#34;python\u0026#34;, \u0026#34;hello\u0026#34;) #hello,python! greet(\u0026#34;python\u0026#34;, welcome_str=\u0026#34;hello\u0026#34;) #hello,python! greet(name=\u0026#34;python\u0026#34;, welcome_str=\u0026#34;hello\u0026#34;) Traceback (most recent call last): File \u0026#34;\u0026lt;stdin\u0026gt;\u0026#34;, line 1, in \u0026lt;module\u0026gt; TypeError: greet() got some positional-only arguments passed as keyword arguments: \u0026#39;name\u0026#39; 函数参数列表中出现*号参数表示左侧参数即可以是位置参数/关键字参数，右侧必须是关键字参数\ndef greet(name, *, welcome_str): print(f\u0026#34;{welcome_str},{name}!\u0026#34;) greet(\u0026#34;hello\u0026#34;, \u0026#34;python\u0026#34;) Traceback (most recent call last): File \u0026#34;\u0026lt;stdin\u0026gt;\u0026#34;, line 1, in \u0026lt;module\u0026gt; TypeError: greet() takes 1 positional argument but 2 were given greet(\u0026#34;hello\u0026#34;, welcome_str=\u0026#34;python\u0026#34;) #python,hello! greet(name=\u0026#34;hello\u0026#34;, welcome_str=\u0026#34;python\u0026#34;) #python,hello! 默认参数\ndef greet(name, welcome_str=\u0026#34;hello\u0026#34;): print(f\u0026#34;{welcome_str},{name}!\u0026#34;) greet(\u0026#34;python\u0026#34;) #hello,python! greet(\u0026#34;python\u0026#34;, \u0026#34;Hello\u0026#34;) #Hello,python! #函数定义时非默认参数必须在默认参数之前 def greet(welcome_str=\u0026#34;hello\u0026#34;, name): #SyntaxError: non-default argument follows default argument print(f\u0026#34;{welcome_str},{name}!\u0026#34;) 特殊参数 *var 会把传递的参数收集成元组\ndef myfunc(a, b, *c): print(a, b, c) myfunc(1,2) #1 2 () myfunc(1,2,3,4,5) #1 2 (3, 4, 5) **var 会把参数收集成字典,多余的参数必须以关键字参数提供\ndef myfunc(a, b, **c): print(a, b, c) myfunc(1,2) #1 2 {} myfunc(1,2, 3) Traceback (most recent call last): File \u0026#34;\u0026lt;stdin\u0026gt;\u0026#34;, line 1, in \u0026lt;module\u0026gt; TypeError: myfunc() takes 2 positional arguments but 3 were given myfunc(1,2,k1=3,k2=4,k3=5) #1 2 {\u0026#39;k1\u0026#39;: 3, \u0026#39;k2\u0026#39;: 4, \u0026#39;k3\u0026#39;: 5} return语句\n函数可以使用return语句返回一个返回值，如果只写return或者函数没有return那么会返回None\n函数返回多个参数和多个形参接收函数的多个返回值\ndef myfunc(): return 1,2,3 #自动打包为一个元组返回 res = myfunc() print(res) #(1, 2, 3) x, y, z = myfunc() #自动解包 print(x, y, z) #1 2 3 x, y = myfunc() #解包失败，解包对应的元素个数必须要和元组中元素个数对应 Traceback (most recent call last): File \u0026#34;\u0026lt;stdin\u0026gt;\u0026#34;, line 1, in \u0026lt;module\u0026gt; ValueError: too many values to unpack (expected 2) def myfunc(): return [1,2,3] x, y, z = myfunc() #列表也可以解包 print(x, y, z) #1 2 3 变量作用域 python找一个变量的过程为LEGB, Local -\u0026gt; Enclosed(嵌套函数的外层作用域) -\u0026gt; Global -\u0026gt; Build-In\ntotal = 0 def myfunc(num1, num2): #函数中访问的都是局部的变量 total = num1+num2 myfunc(1,2) print(total) #0 total = 0 def myfunc(num1, num2): #使用global申明变量为全局变量 global total total = num1+num2 myfunc(1,2) print(total) #3 def myfunc1(): a = 1 b = 2 def myfunc2(): b = 20 #内层函数如果找不到变量，会一直往上找 print(f\u0026#34;total={total} a={a} b={b}\u0026#34;) return myfunc2 func2 = myfunc1() func2() #total=3 a=1 b=20 def myfunc1(): a = 1 def myfunc2(): #内层函数不能修改外层函数的值，除非用nonlocal申明 nonlocal a a = 10 myfunc2() print(a) myfunc1() #10 #nolocal若有多层嵌套也只修改找到的第一个上一层 def myfunc1(): a = 1 def myfunc2(): a = 2 def myfunc3(): nonlocal a a = 10 print(f\u0026#34;in func3 a={a}\u0026#34;) myfunc3() print(f\u0026#34;in func2 a={a}\u0026#34;) myfunc2() print(f\u0026#34;in func1 a={a}\u0026#34;) myfunc1() #in func3 a=10 #in func2 a=10 #in func1 a=1 def myfunc1(): a = 1 def myfunc2(): def myfunc3(): nonlocal a a = 10 print(f\u0026#34;in func3 a={a}\u0026#34;) myfunc3() myfunc2() print(f\u0026#34;in func1 a={a}\u0026#34;) myfunc1() #in func3 a=10 #in func1 a=10 def myfilter(iterable, check_func): ret = [] for item in iterable: if check_func(item): ret.append(item) return ret def odd_func(item): return item % 2 == 0 myfilter([1,2,3,4], odd_func) #[2, 4] myfilter(range(0, 10), odd_func) #[0, 2, 4, 6, 8] 闭包 def exp(n1): def base(n2): return n2 ** n1 return base square = exp(2) square(2) #4 square(3) #9 cube = exp(3) cube(2) #8 cube(3) #27 装饰器 import time def time_recorder(func): def call_func(): start = time.time() func() end = time.time() print(f\u0026#34;共耗费 {end-start} 秒\u0026#34;) return call_func @time_recorder def myfunc(): time.sleep(1) print(\u0026#34;hello, python!\u0026#34;) myfunc() hello, python! 共耗费 1.0047268867492676 秒 等效于 import time def time_recorder(func): def call_func(): start = time.time() func() end = time.time() print(f\u0026#34;共耗费 {end-start} 秒\u0026#34;) return call_func def myfunc(): time.sleep(1) print(\u0026#34;hello, python!\u0026#34;) myfunc = time_recorder(myfunc) myfunc() hello, python! 共耗费 1.0110423564910889 秒 def add(func): print(\u0026#34;add\u0026#34;) def inner(): x = func() return x + 1 return inner def cube(func): print(\u0026#34;cube\u0026#34;) def inner(): x = func() return x ** 3 return inner def square(func): print(\u0026#34;square\u0026#34;) def inner(): x = func() return x ** 2 return inner @add @cube @square def myfunc(): return 2 print(myfunc()) square cube add 65 装饰器的执行是自底向上的 ((2 ** 2) ** 3) + 1 = 65 给装饰器传递参数： import time def logger(msg): def time_recorder(func): def call_func(): start = time.time() func() end = time.time() print(f\u0026#34;{msg} 共耗费 {end-start} 秒\u0026#34;) return call_func return time_recorder @logger(\u0026#34;A\u0026#34;) def myfunc(): time.sleep(1) print(\u0026#34;hello, python!\u0026#34;) myfunc() hello, python! A 共耗费 1.0017378330230713 秒 等效于 import time def logger(msg): def time_recorder(func): def call_func(): start = time.time() func() end = time.time() print(f\u0026#34;{msg} 共耗费 {end-start} 秒\u0026#34;) return call_func return time_recorder def myfunc(): time.sleep(1) print(\u0026#34;hello, python!\u0026#34;) myfunc = logger(\u0026#34;A\u0026#34;)(myfunc) myfunc() 多个参数： import time def logger(msg1, msg2): def time_recorder(func): def call_func(): start = time.time() func() end = time.time() print(f\u0026#34;{msg1} {msg2} 共耗费 {end-start} 秒\u0026#34;) return call_func return time_recorder @logger(\u0026#34;A\u0026#34;, \u0026#34;B\u0026#34;) def myfunc(): time.sleep(1) print(\u0026#34;hello, python!\u0026#34;) myfunc() hello, python! A B 共耗费 1.002345085144043 秒 lambda square = lambda x: x*x square(2) #4 add = lambda x,y: x+y add(1, 2) #3 mapped = map(lambda x:ord(x)+10,\u0026#34;python\u0026#34;) print(list(mapped)) #[122, 131, 126, 114, 121, 120] filtered = filter(lambda x:x%2==0, range(0, 10)) print(list(filtered)) #[0, 2, 4, 6, 8] 生成器 def counter(): num = 1 while num \u0026lt;= 5: yield num num += 1 print(counter()) #\u0026lt;generator object counter at 0x7fb6db7075f0\u0026gt; 生成器是一种迭代器 c = counter() next(c) #1 next(c) #2 next(c) #3 next(c) #4 next(c) #5 next(c) Traceback (most recent call last): File \u0026#34;\u0026lt;stdin\u0026gt;\u0026#34;, line 1, in \u0026lt;module\u0026gt; StopIteration 生成器表达式\nc = (num for num in range(0, 10) if num%2 == 0) print(c) #\u0026lt;generator object \u0026lt;genexpr\u0026gt; at 0x7fb6db707a50\u0026gt; for num in c: print(num) 0 2 4 6 8 递归 def fact(num): if num == 1: return 1 return num * fact(num-1) fact(3) #6 fact(6) #720 def fact(num): sum = 1 for i in range(1, num+1): sum *= i return sum fact(3) #6 fact(6) #720 def fib(n): if n == 1 or n == 2: return 1 return fib(n-1) + fib(n-2) fib(1) #1 fib(2) #1 fib(3) #2 fib(5) #5 def hannota(n, a, b, c): if n == 1: print(f\u0026#34;{a} ===\u0026gt; {c}\u0026#34;) return hannota(n-1, a, c, b) print(f\u0026#34;{a} ===\u0026gt; {c}\u0026#34;) hannota(n-1, b, a, c) hannota(2, \u0026#34;A\u0026#34;, \u0026#34;B\u0026#34;, \u0026#34;C\u0026#34;) A ===\u0026gt; B A ===\u0026gt; C B ===\u0026gt; C hannota(4, \u0026#34;A\u0026#34;, \u0026#34;B\u0026#34;, \u0026#34;C\u0026#34;) A ===\u0026gt; B A ===\u0026gt; C B ===\u0026gt; C A ===\u0026gt; B C ===\u0026gt; A C ===\u0026gt; B A ===\u0026gt; B A ===\u0026gt; C B ===\u0026gt; C B ===\u0026gt; A C ===\u0026gt; A B ===\u0026gt; C A ===\u0026gt; B A ===\u0026gt; C B ===\u0026gt; C 函数文档 def exchange(dollar, rate=6.3): \u0026#34;\u0026#34;\u0026#34; 功能：汇率转换，美元 -\u0026gt; 人民币 - dollar 美元 - rate 汇率 return: - 人民币数量 \u0026#34;\u0026#34;\u0026#34; return dollar * rate help(exchange) Help on function exchange in module __main__: exchange(dollar, rate=6.3) 功能：汇率转换，美元 -\u0026gt; 人民币 - dollar 美元 - rate 汇率 return: - 人民币数量 print(exchange(2)) #12.6 类型注释可以帮助函数调用者知道应该传递参数的类型\ndef exchange(dollar:float, rate:float=6.3) -\u0026gt; float: \u0026#34;\u0026#34;\u0026#34; 功能：汇率转换，美元 -\u0026gt; 人民币 - dollar 美元 - rate 汇率 return: - 人民币数量 \u0026#34;\u0026#34;\u0026#34; return dollar * rate def myfunc(l:list) -\u0026gt; list: pass def myfunc(l:list[int]) -\u0026gt; list[int]: pass def myfunc(d:dict) -\u0026gt; dict: pass def myfunc(d:dict[str,int]) -\u0026gt; dict[str,int]: pass 通过内省查看函数信息\ndef myfunc(d:dict[str,int]) -\u0026gt; dict[str,int]: \u0026#34;\u0026#34;\u0026#34; 测试类型注释 \u0026#34;\u0026#34;\u0026#34; pass myfunc.__name__ #\u0026#39;myfunc\u0026#39; myfunc.__annotations__ #{\u0026#39;d\u0026#39;: dict[str, int], \u0026#39;return\u0026#39;: dict[str, int]} myfunc.__doc__ #\u0026#39;\\n 测试类型注释\\n \u0026#39; 高阶函数 当函数接收一个函数作为参数时，那么该函数就被称为高阶函数\nimport functools #functools库包含的都是高阶函数 functools.reduce(lambda x,y: x+y, range(0, 6)) #15 内置函数 #help(func_ref) 查看函数文档 help(print) str1=\u0026#34;abc\u0026#34; help(str1.split) #str() #list() #tuple() #map() #all() #any() #zip() #enumerate() #max #min() #filter() #pow() #ord() #iter() #next() #type() 类和对象 class Circle: PI = 3.14 #类变量 def __init__(self, r): #构造函数 self.radius = r #实例变量 def area(self): #类中定义的方法必须要接受一个self参数，该参数就是类的实例 ret = Circle.PI * self.radius ** 2 print(ret) c1 = Circle(1) c1.area() #3.14 c1.__dict__ #{\u0026#39;radius\u0026#39;: 1} c1.PI #1 这里能访问的原因是类定义了PI类属性，如果实例的属性列表中找不到会去类的属性列表中找 c2 = Circle(2) c2.radius #2 c1.PI = 3 #这种方式并不能修改到类属性PI，而只是给实例对象加上了PI属性 c1.__dict__ #{\u0026#39;radius\u0026#39;: 1, \u0026#39;PI\u0026#39;: 3} __dict__中保存了实例的属性列表 c2.area() #12.56 Circle.PI = 3 c2.area() #12 class A: x = 1 def hello(self): print(f\u0026#34;A x={self.x}\u0026#34;) class B(A): x = 2 def hello(self): print(f\u0026#34;B x={self.x}\u0026#34;) b1 = B() b1.hello() #B x=2 钻石继承\nclass A: def __init__(self): print(\u0026#34;A init\u0026#34;) class B1(A): def __init__(self): A.__init__(self) print(\u0026#34;B1 init\u0026#34;) class B2(A): def __init__(self): A.__init__(self) print(\u0026#34;B2 init\u0026#34;) class C(B1, B2): def __init__(self): B1.__init__(self) B2.__init__(self) print(\u0026#34;C init\u0026#34;) c1 = C() #A被初始化了两次,这种现象被称为钻石继承 A init B1 init A init B2 init C init class A: def __init__(self): print(\u0026#34;A init\u0026#34;) class B1(A): def __init__(self): super().__init__() #执行的是B2 print(\u0026#34;B1 init\u0026#34;) class B2(A): def __init__(self): super().__init__() #执行的是A print(\u0026#34;B2 init\u0026#34;) class C(B1, B2): def __init__(self): super().__init__() #执行的是B1 print(\u0026#34;C init\u0026#34;) c1 = C() A init B2 init B1 init C init C.mro() [\u0026lt;class \u0026#39;__main__.C\u0026#39;\u0026gt;, \u0026lt;class \u0026#39;__main__.B1\u0026#39;\u0026gt;, \u0026lt;class \u0026#39;__main__.B2\u0026#39;\u0026gt;, \u0026lt;class \u0026#39;__main__.A\u0026#39;\u0026gt;, \u0026lt;class \u0026#39;object\u0026#39;\u0026gt;] 类mro https://zhuanlan.zhihu.com/p/356720970\nclass A: def __init__(self): print(\u0026#34;A init\u0026#34;) class B1(A): def __init__(self): c = super() c.__init__() #执行的是B2 print(\u0026#34;B1 init\u0026#34;, c) class B2(A): def __init__(self): c = super() c.__init__() #执行的是A print(\u0026#34;B2 init\u0026#34;, c) class C(B1, B2): def __init__(self): c = super() c.__init__() #执行的是B1 print(\u0026#34;C init\u0026#34;, c) c1 = C() A init B2 init \u0026lt;super: \u0026lt;class \u0026#39;B2\u0026#39;\u0026gt;, \u0026lt;C object\u0026gt;\u0026gt; B1 init \u0026lt;super: \u0026lt;class \u0026#39;B1\u0026#39;\u0026gt;, \u0026lt;C object\u0026gt;\u0026gt; C init \u0026lt;super: \u0026lt;class \u0026#39;C\u0026#39;\u0026gt;, \u0026lt;C object\u0026gt;\u0026gt; 在多层继承中，父类的self实例也是子类的对象 多态 class Shape: def __init__(self, name): self.name = name def area(self): pass class Square(Shape): def __init__(self, l): super().__init__(\u0026#34;正方形\u0026#34;) #父类的属性也会存储在当前对象中 self.length = l def area(self): print(f\u0026#34;{self.name} 的面积是 {self.length ** 2}\u0026#34;) class Circle(Shape): def __init__(self, r): super().__init__(\u0026#34;圆形\u0026#34;) self.radius = r def area(self): print(f\u0026#34;{self.name} 的面积是 {3.14 * self.radius ** 2}\u0026#34;) s1 = Square(2) s1.area() #正方形 的面积是 4 c1 = Circle(1) c1.area() #圆形 的面积是 3.14 \u0026ldquo;私有变量\u0026rdquo; class A: def __init__(self, x): self.__x = x self._y = x self.___z = x self.a_ = x self.b__ = x self.c___ = x def set_x(self, x): self.__x = x def get_x(self): print(self.__x) a1 = A(2) a1.get_x() #2 #在类中定义的以 __ 开头的变量会被进行名称改写,但是以 _ 结尾的变量不会被改写 a1.__dict__ #{\u0026#39;_A__x\u0026#39;: 2, \u0026#39;_y\u0026#39;: 2, \u0026#39;_A___z\u0026#39;: 2, \u0026#39;a_\u0026#39;: 2, \u0026#39;b__\u0026#39;: 2, \u0026#39;c___\u0026#39;: 2} a1.__abc = \u0026#34;abc\u0026#34; #通过类实例添加的属性并不会进行名称重新 a1.__dict__ #{\u0026#39;_A__x\u0026#39;: 2, \u0026#39;_y\u0026#39;: 2, \u0026#39;_A___z\u0026#39;: 2, \u0026#39;a_\u0026#39;: 2, \u0026#39;b__\u0026#39;: 2, \u0026#39;c___\u0026#39;: 2, \u0026#39;__abc\u0026#39;: \u0026#39;abc\u0026#39;} 动态添加属性 class A: pass a1 = A() a1.x = 1 a1.y = 2 a1.__dict__[\u0026#34;z\u0026#34;] = \u0026#34;abc\u0026#34; a1.__dict__ #{\u0026#39;x\u0026#39;: 1, \u0026#39;y\u0026#39;: 2, \u0026#39;z\u0026#39;: \u0026#39;abc\u0026#39;} 限制添加属性 class A: __slots__ = [\u0026#34;x\u0026#34;, \u0026#34;y\u0026#34;] def __init__(self, x): self.x = x def set_z(self, z): self.z = z a1 = A(2) a1.__dict__ #当类定义类 slots 之后，类对象便不会再有 __dict__ 属性 Traceback (most recent call last): File \u0026#34;\u0026lt;stdin\u0026gt;\u0026#34;, line 1, in \u0026lt;module\u0026gt; AttributeError: \u0026#39;A\u0026#39; object has no attribute \u0026#39;__dict__\u0026#39; a1.y = \u0026#34;abc\u0026#34; a1.z = True Traceback (most recent call last): File \u0026#34;\u0026lt;stdin\u0026gt;\u0026#34;, line 1, in \u0026lt;module\u0026gt; AttributeError: \u0026#39;A\u0026#39; object has no attribute \u0026#39;z\u0026#39; a1.set_z(1) #在类中的方法设置不在 __slots__ 中的属性也是不被允许的 Traceback (most recent call last): File \u0026#34;\u0026lt;stdin\u0026gt;\u0026#34;, line 1, in \u0026lt;module\u0026gt; File \u0026#34;\u0026lt;stdin\u0026gt;\u0026#34;, line 6, in set_z AttributeError: \u0026#39;A\u0026#39; object has no attribute \u0026#39;z\u0026#39; 类的魔法方法 实例化生命函数 class CapStr(str): def __new__(cls, string): #实例化时调用的第一个方法 print(\u0026#34;__new__ exec\u0026#34;, string) string = string.upper() return super().__new__(cls, string) def __init__(self, string): #__new__ 之后调用，用来做对象的定制化 print(\u0026#34;__init__ exec\u0026#34;, string) def __del__(self): #对象销毁时调用 print(\u0026#34;__del__ exec\u0026#34;) cs = CapStr(\u0026#34;python\u0026#34;) __new__ exec python __init__ exec python cs \u0026#39;PYTHON\u0026#39; 运算符魔法方法 class A(str): def __add__(self, other): # + 号对应的魔法方法 print(\u0026#34;__add__ exec\u0026#34;, self, other) return len(self) + len(other) a1 = A(\u0026#34;hello\u0026#34;) a2 = A(\u0026#34;python\u0026#34;) ret = a1 + a2 #调用的是a1的 __add__ 方法 __add__ exec hello python print(ret) 11 class B(str): def __add__(self, other): print(\u0026#34;B __add__ exec\u0026#34;, self, other) return NotImplemented class C(str): def __radd__(self, other): #如果在进行加法运算时，左侧对象的__add__方法未定义或者返回NotImplemented那么会调用右侧对象的__radd__方法代偿 print(\u0026#34;C __radd__ exec\u0026#34;, self, other) return len(self) + len(other) b1 = B(\u0026#34;hello\u0026#34;) c1 = C(\u0026#34;python\u0026#34;) ret = b1 + c1 B __add__ exec hello python C __radd__ exec python hello print(ret) 11 class D(str): def __iadd__(self, other): #对应 += 算数运算符，会使用返回值对运算符左侧对象进行重新赋值 print(\u0026#34;__iadd__ exec\u0026#34;) return len(self) + len(other) d1 = D(\u0026#34;hello\u0026#34;) d2 = D(\u0026#34;python\u0026#34;) d1 += d2 __iadd__ exec print(d1) 11 type(d1) \u0026lt;class \u0026#39;int\u0026#39;\u0026gt; class MyStr(str): def __lt__(self, other): print(f\u0026#34;__lt__ exec\u0026#34;, self, other) return len(self) \u0026lt; len(other) def __le__(self, other): print(f\u0026#34;__le__ exec\u0026#34;, self, other) return len(self) \u0026lt;= len(other) def __gt__(self, other): print(f\u0026#34;__gt__ exec\u0026#34;, self, other) return len(self) \u0026gt; len(other) def __ge__(self, other): print(f\u0026#34;__ge__ exec\u0026#34;, self, other) return len(self) \u0026gt;= len(other) def __eq__(self, other): print(f\u0026#34;__eq__ exec\u0026#34;, self, other) return len(self) == len(other) __ne__ = None #禁用 != 比较运算符，赋值为None避免调用父类的方法 str1 = MyStr(\u0026#34;abc\u0026#34;) str2 = MyStr(\u0026#34;bc\u0026#34;) str1 \u0026lt; str2 __lt__ exec abc bc False str1 \u0026lt;= str2 __le__ exec abc bc False str1 \u0026gt; str2 __gt__ exec abc bc True str1 \u0026gt;= str2 __ge__ exec abc bc True str3 = MyStr(\u0026#34;de\u0026#34;) str2 == str3 __eq__ exec bc de True str2 != str3 Traceback (most recent call last): File \u0026#34;\u0026lt;stdin\u0026gt;\u0026#34;, line 1, in \u0026lt;module\u0026gt; TypeError: \u0026#39;NoneType\u0026#39; object is not callable 类型转换魔法方法 class A(str): def __int__(self): #对应 int() 函数 print(\u0026#34;__int__ exec\u0026#34;, self) return len(self) a1 = A(\u0026#34;python\u0026#34;) ret = int(a1) __int__ exec python print(ret) 6 class Circle: PI = 3.14 def __init__(self, r): self.radius = r def __str__(self): #对应 str() 函数 return f\u0026#34;Circle[radius={self.radius}]\u0026#34; c1 = Circle(2) ret = str(c1) print(ret) \u0026#39;Circle[radius=2]\u0026#39; class A: def __init__(self, data): self.data = data def __bool__(self): print(f\u0026#34;__bool__ exec\u0026#34;, self) return len(self.data) != 0 a1 = A([1,2,3]) bool(a1) #使用bool()函数进行类型转换会调用对象的 __bool__ 方法 __bool__ exec \u0026lt;__main__.A object at 0x7f22dc89fac0\u0026gt; True class A: def __init__(self, data): self.data = data def __len__(self): print(f\u0026#34;__len__ exec\u0026#34;, self) return len(self.data) a1 = A([1,2,3]) bool(a1) #如果对象不存在 __bool__ 方法会调用 __len__ 方法判断返回值是否不等于0进行代偿 __len__ exec \u0026lt;__main__.A object at 0x7f22d4f6e250\u0026gt; True 属性访问魔法方法 class A: def __init__(self, name, age): self.name = name self.age = age a1 = A(\u0026#34;tom\u0026#34;, 20) hasattr(a1, \u0026#34;name\u0026#34;) #True getattr(a1, \u0026#34;name\u0026#34;) #\u0026#39;tom\u0026#39; setattr(a1, \u0026#34;age\u0026#34;, 18) a1.age #18 delattr(a1, \u0026#34;age\u0026#34;) a1.__dict__ #{\u0026#39;name\u0026#39;: \u0026#39;tom\u0026#39;} class A: def __init__(self, name, age): self.name = name self.age = age def __getattribute__(self, attr_name): #对应 getattr() 函数 print(\u0026#34;__getattribute__ exec\u0026#34;, self, attr_name) return super().__getattribute__(attr_name) def __getattr__(self, attr_name): #对于不存在的属性名，使用getattr()访问，会先调用到__getattribute__函数再调用__getattr__ print(\u0026#34;__getattr__ exec\u0026#34;, self, attr_name) raise AttributeError(attr_name) def __setattr__(self, attr_name, attr_value): #对应 setattr() 函数 print(\u0026#34;__setattr__ exec\u0026#34;, self, attr_name, attr_value) self.__dict__[attr_name] = attr_value #不能使用self.attr_name = attr_value进行赋值，不然又会调用带该函数进入死循环 def __delattr__(self, attr_name): #对应 delattr() 函数 print(\u0026#34;__delattr__ exec\u0026#34;, self, attr_name) if attr_name in self.__dict__: del self.__dict__[attr_name] #不能使用 del self.attr_name 删除不然又会调用该函数进入死循环 a1 = A(\u0026#34;tom\u0026#34;, 20) getattr(a1, \u0026#34;name\u0026#34;) __getattribute__ exec \u0026lt;__main__.A object at 0x7f22dc8e7ee0\u0026gt; name \u0026#39;tom\u0026#39; getattr(a1, \u0026#34;gender\u0026#34;) __getattribute__ exec \u0026lt;__main__.A object at 0x7f22d4f50bb0\u0026gt; gender __getattr__ exec \u0026lt;__main__.A object at 0x7f22d4f50bb0\u0026gt; gender Traceback (most recent call last): File \u0026#34;\u0026lt;stdin\u0026gt;\u0026#34;, line 1, in \u0026lt;module\u0026gt; File \u0026#34;\u0026lt;stdin\u0026gt;\u0026#34;, line 10, in __getattr__ AttributeError: gender setattr(a1, \u0026#34;gender\u0026#34;, \u0026#34;M\u0026#34;) __setattr__ exec \u0026lt;__main__.A object at 0x7f22d4f67fa0\u0026gt; gender M __getattribute__ exec \u0026lt;__main__.A object at 0x7f22d4f67fa0\u0026gt; __dict__ a1.addr = \u0026#34;sc chengdu\u0026#34; #直接使用 对象.属性 赋值也会调用 __setattr__ __setattr__ exec \u0026lt;__main__.A object at 0x7f22dc8e3fd0\u0026gt; addr sc chengdu __getattribute__ exec \u0026lt;__main__.A object at 0x7f22dc8e3fd0\u0026gt; __dict__ delattr(a1, \u0026#34;gender\u0026#34;) __delattr__ exec \u0026lt;__main__.A object at 0x7f22d4f67fa0\u0026gt; gender __getattribute__ exec \u0026lt;__main__.A object at 0x7f22d4f67fa0\u0026gt; __dict__ delattr(a1, \u0026#34;addr\u0026#34;) __delattr__ exec \u0026lt;__main__.A object at 0x7f22dc8e3fd0\u0026gt; addr __getattribute__ exec \u0026lt;__main__.A object at 0x7f22dc8e3fd0\u0026gt; __dict__ 对象索引魔法方法 class A: def __index__(self): print(f\u0026#34;__index__ exec\u0026#34;, self) return 1 l1 = [1,2,3] a1 = A() l1[a1] #把对象作为索引值从列表中取值会调用对象的 __index__ 方法 __index__ exec \u0026lt;__main__.A object at 0x7f22dc8e3e80\u0026gt; 2 class A: def __init__(self, data): self.data = data def __getitem__(self, idx): print(f\u0026#34;__getitem__ exec\u0026#34;, self, idx) return self.data[idx] def __setitem__(self, idx, val): print(f\u0026#34;__setitem__ exec\u0026#34;, self, idx, val) self.data[idx] = val a1 = A([1,2,3]) a1[0] #把对象当做一个列表访问 __getitem__ exec \u0026lt;__main__.A object at 0x7f22dc8aa8b0\u0026gt; 0 1 a1[:2] #如果是范围的话传入__getitem__的idx是slice(None, 2, None) __getitem__ exec \u0026lt;__main__.A object at 0x7f22dc8aa8b0\u0026gt; slice(None, 2, None) [1, 2] a1[0] = 10 __setitem__ exec \u0026lt;__main__.A object at 0x7f22dc8aa8b0\u0026gt; 0 10 a1[0] __getitem__ exec \u0026lt;__main__.A object at 0x7f22dc8aa8b0\u0026gt; 0 10 对象执行魔法方法 class A: def __call__(self, name, *args, **kwargs): print(f\u0026#34;name =\u0026gt; {name}\\n*args =\u0026gt; {args}\\n**kwargs =\u0026gt; {kwargs}\u0026#34;) a1 = A() a1(\u0026#34;tom\u0026#34;, 20, \u0026#34;M\u0026#34;, privince=\u0026#34;sc\u0026#34;, city=\u0026#34;cd\u0026#34;) name =\u0026gt; tom *args =\u0026gt; (20, \u0026#39;M\u0026#39;) **kwargs =\u0026gt; {\u0026#39;privince\u0026#39;: \u0026#39;sc\u0026#39;, \u0026#39;city\u0026#39;: \u0026#39;cd\u0026#39;} 对象字符串魔法方法 str(\u0026#34;abc\u0026#34;) \u0026#39;abc\u0026#39; repr(\u0026#34;abc\u0026#34;) \u0026#34;\u0026#39;abc\u0026#39;\u0026#34; #eval()把参数去引号执行 eval(str(\u0026#34;abc\u0026#34;)) Traceback (most recent call last): File \u0026#34;\u0026lt;stdin\u0026gt;\u0026#34;, line 1, in \u0026lt;module\u0026gt; File \u0026#34;\u0026lt;string\u0026gt;\u0026#34;, line 1, in \u0026lt;module\u0026gt; NameError: name \u0026#39;abc\u0026#39; is not defined eval(repr(\u0026#34;abc\u0026#34;)) \u0026#39;abc\u0026#39; eval(repr(123)) #eval 和 repr 互为反函数 123 class A: def __init__(self, data): self.data = data def __str__(self): print(f\u0026#34;__str__ exec\u0026#34;) return f\u0026#34;data = {self.data}\u0026#34; def __repr__(self): print(f\u0026#34;__repr__ exec\u0026#34;) return f\u0026#34;A(data:{self.data})\u0026#34; a1 = A(1) str(a1) __str__ exec \u0026#39;data = 1\u0026#39; repr(a1) __repr__ exec \u0026#39;A(data:1)\u0026#39; class B: def __init__(self, data): self.data = data def __repr__(self): print(f\u0026#34;__repr__ exec\u0026#34;) return f\u0026#34;B(data:{self.data})\u0026#34; b1 = B(1) str(b1) #如果对象 __str__ 方法未定义会调用 __repr__ 代偿 __repr__ exec \u0026#39;B(data:1)\u0026#39; 对象代偿 class A: def __init__(self, data): self.data = data def __contains__(self, val): print(f\u0026#34;__contains__ exec\u0026#34;, self, val) return val in self.data def __getitem__(self, idx): print(f\u0026#34;__getitem__\u0026#34;, self, idx) return self.data[idx] def __iter__(self): print(f\u0026#34;__iter__ exec\u0026#34;, self) self.idx = 0 return self def __next__(self): print(f\u0026#34;__next__ exec\u0026#34;, self) if self.idx == len(self.data): raise StopIteration item = self.data[self.idx] self.idx += 1 return item a1 = A([1,2,3]) 2 in a1 #如果对象有 __contains__ 方法直接调用判断 __contains__ exec \u0026lt;__main__.A object at 0x7f22d4f67b50\u0026gt; 2 True class B: def __init__(self, data): self.data = data def __getitem__(self, idx): print(f\u0026#34;__getitem__\u0026#34;, self, idx) return self.data[idx] def __iter__(self): print(f\u0026#34;__iter__ exec\u0026#34;, self) self.idx = 0 return self def __next__(self): print(f\u0026#34;__next__ exec\u0026#34;, self) if self.idx == len(self.data): raise StopIteration item = self.data[self.idx] self.idx += 1 return item b1 = B([1,2,3]) 2 in b1 #如果没有 __contains__ 方法会调用 __iter__ 方法生成迭代器，然后执行 __next__ 遍历进行对比 __iter__ exec \u0026lt;__main__.B object at 0x7f22dc910400\u0026gt; __next__ exec \u0026lt;__main__.B object at 0x7f22dc910400\u0026gt; __next__ exec \u0026lt;__main__.B object at 0x7f22dc910400\u0026gt; True class C: def __init__(self, data): self.data = data def __getitem__(self, idx): print(f\u0026#34;__getitem__\u0026#34;, self, idx) return self.data[idx] c1 = C([1,2,3]) 2 in c1 #如果 __contains__ 方法和 __iter__ __next__ 方法都不存在，那么会调用 __getitem__ 代偿 __getitem__ \u0026lt;__main__.C object at 0x7f22d4f6e310\u0026gt; 0 __getitem__ \u0026lt;__main__.C object at 0x7f22d4f6e310\u0026gt; 1 True 5 in c1 __getitem__ \u0026lt;__main__.C object at 0x7f22d4f6e310\u0026gt; 0 __getitem__ \u0026lt;__main__.C object at 0x7f22d4f6e310\u0026gt; 1 __getitem__ \u0026lt;__main__.C object at 0x7f22d4f6e310\u0026gt; 2 __getitem__ \u0026lt;__main__.C object at 0x7f22d4f6e310\u0026gt; 3 #这里 __getitem__会抛出IndexError 被上层捕获，idx不再递增 False property函数代理 class A: def __init__(self): self._x = 250 def _getx(self): return self._x def _setx(self, val): self._x = val def _delx(self): del self._x x = property(_getx, _setx, _delx) a1 = A() a1.x #250 a1.x = 520 a1.x #520 del a1.x a1.x Traceback (most recent call last): File \u0026#34;\u0026lt;stdin\u0026gt;\u0026#34;, line 1, in \u0026lt;module\u0026gt; File \u0026#34;\u0026lt;stdin\u0026gt;\u0026#34;, line 5, in _getx AttributeError: \u0026#39;A\u0026#39; object has no attribute \u0026#39;_x\u0026#39; class A: def __init__(self): self._x = 250 @property def x(self): return self._x @x.setter def x(self, val): self._x = val @x.deleter def x(self): del self._x a1 = A() a1.x #250 a1.x = 520 a1.x #520 del a1.x a1.x Traceback (most recent call last): File \u0026#34;\u0026lt;stdin\u0026gt;\u0026#34;, line 1, in \u0026lt;module\u0026gt; File \u0026#34;\u0026lt;stdin\u0026gt;\u0026#34;, line 6, in x AttributeError: \u0026#39;A\u0026#39; object has no attribute \u0026#39;_x\u0026#39; 类方法 类方法 class A: def func1(self): print(\u0026#34;func1\u0026#34;, self) @classmethod def func2(cls): print(\u0026#34;func2\u0026#34;, cls) a1 = A() a1.func1() func1 \u0026lt;__main__.A object at 0x7f6e45d8f7f0\u0026gt; a1.func2() func2 \u0026lt;class \u0026#39;__main__.A\u0026#39;\u0026gt; 统计创建类实例个数 class A: count = 0 def __init__(self): A.count += 1 @classmethod def get_count(cls): print(f\u0026#34;A create {A.count} instance\u0026#34;) a1 = A() a2 = A() a3 = A() #通过类名访问 A.get_count() A create 3 instance #通过实例访问 a1.get_count() A create 3 instance class A: count = 0 @classmethod def add(cls): cls.count += 1 def __init__(self): self.add() @classmethod def print(cls): print(f\u0026#34;{cls} create {cls.count} instance\u0026#34;) class B(A): count = 0 class C(A): count = 0 a1 = A() A.print() \u0026lt;class \u0026#39;__main__.A\u0026#39;\u0026gt; create 1 instance b1, b2 = B(), B() B.print() \u0026lt;class \u0026#39;__main__.B\u0026#39;\u0026gt; create 2 instance c1, c2, c3 = C(), C(), C() C.print() \u0026lt;class \u0026#39;__main__.C\u0026#39;\u0026gt; create 3 instance 静态方法 class A: @staticmethod def func1(): #静态方法不接收参数 print(\u0026#34;static method func1\u0026#34;) a1 = A() A.func1() static method func1 a1.func1() static method func1 文件 #open(file, mode=\u0026#39;r\u0026#39;, buffering=-1, encoding=None, errors=None, newline=None, closefd=True, opener=None)打开文件返回文件对象 mode: \u0026#39;r\u0026#39; 打开已有文件供读取 (默认) \u0026#39;w\u0026#39; 打开已有文件供写入，会覆盖之前的内容 \u0026#39;x\u0026#39; 创建一个新文件并进行写入,文件存在报错 \u0026#39;a\u0026#39; 打开一个已有文件并进行追加写入 \u0026#39;b\u0026#39; 二进制模式 \u0026#39;t\u0026#39; 文本模式 (默认) \u0026#39;+\u0026#39; 打开一个已有文件进行读取写入 echo \u0026#34;test file\u0026#34; \u0026gt; test.txt f.readable()函数返回文件是否可读 f.writable()函数返回文件是否可写 f.read(size=-1)读取文件的指定个字符个数 f.readlines(size=1)读取文件指定行 f.seel(offset,whence=0)修改文件指针到指定位置，whence=0表示从文件起始位置 whence=1代表当前位置 whence=2代表文件末尾 f.tell()返回文件指针所在位置 f.write(text)写文件并返回写入的字符数 f.writelines(lines)将一系列字符串写入到文件对象中 f.truncate(pos=None)截取指定位置之前的内容保存，pos为None时默认为文件当前的指针位置 f.flush()将文件对象中的缓存数据写入磁盘 f.close()关闭文件 python3: f = open(\u0026#34;test.txt\u0026#34;, \u0026#34;r\u0026#34;) print(f.readable()) #True print(f.writable()) #False rd = f.read() print(rd) print(\u0026#34;===========\u0026#34;) rd2 = f.read() print(rd2) #\u0026#39;\u0026#39; ret = f.seek(0) print(ret) #0 rd3 = f.read(2) print(rd3) #te f.tell() #2 f.write(\u0026#34;write\u0026#34;) Traceback (most recent call last): File \u0026#34;\u0026lt;stdin\u0026gt;\u0026#34;, line 1, in \u0026lt;module\u0026gt; io.UnsupportedOperation: not writable f = open(\u0026#34;test.txt\u0026#34;, \u0026#34;w\u0026#34;) f.readable() #False f.writable() #True f.read() Traceback (most recent call last): File \u0026#34;\u0026lt;stdin\u0026gt;\u0026#34;, line 1, in \u0026lt;module\u0026gt; io.UnsupportedOperation: not readable f.write(\u0026#34;write\u0026#34;) #5 f = open(\u0026#34;test.txt\u0026#34;, \u0026#34;x\u0026#34;) Traceback (most recent call last): File \u0026#34;\u0026lt;stdin\u0026gt;\u0026#34;, line 1, in \u0026lt;module\u0026gt; FileExistsError: [Errno 17] File exists: \u0026#39;test.txt\u0026#39; f = open(\u0026#34;test.txt\u0026#34;, \u0026#34;a\u0026#34;) f.readable() #False f.writable() #True f.write(\u0026#34;append\u0026#34;) #6 文件路径\nfrom pathlib import Path p = Path(\u0026#34;.\u0026#34;) q = p / \u0026#34;test.txt\u0026#34; p.is_dir() #True q.is_dir() #False p.is_file() #False q.is_file() #True p.parent() q.parent() with open\nwith open(\u0026#34;test.txt\u0026#34;) as f: pass 等效于 f = open(\u0026#34;test.txt\u0026#34;) pass f.close() #这种方式如果中间pass的语句出错那么不会执行close那么文件写入的内容会丢失 pickle\nimport pickle x = 1 y = \u0026#34;abc\u0026#34; z = [1, True, \u0026#34;ABC\u0026#34;, [1,2,3]] with open(\u0026#34;data.pkl\u0026#34;, \u0026#34;wb\u0026#34;) as f: pickle.dump(x, f) pickle.dump(y, f) pickle.dump(z, f) import pickle with open(\u0026#34;data.pkl\u0026#34;, \u0026#34;rb\u0026#34;) as f: x = pickle.load(f) y = pickle.load(f) z = pickle.load(f) print(x, y, z, sep=\u0026#34;\\n\u0026#34;) 1 abc [1, True, \u0026#39;ABC\u0026#39;, [1, 2, 3]] 模块 python的一个模块是一个python文件，模块能定义函数，类和变量，模块里也能包含可执行的代码\n#使用os.getcwd()获取程序执行路径 mkdir temp cd temp cat \u0026lt;\u0026lt;EOF \u0026gt; main.py import os print(os.getcwd()) EOF python3 main.py /home/aiiqh/python_proj/test/temp cd .. python3 temp/main.py /home/aiiqh/python_proj/test 结论：os.getcwd()获取到的路径只与执行python命令时的路径有关，与py文件路径无关 python中一个文件是一个模块 一个文件夹是一个包，包下应该包含__init__.py文件，会在导入该包时执行 python执行时会把入口文件的父目录加入os.path python中导入包会首先在当前目录下搜索，如果找不到会搜索环境变量PYTHONPATH下的目录、如果找不到会搜索python安装目录下的lib和lib/pythonX.Y/site-packages下的包，所有这些路径都存储在sys.path变量中 如果想让python导报时能导入指定包，可以把路径加入sys.path中 如果导包的过程中使用了.那么久表面是相对路径导入，就会在当前路径下搜索 [root@centos72 p]# tree . ├── m1 │ ├── __init__.py │ ├── m1_file1.py │ ├── __pycache__ │ │ ├── __init__.cpython-39.pyc │ │ └── m1_file1.cpython-39.pyc │ └── sub1 │ ├── __init__.py │ ├── __pycache__ │ │ ├── __init__.cpython-39.pyc │ │ └── sub1_file1.cpython-39.pyc │ └── sub1_file1.py ├── m2 │ ├── __init__.py │ ├── m2_file1.py │ └── __pycache__ │ ├── __init__.cpython-39.pyc │ └── m2_file1.cpython-39.pyc └── main.py cat m1/sub1/sub1_file1.py def sub1func1(): print(\u0026#34;sub1func1 exec\u0026#34;) cat m1/m1_file1.py from .sub1 import sub1_file1 #这里必须加. 这样才是使用相对路径导入，否则就会去sys.path下搜索而导致找不到 def m1func1(): print(\u0026#34;m1func1 exec\u0026#34;) def m1func2(): sub1_file1.sub1func1() print(\u0026#34;m1func2 exec\u0026#34;) cat m2/m2_file1.py from m1 import m1_file1 def m2func1(): print(\u0026#34;m2func1 exec\u0026#34;) def m2func2(): m1_file1.m1func1() print(\u0026#34;m2func2 exec\u0026#34;) def m2func3(): m1_file1.m1func2() print(\u0026#34;m2func3 exec\u0026#34;) cat main.py from m1 import m1_file1 import m2.m2_file1 if __name__ == \u0026#34;__main__\u0026#34;: m1_file1.m1func1() print(\u0026#34;==========\u0026#34;) m1_file1.m1func2() print(\u0026#34;==========\u0026#34;) m2.m2_file1.m2func1() #使用import导入的多级目录的包使用时也必须加上全路径，除非使用as取别名 print(\u0026#34;==========\u0026#34;) m2.m2_file1.m2func2() print(\u0026#34;==========\u0026#34;) m2.m2_file1.m2func3() python3 main.py m1func1 exec ========== sub1func1 exec m1func2 exec ========== m2func1 exec ========== m1func1 exec m2func2 exec ========== sub1func1 exec m1func2 exec m2func3 exec #创建cmd目录把main.py文件移动到该文件下执行 mkdir cmd touch __init__.py mv main.py cmd/ tree ├── cmd │ └── main.py ├── __init__.py ├── m1 │ ├── __init__.py │ ├── m1_file1.py │ ├── __pycache__ │ │ ├── __init__.cpython-39.pyc │ │ └── m1_file1.cpython-39.pyc │ └── sub1 │ ├── __init__.py │ ├── __pycache__ │ │ ├── __init__.cpython-39.pyc │ │ └── sub1_file1.cpython-39.pyc │ └── sub1_file1.py └── m2 ├── __init__.py ├── m2_file1.py └── __pycache__ ├── __init__.cpython-39.pyc └── m2_file1.cpython-39.pyc python3 cmd/main.py Traceback (most recent call last): File \u0026#34;/root/python_t/p/cmd/main.py\u0026#34;, line 1, in \u0026lt;module\u0026gt; from m1 import m1_file1 ModuleNotFoundError: No module named \u0026#39;m1\u0026#39; #会报错这是由于main.py入口文件不在项目根目录下，所以程序执行时是吧cmd目录加入sys.path中，而main.py文件中导包都在cmd目录下查找导致找不到包 #只需把根目录加入到sys.path中即可 cat \u0026lt;\u0026lt;EOF \u0026gt; cmd/main.py import sys, os curr_dir = os.path.dirname(__name__) parent_dir = os.path.dirname(curr_dir) sys.path.insert(0, parent_dir) from m1 import m1_file1 import m2.m2_file1 if __name__ == \u0026#34;__main__\u0026#34;: m1_file1.m1func1() print(\u0026#34;==========\u0026#34;) m1_file1.m1func2() print(\u0026#34;==========\u0026#34;) m2.m2_file1.m2func1() print(\u0026#34;==========\u0026#34;) m2.m2_file1.m2func2() print(\u0026#34;==========\u0026#34;) m2.m2_file1.m2func3() EOF python3 cmd/main.py m1func1 exec ========== sub1func1 exec m1func2 exec ========== m2func1 exec ========== m1func1 exec m2func2 exec ========== sub1func1 exec m1func2 exec m2func3 exec 在导入包的过程中使用相对路径时.表示当前目录 ..表示父目录 ...表示父父目录，依次类推。python在执行过程中项目的根路径不被当成是包，根目录下的各个目录就是顶级包，当使用相对路径导包时不能夸顶级包。\nmkdir m1 m2 cat \u0026lt;\u0026lt;EOF \u0026gt; m1/a.py print(\u0026#34;m1.a start\u0026#34;) var1 = 1 def func1(): print(\u0026#34;func1\u0026#34;) print(\u0026#34;m1.a end\u0026#34;) EOF cat \u0026lt;\u0026lt;EOF \u0026gt; m1/b.py print(\u0026#34;m1.b start\u0026#34;) var2 = 2 def func2(): print(\u0026#34;func2\u0026#34;) print(\u0026#34;m1.b end\u0026#34;) EOF cat \u0026lt;\u0026lt;EOF \u0026gt; m2/c.py print(\u0026#34;m2.c start\u0026#34;) var3 = 3 var4 = 4 def func3(): print(\u0026#34;func3\u0026#34;) print(\u0026#34;m2.c end\u0026#34;) EOF tree ├── m1 │ ├── a.py │ └── b.py └── m2 └── c.py cat \u0026lt;\u0026lt;EOF \u0026gt; module.py import m1 print(\u0026#34;ok\u0026#34;) EOF python3 module.py #ok cat \u0026lt;\u0026lt;EOF \u0026gt; module.py import m1 print(\u0026#34;ok\u0026#34;) m1.a.func1() #_NamespacePath([\u0026#39;/home/aiiqh/python_proj/test/m1\u0026#39;]) EOF python3 module.py cat \u0026lt;\u0026lt;EOF \u0026gt; module.py from m1 import a #导入一个模块会执行该模块的代码，并在import语句出执行 print(\u0026#34;ok\u0026#34;) a.func1() EOF python3 module.py #m1.a start #m1.a end #ok #func1 cat \u0026lt;\u0026lt;EOF \u0026gt; module.py from m1.a import func1 #直接导入函数也会执行模块中的代码 print(\u0026#34;ok\u0026#34;) func1() EOF python3 module.py #m1.a start #m1.a end #ok #func1 cat \u0026lt;\u0026lt;EOF \u0026gt; module.py from m1.a import var1 print(\u0026#34;ok\u0026#34;) print(var1) EOF python3 module.py #m1.a start #m1.a end #ok #1 #导入全部变量 cat \u0026lt;\u0026lt;EOF \u0026gt; module.py from m2.c import * print(\u0026#34;ok\u0026#34;) print(var3) print(var4) EOF python3 module.py #m2.c start #m2.c end #ok #3 #4 import xxx as xxx from xxx import xxx as xxx from xxx import * 控制函数/变量/类导出 在python模块中以_开头的变量、方法、类模块外不可见,但是仅针对import *的情况，直接引入模块的情况仍然能导入\nmkdir m0 cat \u0026lt;\u0026lt;EOF \u0026gt; m0/a.py var1 = 1 _var2 = 2 __var3 = 3 ___var4 = 4 def func1(): print(\u0026#34;func1\u0026#34;) def _func2(): print(\u0026#34;_func2\u0026#34;) class cls1: pass class _clas2: pass EOF cat \u0026lt;\u0026lt;EOF \u0026gt; module.py from m0 import a print(a.var1) print(a._var2) print(a.__var3) print(a.___var4) EOF python3 module.py #1 #2 #3 #4 cat \u0026lt;\u0026lt;EOF \u0026gt; module.py from m0.a import * print(var1) print(_var2) print(__var3) print(___var4) EOF python3 module.py #1 #NameError: name \u0026#39;_var2\u0026#39; is not defined. Did you mean: \u0026#39;var1\u0026#39; 使用__all__控制模块导出\ncat \u0026lt;\u0026lt;EOF \u0026gt; m2/c.py print(\u0026#34;m2.c start\u0026#34;) __all__ = [\u0026#34;var3\u0026#34;] var3 = 3 var4 = 4 def func3(): print(\u0026#34;func3\u0026#34;) print(\u0026#34;m2.c end\u0026#34;) EOF cat \u0026lt;\u0026lt;EOF \u0026gt; module.py from m2.c import * print(\u0026#34;ok\u0026#34;) print(var3) print(var4) EOF python3 module.py #m2.c start #m2.c end #ok #3 #NameError: name \u0026#39;var4\u0026#39; is not defined. Did you mean: \u0026#39;var3\u0026#39; #尽管m2.c模块中设置了 __all__ 参数指定 import * 不导入 var4 但是还是可以直接import cat \u0026lt;\u0026lt;EOF \u0026gt; module.py from m2.c import var4 print(\u0026#34;ok\u0026#34;) print(var4) EOF python3 module.py #m2.c start #m2.c end #ok #4 命令行参数 sys.args\ncat \u0026lt;\u0026lt;EOF \u0026gt; test.py import sys print(sys.argv) EOF python3 test.py a=1 b=2 [\u0026#39;test.py\u0026#39;, \u0026#39;a=1\u0026#39;, \u0026#39;b=2\u0026#39;] #getopt.getopt(args, options[, long_options]) #args是命令行参数列表 #options是参数名称，如果带:号，那么:号前的参数一定要指定 #long_options是完整参数，带=号的前面参数必须指定 cat \u0026lt;\u0026lt;EOF \u0026gt; test.py import sys import getopt opts, args = getopt.getopt(sys.argv[1:], \u0026#34;a:b:c\u0026#34;, [\u0026#34;argA=\u0026#34;, \u0026#34;argB=\u0026#34;, \u0026#34;--argC\u0026#34;]) print(opts, args) EOF python3 test.py -a 1 -b 2 [(\u0026#39;-a\u0026#39;, \u0026#39;1\u0026#39;), (\u0026#39;-b\u0026#39;, \u0026#39;2\u0026#39;)] [] python3 test.py --argA 1 --argB 2 [(\u0026#39;--argA\u0026#39;, \u0026#39;1\u0026#39;), (\u0026#39;--argB\u0026#39;, \u0026#39;2\u0026#39;)] [] python3 test.py --argA=1 --argB=2 [(\u0026#39;--argA\u0026#39;, \u0026#39;1\u0026#39;), (\u0026#39;--argB\u0026#39;, \u0026#39;2\u0026#39;)] [] python3 test.py -a 0 --argA=1 --argB=2 [(\u0026#39;-a\u0026#39;, \u0026#39;0\u0026#39;), (\u0026#39;--argA\u0026#39;, \u0026#39;1\u0026#39;), (\u0026#39;--argB\u0026#39;, \u0026#39;2\u0026#39;)] [] cat \u0026lt;\u0026lt;EOF \u0026gt; test.py import argparse parser = argparse.ArgumentParser(description=\u0026#34;test parse\u0026#34;) parser.add_argument(\u0026#34;arg1\u0026#34;, help=\u0026#34;arg1 parameter\u0026#34;) parser.add_argument(\u0026#34;-arg2\u0026#34;, dest=\u0026#34;abc\u0026#34;, help=\u0026#34;arg2 parameter\u0026#34;) parser.add_argument(\u0026#34;--arg3\u0026#34;, help=\u0026#34;arg3 parameter\u0026#34;) parser.add_argument(\u0026#34;arg4\u0026#34;, help=\u0026#34;arg4 parameter\u0026#34;) args = parser.parse_args() print(args) print(args.arg1) print(args.abc) EOF python3 argparse_test.py 1 4 -arg2=2 虚拟环境 python的虚拟环境用于隔离各个项目，这样每个项目只需要安装锁需要使用到的库，避免打包出来的二进制程序过大\nubuntu系统需要安装\nsudo apt install python3-venv 创建虚拟环境\npython3 -m venv dirname cd dirname ls -la total 24 drwxrwxr-x 5 aiiqh aiiqh 4096 Nov 4 08:55 . drwxrwxr-x 6 aiiqh aiiqh 4096 Nov 4 08:55 .. drwxrwxr-x 2 aiiqh aiiqh 4096 Nov 4 08:55 bin #保存二进制程序和激活、去激活的脚本 drwxrwxr-x 2 aiiqh aiiqh 4096 Nov 4 08:55 include drwxrwxr-x 3 aiiqh aiiqh 4096 Nov 4 08:55 lib lrwxrwxrwx 1 aiiqh aiiqh 3 Nov 4 08:55 lib64 -\u0026gt; lib -rw-rw-r-- 1 aiiqh aiiqh 70 Nov 4 08:55 pyvenv.cfg 激活虚拟环境\nsource bin/activate (env2) aiiqh@aiiqh:~/python_proj/env1/env2$ 去激活\n(env2) aiiqh@aiiqh:~/python_proj/env1/env2$ deactivate 使用pip安装的包会放在lib/pythonx.x/site-packages目录下\n","permalink":"https://moyuduo.github.io/posts/python/","summary":"安装 在https://www.python.org/downloads/source/上找到合适的安装包 在linux上curl -O https://www.python.org/ftp/python/3.7.14/Python-3.7.14.tgz 解压tar -zxvf python/3.7.14/Python-3.7.14.tgz 修改解压目录下的Modules/Setup按需自定义 在解压目录下的bin目录下执行./configure 执行make 执行make install 输入py按tab看是否有提示验证是否安装成功 申明 在编写的python脚本文件中，可以在第一行申明#!/usr/bin/python标识默认改脚本的执行程序(路径未pythen可执行文件的具体路径)，如果使用./xxx.py时就会使用该程序执行脚本，如果未申明默认会当做shell脚本进行执行\n#!/usr/bin/python print(\u0026#34;ok\u0026#34;) 中文编码 如果在执行程序时遇到中文乱码问题，可以在脚本文件中申明# -*- coding: UTF-8 -*-或# coding=utf-8\n#!/usr/bin/python # coding=utf-8 print(\u0026#34;你好！\u0026#34;) 变量 #赋值 x, y = 1, 2 #交换 x, y = y, x 条件语句 num = 3 if num \u0026gt; 2: pass else: pass if num \u0026gt; 2: pass elif num \u0026lt; 0: pass else: pass 条件成立时执行的语句 if cond else 条件不成立时执行的语句 num=3 print(\u0026#34;num\u0026gt;5\u0026#34;) if num\u0026gt;5 else print(\u0026#34;num\u0026lt;=5\u0026#34;) 循环 for item in iterable: pass for item in iterable: pass else: pass #range函数可以用于生成一个数字可迭代对象 range(stop) #默认start为0,生成的数组序列不包含stop range(start, stop) range(start, stop, step) num = 3 while num \u0026gt; 0: pass #使用break跳出循环并不会执行else里面的代码 num = 3 while num \u0026gt; 0: pass else: pass 逻辑运算符 and:操作符左右为Ture才是True，相当于\u0026amp;\u0026amp; or:操作符左右任意一边为True就为True，相当于|| not:取反，相当于 !","title":"python"},{"content":"clickhouse 安装 检查限制 ulimit -a #主要关注open files和max user processes core file size (blocks, -c) 0 data seg size (kbytes, -d) unlimited scheduling priority (-e) 0 file size (blocks, -f) unlimited pending signals (-i) 14989 max locked memory (kbytes, -l) 64 max memory size (kbytes, -m) unlimited open files (-n) 1024 pipe size (512 bytes, -p) 8 POSIX message queues (bytes, -q) 819200 real-time priority (-r) 0 stack size (kbytes, -s) 8192 cpu time (seconds, -t) unlimited max user processes (-u) 14989 virtual memory (kbytes, -v) unlimited file locks (-x) unlimited 修改限制 vi /etc/security/limits.conf * soft nofile 65536 * hard nofile 65536 * soft nproc 131072 * hard nproc 131072 vi /etc/security/limits.d/20-nproc.conf 追加 * sort nofile 65536 * hard nofile 65536 * soft nproc 131072 * hard nproc 131072 退出当前所有登录root用户的终端后重新登录，使用ulimit -a查看应该已经生效\n安装依赖 yum install -y libtool yum install -y *unixODBC* 取消selinux vi /etc/selinux/config 修改 SELINUX=disable 修改selinux配置文件之后必须要重启才能生效\ngetenforce可以用于查看当前selinux状态，并且setenforce 0可以临时禁用selinux\n使用docker运行clickhouse docker run -d --ulimit nofile=262144:262144 -p 8123:8123 -p 9000:9000 yandex/clickhouse-server docker run -d -p 8123:8123 -p9000:9000 --name clickhouse-server --ulimit nofile=262144:262144 clickhouse/clickhouse-server sudo docker exec -it $(sudo docker ps | grep \u0026#34;clickhouse-server\u0026#34; | awk \u0026#39;{print $1}\u0026#39;) sh clickhouse-client ClickHouse client version 22.1.3.7 (official build). Connecting to localhost:9000 as user default. Connected to ClickHouse server version 22.1.3 revision 54455. 8f9048b8bfd4 :) 数据类型 整型 Int8: -128 - 127 Int16: -32768 - 32767 Int32: -2147483648 - 214748364 Int64: -9223372036854775808 - 9223372036854775807 UInt8: 0 - 255 UInt16: 0 - 65535 UInt32: 0 - 4294967295 UInt64: 0 - 18446744073709551615 浮点型 Float16: Float32: 浮点进行计算时会有精度丢失问题\n布尔类型 没有单独的类型存储布尔类型，可以使用Uint8来进行存储\nDecimal 有符号浮点数，在进行运算是能保持精度\nDicimal32(n): 整数部分加小数部分一共9位，其中小数部分n位 Decimal64(n)：整数部分加小数部分一共18位，其中小数部分n位 Decimal129(n)：整数部分加小数部分一共38位，其中小数部分n位 如果存放3.1415926 Decimal32(4)只能保存 3.1415 并不会四舍五入 字符串 String: 任意长度字符串，可以存储空字符串 FixedString(N)：固定长度字符串，如果存储的字符串不够N那么使用空格填充，如果大于N报错 clickhouse字符串类型必须使用单引号不能使用双引号 枚举类型 Enum8 Enum16 create table t_enum ( `x` Enum8(\u0026#39;hello\u0026#39; = 1, \u0026#39;world\u0026#39; = 2) ) ENGINE = TinyLog; insert into t_enum values (\u0026#39;hello\u0026#39;),(\u0026#39;world\u0026#39;),(\u0026#39;hello\u0026#39;); insert into t_enum values (\u0026#39;haha\u0026#39;); Exception on client: Code: 36. DB::Exception: Unknown element \u0026#39;haha\u0026#39; for enum: While executing ValuesBlockInputFormat: data for INSERT was parsed from query. (BAD_ARGUMENTS) 时间类型 Date: 精确到天，存储2019-12-16 Datetime: 精确到秒，存储2019-12-16 20:00:00 Datetime64：精确到毫秒，存储2019-12-16 20:00:00.66 数组 Array(T): 由T类型元素组成的数组，T可以是任何类型，包括数组类型 select array(1, 2) as x, toTypeName(x); #select [1, 2] as x, toTypeName(x); SELECT [1, 2] AS x, toTypeName(x) Query id: 21f9ebd2-44d6-4297-9d27-d0f21b5d06ad ┌─x─────┬─toTypeName(array(1, 2))─┐ │ [1,2] │ Array(UInt8) │ └───────┴─────────────────────────┘ 1 rows in set. Elapsed: 0.003 sec. select array(1, 2, \u0026#39;a\u0026#39;) as x, toTypeName(x); #不能混用，报错 Nullable create table t_null(x Int8, y Nullable(Int8))ENGINE = TinyLog; #Nullable字段不能建立所以 表引擎 TinyLog 以列文件的格式保存在磁盘上，不支持索引，没有并发kongz，一般保存少量数据的小表。\nMemory 数据以未压缩的形式直接存储在内存中，服务器重启数据就会丢失，读写操作不会相互阻塞，不支持索引，简单查询下有非常高的性能表现(超10G/s)\nMergeTree create table t_mgtree ( id UInt32, sku_id String, total_amount Decimal(16, 2), create_time Datetime )engine = MergeTree partition by toYYYYMMDD(create_time) primary key(id) order by(id, sku_id); insert into t_mgtree values(101,\u0026#39;sku_001\u0026#39;,500.00,\u0026#39;2020-01-02 12:00:00\u0026#39;), (102,\u0026#39;sku_001\u0026#39;,9.00,\u0026#39;2020-01-01 20:00:00\u0026#39;), (101,\u0026#39;sku_002\u0026#39;,999.99,\u0026#39;2020-01-03 12:30:00\u0026#39;), (103,\u0026#39;sku_003\u0026#39;,500.00,\u0026#39;2020-01-01 12:00:05\u0026#39;), (102,\u0026#39;sku_002\u0026#39;,899.99,\u0026#39;2020-01-03 19:21:00\u0026#39;), (103,\u0026#39;sku_001\u0026#39;,99.00,\u0026#39;2020-01-02 14:12:00\u0026#39;); select * from t_mgtree; SELECT * FROM t_mgtree Query id: bc02a3d9-687c-4533-b282-1e4d63dd5c7f ┌──id─┬─sku_id──┬─total_amount─┬─────────create_time─┐ │ 101 │ sku_001 │ 1000 │ 2020-01-01 12:00:00 │ └─────┴─────────┴──────────────┴─────────────────────┘ ┌──id─┬─sku_id──┬─total_amount─┬─────────create_time─┐ │ 101 │ sku_001 │ 500 │ 2020-01-02 12:00:00 │ │ 103 │ sku_001 │ 99 │ 2020-01-02 14:12:00 │ └─────┴─────────┴──────────────┴─────────────────────┘ ┌──id─┬─sku_id──┬─total_amount─┬─────────create_time─┐ │ 102 │ sku_001 │ 9 │ 2020-01-01 20:00:00 │ │ 103 │ sku_003 │ 500 │ 2020-01-01 12:00:05 │ └─────┴─────────┴──────────────┴─────────────────────┘ ┌──id─┬─sku_id──┬─total_amount─┬─────────create_time─┐ │ 101 │ sku_002 │ 999.99 │ 2020-01-03 12:30:00 │ │ 102 │ sku_002 │ 899.99 │ 2020-01-03 19:21:00 │ └─────┴─────────┴──────────────┴─────────────────────┘ 7 rows in set. Elapsed: 0.003 sec. MergeTree 的primary key不要求唯一\n插入的数据会根据指定的 partition by 进行分区\norder by 指定分区内的数据排序规则，创建表是必须指定\npartition by 如果不填只会使用一个all分区\n分区后，如果查询涉及多个分区那么会以分区未单位并行查询\nclickhouse的数据存储在/var/lib/clickhouse下，改目录下metadata存储的是库好表的元数据信息，data存储的是具体的数据\npwd /var/lib/clickhouse/metadata ls -l lrwxrwxrwx 1 clickhouse clickhouse 67 Oct 9 06:28 default -\u0026gt; /var/lib/clickhouse/store/209/209bb034-cd2a-4329-a517-f274a1a009e7/ -rw-r----- 1 clickhouse clickhouse 78 Oct 9 06:28 default.sql drwxr-x--- 2 clickhouse clickhouse 4096 Oct 9 06:28 information_schema drwxr-x--- 2 clickhouse clickhouse 4096 Oct 9 06:28 INFORMATION_SCHEMA -rw-r----- 1 clickhouse clickhouse 51 Oct 9 06:28 information_schema.sql -rw-r----- 1 clickhouse clickhouse 51 Oct 9 06:28 INFORMATION_SCHEMA.sql lrwxrwxrwx 1 clickhouse clickhouse 67 Oct 9 06:28 system -\u0026gt; /var/lib/clickhouse/store/fb6/fb6b524c-6d89-424a-9e02-b24f82b6311f/ cd default #两个表的定义文件 -rw-r----- 1 clickhouse clickhouse 120 Oct 9 07:04 t_enum.sql -rw-r----- 1 clickhouse clickhouse 290 Oct 9 07:41 t_mgtree.sql cat t_mgtree.sql ATTACH TABLE _ UUID \u0026#39;432446b3-924c-478f-90d3-3e7c4d64e190\u0026#39; ( `id` UInt32, `sku_id` String, `total_amount` Decimal(16, 2), `create_time` DateTime ) ENGINE = MergeTree PARTITION BY toYYYYMMDD(create_time) PRIMARY KEY id ORDER BY (id, sku_id) SETTINGS index_granularity = 8192 cd /var/lib/clickhouse/data ls -l drwxr-x--- 2 clickhouse clickhouse 4096 Oct 9 07:41 default drwxr-x--- 2 clickhouse clickhouse 4096 Oct 9 07:42 system cd default ls -l total 8 lrwxrwxrwx 1 clickhouse clickhouse 67 Oct 9 07:04 t_enum -\u0026gt; /var/lib/clickhouse/store/b96/b96f976b-f452-4f19-9e73-de3c52e38b96/ lrwxrwxrwx 1 clickhouse clickhouse 67 Oct 9 07:41 t_mgtree -\u0026gt; /var/lib/clickhouse/store/432/432446b3-924c-478f-90d3-3e7c4d64e190/ cd t_mgtree ls -l total 24 drwxr-x--- 2 clickhouse clickhouse 4096 Oct 9 07:42 20200101_1_1_0 drwxr-x--- 2 clickhouse clickhouse 4096 Oct 9 07:46 20200101_3_3_0 drwxr-x--- 2 clickhouse clickhouse 4096 Oct 9 07:46 20200102_2_2_0 drwxr-x--- 2 clickhouse clickhouse 4096 Oct 9 07:46 20200103_4_4_0 drwxr-x--- 2 clickhouse clickhouse 4096 Oct 9 07:41 detached -rw-r----- 1 clickhouse clickhouse 1 Oct 9 07:41 format_version.txt cd 20200101_1_1_0 #第一个 _1 MinBlockNum 代表最小分区编号，每产生一个分区就向上递增一个数字 #第二个 _1 MaxBlockNum 代表最大分区编号，新创建的分区MinBlockNum等于MaxBlockNum #第三个 _0 Level 代表合并层级，合并次数越多改数值越大 ls -l total 36 -rw-r----- 1 clickhouse clickhouse 259 Oct 9 07:42 checksums.txt #校验文件，用于校验各个文件的正确性 -rw-r----- 1 clickhouse clickhouse 118 Oct 9 07:42 columns.txt #列信息 -rw-r----- 1 clickhouse clickhouse 1 Oct 9 07:42 count.txt #数据条数 -rw-r----- 1 clickhouse clickhouse 128 Oct 9 07:42 data.bin #数据文件 -rw-r----- 1 clickhouse clickhouse 144 Oct 9 07:42 data.mrk3 #标记文件 -rw-r----- 1 clickhouse clickhouse 10 Oct 9 07:42 default_compression_codec.txt #默认压缩格式 -rw-r----- 1 clickhouse clickhouse 8 Oct 9 07:42 minmax_create_time.idx #分区键中的最大值和最小值 -rw-r----- 1 clickhouse clickhouse 4 Oct 9 07:42 partition.dat -rw-r----- 1 clickhouse clickhouse 8 Oct 9 07:42 primary.idx #主键索引文件 任何一批数据写入都会产生一个临时分区，不会纳入一个已有的分区，写入后大概10-15分钟后ck会自动执行合并操作(也可 optimize table xxx final / optimize table xxx partition xxx final 只针对指定表的指定分区进行合并)把临时分区的内容合并到已有分区中。\nclickhouse-client ClickHouse client version 22.1.3.7 (official build). Connecting to localhost:9000 as user default. Connected to ClickHouse server version 22.1.3 revision 54455. 8f9048b8bfd4 :) select * from t_mgtree; SELECT * FROM t_mgtree Query id: e3fdf710-f253-4874-91b6-fc71b258cf92 ┌──id─┬─sku_id──┬─total_amount─┬─────────create_time─┐ │ 101 │ sku_002 │ 999.99 │ 2020-01-03 12:30:00 │ │ 102 │ sku_002 │ 899.99 │ 2020-01-03 19:21:00 │ └─────┴─────────┴──────────────┴─────────────────────┘ ┌──id─┬─sku_id──┬─total_amount─┬─────────create_time─┐ │ 102 │ sku_001 │ 9 │ 2020-01-01 20:00:00 │ │ 103 │ sku_003 │ 500 │ 2020-01-01 12:00:05 │ └─────┴─────────┴──────────────┴─────────────────────┘ ┌──id─┬─sku_id──┬─total_amount─┬─────────create_time─┐ │ 101 │ sku_001 │ 500 │ 2020-01-02 12:00:00 │ │ 103 │ sku_001 │ 99 │ 2020-01-02 14:12:00 │ └─────┴─────────┴──────────────┴─────────────────────┘ ┌──id─┬─sku_id──┬─total_amount─┬─────────create_time─┐ │ 101 │ sku_001 │ 1000 │ 2020-01-01 12:00:00 │ └─────┴─────────┴──────────────┴─────────────────────┘ 7 rows in set. Elapsed: 0.009 sec. # 手动进行分区合并 optimize table t_mgtree final; #再次查询，分区已经被合并 select * from t_mgtree; SELECT * FROM t_mgtree Query id: 03d6a0b8-ba00-460d-a893-2e7fc3039cfa ┌──id─┬─sku_id──┬─total_amount─┬─────────create_time─┐ │ 101 │ sku_002 │ 999.99 │ 2020-01-03 12:30:00 │ │ 102 │ sku_002 │ 899.99 │ 2020-01-03 19:21:00 │ └─────┴─────────┴──────────────┴─────────────────────┘ ┌──id─┬─sku_id──┬─total_amount─┬─────────create_time─┐ │ 101 │ sku_001 │ 500 │ 2020-01-02 12:00:00 │ │ 103 │ sku_001 │ 99 │ 2020-01-02 14:12:00 │ └─────┴─────────┴──────────────┴─────────────────────┘ ┌──id─┬─sku_id──┬─total_amount─┬─────────create_time─┐ │ 101 │ sku_001 │ 1000 │ 2020-01-01 12:00:00 │ │ 102 │ sku_001 │ 9 │ 2020-01-01 20:00:00 │ │ 103 │ sku_003 │ 500 │ 2020-01-01 12:00:05 │ └─────┴─────────┴──────────────┴─────────────────────┘ 7 rows in set. Elapsed: 0.002 sec. exit cd /var/lib/clickhouse/data/default/t_mgtree ls -l drwxr-x--- 2 clickhouse clickhouse 4096 Oct 9 07:42 20200101_1_1_0 # 这个原始分区文件后续会被清理 drwxr-x--- 2 clickhouse clickhouse 4096 Oct 9 08:46 20200101_1_3_1 #改文件是 20200101_1_1_0 和 20200101_3_3_0 合并而来，第一个 _1 取的是两个文件对于位置的最小值，第二个 _3 取的是两个文件对于位置的最大值，第三个 _1 取的是对于位置合并次数的最大值+1 drwxr-x--- 2 clickhouse clickhouse 4096 Oct 9 07:46 20200101_3_3_0 drwxr-x--- 2 clickhouse clickhouse 4096 Oct 9 07:46 20200102_2_2_0 drwxr-x--- 2 clickhouse clickhouse 4096 Oct 9 08:46 20200102_2_2_1 drwxr-x--- 2 clickhouse clickhouse 4096 Oct 9 07:46 20200103_4_4_0 drwxr-x--- 2 clickhouse clickhouse 4096 Oct 9 08:46 20200103_4_4_1 drwxr-x--- 2 clickhouse clickhouse 4096 Oct 9 07:41 detached -rw-r----- 1 clickhouse clickhouse 1 Oct 9 07:41 format_version.txt #测试只针对指定表的指定分区进行合并 insert into t_mgtree values(101, \u0026#39;sku_002\u0026#39;, 50, \u0026#39;2020-01-02 18:00:00\u0026#39;), (102, \u0026#39;sku_001\u0026#39;, 222, \u0026#39;2020-01-03 18:00:00\u0026#39;); select * from t_mgtree; SELECT * FROM t_mgtree Query id: ca5b4975-dcf2-47d8-b14c-26511e3b36f4 ┌──id─┬─sku_id──┬─total_amount─┬─────────create_time─┐ │ 102 │ sku_001 │ 222 │ 2020-01-03 18:00:00 │ └─────┴─────────┴──────────────┴─────────────────────┘ ┌──id─┬─sku_id──┬─total_amount─┬─────────create_time─┐ │ 101 │ sku_001 │ 500 │ 2020-01-02 12:00:00 │ │ 103 │ sku_001 │ 99 │ 2020-01-02 14:12:00 │ └─────┴─────────┴──────────────┴─────────────────────┘ ┌──id─┬─sku_id──┬─total_amount─┬─────────create_time─┐ │ 101 │ sku_002 │ 999.99 │ 2020-01-03 12:30:00 │ │ 102 │ sku_002 │ 899.99 │ 2020-01-03 19:21:00 │ └─────┴─────────┴──────────────┴─────────────────────┘ ┌──id─┬─sku_id──┬─total_amount─┬─────────create_time─┐ │ 101 │ sku_002 │ 50 │ 2020-01-02 18:00:00 │ └─────┴─────────┴──────────────┴─────────────────────┘ ┌──id─┬─sku_id──┬─total_amount─┬─────────create_time─┐ │ 101 │ sku_001 │ 1000 │ 2020-01-01 12:00:00 │ │ 102 │ sku_001 │ 9 │ 2020-01-01 20:00:00 │ │ 103 │ sku_003 │ 500 │ 2020-01-01 12:00:05 │ └─────┴─────────┴──────────────┴─────────────────────┘ 9 rows in set. Elapsed: 0.004 sec. #有两个可以合并的分区 exit ls -l total 28 drwxr-x--- 2 clickhouse clickhouse 4096 Oct 9 08:46 20200101_1_3_1 drwxr-x--- 2 clickhouse clickhouse 4096 Oct 9 08:46 20200102_2_2_1 drwxr-x--- 2 clickhouse clickhouse 4096 Oct 9 09:01 20200102_5_5_0 drwxr-x--- 2 clickhouse clickhouse 4096 Oct 9 08:46 20200103_4_4_1 drwxr-x--- 2 clickhouse clickhouse 4096 Oct 9 09:01 20200103_6_6_0 drwxr-x--- 2 clickhouse clickhouse 4096 Oct 9 07:41 detached -rw-r----- 1 clickhouse clickhouse 1 Oct 9 07:41 format_version.txt #只合并 20200103 分区 clickhouse-client optimize table t_mgtree partition \u0026#39;20200103\u0026#39; final; select * from t_mgtree; #只有 20200103 一个分区合并了 SELECT * FROM t_mgtree Query id: fed711df-e69e-45a8-bd09-0db900de0ca0 ┌──id─┬─sku_id──┬─total_amount─┬─────────create_time─┐ │ 101 │ sku_001 │ 500 │ 2020-01-02 12:00:00 │ │ 103 │ sku_001 │ 99 │ 2020-01-02 14:12:00 │ └─────┴─────────┴──────────────┴─────────────────────┘ ┌──id─┬─sku_id──┬─total_amount─┬─────────create_time─┐ │ 101 │ sku_002 │ 50 │ 2020-01-02 18:00:00 │ └─────┴─────────┴──────────────┴─────────────────────┘ ┌──id─┬─sku_id──┬─total_amount─┬─────────create_time─┐ │ 101 │ sku_001 │ 1000 │ 2020-01-01 12:00:00 │ │ 102 │ sku_001 │ 9 │ 2020-01-01 20:00:00 │ │ 103 │ sku_003 │ 500 │ 2020-01-01 12:00:05 │ └─────┴─────────┴──────────────┴─────────────────────┘ ┌──id─┬─sku_id──┬─total_amount─┬─────────create_time─┐ │ 101 │ sku_002 │ 999.99 │ 2020-01-03 12:30:00 │ │ 102 │ sku_001 │ 222 │ 2020-01-03 18:00:00 │ │ 102 │ sku_002 │ 899.99 │ 2020-01-03 19:21:00 │ └─────┴─────────┴──────────────┴─────────────────────┘ 9 rows in set. Elapsed: 0.004 sec. primary key(非必须) primary key不要求唯一 primary key字段会建立稀疏索引，默认稀疏值为8192，不建议改除非存在大量primary key字段重复的记录 primary key的字段必须为order by字段的前缀字段，比如：order by(id, sku_id) 那么primary key必须是 id 或者 (id, sku_id) order by(建表必选) order by在建表时可以指定多个字段，在每个分区内按照指定的order by字段排序，指定多个字段从左到右进行字段排序 当用户不设主键，很多处理会依照order by指定的字段进行处理 二级索引 create table t_mgtree2 ( id UInt32, sku_id String, total_amount Decimal(16, 2), create_time Datetime, index a total_amount type minmax granularity 5 )engine = MergeTree partition by toYYYYMMDD(create_time) primary key(id) order by(id, sku_id); #其中granularity 5是指定二级索引对于一级索引的粒度 数据TTL 列ttl 提供了管理数据表或者列的生命周期管理。会对失效的表或者列在进行数据合并时设置默认值。\n#创建表时定义 create table t_mgtree3 ( id UInt32, sku_id String, total_amount Decimal(16, 2) ttl create_time + interval 30 second, create_time Datetime )engine = MergeTree partition by toYYYYMMDD(create_time) primary key(id) order by(id, sku_id); #修改表时定义 alter table t_mgtree3 modify column total_amount Decimal(16, 2) ttl create_time + interval 30 second #注意插入的时间要以运行ck的机器(物理机/虚拟机/容器)时间为准，而不是windows时间 insert into t_mgtree3 values (106,\u0026#39;sku_001\u0026#39;,1000.00,\u0026#39;2022-10-09 11:56:00\u0026#39;), (107,\u0026#39;sku_002\u0026#39;,2000.00,\u0026#39;2022-10-09 11:56:00\u0026#39;), (110,\u0026#39;sku_003\u0026#39;,600.00,\u0026#39;2022-10-09 11:56:00\u0026#39;); select * from t_mgtree3; SELECT * FROM t_mgtree3 Query id: 5eb51e86-9bfa-46a9-a63a-f71651b48ecf ┌──id─┬─sku_id──┬─total_amount─┬─────────create_time─┐ │ 106 │ sku_001 │ 1000 │ 2022-10-09 19:27:30 │ │ 107 │ sku_002 │ 2000 │ 2022-10-09 19:27:30 │ │ 110 │ sku_003 │ 600 │ 2022-10-09 19:27:30 │ └─────┴─────────┴──────────────┴─────────────────────┘ 3 rows in set. Elapsed: 0.005 sec. #手动执行一次数据合并，观察效果 optimize table t_mgtree3 final; select * from t_mgtree3; SELECT * FROM t_mgtree3 Query id: cbb757b8-0cfc-48b2-9025-bf6a61911a83 Ok. 0 rows in set. Elapsed: 0.001 sec. 行ttl alter table t_mgtree3 modify ttl create_time + interval 10 second; select * from t_mgtree3; #查询数据所有create_time+10s小于当期时间的行记录都被删除了 ReplacingMergeTree ReplacingMergeTree是MergeTree的变种，它存储特性继承MergeTree只是多了一个去重功能，虽然MergeTree可以设置主键，但是主键没有唯一性要求，如果要想处理掉重复的数据，可以借助ReplacingMergeTree。\n去重时机：数据去重只会出现在执行合并的过程过，由于合并是在未知的时间在后台进行，所以无法进行预测。\n去重范围：如果表经过了分区，去重只会在分区内进行，不能跨分区去重。所以ReplacingMergeTree去重的能力是有限的，适用于在后台清除重复的数据节省空间。\n#ReplacingMergeTree()填入列作为版本字段，重复数据只保留版本字段最大的，如果不填，默认按照插入顺序保留最后一条 create table t_rmgtree1 ( id UInt32, sku_id String, total_amount Decimal(16, 2), create_time Datetime )engine = ReplacingMergeTree(create_time) partition by toYYYYMMDD(create_time) primary key(id) order by(id, sku_id); insert into t_rmgtree1 values (101,\u0026#39;sku_001\u0026#39;,1000.00,\u0026#39;2020-06-01 12:00:00\u0026#39;), (101,\u0026#39;sku_001\u0026#39;,1000.00,\u0026#39;2020-06-02 12:00:00\u0026#39;), (102,\u0026#39;sku_002\u0026#39;,2000.00,\u0026#39;2020-06-01 11:00:00\u0026#39;), (102,\u0026#39;sku_002\u0026#39;,2000.00,\u0026#39;2020-06-01 13:00:00\u0026#39;), (102,\u0026#39;sku_002\u0026#39;,12000.00,\u0026#39;2020-06-01 13:00:00\u0026#39;); #可以看到数据已经进行去重了，如果order by指定的字段一致，那么clickhouse就认为数据是一样的 select * from t_rmgtree1; SELECT * FROM t_rmgtree1 Query id: b05144fd-5f4c-46fd-8379-74b2414eba88 ┌──id─┬─sku_id──┬─total_amount─┬─────────create_time─┐ │ 101 │ sku_001 │ 1000 │ 2020-06-02 12:00:00 │ └─────┴─────────┴──────────────┴─────────────────────┘ ┌──id─┬─sku_id──┬─total_amount─┬─────────create_time─┐ │ 101 │ sku_001 │ 1000 │ 2020-06-01 12:00:00 │ │ 102 │ sku_002 │ 12000 │ 2020-06-01 13:00:00 │ └─────┴─────────┴──────────────┴─────────────────────┘ 3 rows in set. Elapsed: 0.003 sec ReplacingMergeTree特点：\n以order by指定的字段作为判断数据是否重复的依据，如果两条记录order by指定的字段相同，那么ck就认为这两条数据重复 去重是针对同一分区内的数据而言的，不能跨分区去重 在分区合并时进行去重，也就意味着某一时刻可能存在多条应该去重的数据 如果ReplacingMergeTree()指定了字段，那么去重时保留该字段最大的记录，如果没指定字段，那么按照插入顺序保留最后插入的数据 SummingMergeTree 对于不关心明细，只关心以聚合方式进行查询的场景，存储开销和聚合查询时的聚合开销都能大，对于这种场景可以使用\u0026quot;预聚合\u0026quot;引擎SummingMergeTree.\n该引擎会把相同的行(order by指定的所有字段的值都相同)\ncreate table t_smgtree1 ( id UInt32, sku_id String, total_amount Decimal(16, 2), create_time Datetime )engine = SummingMergeTree(total_amount) partition by toYYYYMMDD(create_time) primary key(id) order by(id, sku_id); insert into t_smgtree1 values (101,\u0026#39;sku_001\u0026#39;,1000.00,\u0026#39;2020-06-01 12:00:00\u0026#39;), (102,\u0026#39;sku_002\u0026#39;,2000.00,\u0026#39;2020-06-01 11:00:00\u0026#39;), (102,\u0026#39;sku_002\u0026#39;,2000.00,\u0026#39;2020-06-01 13:00:00\u0026#39;), (102,\u0026#39;sku_002\u0026#39;,12000.00,\u0026#39;2020-06-01 13:00:00\u0026#39;), (102,\u0026#39;sku_002\u0026#39;,600.00,\u0026#39;2020-06-02 12:00:00\u0026#39;), (102,\u0026#39;sku_004\u0026#39;,2500.00,\u0026#39;2020-06-01 12:00:00\u0026#39;); #这三条数据应该会进行聚合 (102,\u0026#39;sku_002\u0026#39;,2000.00,\u0026#39;2020-06-01 11:00:00\u0026#39;), (102,\u0026#39;sku_002\u0026#39;,2000.00,\u0026#39;2020-06-01 13:00:00\u0026#39;), (102,\u0026#39;sku_002\u0026#39;,12000.00,\u0026#39;2020-06-01 13:00:00\u0026#39;), #这条数据不会和以上三条数据进行聚合，因为他们不在一个分区 (102,\u0026#39;sku_002\u0026#39;,600.00,\u0026#39;2020-06-02 12:00:00\u0026#39;), #可以看到数据已经被聚合了，而且非聚合字段取的是第一条记录的值 select * from t_smgtree1; SELECT * FROM t_smgtree1 Query id: 6a215617-6e4e-41a7-9ef0-8b0cf3bfdc3d ┌──id─┬─sku_id──┬─total_amount─┬─────────create_time─┐ │ 102 │ sku_002 │ 600 │ 2020-06-02 12:00:00 │ └─────┴─────────┴──────────────┴─────────────────────┘ ┌──id─┬─sku_id──┬─total_amount─┬─────────create_time─┐ │ 101 │ sku_001 │ 1000 │ 2020-06-01 12:00:00 │ │ 102 │ sku_002 │ 16000 │ 2020-06-01 11:00:00 │ │ 102 │ sku_004 │ 2500 │ 2020-06-01 12:00:00 │ └─────┴─────────┴──────────────┴─────────────────────┘ 4 rows in set. Elapsed: 0.003 sec. SummingMergeTree特点：\n以建表时SummingMergeTree()中指定的字段作为聚合字段，如果未指定，那么除了order by指定的字段之外的所有数值列都会进行聚合 以order by列作为一句判断行是不是需要进行聚合(对于多行数据来说，如果order by的列都相同，那么就聚合) 除开聚合的列之外的其他列取第一行的值 只有同一分区的数据才会进行聚合 执行聚合的时机是执行合并式，所以某一时刻不一定该聚合的数据都聚合了 注意：虽然SummingMergeTree引擎有聚合的特点，但是统计某一条件的记录仍要使用sum，因为某一时刻不一定数据都聚合了\nsql操作 insert create table if not exists tab1 ( id UInt64, name String )engine=TinyLog; insert into tab1 values(1, \u0026#39;aaa\u0026#39;), (2, \u0026#39;bbb\u0026#39;), (3, \u0026#39;ccc\u0026#39;); create table if not exists tab2 ( id UInt64, name String )engine=TinyLog; insert into tab2 select id,name from tab1; update clickhouse的更新和删除都会导致放弃原有的分区，把分区内处理完后的数据(更新完或删除后)的数据保存到新的分区并把原来的分区打上逻辑失效的标记(同步执行)，然后在执行合并时删除失效的分区，所以更新和删除的代价都非常大\n#更新之前 select * from t_mgtree; SELECT * FROM t_mgtree Query id: 26ec771a-26fc-45ab-8df0-6a4ebd06608a ┌──id─┬─sku_id──┬─total_amount─┬─────────create_time─┐ │ 101 │ sku_002 │ 999.99 │ 2020-01-03 12:30:00 │ │ 102 │ sku_001 │ 222 │ 2020-01-03 18:00:00 │ │ 102 │ sku_002 │ 899.99 │ 2020-01-03 19:21:00 │ └─────┴─────────┴──────────────┴─────────────────────┘ ┌──id─┬─sku_id──┬─total_amount─┬─────────create_time─┐ │ 101 │ sku_001 │ 500 │ 2020-01-02 12:00:00 │ │ 101 │ sku_002 │ 50 │ 2020-01-02 18:00:00 │ │ 103 │ sku_001 │ 99 │ 2020-01-02 14:12:00 │ └─────┴─────────┴──────────────┴─────────────────────┘ ┌──id─┬─sku_id──┬─total_amount─┬─────────create_time─┐ │ 101 │ sku_001 │ 1000 │ 2020-01-01 12:00:00 │ │ 102 │ sku_001 │ 9 │ 2020-01-01 20:00:00 │ │ 103 │ sku_003 │ 500 │ 2020-01-01 12:00:05 │ └─────┴─────────┴──────────────┴─────────────────────┘ #分区文件 ls -la total 28 drwxr-x--- 6 clickhouse clickhouse 4096 Oct 11 14:02 . drwxr-x--- 3 clickhouse clickhouse 4096 Oct 9 07:41 .. drwxr-x--- 2 clickhouse clickhouse 4096 Oct 11 13:54 20200101_1_3_2 drwxr-x--- 2 clickhouse clickhouse 4096 Oct 11 13:54 20200102_2_5_2 drwxr-x--- 2 clickhouse clickhouse 4096 Oct 11 13:54 20200103_4_6_3 drwxr-x--- 2 clickhouse clickhouse 4096 Oct 9 07:41 detached -rw-r----- 1 clickhouse clickhouse 1 Oct 9 07:41 format_version.txt #更新一条记录 alter table t_mgtree update total_amount=0 where id=103 and sku_id=\u0026#39;sku_003\u0026#39;; #观察现在的分区文件 #所有分区文件不管更新有没有涉及到，都重新复制了一份保存更新后的数据 ls -la total 44 drwxr-x--- 9 clickhouse clickhouse 4096 Oct 11 14:09 . drwxr-x--- 3 clickhouse clickhouse 4096 Oct 9 07:41 .. drwxr-x--- 2 clickhouse clickhouse 4096 Oct 11 13:54 20200101_1_3_2 drwxr-x--- 2 clickhouse clickhouse 4096 Oct 11 14:09 20200101_1_3_2_7 drwxr-x--- 2 clickhouse clickhouse 4096 Oct 11 13:54 20200102_2_5_2 drwxr-x--- 2 clickhouse clickhouse 4096 Oct 11 14:09 20200102_2_5_2_7 drwxr-x--- 2 clickhouse clickhouse 4096 Oct 11 13:54 20200103_4_6_3 drwxr-x--- 2 clickhouse clickhouse 4096 Oct 11 14:09 20200103_4_6_3_7 drwxr-x--- 2 clickhouse clickhouse 4096 Oct 9 07:41 detached -rw-r----- 1 clickhouse clickhouse 1 Oct 9 07:41 format_version.txt -rw-r----- 1 clickhouse clickhouse 129 Oct 11 14:09 mutation_7.txt #多了这个文件 delete #删除数据以前查看分区文件 ls -la total 32 drwxr-x--- 6 clickhouse clickhouse 4096 Oct 11 14:22 . drwxr-x--- 3 clickhouse clickhouse 4096 Oct 9 07:41 .. drwxr-x--- 2 clickhouse clickhouse 4096 Oct 11 14:14 20200101_1_3_3_7 drwxr-x--- 2 clickhouse clickhouse 4096 Oct 11 14:14 20200102_2_5_3_7 drwxr-x--- 2 clickhouse clickhouse 4096 Oct 11 14:14 20200103_4_6_4_7 drwxr-x--- 2 clickhouse clickhouse 4096 Oct 9 07:41 detached -rw-r----- 1 clickhouse clickhouse 1 Oct 9 07:41 format_version.txt -rw-r----- 1 clickhouse clickhouse 129 Oct 11 14:09 mutation_7.txt select * from t_mgtree; SELECT * FROM t_mgtree Query id: 08eb4c31-241a-4197-84d9-526b3d3007bf ┌──id─┬─sku_id──┬─total_amount─┬─────────create_time─┐ │ 101 │ sku_002 │ 999.99 │ 2020-01-03 12:30:00 │ │ 102 │ sku_001 │ 222 │ 2020-01-03 18:00:00 │ │ 102 │ sku_002 │ 899.99 │ 2020-01-03 19:21:00 │ └─────┴─────────┴──────────────┴─────────────────────┘ ┌──id─┬─sku_id──┬─total_amount─┬─────────create_time─┐ │ 101 │ sku_001 │ 500 │ 2020-01-02 12:00:00 │ │ 101 │ sku_002 │ 50 │ 2020-01-02 18:00:00 │ │ 103 │ sku_001 │ 99 │ 2020-01-02 14:12:00 │ └─────┴─────────┴──────────────┴─────────────────────┘ ┌──id─┬─sku_id──┬─total_amount─┬─────────create_time─┐ │ 101 │ sku_001 │ 1000 │ 2020-01-01 12:00:00 │ │ 102 │ sku_001 │ 9 │ 2020-01-01 20:00:00 │ │ 103 │ sku_003 │ 0 │ 2020-01-01 12:00:05 │ └─────┴─────────┴──────────────┴─────────────────────┘ #删除数据 alter table t_mgtree delete where id=103 and sku_id=\u0026#39;sku_003\u0026#39;; #查看分区文件，所有分区都复制了一份不管删除操作有没有涉及到 ls -la total 48 drwxr-x--- 9 clickhouse clickhouse 4096 Oct 11 14:34 . drwxr-x--- 3 clickhouse clickhouse 4096 Oct 9 07:41 .. drwxr-x--- 2 clickhouse clickhouse 4096 Oct 11 14:14 20200101_1_3_3_7 drwxr-x--- 2 clickhouse clickhouse 4096 Oct 11 14:34 20200101_1_3_3_8 #新增的 drwxr-x--- 2 clickhouse clickhouse 4096 Oct 11 14:14 20200102_2_5_3_7 drwxr-x--- 2 clickhouse clickhouse 4096 Oct 11 14:34 20200102_2_5_3_8 #新增的 drwxr-x--- 2 clickhouse clickhouse 4096 Oct 11 14:14 20200103_4_6_4_7 drwxr-x--- 2 clickhouse clickhouse 4096 Oct 11 14:34 20200103_4_6_4_8 #新增的 drwxr-x--- 2 clickhouse clickhouse 4096 Oct 9 07:41 detached -rw-r----- 1 clickhouse clickhouse 1 Oct 9 07:41 format_version.txt -rw-r----- 1 clickhouse clickhouse 129 Oct 11 14:09 mutation_7.txt -rw-r----- 1 clickhouse clickhouse 112 Oct 11 14:34 mutation_8.txt #多了这个文件 #删除素有数据 alter table t_mgtree delete where 1=1; select clickhouse的查询同mysql类似，但是ck提供了许多内置的函数\nalter alter用于修改表的结构，添加/删除/修改列的定义\n#新增列 alter table tableName add column newcolname String after col1; #删除列 alter table tableName drop column col1; #修改列 alter table tableName add column col2 String after col1; 副本引擎 副本的目的主要是保障数据的高可用性，即使一台 ClickHouse 节点宕机，那么也可以从 其他服务器获得相同的数据。\n分片集群 副本虽然能够提高数据的可用性，降低丢失风险，但是每台服务器实际上必须容纳全量 数据，对数据的横向扩容没有解决。 要解决数据水平切分的问题，需要引入分片的概念。通过分片把一份完整的数据进行切 分，不同的分片分布到不同的节点上，再通过 Distributed 表引擎把数据拼接起来一同使用。 Distributed 表引擎本身不存储数据，有点类似于 MyCat 之于 MySql，成为一种中间件， 通过分布式逻辑表来写入、分发、路由来操作多台节点不同分片的分布式数据。\n","permalink":"https://moyuduo.github.io/posts/clickhouse/","summary":"clickhouse 安装 检查限制 ulimit -a #主要关注open files和max user processes core file size (blocks, -c) 0 data seg size (kbytes, -d) unlimited scheduling priority (-e) 0 file size (blocks, -f) unlimited pending signals (-i) 14989 max locked memory (kbytes, -l) 64 max memory size (kbytes, -m) unlimited open files (-n) 1024 pipe size (512 bytes, -p) 8 POSIX message queues (bytes, -q) 819200 real-time priority (-r) 0 stack size (kbytes, -s) 8192 cpu time (seconds, -t) unlimited max user processes (-u) 14989 virtual memory (kbytes, -v) unlimited file locks (-x) unlimited 修改限制 vi /etc/security/limits.","title":"clickhouse"},{"content":"ArrayList、LinkedList和Vector源码分析 ArrayList ArrayList是一个底层使用数组来存储对象，但不是线程安全的集合类\nArrayList的类结构关系 public class ArrayList\u0026lt;E\u0026gt; extends AbstractList\u0026lt;E\u0026gt; implements List\u0026lt;E\u0026gt;, RandomAccess, Cloneable, java.io.Serializable { } ArrayList实现了List接口，List接口中定义了一些对列表通过下标进行添加删除等方法\nArrayList实现了RandomAccess接口，这个接口是一个标记接口，接口中并没有任何的方法，ArrayList底层是用数组来存储对象，当然是能够通过下标随机访问的，实现了RandomAccess接口的类在查询时的速度会很快但是添加删除元素慢，而LinkedList是通过链表的方式实现的，它没有实现RandomAccess接口，在查询时慢但是增加删除的速度快\n所以在使用集合遍历大量数据时，可以先用instanceof来判断集合是不是实现了RandomAccess\npublic void test1() { List\u0026lt;Integer\u0026gt; list=new ArrayList\u0026lt;Integer\u0026gt;(); list.add(1); if(list instanceof RandomAccess) {//RandomAccess实现类，使用下标访问 for(int i=0;i\u0026lt;list.size();i++) { //todo } }else {//不是RandomAccess实现类，使用iterator遍历 Iterator\u0026lt;Integer\u0026gt; iterator = list.iterator(); while(iterator.hasNext()) { //todo } } } ArrayList实现了Cloneable接口,所以可以合法调用clone方法，如果没有实现Cloneable接口，那么会抛出CloneNotSupporteddException，详见\nArrayList实现了Serializable接口，可以将对象序列化，用于传输或持久化，详见\n属性 //序列化Id private static final long serialVersionUID = 8683452581122892189L; //默认初始化大小 private static final int DEFAULT_CAPACITY = 10; //空数组对象，用于有参构造且初始化大小为0时 private static final Object[] EMPTY_ELEMENTDATA = {}; //空数组对象，用于无参构造时，这两个属性主要用来区分创建ArrayList时有没有指定容量 private static final Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = {}; //保存对象的容器，使用transient修饰即在序列化时，不进行序列化，这是因为ArrayList添加了序列化方法private void writeObject(java.io.ObjectOutputStream s)只把保存的数据序列化了，而不是把整个数组序列化，提高效率 transient Object[] elementData; //保存的对象个数 private int size; //最大容量2的31次方减9 private static final int MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8; 构造器 ArrayList提供了三个构造器，一个是指定初始化大小的构造器，一个人无参默认初始化大小构造器，一个是使用集合初始化的构造器\npublic ArrayList(int initialCapacity) { if (initialCapacity \u0026gt; 0) { //数组的大小为指定大小 this.elementData = new Object[initialCapacity]; } else if (initialCapacity == 0) { //大小为0用一个共享的空数组赋值 this.elementData = EMPTY_ELEMENTDATA; } else { throw new IllegalArgumentException(\u0026#34;Illegal Capacity: \u0026#34;+ initialCapacity); } } public ArrayList() { //用共享的空数组赋值，不使用EMPTY_ELEMENTDATA主要是区分是使用的哪个构造器 this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA; } public ArrayList(Collection\u0026lt;? extends E\u0026gt; c) { elementData = c.toArray(); if ((size = elementData.length) != 0) { // c.toArray might (incorrectly) not return Object[] (see 6260652) if (elementData.getClass() != Object[].class) elementData = Arrays.copyOf(elementData, size, Object[].class); } else { // 集合为空，使用空数组 this.elementData = EMPTY_ELEMENTDATA; } } 添加元素 在数组尾添加元素 public boolean add(E e) { ensureCapacityInternal(size + 1); // Increments modCount!! elementData[size++] = e; return true; } private void ensureCapacityInternal(int minCapacity) { ensureExplicitCapacity(calculateCapacity(elementData, minCapacity)); } //计算容量 private static int calculateCapacity(Object[] elementData, int minCapacity) { if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) {//通过无参构造器创建 return Math.max(DEFAULT_CAPACITY, minCapacity); } return minCapacity; } private void ensureExplicitCapacity(int minCapacity) { modCount++; // 如果最小需要的容量\u0026gt;数组大小 if (minCapacity - elementData.length \u0026gt; 0) //进行扩容 grow(minCapacity); } private void grow(int minCapacity) { int oldCapacity = elementData.length; //新容量=老容量+老容量\u0026gt;\u0026gt;1;老容量\u0026gt;\u0026gt;1即老容量无符号右移1位，即除以2，所以最后新容量是老容量的1.5倍 int newCapacity = oldCapacity + (oldCapacity \u0026gt;\u0026gt; 1); if (newCapacity - minCapacity \u0026lt; 0)//新容量比最小容量小那么把最小容量赋值给新容量 newCapacity = minCapacity; if (newCapacity - MAX_ARRAY_SIZE \u0026gt; 0)//如果minCapacity很大，计算得出newCapacity超出最大容量 newCapacity = hugeCapacity(minCapacity); // 复制未扩容之前的数据 elementData = Arrays.copyOf(elementData, newCapacity); } private static int hugeCapacity(int minCapacity) { if (minCapacity \u0026lt; 0) // overflow throw new OutOfMemoryError(); //如果最小容量还超出ArrayList规定的最大值那么数组大小为Integer.MAX_VALUE否则为ArrayList规定的最大值 return (minCapacity \u0026gt; MAX_ARRAY_SIZE) ? Integer.MAX_VALUE : MAX_ARRAY_SIZE; } 在指定位置添加元素 public void add(int index, E element) { //检查添加元素的下标 rangeCheckForAdd(index); //检查容量，进行扩容 ensureCapacityInternal(size + 1); // Increments modCount!! // public static native void arraycopy(src, srcPos,dest, destPos,length); //src：源数组；srcPos：源数组起始下标；dest：目标数组；destPos：目标数组起始下标；length：拷贝长度 System.arraycopy(elementData, index, elementData, index + 1, size - index); elementData[index] = element; size++; } private void rangeCheckForAdd(int index) { //元素的下标必须为0-size if (index \u0026gt; size || index \u0026lt; 0) throw new IndexOutOfBoundsException(outOfBoundsMsg(index)); } 移除元素 按照下标移除元素 public E remove(int index) { //检查下标 rangeCheck(index); modCount++; //按照下标获取元素 E oldValue = elementData(index); //计算需要移动的数据个数 int numMoved = size - index - 1; if (numMoved \u0026gt; 0) System.arraycopy(elementData, index+1, elementData, index, numMoved); //清理数组elementData[size]位置的元素 elementData[--size] = null; // clear to let GC do its work return oldValue; } private void rangeCheck(int index) { //下标必须在0到size-1之间 if (index \u0026gt;= size) throw new IndexOutOfBoundsException(outOfBoundsMsg(index)); } E elementData(int index) { return (E) elementData[index]; } 按值移除元素 public boolean remove(Object o) { if (o == null) {//如果移除的元素为null,依次遍历保存的元素，移除第一个为null的元素 for (int index = 0; index \u0026lt; size; index++) if (elementData[index] == null) { //移除 fastRemove(index); return true; } } else { for (int index = 0; index \u0026lt; size; index++) //使用equals判断是否相等 if (o.equals(elementData[index])) { fastRemove(index); return true; } } return false; } private void fastRemove(int index) { modCount++; //计算移除后需要移动的元素个数 int numMoved = size - index - 1; if (numMoved \u0026gt; 0) System.arraycopy(elementData, index+1, elementData, index, numMoved); //清理数组elementData[size]位置的元素 elementData[--size] = null; // clear to let GC do its work } modCount ArrayList在进行add、set、remove时，都进行了modCount+1操作，这个属性与fast fail有关，当对象创建Iterator对象时会把modCount赋值给expectedModCount，当使用Iterator进行遍历时，如果发现对象的modCount与expectedModCount不相等，会直接抛出ConcurrentModificationException异常\npublic Iterator\u0026lt;E\u0026gt; iterator() { return new Itr(); } private class Itr implements Iterator\u0026lt;E\u0026gt; { int cursor; // index of next element to return int lastRet = -1; // index of last element returned; -1 if no such int expectedModCount = modCount; ... public E next() { checkForComodification(); ... } final void checkForComodification() { if (modCount != expectedModCount)//直接抛出异常 throw new ConcurrentModificationException(); } 出现情况：当Iterator遍历时，如果对象的modCount和expectedModCount不等就会抛出异常，主要有这些情况\n使用iterator遍历时，进行了add、remove等破坏结构的操作 多线程环境下，一个线程在遍历时，另一个线程进行了add、remove等破坏结构的操作 通过源码学习，我发现set方法并没有增加modCount,为什么呢？难道一个线程在使用iterator遍历，另外一个线程改变了一个位置的元素，Iterator不用抛出异常？有知道的请赐教！\nLinkedList LinkedList类结构 public class LinkedList\u0026lt;E\u0026gt; extends AbstractSequentialList\u0026lt;E\u0026gt; implements List\u0026lt;E\u0026gt;, Deque\u0026lt;E\u0026gt;, Cloneable, java.io.Serializable LinkedList继承AbstractSequentialList可以实现通过Iterator的随机访问\nLinkedList实现List接口可以进行添加删除等操作\nLinkedList实现了DeQue,允许在队列的两端进行入队和出队，所以可以把LinkedList当做队列或栈使用\nLinkedList实现了Cloneable，可以通过clone快速克隆对象\nLinkedList实现了Serializable接口，可以将LinkedList序列化，进行流操作\n构造器 public LinkedList() { } //使用集合初始化链表 public LinkedList(Collection\u0026lt;? extends E\u0026gt; c) { this(); addAll(c); } 属性 //链表的大小，transient表明在序列化的时候不进行序列化，但是LinkedList自定义的序列化方法中进行了序列化 transient int size = 0; //链表的头节点 transient Node\u0026lt;E\u0026gt; first; //链表的尾节点 transient Node\u0026lt;E\u0026gt; last; 节点 private static class Node\u0026lt;E\u0026gt; { E item; //前驱 Node\u0026lt;E\u0026gt; next; //后继 Node\u0026lt;E\u0026gt; prev; Node(Node\u0026lt;E\u0026gt; prev, E element, Node\u0026lt;E\u0026gt; next) { this.item = element; this.next = next; this.prev = prev; } } 可以看到LinkedList是一个双向链表\n方法 Deque是一个双端链表，即链表可有当做栈和队列使用\ngetFirst方法,相当于Queue中的element方法,如果队空，就抛出异常\npublic E getFirst() { final Node\u0026lt;E\u0026gt; f = first; if (f == null) throw new NoSuchElementException(); return f.item; } getLast方法\npublic E getLast() { final Node\u0026lt;E\u0026gt; l = last; if (l == null) throw new NoSuchElementException(); return l.item; } removeFirst方法，相当于Queue的remove方法，删除队头元素，如果队空，抛出异常\npublic E removeFirst() { final Node\u0026lt;E\u0026gt; f = first; if (f == null) throw new NoSuchElementException(); return unlinkFirst(f); } private E unlinkFirst(Node\u0026lt;E\u0026gt; f) { // assert f == first \u0026amp;\u0026amp; f != null; final E element = f.item; final Node\u0026lt;E\u0026gt; next = f.next; f.item = null; f.next = null; // help GC first = next; if (next == null) //如果原头节点的后继为空，那么把尾指针也更新为空 last = null; else //原头节点的后继为不空，那么需要把它的前驱更新为空 next.prev = null; //更新链表大小 size--; modCount++; return element; } removeLast方法，如果队空，抛出异常\npublic E removeLast() { final Node\u0026lt;E\u0026gt; l = last; if (l == null) throw new NoSuchElementException(); return unlinkLast(l); } private E unlinkLast(Node\u0026lt;E\u0026gt; l) { // assert l == last \u0026amp;\u0026amp; l != null; final E element = l.item; final Node\u0026lt;E\u0026gt; prev = l.prev; l.item = null; l.prev = null; // help GC last = prev; if (prev == null) //如果原尾指针的前驱为空，那么头指针指向也为空 first = null; else //原尾指针的前驱不为空，那么它的后继应该改为空 prev.next = null; size--; modCount++; return element; } addFirst方法，相当于Statck中的push方法\npublic void addFirst(E e) { linkFirst(e); } private void linkFirst(E e) { final Node\u0026lt;E\u0026gt; f = first; //创建一个前驱为空，后驱为first的新节点 final Node\u0026lt;E\u0026gt; newNode = new Node\u0026lt;\u0026gt;(null, e, f); first = newNode; if (f == null) //如果原头指针为空，那么把尾指针也赋值为新加节点 last = newNode; else //原头指正不空，把它的前驱更新为新节点 f.prev = newNode; size++; modCount++; } addLast方法,相当于Queue中的add方法\npublic void addLast(E e) { linkLast(e); } void linkLast(E e) { final Node\u0026lt;E\u0026gt; l = last; final Node\u0026lt;E\u0026gt; newNode = new Node\u0026lt;\u0026gt;(l, e, null); last = newNode; if (l == null) //如果原为指针指向就为空，那么头指针也指向新节点 first = newNode; else //原为指针指向就不为空，那么它的后继更新为新加节点 l.next = newNode; size++; modCount++; } add方法是重写AbstractList中的方法，即往List中添加元素\npublic boolean add(E e) { linkLast(e); return true; } void linkLast(E e) { final Node\u0026lt;E\u0026gt; l = last; final Node\u0026lt;E\u0026gt; newNode = new Node\u0026lt;\u0026gt;(l, e, null); last = newNode; if (l == null) first = newNode; else l.next = newNode; size++; modCount++; } remove方法移除链表中指定元素\npublic boolean remove(Object o) { if (o == null) { //如果要移除的对象为null,那么取链表中找第一个null元素并移除 for (Node\u0026lt;E\u0026gt; x = first; x != null; x = x.next) { if (x.item == null) { unlink(x); return true; } } } else { for (Node\u0026lt;E\u0026gt; x = first; x != null; x = x.next) { if (o.equals(x.item)) {//使用equals比较两个对象是否相同 unlink(x); return true; } } } return false; } addAll方法向链表中添加指定集合的元素\npublic boolean addAll(Collection\u0026lt;? extends E\u0026gt; c) { return addAll(size, c); } public boolean addAll(int index, Collection\u0026lt;? extends E\u0026gt; c) { checkPositionIndex(index); Object[] a = c.toArray(); int numNew = a.length; //如果集合大小为0 if (numNew == 0) return false; //什么一个前驱节点和一个后继节点 Node\u0026lt;E\u0026gt; pred, succ; if (index == size) { //如果添加的位置恰好是size即在链表最后添加,那么后继为null，前驱为链表尾指针 succ = null; pred = last; } else { succ = node(index); pred = succ.prev; } for (Object o : a) { @SuppressWarnings(\u0026#34;unchecked\u0026#34;) E e = (E) o; Node\u0026lt;E\u0026gt; newNode = new Node\u0026lt;\u0026gt;(pred, e, null); if (pred == null)//如果没有前驱节点 //把链表头指针指向新节点 first = newNode; else pred.next = newNode; //前驱节点赋值为当前新节点 pred = newNode; } if (succ == null) {//如果没有后继节点 //把尾指针指向\u0026#39;前驱节点\u0026#39; last = pred; } else { pred.next = succ; succ.prev = pred; } size += numNew; modCount++; return true; } clear方法清空链表，但是modCount并不会清空\npublic void clear() { for (Node\u0026lt;E\u0026gt; x = first; x != null; ) { Node\u0026lt;E\u0026gt; next = x.next; //help GC？ x.item = null; x.next = null; x.prev = null; x = next; } first = last = null; size = 0; modCount++; } get方法获取指定下标元素，非法下标抛出异常\npublic E get(int index) { checkElementIndex(index); return node(index).item; } Node\u0026lt;E\u0026gt; node(int index) { // assert isElementIndex(index); //通过一个二分遍历拿元素 if (index \u0026lt; (size \u0026gt;\u0026gt; 1)) { Node\u0026lt;E\u0026gt; x = first; for (int i = 0; i \u0026lt; index; i++) x = x.next; return x; } else { Node\u0026lt;E\u0026gt; x = last; for (int i = size - 1; i \u0026gt; index; i--) x = x.prev; return x; } } set方法设置指定下标元素值，非法下标抛出异常，set方法modCount不++？why？\npublic E set(int index, E element) { checkElementIndex(index); //获取元素 Node\u0026lt;E\u0026gt; x = node(index); E oldVal = x.item; //替换 x.item = element; return oldVal; } add方法，指定下标添加元素，非法下标抛出异常\npublic void add(int index, E element) { checkPositionIndex(index); if (index == size)//链表尾添加元素 linkLast(element); else //链表中间位置添加元素 linkBefore(element, node(index)); } void linkBefore(E e, Node\u0026lt;E\u0026gt; succ) { // assert succ != null; final Node\u0026lt;E\u0026gt; pred = succ.prev; final Node\u0026lt;E\u0026gt; newNode = new Node\u0026lt;\u0026gt;(pred, e, succ); succ.prev = newNode; if (pred == null)//添加元素位置前驱为null，即添加位置本来就是头指针位置 first = newNode; else //更新前驱的next为当前添加节点 pred.next = newNode; size++; modCount++; } remove方法，移除指定下标元素，非法下标抛出异常\npublic E remove(int index) { checkElementIndex(index); return unlink(node(index)); } E unlink(Node\u0026lt;E\u0026gt; x) { // assert x != null; final E element = x.item; final Node\u0026lt;E\u0026gt; next = x.next; final Node\u0026lt;E\u0026gt; prev = x.prev; if (prev == null) {//如果移除节点的前驱为null，即移除节点为头指针指向位置 first = next; } else { prev.next = next; //help GC？ x.prev = null; } if (next == null) {//如果移除节点的后继节点为null，即移除节点是尾指针指向位置 last = prev; } else { next.prev = prev; //help GC？ x.next = null; } //help GC？ x.item = null; size--; modCount++; return element; } peek方法，获取链表头节点，可为Queue/Stack方法，Queue方法即获取队手元素，Stack方法即获取栈顶元素\npublic E peek() { final Node\u0026lt;E\u0026gt; f = first; return (f == null) ? null : f.item; } element方法，获取链表头节点，与peek方法不同的是，如果队列为空，抛出异常\npublic E element() { return getFirst(); } public E getFirst() { final Node\u0026lt;E\u0026gt; f = first; if (f == null) //链表空抛出异常 throw new NoSuchElementException(); return f.item; } poll方法移除链表头节点，链表空返回null\npublic E poll() { final Node\u0026lt;E\u0026gt; f = first; return (f == null) ? null : unlinkFirst(f); } remove方法移除链表头节点，链表空抛出异常\npublic E remove() { return removeFirst(); } public E removeFirst() { final Node\u0026lt;E\u0026gt; f = first; if (f == null) //链表空抛出异常 throw new NoSuchElementException(); return unlinkFirst(f); } offer方法，在链表尾添加元素\npublic boolean offer(E e) { return add(e); } public boolean add(E e) { linkLast(e); return true; } offerFirst方法，在链表头添加节点，对应栈的入栈操作\npublic boolean offerFirst(E e) { addFirst(e); return true; } public void addFirst(E e) { linkFirst(e); } offerLast方法，在链表尾添加元素，本质上和offer方法没有区别\npublic boolean offerLast(E e) { addLast(e); return true; } public void addLast(E e) { linkLast(e); } peekFirst方法，查看链表头节点，相当于Queue和Stack的peek方法，链表空返回null\npublic E peekFirst() { final Node\u0026lt;E\u0026gt; f = first; return (f == null) ? null : f.item; } peekLast方法，查看链表尾节点，链表空返回null\npublic E peekLast() { final Node\u0026lt;E\u0026gt; l = last; return (l == null) ? null : l.item; } pollFirst方法，查看并删除链表头节点，链表空返回null\npublic E pollFirst() { final Node\u0026lt;E\u0026gt; f = first; return (f == null) ? null : unlinkFirst(f); } pollLast查看并删除链表尾节点，链表空返回null\npublic E pollLast() { final Node\u0026lt;E\u0026gt; l = last; return (l == null) ? null : unlinkLast(l); } push方法头节点位置添加，Stack的push方法\npublic void push(E e) { addFirst(e); } public void addFirst(E e) { linkFirst(e); } pop方法删除头节点位置元素,Stack的pop方法\npublic E pop() { return removeFirst(); } public E removeFirst() { final Node\u0026lt;E\u0026gt; f = first; if (f == null)//链表空抛异常 throw new NoSuchElementException(); return unlinkFirst(f); } removeFirstOccurrence方法从头结点开始查找指定元素并移除\npublic boolean removeFirstOccurrence(Object o) { return remove(o); } public boolean remove(Object o) { if (o == null) {//要移除的元素为null for (Node\u0026lt;E\u0026gt; x = first; x != null; x = x.next) {//从头查找，移除第一个为null元素 if (x.item == null) { unlink(x); return true; } } } else { for (Node\u0026lt;E\u0026gt; x = first; x != null; x = x.next) {//依次遍历 if (o.equals(x.item)) {//使用equals判断相等 unlink(x); return true; } } } return false; } removeLastOccurrence方法从尾节点开始查找并移除指定元素\npublic boolean removeLastOccurrence(Object o) { if (o == null) {//如果移除元素为null for (Node\u0026lt;E\u0026gt; x = last; x != null; x = x.prev) {//从后往前遍历 if (x.item == null) { unlink(x); return true; } } } else { for (Node\u0026lt;E\u0026gt; x = last; x != null; x = x.prev) { if (o.equals(x.item)) {//使用equals判断相等 unlink(x); return true; } } } return false; } listIterator方法返回链表迭代器\npublic ListIterator\u0026lt;E\u0026gt; listIterator(int index) { checkPositionIndex(index); return new ListItr(index); } //由于LinkedList是双向链表，所以可以双向遍历 private class ListItr implements ListIterator\u0026lt;E\u0026gt; { private Node\u0026lt;E\u0026gt; lastReturned; private Node\u0026lt;E\u0026gt; next; private int nextIndex; //expectedModCount保存拿到迭代器时，LinkedList的modCount值，与快速失败有关 private int expectedModCount = modCount; public boolean hasNext() { return nextIndex \u0026lt; size; } public E next() { checkForComodification(); if (!hasNext()) throw new NoSuchElementException(); lastReturned = next; next = next.next; nextIndex++; return lastReturned.item; } public boolean hasPrevious() { return nextIndex \u0026gt; 0; } public E previous() { checkForComodification(); if (!hasPrevious()) throw new NoSuchElementException(); lastReturned = next = (next == null) ? last : next.prev; nextIndex--; return lastReturned.item; } final void checkForComodification() { if (modCount != expectedModCount)//如果链表的modCount和拿到迭代器时modCount不同，说明在迭代过程中，链表进行了破坏结构的修改，那么应该直接抛出异常 throw new ConcurrentModificationException(); } } Vector 类结构 可以看到，Vector的类结构和ArrayList的一模一样\nVector继承AbstractList实现了List接口\nVector实现了RandomAccess接口，可以随机访问\nVector实现了Cloneable接口，可以使用克隆对象\nVector实现了Serializable接口，可以序列化\n属性 //保存对象的数组 protected Object[] elementData; //保存元素个数 protected int elementCount; //增长因子 protected int capacityIncrement; //定义的最大容量，为2的31次方-9 private static final int MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8; 构造器 public Vector(int initialCapacity, int capacityIncrement) {//指定初始容量和增长因子 super(); if (initialCapacity \u0026lt; 0) throw new IllegalArgumentException(\u0026#34;Illegal Capacity: \u0026#34;+ initialCapacity); //直接把数组创建为初始化值大小 this.elementData = new Object[initialCapacity]; this.capacityIncrement = capacityIncrement; } public Vector(int initialCapacity) { //把增长因子设置为0 this(initialCapacity, 0); } public Vector() { //默认初始化大小为10 this(10); } public Vector(Collection\u0026lt;? extends E\u0026gt; c) { elementData = c.toArray(); elementCount = elementData.length; // c.toArray might (incorrectly) not return Object[] (see 6260652) if (elementData.getClass() != Object[].class) elementData = Arrays.copyOf(elementData, elementCount, Object[].class); } 方法 线程安全的方法 copyInto方法把元素拷贝到指定数组\npublic synchronized void copyInto(Object[] anArray) { System.arraycopy(elementData, 0, anArray, 0, elementCount); } trimToSize方法把保存元素的数组修改到保存元素个数大小\npublic synchronized void trimToSize() { modCount++; int oldCapacity = elementData.length; if (elementCount \u0026lt; oldCapacity) {//如果元素个数比容量小 elementData = Arrays.copyOf(elementData, elementCount); } } ensureCapacity方法用于添加元素时，确保数组大小\npublic synchronized void ensureCapacity(int minCapacity) { if (minCapacity \u0026gt; 0) { modCount++; ensureCapacityHelper(minCapacity); } } private void ensureCapacityHelper(int minCapacity) { // overflow-conscious code if (minCapacity - elementData.length \u0026gt; 0)//如果需要的最小容量大于数组大小 //扩容 grow(minCapacity); } private void grow(int minCapacity) { // overflow-conscious code int oldCapacity = elementData.length; //如果指定了增长因子而且增长因子\u0026gt;0那么新容量就等于原容量+增长因子，否则就是原容量的二倍 int newCapacity = oldCapacity + ((capacityIncrement \u0026gt; 0) ? capacityIncrement : oldCapacity); if (newCapacity - minCapacity \u0026lt; 0) newCapacity = minCapacity; if (newCapacity - MAX_ARRAY_SIZE \u0026gt; 0) newCapacity = hugeCapacity(minCapacity); elementData = Arrays.copyOf(elementData, newCapacity); } setSize方法设置向量的大小\npublic synchronized void setSize(int newSize) { modCount++; if (newSize \u0026gt; elementCount) {//如果新容量比原容量大，多的元素全为null ensureCapacityHelper(newSize); } else { //新容量比原容量小 for (int i = newSize ; i \u0026lt; elementCount ; i++) { elementData[i] = null; } } elementCount = newSize; } removeElementAt移除指定位置元素\npublic synchronized void removeElementAt(int index) { modCount++; if (index \u0026gt;= elementCount) { throw new ArrayIndexOutOfBoundsException(index + \u0026#34; \u0026gt;= \u0026#34; + elementCount); } else if (index \u0026lt; 0) { throw new ArrayIndexOutOfBoundsException(index); } //要移动的元素个数 int j = elementCount - index - 1; if (j \u0026gt; 0) { System.arraycopy(elementData, index + 1, elementData, index, j); } elementCount--; elementData[elementCount] = null; /* to let gc do its work */ } insertElementAt指定位置插入元素\npublic synchronized void insertElementAt(E obj, int index) { modCount++; if (index \u0026gt; elementCount) { throw new ArrayIndexOutOfBoundsException(index + \u0026#34; \u0026gt; \u0026#34; + elementCount); } //确保容量 ensureCapacityHelper(elementCount + 1); System.arraycopy(elementData, index, elementData, index + 1, elementCount - index); elementData[index] = obj; elementCount++; } addElement在尾部添加元素\npublic synchronized void addElement(E obj) { modCount++; //确保容量 ensureCapacityHelper(elementCount + 1); elementData[elementCount++] = obj; } removeElement移除指定元素\npublic synchronized boolean removeElement(Object obj) { modCount++; int i = indexOf(obj); if (i \u0026gt;= 0) { removeElementAt(i); return true; } return false; } removeAllElements移除所有元素\npublic synchronized void removeAllElements() { modCount++; // Let gc do its work for (int i = 0; i \u0026lt; elementCount; i++) elementData[i] = null; elementCount = 0; } get获取指定位置元素\npublic synchronized E get(int index) { if (index \u0026gt;= elementCount) throw new ArrayIndexOutOfBoundsException(index); return elementData(index); } set替换指定位置元素\npublic synchronized E set(int index, E element) { if (index \u0026gt;= elementCount) throw new ArrayIndexOutOfBoundsException(index); E oldValue = elementData(index); elementData[index] = element; return oldValue; } add方法添加元素，与addElement方法的区别仅仅是返回值不同\npublic synchronized boolean add(E e) { modCount++; ensureCapacityHelper(elementCount + 1); elementData[elementCount++] = e; return true; } remove移除尾元素\npublic boolean remove(Object o) { return removeElement(o); } add指定位置添加元素\npublic void add(int index, E element) { insertElementAt(element, index); } remove移除指定位置元素\npublic synchronized E remove(int index) { modCount++; if (index \u0026gt;= elementCount) throw new ArrayIndexOutOfBoundsException(index); E oldValue = elementData(index); //计算要移动的元素个数 int numMoved = elementCount - index - 1; if (numMoved \u0026gt; 0) System.arraycopy(elementData, index+1, elementData, index, numMoved); elementData[--elementCount] = null; // Let gc do its work return oldValue; } listIterator获取向量的迭代器，可以进行向前向后遍历\npublic synchronized ListIterator\u0026lt;E\u0026gt; listIterator() { return new ListItr(0); } final class ListItr extends Itr implements ListIterator\u0026lt;E\u0026gt; { ListItr(int index) { super(); cursor = index; } public boolean hasPrevious() { return cursor != 0; } public int nextIndex() { return cursor; } public int previousIndex() { return cursor - 1; } public E previous() { synchronized (Vector.this) { checkForComodification(); int i = cursor - 1; if (i \u0026lt; 0) throw new NoSuchElementException(); cursor = i; return elementData(lastRet = i); } } public void set(E e) { if (lastRet == -1) throw new IllegalStateException(); synchronized (Vector.this) { checkForComodification(); Vector.this.set(lastRet, e); } } public void add(E e) { int i = cursor; synchronized (Vector.this) { checkForComodification(); Vector.this.add(i, e); expectedModCount = modCount; } cursor = i + 1; lastRet = -1; } } 可以看到Vector和ArrayList的源码基本相同，只是Vector是线程安全的，还有就是Vector和ArrayList在扩容上有一点点不同，Vector如果指定了增长因子，那么新容量是原容量+增长因子，而ArrayList是直接扩大两倍原容量\n","permalink":"https://moyuduo.github.io/posts/arraylistlinkedlist%E5%92%8Cvector%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/","summary":"ArrayList、LinkedList和Vector源码分析 ArrayList ArrayList是一个底层使用数组来存储对象，但不是线程安全的集合类\nArrayList的类结构关系 public class ArrayList\u0026lt;E\u0026gt; extends AbstractList\u0026lt;E\u0026gt; implements List\u0026lt;E\u0026gt;, RandomAccess, Cloneable, java.io.Serializable { } ArrayList实现了List接口，List接口中定义了一些对列表通过下标进行添加删除等方法\nArrayList实现了RandomAccess接口，这个接口是一个标记接口，接口中并没有任何的方法，ArrayList底层是用数组来存储对象，当然是能够通过下标随机访问的，实现了RandomAccess接口的类在查询时的速度会很快但是添加删除元素慢，而LinkedList是通过链表的方式实现的，它没有实现RandomAccess接口，在查询时慢但是增加删除的速度快\n所以在使用集合遍历大量数据时，可以先用instanceof来判断集合是不是实现了RandomAccess\npublic void test1() { List\u0026lt;Integer\u0026gt; list=new ArrayList\u0026lt;Integer\u0026gt;(); list.add(1); if(list instanceof RandomAccess) {//RandomAccess实现类，使用下标访问 for(int i=0;i\u0026lt;list.size();i++) { //todo } }else {//不是RandomAccess实现类，使用iterator遍历 Iterator\u0026lt;Integer\u0026gt; iterator = list.iterator(); while(iterator.hasNext()) { //todo } } } ArrayList实现了Cloneable接口,所以可以合法调用clone方法，如果没有实现Cloneable接口，那么会抛出CloneNotSupporteddException，详见\nArrayList实现了Serializable接口，可以将对象序列化，用于传输或持久化，详见\n属性 //序列化Id private static final long serialVersionUID = 8683452581122892189L; //默认初始化大小 private static final int DEFAULT_CAPACITY = 10; //空数组对象，用于有参构造且初始化大小为0时 private static final Object[] EMPTY_ELEMENTDATA = {}; //空数组对象，用于无参构造时，这两个属性主要用来区分创建ArrayList时有没有指定容量 private static final Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = {}; //保存对象的容器，使用transient修饰即在序列化时，不进行序列化，这是因为ArrayList添加了序列化方法private void writeObject(java.","title":"ArrayList、LinkedList和Vector源码分析"},{"content":"edgewize1.1 云端调用边端驱动服务流程：\nreq(/devices/{deviceId}/call/{identifier})\t=\u0026gt;\tiot-api-server\t=\u0026gt;\tiot-dispatch =\u0026gt;\t构建topic /sys/{thingId}/{deviceId}/thing/service/{identifier}/call\t=\u0026gt;\tkafka =\u0026gt;\txxx\t=\u0026gt;\texia.bridge\t=\u0026gt; exia.broker\t=\u0026gt;\tdriver\n应用管理中的应用启动、停止、重启也是使用的和调用边端驱动相同的接口，启动使用的identifier是appStart,停止使用的identifier是appStop，重启使用的identifier也是appStart，所以重启并不是真正意义上的重启。\n云端部署驱动流程：\nreq(/deploy)\t=\u0026gt;\tiot-api-server\t=\u0026gt;\tiot-deployserver\t=\u0026gt;\tiot-deploycore\t=\u0026gt;\tredis\t=\u0026gt;\tiot-deployexecutor\t=\u0026gt;\t15s每次http轮询\t=\u0026gt; scheduler\n应用管理中的应用升级也是走的和边端驱动部署一样的接口，只能传递参数是deploy_type不一样\n","permalink":"https://moyuduo.github.io/posts/edgewize1.1/","summary":"edgewize1.1 云端调用边端驱动服务流程：\nreq(/devices/{deviceId}/call/{identifier})\t=\u0026gt;\tiot-api-server\t=\u0026gt;\tiot-dispatch =\u0026gt;\t构建topic /sys/{thingId}/{deviceId}/thing/service/{identifier}/call\t=\u0026gt;\tkafka =\u0026gt;\txxx\t=\u0026gt;\texia.bridge\t=\u0026gt; exia.broker\t=\u0026gt;\tdriver\n应用管理中的应用启动、停止、重启也是使用的和调用边端驱动相同的接口，启动使用的identifier是appStart,停止使用的identifier是appStop，重启使用的identifier也是appStart，所以重启并不是真正意义上的重启。\n云端部署驱动流程：\nreq(/deploy)\t=\u0026gt;\tiot-api-server\t=\u0026gt;\tiot-deployserver\t=\u0026gt;\tiot-deploycore\t=\u0026gt;\tredis\t=\u0026gt;\tiot-deployexecutor\t=\u0026gt;\t15s每次http轮询\t=\u0026gt; scheduler\n应用管理中的应用升级也是走的和边端驱动部署一样的接口，只能传递参数是deploy_type不一样","title":"edgewize1.1"},{"content":"edgewize备忘录 安装脚本 sudo curl -O https://iot-edgewize.pek3a.qingstor.com/public/index.sh \u0026amp;\u0026amp; sudo chmod +x index.sh \u0026amp;\u0026amp; sudo ./index.sh edgewize-1.0.0-Linux-Ubuntu-16.04.6-x86_64 eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9.eyJhY3IiOiIxIiwiYXVkIjoiaWFtIiwiYXpwIjoiaWFtIiwiZXhwIjoxNjYzNDcwMjQyLCJpYXQiOjE2MzE5MzQyNDIsImlzcyI6InN0cyIsImp0aSI6InM5aVM5UWdxS1E1bGxqZmxBdjRTaTAiLCJuYmYiOjAsIm9yZ2kiOiJpb3RkLTg1YzFjOTk1LTNjNzktNGM3MS1iYzJkLWI0NDFjNTRjMjI3OSIsIm93dXIiOiJ1c3ItSGdrSmZ2UkUiLCJzdWIiOiJzdHMiLCJ0aGlkIjoiaW90dC14UHpxZmJBWUtqIiwidHlwIjoiSUQifQ.BZU_Vx07rm_0zq9ZITqZ8Q6ylfBuIRl8oQRzAPZB9-migJQC_NZdu_hTr4pgdDgjciADUDJyhlNVKUKo4FJh-6aEzuPs6Q7xd-ooJQKjKLz3syRGzQNKTVZKLXAZDFO0tOzU_Zom9M-ZprnPHIMJa_TS_UWEy7uLK9ymYjTMNCs static c2d93559-182e-11ec-80b9-52549e8f212b edge_param_version=$1=edgewize-1.0.0-Linux-Ubuntu-16.04.6-x86_64 #/etc/token中的内容 edge_param_certificate=$2=eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9.eyJhY3IiOiIxIiwiYXVkIjoiaWFtIiwiYXpwIjoiaWFtIiwiZXhwIjoxNjYzNDcwMjQyLCJpYXQiOjE2MzE5MzQyNDIsImlzcyI6InN0cyIsImp0aSI6InM5aVM5UWdxS1E1bGxqZmxBdjRTaTAiLCJuYmYiOjAsIm9yZ2kiOiJpb3RkLTg1YzFjOTk1LTNjNzktNGM3MS1iYzJkLWI0NDFjNTRjMjI3OSIsIm93dXIiOiJ1c3ItSGdrSmZ2UkUiLCJzdWIiOiJzdHMiLCJ0aGlkIjoiaW90dC14UHpxZmJBWUtqIiwidHlwIjoiSUQifQ.BZU_Vx07rm_0zq9ZITqZ8Q6ylfBuIRl8oQRzAPZB9-migJQC_NZdu_hTr4pgdDgjciADUDJyhlNVKUKo4FJh-6aEzuPs6Q7xd-ooJQKjKLz3syRGzQNKTVZKLXAZDFO0tOzU_Zom9M-ZprnPHIMJa_TS_UWEy7uLK9ymYjTMNCs edge_param_register_type=$3=static edge_param_active_code=$4=c2d93559-182e-11ec-80b9-52549e8f212b 项目 端口 备注 exia 1883 本地mqtt broker监听端口 exia 9612 本地mqtt broker桥接上传云端的计量服务 metadata 9611 本地保存配置的服务 scheduler 9610 ","permalink":"https://moyuduo.github.io/posts/edgewize%E5%A4%87%E5%BF%98%E5%BD%95/","summary":"edgewize备忘录 安装脚本 sudo curl -O https://iot-edgewize.pek3a.qingstor.com/public/index.sh \u0026amp;\u0026amp; sudo chmod +x index.sh \u0026amp;\u0026amp; sudo ./index.sh edgewize-1.0.0-Linux-Ubuntu-16.04.6-x86_64 eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9.eyJhY3IiOiIxIiwiYXVkIjoiaWFtIiwiYXpwIjoiaWFtIiwiZXhwIjoxNjYzNDcwMjQyLCJpYXQiOjE2MzE5MzQyNDIsImlzcyI6InN0cyIsImp0aSI6InM5aVM5UWdxS1E1bGxqZmxBdjRTaTAiLCJuYmYiOjAsIm9yZ2kiOiJpb3RkLTg1YzFjOTk1LTNjNzktNGM3MS1iYzJkLWI0NDFjNTRjMjI3OSIsIm93dXIiOiJ1c3ItSGdrSmZ2UkUiLCJzdWIiOiJzdHMiLCJ0aGlkIjoiaW90dC14UHpxZmJBWUtqIiwidHlwIjoiSUQifQ.BZU_Vx07rm_0zq9ZITqZ8Q6ylfBuIRl8oQRzAPZB9-migJQC_NZdu_hTr4pgdDgjciADUDJyhlNVKUKo4FJh-6aEzuPs6Q7xd-ooJQKjKLz3syRGzQNKTVZKLXAZDFO0tOzU_Zom9M-ZprnPHIMJa_TS_UWEy7uLK9ymYjTMNCs static c2d93559-182e-11ec-80b9-52549e8f212b edge_param_version=$1=edgewize-1.0.0-Linux-Ubuntu-16.04.6-x86_64 #/etc/token中的内容 edge_param_certificate=$2=eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9.eyJhY3IiOiIxIiwiYXVkIjoiaWFtIiwiYXpwIjoiaWFtIiwiZXhwIjoxNjYzNDcwMjQyLCJpYXQiOjE2MzE5MzQyNDIsImlzcyI6InN0cyIsImp0aSI6InM5aVM5UWdxS1E1bGxqZmxBdjRTaTAiLCJuYmYiOjAsIm9yZ2kiOiJpb3RkLTg1YzFjOTk1LTNjNzktNGM3MS1iYzJkLWI0NDFjNTRjMjI3OSIsIm93dXIiOiJ1c3ItSGdrSmZ2UkUiLCJzdWIiOiJzdHMiLCJ0aGlkIjoiaW90dC14UHpxZmJBWUtqIiwidHlwIjoiSUQifQ.BZU_Vx07rm_0zq9ZITqZ8Q6ylfBuIRl8oQRzAPZB9-migJQC_NZdu_hTr4pgdDgjciADUDJyhlNVKUKo4FJh-6aEzuPs6Q7xd-ooJQKjKLz3syRGzQNKTVZKLXAZDFO0tOzU_Zom9M-ZprnPHIMJa_TS_UWEy7uLK9ymYjTMNCs edge_param_register_type=$3=static edge_param_active_code=$4=c2d93559-182e-11ec-80b9-52549e8f212b 项目 端口 备注 exia 1883 本地mqtt broker监听端口 exia 9612 本地mqtt broker桥接上传云端的计量服务 metadata 9611 本地保存配置的服务 scheduler 9610 ","title":"edgewize备忘录"},{"content":"edgex 架构 EdgeX是一个开源、供应商中立、灵活、可互操作的边缘软件平台，可与设备、传感器、执行器和其他物联网对象的物理世界进行交互。Edgex采用微服务架构，这些微服务被组织成 4 个服务层和 2 个底层增强系统服务。四个服务层从下向上依次是：\n设备服务层：\n设备服务层负责把设备接入到edgex中，对于一些常用协议如：modbus、opc-ua、mqtt等，edgex已经有设备服务可供选择，可直接进行部署。对于一些私有协议，edgex提供了设备接入sdk，开发者通过sdk来进行设备接入。\n核心服务层：\n核心服务层主要是core data、command、metadata三个服务，core data是负责把设备收集的数据提供集中持久化。command服务对设备进行控制操作设备。metadata服务保存设备的定义和控制设备的命令。\n支持服务层：\n支持服务主要包含rules engine、scheduling、alerts \u0026amp; notifications服务，该层服务为可选的。其中rules engine服务是基于kuiper实现的一个规则引擎。scheduling服务可以进行配置规则通过REST API定时调用，如定时清理核心服务层持久化的数据。alerts \u0026amp; notifications服务通过设置的规则将告警信息通知到应用。\n应用服务层：\n应用服务层负责将数据从edgex导出到外部系统(iot平台)或程序,目前开箱即用的端点有http和mqtt。开发人员也可以基于提供的sdk进行开发，将数据导出至任何地方。\n2 个底层增强系统服是：\n安全服务：\n主要是提供安全的存储和使用反向代理使得服务REST API不能直接访问必须经过安全服务鉴权后进行访问\n管理服务：\n提供对edgex服务的管理，如：启动服务、停止服务、重启服务、获取配置、获取运行状态、获取服务占用资源信息\n##工作原理\n温度测量仪将真实的设备数据通过mqtt协议上报到设备服务层的mqtt服务，mqtt服务将传感器数据转换为edgex事件对象并通过REST通信将事件对象发送到核心服务层的core服务 核心服务层的core服务将收到的事件对象发送到消息中间件的指定主题上 应用服务层根据需要将数据进行过滤、压缩、加密或导出到外部系统或应用程序 应用服务层的程序将包发送给edgex内置的规则引擎 当规则引起中的规则被匹配时，会调用核心服务层的command服务来触发某些操作 核心服务层的command服务获取到命令并确定需要对那个设备执行命令，然后调用设备的服务来执行 openyurt和edgex整合 整合架构：\nyurt-edgex-manager组件 yurt-edgex-manager组件是openyurt用来管理edgex生命周期的组件，它定义了一个edgex自定义资源用来表示运行在边缘节点的edgex实例，用户可以操作edgex的cr来对edgex进行安装/删除/升级操作。\nyurt-device-controller组件 func main() { //监听k8s DeviceProfile资源的变化把DeviceProfile的增加/删除/更新 同步到edgex if err = (\u0026amp;controllers.DeviceProfileReconciler{ Client: mgr.GetClient(), Log: ctrl.Log.WithName(\u0026#34;controllers\u0026#34;).WithName(\u0026#34;DeviceProfile\u0026#34;), Scheme: mgr.GetScheme(), }).SetupWithManager(mgr); err != nil { setupLog.Error(err, \u0026#34;unable to create controller\u0026#34;, \u0026#34;controller\u0026#34;, \u0026#34;DeviceProfile\u0026#34;) os.Exit(1) } //定时从edgex 的metadata获取DeviceProfile把edgex中的DeviceProfile的增加/删除/更新 同步到k8s dfs, err := controllers.NewDeviceProfileSyncer(mgr.GetClient(), mgr.GetLogger(), EdgeXSyncPeriodSecs, mgr.GetConfig()) if err != nil { setupLog.Error(err, \u0026#34;unable to create syncer\u0026#34;, \u0026#34;syncer\u0026#34;, \u0026#34;DeviceProfile\u0026#34;) os.Exit(1) } mgr.Add(dfs.NewDeviceProfileSyncerRunnable()) setupLog.Info(\u0026#34;add device profile syncer\u0026#34;) //监听k8s Device资源的变化把Device设备的增加/删除/更新 同步到edgex if err = (\u0026amp;controllers.DeviceReconciler{ Client: mgr.GetClient(), Log: ctrl.Log.WithName(\u0026#34;controllers\u0026#34;).WithName(\u0026#34;Device\u0026#34;), Scheme: mgr.GetScheme(), }).SetupWithManager(mgr); err != nil { setupLog.Error(err, \u0026#34;unable to create controller\u0026#34;, \u0026#34;controller\u0026#34;, \u0026#34;Device\u0026#34;) os.Exit(1) } //定时从edgex 的metadata获取Device把edgex中的Device设备的增加/删除/更新 同步到k8s ds, err := controllers.NewDeviceSyncer(mgr.GetClient(), mgr.GetLogger(), EdgeXSyncPeriodSecs, mgr.GetConfig()) if err != nil { setupLog.Error(err, \u0026#34;unable to create syncer\u0026#34;, \u0026#34;controller\u0026#34;, \u0026#34;Device\u0026#34;) os.Exit(1) } mgr.Add(ds.NewDeviceSyncerRunnablel()) setupLog.Info(\u0026#34;add device syncer\u0026#34;) //监听k8s DeviceService资源的变化把DeviceService的增加/删除/更新 同步到edgex if err = (\u0026amp;controllers.DeviceServiceReconciler{ Client: mgr.GetClient(), Log: ctrl.Log.WithName(\u0026#34;controllers\u0026#34;).WithName(\u0026#34;DeviceService\u0026#34;), Scheme: mgr.GetScheme(), }).SetupWithManager(mgr); err != nil { setupLog.Error(err, \u0026#34;unable to create controller\u0026#34;, \u0026#34;controller\u0026#34;, \u0026#34;DeviceService\u0026#34;) os.Exit(1) } //定时从edgex 的metadata获取DeviceService把edgex中的DeviceService的增加/删除/更新 同步到k8s dss, err := controllers.NewDeviceServiceSyncer(mgr.GetClient(), mgr.GetLogger(), EdgeXSyncPeriodSecs, mgr.GetConfig()) if err != nil { setupLog.Error(err, \u0026#34;unable to create syncer\u0026#34;, \u0026#34;syncer\u0026#34;, \u0026#34;DeviceService\u0026#34;) os.Exit(1) } mgr.Add(dss.NewDeviceServiceSyncerRunnable()) } 部署 把device service部署在设备侧的设备上，然后把core service、support service、application service部署在云端，这种部署方式要求部署device service的设备和云端要能够互相访问，不能跨内网，因为core service中的command模块需要通过reset api形式调用device service 把device service部署到设备侧的设备上，在网关上部署core service、support service、application service，通过support service的规则引擎或通过application service把数据上云 把device service部署到设备侧的设备上，在网关上部署core service、support service，通过规则引擎把数据导出到私有服务器的应用和分析程序，最后导出到云 通过把device service内置到物理设备，通过device service把数据上传到部署core service、support service、application service的私有服务器，最后数据上云 参考 https://docs.edgexfoundry.org/1.2/#how-edgex-works\n","permalink":"https://moyuduo.github.io/posts/edgex/","summary":"edgex 架构 EdgeX是一个开源、供应商中立、灵活、可互操作的边缘软件平台，可与设备、传感器、执行器和其他物联网对象的物理世界进行交互。Edgex采用微服务架构，这些微服务被组织成 4 个服务层和 2 个底层增强系统服务。四个服务层从下向上依次是：\n设备服务层：\n设备服务层负责把设备接入到edgex中，对于一些常用协议如：modbus、opc-ua、mqtt等，edgex已经有设备服务可供选择，可直接进行部署。对于一些私有协议，edgex提供了设备接入sdk，开发者通过sdk来进行设备接入。\n核心服务层：\n核心服务层主要是core data、command、metadata三个服务，core data是负责把设备收集的数据提供集中持久化。command服务对设备进行控制操作设备。metadata服务保存设备的定义和控制设备的命令。\n支持服务层：\n支持服务主要包含rules engine、scheduling、alerts \u0026amp; notifications服务，该层服务为可选的。其中rules engine服务是基于kuiper实现的一个规则引擎。scheduling服务可以进行配置规则通过REST API定时调用，如定时清理核心服务层持久化的数据。alerts \u0026amp; notifications服务通过设置的规则将告警信息通知到应用。\n应用服务层：\n应用服务层负责将数据从edgex导出到外部系统(iot平台)或程序,目前开箱即用的端点有http和mqtt。开发人员也可以基于提供的sdk进行开发，将数据导出至任何地方。\n2 个底层增强系统服是：\n安全服务：\n主要是提供安全的存储和使用反向代理使得服务REST API不能直接访问必须经过安全服务鉴权后进行访问\n管理服务：\n提供对edgex服务的管理，如：启动服务、停止服务、重启服务、获取配置、获取运行状态、获取服务占用资源信息\n##工作原理\n温度测量仪将真实的设备数据通过mqtt协议上报到设备服务层的mqtt服务，mqtt服务将传感器数据转换为edgex事件对象并通过REST通信将事件对象发送到核心服务层的core服务 核心服务层的core服务将收到的事件对象发送到消息中间件的指定主题上 应用服务层根据需要将数据进行过滤、压缩、加密或导出到外部系统或应用程序 应用服务层的程序将包发送给edgex内置的规则引擎 当规则引起中的规则被匹配时，会调用核心服务层的command服务来触发某些操作 核心服务层的command服务获取到命令并确定需要对那个设备执行命令，然后调用设备的服务来执行 openyurt和edgex整合 整合架构：\nyurt-edgex-manager组件 yurt-edgex-manager组件是openyurt用来管理edgex生命周期的组件，它定义了一个edgex自定义资源用来表示运行在边缘节点的edgex实例，用户可以操作edgex的cr来对edgex进行安装/删除/升级操作。\nyurt-device-controller组件 func main() { //监听k8s DeviceProfile资源的变化把DeviceProfile的增加/删除/更新 同步到edgex if err = (\u0026amp;controllers.DeviceProfileReconciler{ Client: mgr.GetClient(), Log: ctrl.Log.WithName(\u0026#34;controllers\u0026#34;).WithName(\u0026#34;DeviceProfile\u0026#34;), Scheme: mgr.GetScheme(), }).SetupWithManager(mgr); err != nil { setupLog.Error(err, \u0026#34;unable to create controller\u0026#34;, \u0026#34;controller\u0026#34;, \u0026#34;DeviceProfile\u0026#34;) os.","title":"edgex"},{"content":"elasticsearch相关 安装 保证已有java环境\n下载安装包\nmkdir -p /opt/elasticsearch cd /opt/elasticsearch #从https://www.elastic.co/cn/downloads/elasticsearch获取es安装包路径 curl -O https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.14.1-linux-x86_64.tar.gz 解压\ntar -zxvf elasticsearch-7.14.1-linux-x86_64.tar.gz 启动\ncd elasticsearch-7.14.1/bin/ ./elasticsearch #出现以下错误 java.lang.RuntimeException: can not run elasticsearch as root #第一步，添加es组及该组下的es用户 groupadd es useradd es -g es #出现以下错误 useradd: cannot open /etc/passwd #查看该文件的权限 lsattr /etc/passwd -----a-------e-- /etc/passwd #去除掉该文件的a权限 chattr -a /etc/passwd #再次尝试添加用户 useradd es -g es #出现以下错误，解决思路和上面类似 useradd: cannot open /etc/shadow lsattr /etc/shadow -----a-------e-- /etc/shadow chattr -a /etc/shadow #再次创建用户就成功了 useradd es -g es #第二部，更改elasticsearch文件夹的权限为es组下的es用户 chown -R es:es /opt/elasticsearch #第三步，切换到es用户再启动es su es ./elasticsearch 本机测试访问\ncurl localhost:9200 { \u0026#34;name\u0026#34; : \u0026#34;i-u8fxb68q\u0026#34;, \u0026#34;cluster_name\u0026#34; : \u0026#34;elasticsearch\u0026#34;, \u0026#34;cluster_uuid\u0026#34; : \u0026#34;ilI5gIKCQeWmQ0X8r2HXtg\u0026#34;, \u0026#34;version\u0026#34; : { \u0026#34;number\u0026#34; : \u0026#34;7.14.1\u0026#34;, \u0026#34;build_flavor\u0026#34; : \u0026#34;default\u0026#34;, \u0026#34;build_type\u0026#34; : \u0026#34;tar\u0026#34;, \u0026#34;build_hash\u0026#34; : \u0026#34;66b55ebfa59c92c15db3f69a335d500018b3331e\u0026#34;, \u0026#34;build_date\u0026#34; : \u0026#34;2021-08-26T09:01:05.390870785Z\u0026#34;, \u0026#34;build_snapshot\u0026#34; : false, \u0026#34;lucene_version\u0026#34; : \u0026#34;8.9.0\u0026#34;, \u0026#34;minimum_wire_compatibility_version\u0026#34; : \u0026#34;6.8.0\u0026#34;, \u0026#34;minimum_index_compatibility_version\u0026#34; : \u0026#34;6.0.0-beta1\u0026#34; }, \u0026#34;tagline\u0026#34; : \u0026#34;You Know, for Search\u0026#34; } 修改配置文件支持其他机器访问\ncd /opt/elasticsearch/elasticsearch-7.14.1/config vim elasticsearch.yml #把network.host的注释去掉，并修改为接受访问的ip network.host: 0.0.0.0 cd /opt/elasticsearch/elasticsearch-7.14.1/bin #重启启动es #可以使用-d参数指定后台启动 ./elasticsearch #出现以下三个错误 bootstrap check failure [1] of [3]: max file descriptors [4096] for elasticsearch process is too low, increase to at least [65535] bootstrap check failure [2] of [3]: max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144] bootstrap check failure [3] of [3]: the default discovery settings are unsuitable for production use; at least one of [discovery.seed_hosts, discovery.seed_providers, cluster.initial_master_nodes] must be configured #参考：https://www.cnblogs.com/zhi-leaf/p/8484337.html #解决第一个错误，大概意思是es需要打开的文件多，超过了最大现在，要开放多点可以打开的文件数 #编辑 /etc/security/limits.conf，追加以下内容 soft nofile 65536 hard nofile 65536 su root echo \u0026#34;* soft nofile 65536\u0026#34; \u0026gt;\u0026gt; /etc/security/limits.conf echo \u0026#34;* hard nofile 65536\u0026#34; \u0026gt;\u0026gt; /etc/security/limits.conf #解决第二个问题 sudo sysctl -w vm.max_map_count=262144 #解决第三个问题 #修改es的config目录下的elasticsearch.yml文件，在cluster.initial_master_nodes: [\u0026#34;node-1\u0026#34;, \u0026#34;node-2\u0026#34;]的下面新增cluster.initial_master_nodes: [\u0026#34;node-1\u0026#34;] 添加开机自启动\n#!/bin/bash while true do count=`ps -ef|grep elasticsearch|grep -v grep|grep -v auto_start|wc -l` if [ $count -eq 0 ]; then su - es -s /bin/bash /opt/elasticsearch/elasticsearch-7.14.1/bin/elasticsearch \u0026amp; echo \u0026#34;restart elasticsearch at $(date)\u0026#34; \u0026gt;\u0026gt; /opt/elasticsearch/record fi sleep 1 done 图形化管理界面kibana 在https://www.elastic.co/cn/downloads/kibana上选择与es版本对应的kibana\n下载kibana到linux\nmkdir -p /opt/kibana cd /opt/kibana curl -O https://artifacts.elastic.co/downloads/kibana/kibana-7.14.1-linux-x86_64.tar.gz 解压\ntar -zxvf kibana-7.14.1-linux-x86_64.tar.gz 修改配置文件\ncd /opt/kibana/kibana-7.14.1-linux-x86_64/config vim kibana.yml #kibana管理界面web的访问端口 server.port: 5601 #kibana接受访问的ip，配置0.0.0.0以供外部访问 server.host: 0.0.0.0 #es集群的地址，如果es部署的环境不是和kibana同一台机器需要修改 elasticsearch.hosts: [\u0026#34;http://localhost:9200\u0026#34;] #kibana管理界面语言，支持en(默认)、zh-CN i18n.locale: \u0026#34;zh-CN\u0026#34; 修改防火墙开放端口\nfirewall-cmd --add-port=5601/tcp --permanent firewall-cmd --reload 启动\n#在启动kibana之前必须保证es已经启动 cd ../bin/ ./kibana #提示 Kibana should not be run as root. Use --allow-root to continue. ./kibana --allow-root #出现以下即成功 log [10:37:32.033] [info][status] Kibana is now available 操作 查看当前节点下的所有index\ncurl 139.198.11.13:9200/_cat/indices?v 查看所有index包含的mapping\ncurl 139.198.11.13:9200/_mapping?pretty=true 创建和删除index\ncurl -X PUT 139.198.11.13:9200/weather #acknowledged为true表示成功创建index {\u0026#34;acknowledged\u0026#34;:true,\u0026#34;shards_acknowledged\u0026#34;:true,\u0026#34;index\u0026#34;:\u0026#34;weather\u0026#34;} curl -X DELETE 139.198.11.13:9200/weather #acknowledged为true表示删除index成功 {\u0026#34;acknowledged\u0026#34;:true} 创建index并指定mapping\n7.x以前\nPUT twitter { \u0026#34;mappings\u0026#34;: { \u0026#34;user\u0026#34;: { \u0026#34;properties\u0026#34;: { \u0026#34;name\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;text\u0026#34; }, \u0026#34;user_name\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;keyword\u0026#34; }, \u0026#34;email\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;keyword\u0026#34; } } }, \u0026#34;tweet\u0026#34;: { \u0026#34;properties\u0026#34;: { \u0026#34;content\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;text\u0026#34; }, \u0026#34;user_name\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;keyword\u0026#34; }, \u0026#34;tweeted_at\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;date\u0026#34; } } } } } 在7.x以前一个index可以指定多个mapping，但是7.x以后移除了对一个index多个mapping的执行，创建多个index会报错\nFailed to parse mapping [_doc]: Root mapping definition has unsupported parameters\n现在默认的mapping为_doc\n移除index多个mapping的主要原因是：以前使用index类比database，mapping类比table，doc类比row，也就意味着index可以创建多个mapping，但是正数据库中多个表的同名字段如name其实是没有任何关联的，但是在es中，一个index下的所有mapping的同名字段其实都对应一个field，也就意味着多个mapping的同名字段的类型必须相同，在进行删除一个type的filed时可能失败(其他mapping还在使用),并且统一索引中没有公共字段的或很少公共字段的实体会导致数据稀疏，影响lucene压缩文档的能力\n#每个index只能有一个mapping $ curl -X PUT \u0026#39;localhost:9200/accounts222\u0026#39; -d \u0026#39; { \u0026#34;mappings\u0026#34;: { \u0026#34;properties\u0026#34;: { \u0026#34;user\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;text\u0026#34; }, \u0026#34;title\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;text\u0026#34; }, \u0026#34;desc\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;text\u0026#34; } } } }\u0026#39; #单独创建type,但是如果index user不存在会报错 http://139.198.11.13:9200/user/_mapping body:{ \u0026#34;properties\u0026#34;:{ \u0026#34;name\u0026#34;:{ \u0026#34;type\u0026#34;: \u0026#34;text\u0026#34;, \u0026#34;index\u0026#34;: true }, \u0026#34;age\u0026#34;:{ \u0026#34;type\u0026#34;: \u0026#34;long\u0026#34;, \u0026#34;index\u0026#34;: true }, \u0026#34;gender\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;text\u0026#34;, \u0026#34;index\u0026#34;: true } } } resp:{ \u0026#34;acknowledged\u0026#34;: true } #如果以上请求发送多次那么mapping的properties会叠加 查看指定index的mapping\nurl:{{localhost}}:9200/accounts222/_mapping resp:{ \u0026#34;accounts222\u0026#34;: { \u0026#34;mappings\u0026#34;: { \u0026#34;properties\u0026#34;: { \u0026#34;desc\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;text\u0026#34; }, \u0026#34;title\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;text\u0026#34; }, \u0026#34;user\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;text\u0026#34; } } } } } 创建doc不指定id，POST非幂等性\n{{localhost}}:9200/accounts222/_doc body:{ \u0026#34;user\u0026#34;: \u0026#34;张三\u0026#34;, \u0026#34;title\u0026#34;: \u0026#34;工程师\u0026#34;, \u0026#34;desc\u0026#34;: \u0026#34;数据库管理\u0026#34; } #随机id resp:{ \u0026#34;_index\u0026#34;: \u0026#34;accounts222\u0026#34;, \u0026#34;_type\u0026#34;: \u0026#34;_doc\u0026#34;, \u0026#34;_id\u0026#34;: \u0026#34;E83dxHsBx8UYn7wDPx-g\u0026#34;, \u0026#34;_version\u0026#34;: 1, \u0026#34;result\u0026#34;: \u0026#34;created\u0026#34;, \u0026#34;_shards\u0026#34;: { \u0026#34;total\u0026#34;: 2, \u0026#34;successful\u0026#34;: 1, \u0026#34;failed\u0026#34;: 0 }, \u0026#34;_seq_no\u0026#34;: 0, \u0026#34;_primary_term\u0026#34;: 1 } 创建doc并指定id，PUT幂等性\n{{localhost}}:9200/accounts222/_doc/1 body: { \u0026#34;user\u0026#34;: \u0026#34;李四\u0026#34;, \u0026#34;title\u0026#34;: \u0026#34;工程师\u0026#34;, \u0026#34;desc\u0026#34;: \u0026#34;开发\u0026#34; } resp: { \u0026#34;_index\u0026#34;: \u0026#34;accounts222\u0026#34;, \u0026#34;_type\u0026#34;: \u0026#34;_doc\u0026#34;, \u0026#34;_id\u0026#34;: \u0026#34;1\u0026#34;, \u0026#34;_version\u0026#34;: 1, \u0026#34;result\u0026#34;: \u0026#34;created\u0026#34;, \u0026#34;_shards\u0026#34;: { \u0026#34;total\u0026#34;: 2, \u0026#34;successful\u0026#34;: 1, \u0026#34;failed\u0026#34;: 0 }, \u0026#34;_seq_no\u0026#34;: 1, \u0026#34;_primary_term\u0026#34;: 1 } 查看指定index所有doc\nurl：{{localhost}}:9200/accounts222/_search body(也可以不指定)：{ \u0026#34;query\u0026#34;:{ \u0026#34;match_all\u0026#34;:{} } } resp:{ \u0026#34;took\u0026#34;: 1, \u0026#34;timed_out\u0026#34;: false, \u0026#34;_shards\u0026#34;: { \u0026#34;total\u0026#34;: 1, \u0026#34;successful\u0026#34;: 1, \u0026#34;skipped\u0026#34;: 0, \u0026#34;failed\u0026#34;: 0 }, \u0026#34;hits\u0026#34;: { \u0026#34;total\u0026#34;: { \u0026#34;value\u0026#34;: 2, \u0026#34;relation\u0026#34;: \u0026#34;eq\u0026#34; }, \u0026#34;max_score\u0026#34;: 1, \u0026#34;hits\u0026#34;: [ { \u0026#34;_index\u0026#34;: \u0026#34;accounts222\u0026#34;, \u0026#34;_type\u0026#34;: \u0026#34;_doc\u0026#34;, \u0026#34;_id\u0026#34;: \u0026#34;E83dxHsBx8UYn7wDPx-g\u0026#34;, \u0026#34;_score\u0026#34;: 1, \u0026#34;_source\u0026#34;: { \u0026#34;user\u0026#34;: \u0026#34;张三\u0026#34;, \u0026#34;title\u0026#34;: \u0026#34;工程师\u0026#34;, \u0026#34;desc\u0026#34;: \u0026#34;数据库管理\u0026#34; } }, { \u0026#34;_index\u0026#34;: \u0026#34;accounts222\u0026#34;, \u0026#34;_type\u0026#34;: \u0026#34;_doc\u0026#34;, \u0026#34;_id\u0026#34;: \u0026#34;1\u0026#34;, \u0026#34;_score\u0026#34;: 1, \u0026#34;_source\u0026#34;: { \u0026#34;user\u0026#34;: \u0026#34;李四\u0026#34;, \u0026#34;title\u0026#34;: \u0026#34;工程师\u0026#34;, \u0026#34;desc\u0026#34;: \u0026#34;开发\u0026#34; } } ] } } 按照id查询index下指定文档\nurl:{{localhost}}:9200/accounts222/_doc/1 resp: 未找到情况 { \u0026#34;_index\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;_type\u0026#34;: \u0026#34;_doc\u0026#34;, \u0026#34;_id\u0026#34;: \u0026#34;1\u0026#34;, \u0026#34;found\u0026#34;: false } 查找到 { \u0026#34;_index\u0026#34;: \u0026#34;accounts222\u0026#34;, \u0026#34;_type\u0026#34;: \u0026#34;_doc\u0026#34;, \u0026#34;_id\u0026#34;: \u0026#34;1\u0026#34;, \u0026#34;_version\u0026#34;: 2, \u0026#34;_seq_no\u0026#34;: 2, \u0026#34;_primary_term\u0026#34;: 1, \u0026#34;found\u0026#34;: true, \u0026#34;_source\u0026#34;: { \u0026#34;user\u0026#34;: \u0026#34;李四\u0026#34;, \u0026#34;title\u0026#34;: \u0026#34;工程师\u0026#34;, \u0026#34;desc\u0026#34;: \u0026#34;开发\u0026#34; } } 修改文档\nurl:{{localhost}}:9200/accounts222/_doc/1 #如果指定的filed比mapping的字段少，那么其余字段都会被置空 body:{ \u0026#34;user\u0026#34;: \u0026#34;lisi\u0026#34;, \u0026#34;title\u0026#34;: \u0026#34;经理\u0026#34;, \u0026#34;desc\u0026#34;: \u0026#34;男\u0026#34; } resp:{ \u0026#34;_index\u0026#34;: \u0026#34;accounts222\u0026#34;, \u0026#34;_type\u0026#34;: \u0026#34;_doc\u0026#34;, \u0026#34;_id\u0026#34;: \u0026#34;1\u0026#34;, \u0026#34;_version\u0026#34;: 3, \u0026#34;result\u0026#34;: \u0026#34;updated\u0026#34;, \u0026#34;_shards\u0026#34;: { \u0026#34;total\u0026#34;: 2, \u0026#34;successful\u0026#34;: 1, \u0026#34;failed\u0026#34;: 0 }, \u0026#34;_seq_no\u0026#34;: 3, \u0026#34;_primary_term\u0026#34;: 1 } 修改文档单个字段\nurl:{{localhost}}:9200/accounts222/_update/1 body:{ \u0026#34;doc\u0026#34;:{ \u0026#34;user\u0026#34;:\u0026#34;李四\u0026#34; } } resp:{ \u0026#34;_index\u0026#34;: \u0026#34;accounts222\u0026#34;, \u0026#34;_type\u0026#34;: \u0026#34;_doc\u0026#34;, \u0026#34;_id\u0026#34;: \u0026#34;1\u0026#34;, \u0026#34;_version\u0026#34;: 4, \u0026#34;result\u0026#34;: \u0026#34;updated\u0026#34;, \u0026#34;_shards\u0026#34;: { \u0026#34;total\u0026#34;: 2, \u0026#34;successful\u0026#34;: 1, \u0026#34;failed\u0026#34;: 0 }, \u0026#34;_seq_no\u0026#34;: 4, \u0026#34;_primary_term\u0026#34;: 1 } 删除文档\nurl:{{localhost}}:9200/accounts222/_doc/E83dxHsBx8UYn7wDPx-g resp:{ \u0026#34;_index\u0026#34;: \u0026#34;accounts222\u0026#34;, \u0026#34;_type\u0026#34;: \u0026#34;_doc\u0026#34;, \u0026#34;_id\u0026#34;: \u0026#34;E83dxHsBx8UYn7wDPx-g\u0026#34;, \u0026#34;_version\u0026#34;: 2, \u0026#34;result\u0026#34;: \u0026#34;deleted\u0026#34;, \u0026#34;_shards\u0026#34;: { \u0026#34;total\u0026#34;: 2, \u0026#34;successful\u0026#34;: 1, \u0026#34;failed\u0026#34;: 0 }, \u0026#34;_seq_no\u0026#34;: 6, \u0026#34;_primary_term\u0026#34;: 1 } 但条件查询,默认一次返回10条记录，可以通过size指定,可以通过from指定偏移量\nurl:{{localhost}}:9200/accounts222/_doc/_search或{{localhost}}:9200/accounts222/_search body:{ \u0026#34;query\u0026#34;:{ \u0026#34;match\u0026#34;:{ \u0026#34;user\u0026#34;: \u0026#34;张\u0026#34; } }, \u0026#34;size\u0026#34;: 5, \u0026#34;from\u0026#34;: 5 } resp:{ \u0026#34;took\u0026#34;: 0, \u0026#34;timed_out\u0026#34;: false, \u0026#34;_shards\u0026#34;: { \u0026#34;total\u0026#34;: 1, \u0026#34;successful\u0026#34;: 1, \u0026#34;skipped\u0026#34;: 0, \u0026#34;failed\u0026#34;: 0 }, \u0026#34;hits\u0026#34;: { \u0026#34;total\u0026#34;: { \u0026#34;value\u0026#34;: 1, \u0026#34;relation\u0026#34;: \u0026#34;eq\u0026#34; }, \u0026#34;max_score\u0026#34;: 1.2576691, \u0026#34;hits\u0026#34;: [ { \u0026#34;_index\u0026#34;: \u0026#34;accounts222\u0026#34;, \u0026#34;_type\u0026#34;: \u0026#34;_doc\u0026#34;, \u0026#34;_id\u0026#34;: \u0026#34;G80hyXsBx8UYn7wDUh9z\u0026#34;, \u0026#34;_score\u0026#34;: 1.2576691, \u0026#34;_source\u0026#34;: { \u0026#34;user\u0026#34;: \u0026#34;张三\u0026#34;, \u0026#34;title\u0026#34;: \u0026#34;工程师\u0026#34;, \u0026#34;desc\u0026#34;: \u0026#34;数据库管理\u0026#34; } } ] } } #如果查询参数用多个且用空格分开，那么es认为它们是or的关系 body:{ \u0026#34;query\u0026#34;:{ \u0026#34;match\u0026#34;:{ \u0026#34;user\u0026#34;: \u0026#34;张 五\u0026#34; } }, \u0026#34;size\u0026#34;: 5, \u0026#34;from\u0026#34;: 5 } #如以上查询条件可匹配user为张三、王五的记录 #如果多个关键词是and的关系，那么要使用bool查询器 url:{{localhost}}:9200/accounts222/_search body:{ \u0026#34;query\u0026#34;: { \u0026#34;bool\u0026#34;:{ \u0026#34;must\u0026#34;: [ {\u0026#34;match\u0026#34;:{\u0026#34;user\u0026#34;:\u0026#34;张\u0026#34;}}, {\u0026#34;match\u0026#34;:{\u0026#34;desc\u0026#34;: \u0026#34;管理\u0026#34;}} ] } } } #以上查询条件可匹配user中包含张、desc中包含管理的记录 #精确匹配field url:{{localhost}}:9200/accounts222/_search body:{ \u0026#34;query\u0026#34;:{ \u0026#34;terms\u0026#34;: { \u0026#34;user\u0026#34;: [\u0026#34;tom\u0026#34;, \u0026#34;jack\u0026#34;] } } } resp: { \u0026#34;took\u0026#34;: 1, \u0026#34;timed_out\u0026#34;: false, \u0026#34;_shards\u0026#34;: { \u0026#34;total\u0026#34;: 1, \u0026#34;successful\u0026#34;: 1, \u0026#34;skipped\u0026#34;: 0, \u0026#34;failed\u0026#34;: 0 }, \u0026#34;hits\u0026#34;: { \u0026#34;total\u0026#34;: { \u0026#34;value\u0026#34;: 2, \u0026#34;relation\u0026#34;: \u0026#34;eq\u0026#34; }, \u0026#34;max_score\u0026#34;: 1, \u0026#34;hits\u0026#34;: [ { \u0026#34;_index\u0026#34;: \u0026#34;accounts222\u0026#34;, \u0026#34;_type\u0026#34;: \u0026#34;_doc\u0026#34;, \u0026#34;_id\u0026#34;: \u0026#34;1\u0026#34;, \u0026#34;_score\u0026#34;: 1, \u0026#34;_source\u0026#34;: { \u0026#34;user\u0026#34;: \u0026#34;jack\u0026#34;, \u0026#34;title\u0026#34;: \u0026#34;工程师\u0026#34;, \u0026#34;desc\u0026#34;: \u0026#34;开发\u0026#34; } }, { \u0026#34;_index\u0026#34;: \u0026#34;accounts222\u0026#34;, \u0026#34;_type\u0026#34;: \u0026#34;_doc\u0026#34;, \u0026#34;_id\u0026#34;: \u0026#34;2\u0026#34;, \u0026#34;_score\u0026#34;: 1, \u0026#34;_source\u0026#34;: { \u0026#34;user\u0026#34;: \u0026#34;tom\u0026#34;, \u0026#34;title\u0026#34;: \u0026#34;工程师\u0026#34;, \u0026#34;desc\u0026#34;: \u0026#34;开发\u0026#34; } } ] } } #精确匹配只适用于英文，中文只能用模糊匹配 { \u0026#34;query\u0026#34;:{ \u0026#34;match\u0026#34;:{\u0026#34;user\u0026#34;:\u0026#34;张三 王五\u0026#34;} } } 查询文档指定字段\nurl:{{localhost}}:9200/accounts222/_doc/_search body:{ \u0026#34;_source\u0026#34;:[\u0026#34;user\u0026#34;] } resp:{ \u0026#34;took\u0026#34;: 1, \u0026#34;timed_out\u0026#34;: false, \u0026#34;_shards\u0026#34;: { \u0026#34;total\u0026#34;: 1, \u0026#34;successful\u0026#34;: 1, \u0026#34;skipped\u0026#34;: 0, \u0026#34;failed\u0026#34;: 0 }, \u0026#34;hits\u0026#34;: { \u0026#34;total\u0026#34;: { \u0026#34;value\u0026#34;: 6, \u0026#34;relation\u0026#34;: \u0026#34;eq\u0026#34; }, \u0026#34;max_score\u0026#34;: 1, \u0026#34;hits\u0026#34;: [ { \u0026#34;_index\u0026#34;: \u0026#34;accounts222\u0026#34;, \u0026#34;_type\u0026#34;: \u0026#34;_doc\u0026#34;, \u0026#34;_id\u0026#34;: \u0026#34;G80hyXsBx8UYn7wDUh9z\u0026#34;, \u0026#34;_score\u0026#34;: 1, \u0026#34;_source\u0026#34;: { \u0026#34;user\u0026#34;: \u0026#34;张三\u0026#34; } }, { \u0026#34;_index\u0026#34;: \u0026#34;accounts222\u0026#34;, \u0026#34;_type\u0026#34;: \u0026#34;_doc\u0026#34;, \u0026#34;_id\u0026#34;: \u0026#34;HM0hyXsBx8UYn7wDlB8-\u0026#34;, \u0026#34;_score\u0026#34;: 1, \u0026#34;_source\u0026#34;: { \u0026#34;user\u0026#34;: \u0026#34;王五\u0026#34; } }, { \u0026#34;_index\u0026#34;: \u0026#34;accounts222\u0026#34;, \u0026#34;_type\u0026#34;: \u0026#34;_doc\u0026#34;, \u0026#34;_id\u0026#34;: \u0026#34;1\u0026#34;, \u0026#34;_score\u0026#34;: 1, \u0026#34;_source\u0026#34;: { \u0026#34;user\u0026#34;: \u0026#34;jack\u0026#34; } }, { \u0026#34;_index\u0026#34;: \u0026#34;accounts222\u0026#34;, \u0026#34;_type\u0026#34;: \u0026#34;_doc\u0026#34;, \u0026#34;_id\u0026#34;: \u0026#34;2\u0026#34;, \u0026#34;_score\u0026#34;: 1, \u0026#34;_source\u0026#34;: { \u0026#34;user\u0026#34;: \u0026#34;tom\u0026#34; } }, { \u0026#34;_index\u0026#34;: \u0026#34;accounts222\u0026#34;, \u0026#34;_type\u0026#34;: \u0026#34;_doc\u0026#34;, \u0026#34;_id\u0026#34;: \u0026#34;3\u0026#34;, \u0026#34;_score\u0026#34;: 1, \u0026#34;_source\u0026#34;: { \u0026#34;user\u0026#34;: \u0026#34;mary\u0026#34; } }, { \u0026#34;_index\u0026#34;: \u0026#34;accounts222\u0026#34;, \u0026#34;_type\u0026#34;: \u0026#34;_doc\u0026#34;, \u0026#34;_id\u0026#34;: \u0026#34;myd\u0026#34;, \u0026#34;_score\u0026#34;: 1, \u0026#34;_source\u0026#34;: { \u0026#34;user\u0026#34;: \u0026#34;myd\u0026#34; } } ] } } 按_id查询文档\nurl:{{localhost}}:9200/accounts222/_doc/1 resp:{ \u0026#34;_index\u0026#34;: \u0026#34;accounts222\u0026#34;, \u0026#34;_type\u0026#34;: \u0026#34;_doc\u0026#34;, \u0026#34;_id\u0026#34;: \u0026#34;1\u0026#34;, \u0026#34;_version\u0026#34;: 10, \u0026#34;_seq_no\u0026#34;: 13, \u0026#34;_primary_term\u0026#34;: 1, \u0026#34;found\u0026#34;: true, \u0026#34;_source\u0026#34;: { \u0026#34;user\u0026#34;: \u0026#34;jack\u0026#34;, \u0026#34;title\u0026#34;: \u0026#34;工程师\u0026#34;, \u0026#34;desc\u0026#34;: \u0026#34;开发\u0026#34; } } 高亮显示搜索词\nurl:{{localhost}}:9200/accounts222/_doc/_search body:{ \u0026#34;query\u0026#34;:{ \u0026#34;match\u0026#34;:{ \u0026#34;user\u0026#34;: \u0026#34;张\u0026#34; } }, \u0026#34;highlight\u0026#34;:{ \u0026#34;fields\u0026#34;:{ \u0026#34;user\u0026#34;:{} } } } resp:{ \u0026#34;took\u0026#34;: 74, \u0026#34;timed_out\u0026#34;: false, \u0026#34;_shards\u0026#34;: { \u0026#34;total\u0026#34;: 1, \u0026#34;successful\u0026#34;: 1, \u0026#34;skipped\u0026#34;: 0, \u0026#34;failed\u0026#34;: 0 }, \u0026#34;hits\u0026#34;: { \u0026#34;total\u0026#34;: { \u0026#34;value\u0026#34;: 1, \u0026#34;relation\u0026#34;: \u0026#34;eq\u0026#34; }, \u0026#34;max_score\u0026#34;: 1.5108216, \u0026#34;hits\u0026#34;: [ { \u0026#34;_index\u0026#34;: \u0026#34;accounts222\u0026#34;, \u0026#34;_type\u0026#34;: \u0026#34;_doc\u0026#34;, \u0026#34;_id\u0026#34;: \u0026#34;G80hyXsBx8UYn7wDUh9z\u0026#34;, \u0026#34;_score\u0026#34;: 1.5108216, \u0026#34;_source\u0026#34;: { \u0026#34;user\u0026#34;: \u0026#34;张三\u0026#34;, \u0026#34;title\u0026#34;: \u0026#34;工程师\u0026#34;, \u0026#34;desc\u0026#34;: \u0026#34;数据库管理\u0026#34; }, \u0026#34;highlight\u0026#34;: { \u0026#34;user\u0026#34;: [ \u0026#34;\u0026lt;em\u0026gt;张\u0026lt;/em\u0026gt;三\u0026#34; ] } } ] } } 短语查询(phrase search)\n#针对英文有效，中文情况下无效 url:{{localhost}}:9200/accounts222/_doc/_search body:{ \u0026#34;query\u0026#34;:{ \u0026#34;match_phrase\u0026#34;:{ \u0026#34;user\u0026#34;:\u0026#34;tom\u0026#34; } } } resp:{ \u0026#34;took\u0026#34;: 0, \u0026#34;timed_out\u0026#34;: false, \u0026#34;_shards\u0026#34;: { \u0026#34;total\u0026#34;: 1, \u0026#34;successful\u0026#34;: 1, \u0026#34;skipped\u0026#34;: 0, \u0026#34;failed\u0026#34;: 0 }, \u0026#34;hits\u0026#34;: { \u0026#34;total\u0026#34;: { \u0026#34;value\u0026#34;: 1, \u0026#34;relation\u0026#34;: \u0026#34;eq\u0026#34; }, \u0026#34;max_score\u0026#34;: 1.4417952, \u0026#34;hits\u0026#34;: [ { \u0026#34;_index\u0026#34;: \u0026#34;accounts222\u0026#34;, \u0026#34;_type\u0026#34;: \u0026#34;_doc\u0026#34;, \u0026#34;_id\u0026#34;: \u0026#34;2\u0026#34;, \u0026#34;_score\u0026#34;: 1.4417952, \u0026#34;_source\u0026#34;: { \u0026#34;user\u0026#34;: \u0026#34;tom\u0026#34;, \u0026#34;title\u0026#34;: \u0026#34;工程师\u0026#34;, \u0026#34;desc\u0026#34;: \u0026#34;开发\u0026#34; } } ] } } 条件删除文档\nurl:{{localhost}}:9200/accounts222/_doc/_delete_by_query\tpost body:{ \u0026#34;query\u0026#34;:{ \u0026#34;match\u0026#34;:{ \u0026#34;user\u0026#34;:\u0026#34;myd\u0026#34; } } } resp:{ \u0026#34;took\u0026#34;: 11, \u0026#34;timed_out\u0026#34;: false, \u0026#34;total\u0026#34;: 1, \u0026#34;deleted\u0026#34;: 1, \u0026#34;batches\u0026#34;: 1, \u0026#34;version_conflicts\u0026#34;: 0, \u0026#34;noops\u0026#34;: 0, \u0026#34;retries\u0026#34;: { \u0026#34;bulk\u0026#34;: 0, \u0026#34;search\u0026#34;: 0 }, \u0026#34;throttled_millis\u0026#34;: 0, \u0026#34;requests_per_second\u0026#34;: -1, \u0026#34;throttled_until_millis\u0026#34;: 0, \u0026#34;failures\u0026#34;: [] } 路径通配符,通配符支持*和？*匹配任意多字符包括空字符，?只能匹配一个字符\nurl:{{localhost}}:9200/account*/_doc/_search\tget resp:{ \u0026#34;took\u0026#34;: 1, \u0026#34;timed_out\u0026#34;: false, \u0026#34;_shards\u0026#34;: { \u0026#34;total\u0026#34;: 2, \u0026#34;successful\u0026#34;: 2, \u0026#34;skipped\u0026#34;: 0, \u0026#34;failed\u0026#34;: 0 }, \u0026#34;hits\u0026#34;: { \u0026#34;total\u0026#34;: { \u0026#34;value\u0026#34;: 6, \u0026#34;relation\u0026#34;: \u0026#34;eq\u0026#34; }, \u0026#34;max_score\u0026#34;: 1, \u0026#34;hits\u0026#34;: [ { \u0026#34;_index\u0026#34;: \u0026#34;account\u0026#34;, \u0026#34;_type\u0026#34;: \u0026#34;_doc\u0026#34;, \u0026#34;_id\u0026#34;: \u0026#34;Hc3YznsBx8UYn7wDPB9x\u0026#34;, \u0026#34;_score\u0026#34;: 1, \u0026#34;_source\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;myd\u0026#34;, \u0026#34;age\u0026#34;: 20 } }, { \u0026#34;_index\u0026#34;: \u0026#34;accounts222\u0026#34;, \u0026#34;_type\u0026#34;: \u0026#34;_doc\u0026#34;, \u0026#34;_id\u0026#34;: \u0026#34;G80hyXsBx8UYn7wDUh9z\u0026#34;, \u0026#34;_score\u0026#34;: 1, \u0026#34;_source\u0026#34;: { \u0026#34;user\u0026#34;: \u0026#34;张三\u0026#34;, \u0026#34;title\u0026#34;: \u0026#34;工程师\u0026#34;, \u0026#34;desc\u0026#34;: \u0026#34;数据库管理\u0026#34; } }, { \u0026#34;_index\u0026#34;: \u0026#34;accounts222\u0026#34;, \u0026#34;_type\u0026#34;: \u0026#34;_doc\u0026#34;, \u0026#34;_id\u0026#34;: \u0026#34;HM0hyXsBx8UYn7wDlB8-\u0026#34;, \u0026#34;_score\u0026#34;: 1, \u0026#34;_source\u0026#34;: { \u0026#34;user\u0026#34;: \u0026#34;王五\u0026#34;, \u0026#34;title\u0026#34;: \u0026#34;经理\u0026#34;, \u0026#34;desc\u0026#34;: \u0026#34;manager\u0026#34; } }, { \u0026#34;_index\u0026#34;: \u0026#34;accounts222\u0026#34;, \u0026#34;_type\u0026#34;: \u0026#34;_doc\u0026#34;, \u0026#34;_id\u0026#34;: \u0026#34;1\u0026#34;, \u0026#34;_score\u0026#34;: 1, \u0026#34;_source\u0026#34;: { \u0026#34;user\u0026#34;: \u0026#34;jack\u0026#34;, \u0026#34;title\u0026#34;: \u0026#34;工程师\u0026#34;, \u0026#34;desc\u0026#34;: \u0026#34;开发\u0026#34; } }, { \u0026#34;_index\u0026#34;: \u0026#34;accounts222\u0026#34;, \u0026#34;_type\u0026#34;: \u0026#34;_doc\u0026#34;, \u0026#34;_id\u0026#34;: \u0026#34;2\u0026#34;, \u0026#34;_score\u0026#34;: 1, \u0026#34;_source\u0026#34;: { \u0026#34;user\u0026#34;: \u0026#34;tom\u0026#34;, \u0026#34;title\u0026#34;: \u0026#34;工程师\u0026#34;, \u0026#34;desc\u0026#34;: \u0026#34;开发\u0026#34; } }, { \u0026#34;_index\u0026#34;: \u0026#34;accounts222\u0026#34;, \u0026#34;_type\u0026#34;: \u0026#34;_doc\u0026#34;, \u0026#34;_id\u0026#34;: \u0026#34;3\u0026#34;, \u0026#34;_score\u0026#34;: 1, \u0026#34;_source\u0026#34;: { \u0026#34;user\u0026#34;: \u0026#34;mary\u0026#34;, \u0026#34;title\u0026#34;: \u0026#34;工程师\u0026#34;, \u0026#34;desc\u0026#34;: \u0026#34;开发\u0026#34; } } ] } } 查询条件通配符\nurl:{{localhost}}:9200/account/_doc/_search\tget body:{ \u0026#34;query\u0026#34;:{ \u0026#34;wildcard\u0026#34;:{ \u0026#34;name\u0026#34;: \u0026#34;m*\u0026#34; } } } resp:{ \u0026#34;took\u0026#34;: 13, \u0026#34;timed_out\u0026#34;: false, \u0026#34;_shards\u0026#34;: { \u0026#34;total\u0026#34;: 1, \u0026#34;successful\u0026#34;: 1, \u0026#34;skipped\u0026#34;: 0, \u0026#34;failed\u0026#34;: 0 }, \u0026#34;hits\u0026#34;: { \u0026#34;total\u0026#34;: { \u0026#34;value\u0026#34;: 2, \u0026#34;relation\u0026#34;: \u0026#34;eq\u0026#34; }, \u0026#34;max_score\u0026#34;: 1, \u0026#34;hits\u0026#34;: [ { \u0026#34;_index\u0026#34;: \u0026#34;account\u0026#34;, \u0026#34;_type\u0026#34;: \u0026#34;_doc\u0026#34;, \u0026#34;_id\u0026#34;: \u0026#34;Hc3YznsBx8UYn7wDPB9x\u0026#34;, \u0026#34;_score\u0026#34;: 1, \u0026#34;_source\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;myd\u0026#34;, \u0026#34;age\u0026#34;: 20 } }, { \u0026#34;_index\u0026#34;: \u0026#34;account\u0026#34;, \u0026#34;_type\u0026#34;: \u0026#34;_doc\u0026#34;, \u0026#34;_id\u0026#34;: \u0026#34;Hs3bznsBx8UYn7wD9x93\u0026#34;, \u0026#34;_score\u0026#34;: 1, \u0026#34;_source\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;mary\u0026#34;, \u0026#34;age\u0026#34;: 30 } } ] } } 聚合查询\n#查询最大值 url:{{localhost}}:9200/account/_doc/_search\tget #\u0026#34;size\u0026#34;: 0去除hit.hit中的数据 body:{ \u0026#34;aggs\u0026#34;:{ \u0026#34;max_age\u0026#34;:{ \u0026#34;max\u0026#34;:{ \u0026#34;field\u0026#34;:\u0026#34;age\u0026#34; } } }, \u0026#34;size\u0026#34;: 0 } resp:{ \u0026#34;took\u0026#34;: 1, \u0026#34;timed_out\u0026#34;: false, \u0026#34;_shards\u0026#34;: { \u0026#34;total\u0026#34;: 1, \u0026#34;successful\u0026#34;: 1, \u0026#34;skipped\u0026#34;: 0, \u0026#34;failed\u0026#34;: 0 }, \u0026#34;hits\u0026#34;: { \u0026#34;total\u0026#34;: { \u0026#34;value\u0026#34;: 5, \u0026#34;relation\u0026#34;: \u0026#34;eq\u0026#34; }, \u0026#34;max_score\u0026#34;: null, \u0026#34;hits\u0026#34;: [] }, \u0026#34;aggregations\u0026#34;: { \u0026#34;max_age\u0026#34;: { \u0026#34;value\u0026#34;: 30 } } } go api操作 package main import ( \u0026#34;context\u0026#34; \u0026#34;encoding/json\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;reflect\u0026#34; \u0026#34;time\u0026#34; es \u0026#34;github.com/olivere/elastic/v7\u0026#34; ) type Tweet struct { User string `json:\u0026#34;user\u0026#34;` Message string `json:\u0026#34;message\u0026#34;` Retweets int `json:\u0026#34;retweets\u0026#34;` Image string `json:\u0026#34;image,omitempty\u0026#34;` Created time.Time `json:\u0026#34;created,omitempty\u0026#34;` Tags []string `json:\u0026#34;tags,omitempty\u0026#34;` Location string `json:\u0026#34;location,omitempty\u0026#34;` Suggest *es.SuggestField `json:\u0026#34;suggest_field,omitempty\u0026#34;` } const mapping = ` { \u0026#34;settings\u0026#34;:{ \u0026#34;number_of_shards\u0026#34;: 1, \u0026#34;number_of_replicas\u0026#34;: 0 }, \u0026#34;mappings\u0026#34;:{ \u0026#34;properties\u0026#34;:{ \u0026#34;user\u0026#34;:{ \u0026#34;type\u0026#34;:\u0026#34;keyword\u0026#34; }, \u0026#34;message\u0026#34;:{ \u0026#34;type\u0026#34;:\u0026#34;text\u0026#34;, \u0026#34;store\u0026#34;: true, \u0026#34;fielddata\u0026#34;: true }, \u0026#34;image\u0026#34;:{ \u0026#34;type\u0026#34;:\u0026#34;keyword\u0026#34; }, \u0026#34;created\u0026#34;:{ \u0026#34;type\u0026#34;:\u0026#34;date\u0026#34; }, \u0026#34;tags\u0026#34;:{ \u0026#34;type\u0026#34;:\u0026#34;keyword\u0026#34; }, \u0026#34;location\u0026#34;:{ \u0026#34;type\u0026#34;:\u0026#34;geo_point\u0026#34; }, \u0026#34;suggest_field\u0026#34;:{ \u0026#34;type\u0026#34;:\u0026#34;completion\u0026#34; } } } }` func main() { host := \u0026#34;http://139.198.11.13:9200\u0026#34; client, err := es.NewClient( es.SetURL(host), es.SetSniff(false), es.SetHealthcheck(false), ) // client, err := es.NewClientFromConfig(\u0026amp;config.Config{ // URL: \u0026#34;http://139.198.11.13:9200\u0026#34;, // }) if err != nil { panic(err) } fmt.Println(\u0026#34;connect to es success.\u0026#34;) version, err := client.ElasticsearchVersion(host) if err != nil { panic(err) } fmt.Println(\u0026#34;version:\u0026#34;, version) ctx := context.Background() res, code, err := client.Ping(host).Do(ctx) if err != nil { panic(err) } fmt.Printf(\u0026#34;version:%s \\n code:%d \\n\u0026#34;, res.Version.Number, code) exists, err := client.IndexExists(\u0026#34;twitter\u0026#34;).Do(ctx) if err != nil { panic(err) } fmt.Println(\u0026#34;twitter exists:\u0026#34;, exists) if !exists { res, err := client.CreateIndex(\u0026#34;twitter\u0026#34;).BodyString(mapping).Do(ctx) if err != nil { panic(err) } if !res.Acknowledged { fmt.Println(\u0026#34;create index twitter faild\u0026#34;) } else { fmt.Println(\u0026#34;create index twitter success\u0026#34;) } } //add a doc to twitter use json tweet1 := Tweet{User: \u0026#34;olivere\u0026#34;, Message: \u0026#34;Take Five\u0026#34;, Retweets: 0} put1, err := client.Index().Index(\u0026#34;twitter\u0026#34;).BodyJson(tweet1).Id(\u0026#34;1\u0026#34;).Do(ctx) if err != nil { panic(err) } fmt.Printf(\u0026#34;add tweet %s to index %s type is %s \\n\u0026#34;, put1.Id, put1.Index, put1.Type) //add a doc to twitter use string tweet2 := `{\u0026#34;user\u0026#34; : \u0026#34;olivere\u0026#34;, \u0026#34;message\u0026#34; : \u0026#34;aaa\u0026#34;}` put2, err := client.Index().Index(\u0026#34;twitter\u0026#34;).Type(\u0026#34;_doc\u0026#34;).Id(\u0026#34;2\u0026#34;).BodyString(tweet2).Do(ctx) if err != nil { panic(err) } fmt.Printf(\u0026#34;add tweet %s to index %s type is %s \\n\u0026#34;, put2.Id, put2.Index, put2.Type) //get doc tweet specified id get1, err := client.Get().Index(\u0026#34;twitter\u0026#34;).Type(\u0026#34;_doc\u0026#34;).Id(\u0026#34;1\u0026#34;).Do(ctx) if err != nil { panic(err) } if get1.Found { fmt.Printf(\u0026#34;doc %s in index %s founded, version is %d, doc: %s \\n\u0026#34;, get1.Id, get1.Index, get1.Version, get1.Source) } else { fmt.Println(\u0026#34;doc 1 in index twitter not found\u0026#34;) } termQ := es.NewTermQuery(\u0026#34;user\u0026#34;, \u0026#34;olivere\u0026#34;) search1, err := client.Search().Index(\u0026#34;twitter\u0026#34;).Query(termQ).From(1).Size(1).Pretty(true).Do(ctx) if err != nil { panic(err) } fmt.Printf(\u0026#34;term query took %d ms \\n\u0026#34;, search1.TookInMillis) var ttyp Tweet for _, item := range search1.Each(reflect.TypeOf(ttyp)) { if t, ok := item.(Tweet); ok { fmt.Printf(\u0026#34;Tweet by %s: %s \\n\u0026#34;, t.User, t.Message) fmt.Printf(\u0026#34;---Tweet: %#v \\n\u0026#34;, t) } } fmt.Printf(\u0026#34;found a total of %d tweets \\n\u0026#34;, search1.TotalHits()) if search1.Hits.TotalHits.Value \u0026gt; 0 { fmt.Printf(\u0026#34;found a total of %d tweets \\n\u0026#34;, search1.Hits.TotalHits.Value) for _, hit := range search1.Hits.Hits { var t Tweet err := json.Unmarshal(hit.Source, \u0026amp;t) if err != nil { panic(err) } fmt.Printf(\u0026#34;tweet by %s : %s \\n\u0026#34;, t.User, t.Message) fmt.Printf(\u0026#34;===Tweet: %#v \\n\u0026#34;, t) } } else { fmt.Println(\u0026#34;found no tweets\u0026#34;) } //update doc update1, err := client.Update().Index(\u0026#34;twitter\u0026#34;).Id(\u0026#34;1\u0026#34;).Script(es.NewScriptInline(\u0026#34;ctx._source.retweets += params.num\u0026#34;).Lang(\u0026#34;painless\u0026#34;).Param(\u0026#34;num\u0026#34;, 1)). Upsert(map[string]interface{}{\u0026#34;retweets\u0026#34;: 5}).Do(ctx) if err != nil { panic(err) } fmt.Printf(\u0026#34;new version of tweet %q is now %d\\n\u0026#34;, update1.Id, update1.Version) //del doc del1, err := client.Delete().Index(\u0026#34;twitter\u0026#34;).Id(\u0026#34;1\u0026#34;).Do(ctx) if err != nil { panic(err) } fmt.Printf(\u0026#34;delete status: %d \\n\u0026#34;, del1.Status) } es中的shard(primary shard)和replica(replica shard) es是集群工作的，如果只有一台机器的话那么整个集群就只有这一台，es集群按照index来划分数据，在创建index的时候如果什么参数都不指定，那么默认创建一个shard(primary shard)和1个replica(replica shard),但是一个shard对应的replica不能在同一台机器上，如果是一台机器的集群，那么replica有没有机器去分配，那么该index的状态就会是yellow,一个index的状态由green、yellow、red三种，green状态是index的所有shard和replica都正常，yellow状态是index的所有shard正常，部分或全部replica不正常，red状态则是有shard不正常\n在创建index的时候可以指定shard、replicad 的个数，使用\n{ \u0026#34;settings\u0026#34;:{ \u0026#34;number_of_shards\u0026#34;:2, \u0026#34;number_of_replicas\u0026#34;:1 } } 这里要注意的是number_of_replicas的数量不是总的replica数量，replica是针对shard而言的，也就是这里的number_of_replicas是指每个shard有多少个replica\n如果在创建index时指定了多个shard而es集群只有单台机器，那么有所的shard会存在同一台机器上，当有新的机器加入es集群，这些shard会移动到新加入的es节点上\n一个index的多个replica不能在es集群的同一个节点上\nes中创建doc时存储路由 在es中一个index有多个primary，每个doc都是存储到一个指定的primary，那么在创建doc的时候是如何选择该doc是要保存在那个primary中的，在es中选择doc存储的primary是通过routing来决定的，默认情况下routing为_id，具体计算存那个primary的规则为：hash(routing) % number_primarys 来得到该文档存放的primary下标，在创建doc的时候也可以指定routing来手动指定要存放的位置\nurl:{{localhost}}:9200/testroute1/_doc/2?routing=b\tPUT body:{ \u0026#34;name\u0026#34;:\u0026#34;b\u0026#34; } resp:{ \u0026#34;_index\u0026#34;: \u0026#34;testroute1\u0026#34;, \u0026#34;_type\u0026#34;: \u0026#34;_doc\u0026#34;, \u0026#34;_id\u0026#34;: \u0026#34;2\u0026#34;, \u0026#34;_version\u0026#34;: 1, \u0026#34;result\u0026#34;: \u0026#34;created\u0026#34;, \u0026#34;_shards\u0026#34;: { \u0026#34;total\u0026#34;: 1, \u0026#34;successful\u0026#34;: 1, \u0026#34;failed\u0026#34;: 0 }, \u0026#34;_seq_no\u0026#34;: 0, \u0026#34;_primary_term\u0026#34;: 1 } 查询doc并指定routing\nurl:{{localhost}}:9200/testroute1/_doc/_search?routing=a\tGET resp:{ \u0026#34;took\u0026#34;: 422, \u0026#34;timed_out\u0026#34;: false, \u0026#34;_shards\u0026#34;: { \u0026#34;total\u0026#34;: 1, \u0026#34;successful\u0026#34;: 1, \u0026#34;skipped\u0026#34;: 0, \u0026#34;failed\u0026#34;: 0 }, \u0026#34;hits\u0026#34;: { \u0026#34;total\u0026#34;: { \u0026#34;value\u0026#34;: 1, \u0026#34;relation\u0026#34;: \u0026#34;eq\u0026#34; }, \u0026#34;max_score\u0026#34;: 1, \u0026#34;hits\u0026#34;: [ { \u0026#34;_index\u0026#34;: \u0026#34;testroute1\u0026#34;, \u0026#34;_type\u0026#34;: \u0026#34;_doc\u0026#34;, \u0026#34;_id\u0026#34;: \u0026#34;1\u0026#34;, \u0026#34;_score\u0026#34;: 1, \u0026#34;_routing\u0026#34;: \u0026#34;a\u0026#34;, \u0026#34;_source\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;a\u0026#34; } } ] } } url:{{localhost}}:9200/testroute1/_doc/2?routing=a GET resp:{ \u0026#34;_index\u0026#34;: \u0026#34;testroute1\u0026#34;, \u0026#34;_type\u0026#34;: \u0026#34;_doc\u0026#34;, \u0026#34;_id\u0026#34;: \u0026#34;2\u0026#34;, \u0026#34;found\u0026#34;: false } 创建index的时候指定doc增删改查都必须带上routing\nurl:{{localhost}}:9200/testroute2\tPUT body:{ \u0026#34;settings\u0026#34;:{ \u0026#34;number_of_shards\u0026#34;:2, \u0026#34;number_of_replicas\u0026#34;:2 }, \u0026#34;mappings\u0026#34;:{ \u0026#34;_routing\u0026#34;:{ \u0026#34;required\u0026#34;:true } } } resp:{ \u0026#34;acknowledged\u0026#34;: true, \u0026#34;shards_acknowledged\u0026#34;: true, \u0026#34;index\u0026#34;: \u0026#34;testroute2\u0026#34; } ","permalink":"https://moyuduo.github.io/posts/elasticsearch%E7%9B%B8%E5%85%B3/","summary":"elasticsearch相关 安装 保证已有java环境\n下载安装包\nmkdir -p /opt/elasticsearch cd /opt/elasticsearch #从https://www.elastic.co/cn/downloads/elasticsearch获取es安装包路径 curl -O https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.14.1-linux-x86_64.tar.gz 解压\ntar -zxvf elasticsearch-7.14.1-linux-x86_64.tar.gz 启动\ncd elasticsearch-7.14.1/bin/ ./elasticsearch #出现以下错误 java.lang.RuntimeException: can not run elasticsearch as root #第一步，添加es组及该组下的es用户 groupadd es useradd es -g es #出现以下错误 useradd: cannot open /etc/passwd #查看该文件的权限 lsattr /etc/passwd -----a-------e-- /etc/passwd #去除掉该文件的a权限 chattr -a /etc/passwd #再次尝试添加用户 useradd es -g es #出现以下错误，解决思路和上面类似 useradd: cannot open /etc/shadow lsattr /etc/shadow -----a-------e-- /etc/shadow chattr -a /etc/shadow #再次创建用户就成功了 useradd es -g es #第二部，更改elasticsearch文件夹的权限为es组下的es用户 chown -R es:es /opt/elasticsearch #第三步，切换到es用户再启动es su es .","title":"elasticsearch相关"},{"content":"equals和hashCode方法 equals 我们知道equals是用来比较两个对象是否相等的，比如我们常用的String.equals方法 @Test public void test() { String str1=new String(\u0026#34;abc\u0026#34;); String str2=new String(\u0026#34;abc\u0026#34;); boolean equals = str1.equals(str2); System.out.println(equals);//true } hashCode方法 hashCode方法是通过一定的算法得到一个hash值，一般配合散列集合一起使用，如HashMap、HashSet都是不可以存放重复元素的，那么当容器中元素个数很多时，你要添加一个元素时，难道一个一个去equals比较？当然这是可以的，但是难免效率很低，而HashMap和HashSet的底层都是使用数组+链表的方式实现的，这样有什么好处呢，当一个对象要加入集合，直接用hashCode进行一些运算得到保存的数组下标，再去数组下标对应的链表中一个一个元素比较（equals）,这样显然减少了比较次数，提高了效率\n那Object的hashCode方法的默认实现是怎样的呢？\npublic native int hashCode(); 可以看到它是一个本地方法，实际上Object的hashCode方法返回是元素的地址（不同的虚拟机可能不一样，但Hotspot的是）\nclass Emp{ String idCord; String name; int age; public Emp(String idCord, String name, int age) { super(); this.idCord = idCord; this.name = name; this.age = age; } } @Test public void test2() { Emp e=new Emp(\u0026#34;0101001\u0026#34;,\u0026#34;zhangsan\u0026#34;,20); System.out.println(e.hashCode());//1717159510 System.out.println(e);//com.moyuduo.test.Emp@6659c656 } 6659c656转换成十进制也就是1717159510\n哈希集合的使用 我们很多时候这样使用HashMap\n@Test public void test3() { HashMap\u0026lt;String,Emp\u0026gt; map=new HashMap\u0026lt;\u0026gt;(); map.put(new String(\u0026#34;zhangsan\u0026#34;), new Emp(\u0026#34;01001\u0026#34;,\u0026#34;zhangsan\u0026#34;,20)); map.put(new String(\u0026#34;lisi\u0026#34;), new Emp(\u0026#34;01002\u0026#34;,\u0026#34;lisi\u0026#34;,22)); map.put(new String(\u0026#34;zhangsan\u0026#34;), new Emp(\u0026#34;01003\u0026#34;,\u0026#34;zhangsan\u0026#34;,23)); Emp emp = map.get(\u0026#34;zhangsan\u0026#34;); System.out.println(emp);//Emp [idCord=01003, name=zhangsan, age=23] } 额？不对呀，编号为01001的张三呢？而且我们知道new出来的String的hashCode是地址一定是不相同的，那么为什么后一个张三还是把前一个张三覆盖了呢？\n是因为String重写了hashCode方法和equals方法\npublic int hashCode() { //默认为0 int h = hash; if (h == 0 \u0026amp;\u0026amp; value.length \u0026gt; 0) { char val[] = value; //一个一个遍历String的char[] for (int i = 0; i \u0026lt; value.length; i++) { //hash值等于当前字符前字符的hash*31+当前字符的Unicode h = 31 * h + val[i]; } hash = h; } return h; } public boolean equals(Object anObject) { //判断两个对象的地址是否相同 if (this == anObject) { return true; } //判断传入的对象是不是String类型 if (anObject instanceof String) { String anotherString = (String)anObject; int n = value.length; //判断两个String的char[]的长度是否一致 if (n == anotherString.value.length) { char v1[] = value; char v2[] = anotherString.value; int i = 0; //一个一个字符进行比较 while (n-- != 0) { if (v1[i] != v2[i]) return false; i++; } return true; } } return false; } 那么当我们使用自己的对象作为键时\n@Test public void test4() { HashMap\u0026lt;Emp,Integer\u0026gt; map=new HashMap\u0026lt;\u0026gt;();\tmap.put(new Emp(\u0026#34;01001\u0026#34;,\u0026#34;zhangsan\u0026#34;,20),6000); map.put(new Emp(\u0026#34;01002\u0026#34;,\u0026#34;lisi\u0026#34;,22),8000); Integer integer = map.get(new Emp(\u0026#34;01001\u0026#34;,\u0026#34;zhangsan\u0026#34;,20)); System.out.println(integer);//null } 可以看到输出的是null，这是为什么呢，就是因为我们自定义的类没有重新写hashCode方法，get的时候新new出来的Emp对象的hashCode（也就是地址）肯定和存的时候的hashCode不一样，所以拿不到，所以当我们自定义的类要使用散列集合存储时，一定要重写equals方法和hashCode方法\nHashMap的底层原理 为什么当我们要使用自定义对象作为key存放在HashMap中时，一定要重写equals和hashCode呢？\n我们去看看HashMap底层是怎么存键值对和得到值的\nHashMap的put方法\npublic V put(K key, V value) { return putVal(hash(key), key, value, false, true); } //计算键的hash static final int hash(Object key) { int h; //如果键为null那么hash为0，这也是为什么HashMap只能存放一个键为null的元素，否则hash为hashCode与上hashCode无符号右移16位 return (key == null) ? 0 : (h = key.hashCode()) ^ (h \u0026gt;\u0026gt;\u0026gt; 16); } final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) { Node\u0026lt;K,V\u0026gt;[] tab; Node\u0026lt;K,V\u0026gt; p; int n, i; //如果当前的Node数组还未初始化或长度为0 if ((tab = table) == null || (n = tab.length) == 0) //进行扩容 n = (tab = resize()).length; //节点存放的下标是数组长度-1与上键的hash if ((p = tab[i = (n - 1) \u0026amp; hash]) == null) //运算得到的下标的位置没有存放元素，那么直接保存 tab[i] = newNode(hash, key, value, null); else { Node\u0026lt;K,V\u0026gt; e; K k; if (p.hash == hash \u0026amp;\u0026amp; ((k = p.key) == key || (key != null \u0026amp;\u0026amp; key.equals(k)))) //如果下标位置元素的hash和键的hash相等并且下标元素的key和键的地址相同或equals那么直接覆盖 e = p; else if (p instanceof TreeNode) //如果下标元素位置存放的元素本来就是红黑色节点,那么按照红黑树的规则插入 e = ((TreeNode\u0026lt;K,V\u0026gt;)p).putTreeVal(this, tab, hash, key, value); else { //下标位置有元素而且还没转化为红黑树，说明是链表存储 for (int binCount = 0; ; ++binCount) { //让e指向链表下一个节点 if ((e = p.next) == null) {//当找到最后e等于null了说明链表中没有元素的key和当前插入的key相同 //直接把节点挂到链表尾 p.next = newNode(hash, key, value, null); if (binCount \u0026gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; } //如果找到已存入元素的key和插入key的hash相同并且两key地址相等或equals，那么e就是要替换的元素 if (e.hash == hash \u0026amp;\u0026amp; ((k = e.key) == key || (key != null \u0026amp;\u0026amp; key.equals(k)))) break; p = e; } } if (e != null) { // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) //替换旧值 e.value = value; afterNodeAccess(e); return oldValue; } } ++modCount; if (++size \u0026gt; threshold) //插入后元素大小超过阈值进行扩容 resize(); afterNodeInsertion(evict); return null; } HashMap的get方法\npublic V get(Object key) { Node\u0026lt;K,V\u0026gt; e; //如果通过key拿到的键值对节点为null就返回null，否则返回节点的value return (e = getNode(hash(key), key)) == null ? null : e.value; } final Node\u0026lt;K,V\u0026gt; getNode(int hash, Object key) { Node\u0026lt;K,V\u0026gt;[] tab; Node\u0026lt;K,V\u0026gt; first, e; int n; K k; //Node[]是否已经初始化并且长度\u0026gt;0并且通过hash运算得到的下标已经有元素 if ((tab = table) != null \u0026amp;\u0026amp; (n = tab.length) \u0026gt; 0 \u0026amp;\u0026amp; (first = tab[(n - 1) \u0026amp; hash]) != null) { //判断下标第一个位置节点的hash和查询key的hash一致并且两key地址一样或equals if (first.hash == hash \u0026amp;\u0026amp; // always check first node ((k = first.key) == key || (key != null \u0026amp;\u0026amp; key.equals(k)))) return first; //下标节点还有next if ((e = first.next) != null) { //节点是红黑树，那么按照红黑树的查找规则进行 if (first instanceof TreeNode) return ((TreeNode\u0026lt;K,V\u0026gt;)first).getTreeNode(hash, key); do { //是链表，那么依次遍历 if (e.hash == hash \u0026amp;\u0026amp; ((k = e.key) == key || (key != null \u0026amp;\u0026amp; key.equals(k)))) return e; } while ((e = e.next) != null); } } return null; } 可以看到存的时候是通过hashCode得到hash再用hash得到存放下标，然后存入键值对\n取的时候是通过hashCode得到hash再得到下标元素，下标元素再根据**hash\u0026amp;\u0026amp;（地址相等||equals）**得到键值对\nObject规范 说了这些再来说说Object规范\n两对象equals那么hashCode值一定要相同 两对象hashCode值相等，对象不一定equals，这主要是因为hashCode是根据对象的特征值生成的，hashCode的算法是程序员自己实现的，在某些情况下可能两对象在逻辑上也不同也能生成相同的hashCode equals和hashCode联系 当我们自定义类不需要充当key来在散列表中存储对象时，equals和hashCode根本没有关系，你也没必要重写hashCode方法 当我们会用自定义类充当key在散列表中存对象，这时候你一定要重写equals和hashCode ","permalink":"https://moyuduo.github.io/posts/equals%E5%92%8Chashcode%E6%96%B9%E6%B3%95/","summary":"equals和hashCode方法 equals 我们知道equals是用来比较两个对象是否相等的，比如我们常用的String.equals方法 @Test public void test() { String str1=new String(\u0026#34;abc\u0026#34;); String str2=new String(\u0026#34;abc\u0026#34;); boolean equals = str1.equals(str2); System.out.println(equals);//true } hashCode方法 hashCode方法是通过一定的算法得到一个hash值，一般配合散列集合一起使用，如HashMap、HashSet都是不可以存放重复元素的，那么当容器中元素个数很多时，你要添加一个元素时，难道一个一个去equals比较？当然这是可以的，但是难免效率很低，而HashMap和HashSet的底层都是使用数组+链表的方式实现的，这样有什么好处呢，当一个对象要加入集合，直接用hashCode进行一些运算得到保存的数组下标，再去数组下标对应的链表中一个一个元素比较（equals）,这样显然减少了比较次数，提高了效率\n那Object的hashCode方法的默认实现是怎样的呢？\npublic native int hashCode(); 可以看到它是一个本地方法，实际上Object的hashCode方法返回是元素的地址（不同的虚拟机可能不一样，但Hotspot的是）\nclass Emp{ String idCord; String name; int age; public Emp(String idCord, String name, int age) { super(); this.idCord = idCord; this.name = name; this.age = age; } } @Test public void test2() { Emp e=new Emp(\u0026#34;0101001\u0026#34;,\u0026#34;zhangsan\u0026#34;,20); System.out.println(e.hashCode());//1717159510 System.out.println(e);//com.moyuduo.test.Emp@6659c656 } 6659c656转换成十进制也就是1717159510\n哈希集合的使用 我们很多时候这样使用HashMap","title":"equals和hashCode方法"},{"content":"etcd docker起etcd docker run -d --name Etcd-server \\ -p 22379:2379 \\ -p 22380:2380 \\ --env ALLOW_NONE_AUTHENTICATION=yes \\ --env ETCD_LISTEN_CLIENT_URLS=http://0.0.0.0:2379 \\ bitnami/etcd:latest 连接远程 etcdctl --endpoints=http://192.168.12.223:2379 put /msg hello etcdctl --endpoints=http://192.168.12.223:2379 get --prefix \u0026#34;/\u0026#34; etcdctl --endpoints=http://192.168.14.102:2379 get --prefix \u0026#34;ruleV0.0.2/usr-wEL6MHRg/iot-rule-9bd4422e5d9a4b\u0026#34; ruleV0.0.2/usr-K0G9udc8 ruleV0.0.2/usr-wEL6MHRg ","permalink":"https://moyuduo.github.io/posts/etcd/","summary":"etcd docker起etcd docker run -d --name Etcd-server \\ -p 22379:2379 \\ -p 22380:2380 \\ --env ALLOW_NONE_AUTHENTICATION=yes \\ --env ETCD_LISTEN_CLIENT_URLS=http://0.0.0.0:2379 \\ bitnami/etcd:latest 连接远程 etcdctl --endpoints=http://192.168.12.223:2379 put /msg hello etcdctl --endpoints=http://192.168.12.223:2379 get --prefix \u0026#34;/\u0026#34; etcdctl --endpoints=http://192.168.14.102:2379 get --prefix \u0026#34;ruleV0.0.2/usr-wEL6MHRg/iot-rule-9bd4422e5d9a4b\u0026#34; ruleV0.0.2/usr-K0G9udc8 ruleV0.0.2/usr-wEL6MHRg ","title":"etcd"},{"content":"fabedge云边通信、边边通信 operator Operator组件通过监听node、svc、endpoint等k8s的资源为每个节点维护一个ConfigMap和Secret，其中ConfigMap中主要保存节点上svc、运行的pod等详细信息，Secret中则保存有fabedge如何创建隧道、和哪个node创建隧道以及创建隧道所需要的证书等信息，并实时为每个agent更新配置信息，并管理agent的生命周期。\nfunc (opts Options) initializeControllers(ctx context.Context) error { ... //获取edge node和解析community err := opts.recordEndpoints(ctx) if err != nil { log.Error(err, \u0026#34;failed to initialize allocator and store\u0026#34;) return err } //通过解析出的node 定时检查生成community和所有节点的信息保存到configmap getConnectorEndpoint, err := connectorctl.AddToManager(opts.Connector) if err != nil { log.Error(err, \u0026#34;failed to add communities controller to manager\u0026#34;) return err } opts.Agent.GetConnectorEndpoint = getConnectorEndpoint //创建agent启动需要的configmap(保存节点的ip、pod cidr、service pod对应关系)和secret(保存创建隧道锁需要的证书) if err = agentctl.AddToManager(opts.Agent); err != nil { log.Error(err, \u0026#34;failed to add agent controller to manager\u0026#34;) return err } //监听community资源的变化，维护保存的community信息 if err = cmmctl.AddToManager(cmmctl.Config{ Manager: opts.Manager, Store: opts.Store, }); err != nil { log.Error(err, \u0026#34;failed to add communities controller to manager\u0026#34;) return err } ... } operator主要做了4件事：\n通过label(适配不同的边缘极端平台label不一样)选择边缘节点、解析自定义资源community\n把边缘节点和community自定义资源保存到configmap中\n[root@k8s-node1 k8s-t]# k get configmap -n fabedge NAME DATA AGE connector-config 1 7d11h fabedge-agent-config-k8s-node2 2 7d11h fabedge-agent-config-openyurt-edge2 2 7d11h kube-root-ca.crt 1 7d11h [root@k8s-node1 k8s-t]# k describe configmap fabedge-agent-config-openyurt-edge2 -n fabedge Name: fabedge-agent-config-openyurt-edge2 Namespace: fabedge Labels: fabedge.io/app=fabedge-agent fabedge.io/created-by=fabedge-operator Annotations: \u0026lt;none\u0026gt; Data ==== services.yaml: ---- tunnels.yaml: ---- id: C=CN, O=fabedge.io, CN=openyurt-edge2 name: openyurt-edge2 publicAddresses: - 172.23.0.4 subnets: - 192.168.3.0/24 nodeSubnets: - 172.23.0.4 peers: - id: C=CN, O=fabedge.io, CN=cloud-connector name: cloud-connector publicAddresses: - 139.198.9.172 subnets: - 10.96.0.0/16 - 192.168.4.0/24 - 192.168.0.0/24 nodeSubnets: - 192.168.37.140 - 172.31.0.2 - id: C=CN, O=fabedge.io, CN=k8s-node2 name: k8s-node2 publicAddresses: - 172.31.0.3 subnets: - 192.168.1.0/24 nodeSubnets: - 172.31.0.3 Events: \u0026lt;none\u0026gt; 创建隧道锁需要的证书保存在secret中\n[root@k8s-node1 k8s-t]# k get secret -n fabedge NAME TYPE DATA AGE cert-token-fv6cf kubernetes.io/service-account-token 3 7d11h cloud-connector kubernetes.io/tls 4 7d11h default-token-zgj6d kubernetes.io/service-account-token 3 7d11h fabedge-agent-tls-k8s-node2 kubernetes.io/tls 4 7d11h fabedge-agent-tls-openyurt-edge2 kubernetes.io/tls 4 7d11h fabedge-ca Opaque 2 7d11h fabedge-operator-token-x5nkf kubernetes.io/service-account-token 3 7d11h sh.helm.release.v1.fabedge.v1 helm.sh/release.v1 1 7d11h [root@k8s-node1 k8s-t]# k describe secret fabedge-agent-tls-openyurt-edge2 -n fabedge Name: fabedge-agent-tls-openyurt-edge2 Namespace: fabedge Labels: fabedge.io/created-by=fabedge-operator fabedge.io/node=openyurt-edge2 Annotations: \u0026lt;none\u0026gt; Type: kubernetes.io/tls Data ==== ipsec.secrets: 14 bytes tls.crt: 1541 bytes tls.key: 1675 bytes ca.crt: 1862 bytes connector Connector运行在云端选定的节点，主要负责管理边缘节点发起的隧道，在云端和边端之间进行流量的转发。fabedge能够解决边端上pod到node的网络访问问题，以及云端和边端的隧道，对于云端的node可以使用符合k8s cni规范的任一网络插件，也就是说流量到达云端connector后需要通过connector同云端使用的cni进行适配。\nconnector组件的pod中有两个container，一个是strongswan用于创建隧道，一个是connector用于隧道控制，在connector中使用strongswan的sdk控制strongswan的行为，如创建隧道、销毁隧道\n[root@k8s-node1 k8s-t]# k get pod -n fabedge -o wide NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES cert-wqnth 0/1 Completed 0 7d11h 192.168.0.14 k8s-node1 \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; connector-68dbbdf547-pxj8z 2/2 Running 8 7d11h 172.31.0.2 k8s-node1 \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; fabedge-agent-k8s-node2 2/2 Running 0 7d11h 172.31.0.3 k8s-node2 \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; fabedge-agent-openyurt-edge2 2/2 Running 2 7d11h 172.23.0.4 openyurt-edge2 \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; fabedge-operator-6544c47c56-z2hct 1/1 Running 3 7d11h 172.31.0.2 k8s-node1 \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; [root@k8s-node1 k8s-t]# k describe pod connector-68dbbdf547-pxj8z -n fabedge ... Containers: strongswan: Container ID: docker://633630a2c95634c26fc0e784a0f300c67b8ca53874c4a564e1e9c7d92faadc3f Image: fabedge/strongswan:5.9.1 Image ID: docker-pullable://fabedge/strongswan@sha256:9e729c46995ad28c1b52c3fc873352b548bffaf5323472174c1c18a013d3dec0 Port: \u0026lt;none\u0026gt; Host Port: \u0026lt;none\u0026gt; State: Running Started: Wed, 08 Dec 2021 21:48:03 +0800 Last State: Terminated Reason: Completed Exit Code: 0 Started: Tue, 07 Dec 2021 11:15:03 +0800 Finished: Tue, 07 Dec 2021 12:48:14 +0800 Ready: True Restart Count: 3 Readiness: exec [/usr/sbin/swanctl --version] delay=15s timeout=1s period=10s #success=1 #failure=3 Environment: \u0026lt;none\u0026gt; Mounts: /etc/ipsec.d/ from ipsec-d (ro) /etc/ipsec.secrets from ipsec-secrets (ro,path=\u0026#34;ipsec.secrets\u0026#34;) /var/run/ from var-run (rw) /var/run/secrets/kubernetes.io/serviceaccount from default-token-zgj6d (ro) connector: Container ID: docker://2f7472f203fe993eac687dbcc2c0565d3fa20b9753bccf8ec4fbb92a7c5b5f3e Image: fabedge/connector:v0.3 Image ID: docker-pullable://fabedge/connector@sha256:e47188fd04a34e2a5b387980953775af5ab67e3ac08313a939c10558ac98af50 Port: \u0026lt;none\u0026gt; Host Port: \u0026lt;none\u0026gt; Args: --cni-type=flannel --sync-period=1m -v=5 State: Running Started: Wed, 08 Dec 2021 21:48:04 +0800 Last State: Terminated Reason: Completed Exit Code: 0 Started: Tue, 07 Dec 2021 11:15:03 +0800 Finished: Tue, 07 Dec 2021 12:48:14 +0800 Ready: True Restart Count: 5 Environment: \u0026lt;none\u0026gt; Mounts: /etc/fabedge/ from connector-config (rw) /etc/ipsec.d/ from ipsec-d (ro) /var/run/ from var-run (rw) /var/run/secrets/kubernetes.io/serviceaccount from default-token-zgj6d (ro) ... func (m *Manager) Start() { //创建路由，用于把流量引导到指定的网卡，供ipsec隧道转发，由于云端节点直接可能使用不同的cni插件，ipsec隧道流量到云端cni的适配工作也是这里完成的 routeTaskFn := func() { ... } //创建iptables规则，目的是为了允许流量的转发，如云端要访问边端的pod，那么流量势必要经过云端节点，这里就是设置允许流量转发 iptablesTaskFn := func() { ... } //监听connector-config文件的变化，以便创建/销毁隧道 tunnelTaskFn := func() { ... } //创建ipset规则，为了方便iptables ipsetTaskFn := func() { ... } tasks := []func(){tunnelTaskFn, routeTaskFn, ipsetTaskFn, iptablesTaskFn} if err := m.clearFabedgeIptablesChains(); err != nil { klog.Errorf(\u0026#34;failed to clean iptables: %s\u0026#34;, err) } // repeats regular tasks periodically go runTasks(m.SyncPeriod, tasks...) // 监听connector-config文件的变化，重新执行tasks go m.onConfigFileChange(m.TunnelConfigFile, tasks...) } agent Agent运行在每一个边缘节点上，它使用自己的ConfigMap、Secret发起到云端Connector和其他边缘节点的隧道。\nagent组件的pod中也包含两个container，一个是strongswan用于实际创建隧道、另一个是agent，在agent中通过strongswan的sdk控制strongswan创建/销毁隧道的行为\nfunc (m *Manager) start() { go m.sync() for range m.events { ... if m.MASQOutgoing { //根据最新的tunnel.yaml文件进行ipset同步 go retryForever(ctx, m.syncIPSetPeerCIDR, func(n uint, err error) { m.log.Error(err, \u0026#34;failed to sync ipset FABEDGE-PEER-CIDR\u0026#34;, \u0026#34;retryNum\u0026#34;, n) }) } //根据配置文件创建隧道，并配置iptables规则、路由保证流量能通 go retryForever(ctx, m.mainNetwork, func(n uint, err error) { m.log.Error(err, \u0026#34;failed to configure network\u0026#34;, \u0026#34;retryNum\u0026#34;, n) }) ... } } func (m *Manager) mainNetwork() error { m.log.V(3).Info(\u0026#34;load network config\u0026#34;) conf, err := netconf.LoadNetworkConf(m.TunnelsConfPath) if err != nil { return err } m.log.V(3).Info(\u0026#34;synchronize tunnels\u0026#34;) //根据配置文件创建隧道，并清除过时的隧道 if err := m.ensureConnections(conf); err != nil { return err } if m.EnableIPAM { m.log.V(3).Info(\u0026#34;generate cni config file\u0026#34;) //根据tunnel配置文件创建当前节点的cni配置文件 if err := m.generateCNIConfig(conf); err != nil { return err } } m.log.V(3).Info(\u0026#34;keep iptables rules\u0026#34;) //构建iptables的forward链保证外部请求pod/pod请求外部的流量都进行转发 if err := m.ensureIPTablesRules(conf); err != nil { return err } m.log.V(3).Info(\u0026#34;maintain dummy/xfrm interface and routes\u0026#34;) //配置到其他节点的路由 return m.ensureInterfacesAndRoutes(conf) } ","permalink":"https://moyuduo.github.io/posts/fabedge%E4%BA%91%E8%BE%B9%E9%80%9A%E4%BF%A1%E8%BE%B9%E8%BE%B9%E9%80%9A%E4%BF%A1/","summary":"fabedge云边通信、边边通信 operator Operator组件通过监听node、svc、endpoint等k8s的资源为每个节点维护一个ConfigMap和Secret，其中ConfigMap中主要保存节点上svc、运行的pod等详细信息，Secret中则保存有fabedge如何创建隧道、和哪个node创建隧道以及创建隧道所需要的证书等信息，并实时为每个agent更新配置信息，并管理agent的生命周期。\nfunc (opts Options) initializeControllers(ctx context.Context) error { ... //获取edge node和解析community err := opts.recordEndpoints(ctx) if err != nil { log.Error(err, \u0026#34;failed to initialize allocator and store\u0026#34;) return err } //通过解析出的node 定时检查生成community和所有节点的信息保存到configmap getConnectorEndpoint, err := connectorctl.AddToManager(opts.Connector) if err != nil { log.Error(err, \u0026#34;failed to add communities controller to manager\u0026#34;) return err } opts.Agent.GetConnectorEndpoint = getConnectorEndpoint //创建agent启动需要的configmap(保存节点的ip、pod cidr、service pod对应关系)和secret(保存创建隧道锁需要的证书) if err = agentctl.AddToManager(opts.Agent); err != nil { log.Error(err, \u0026#34;failed to add agent controller to manager\u0026#34;) return err } //监听community资源的变化，维护保存的community信息 if err = cmmctl.","title":"fabedge云边通信、边边通信"},{"content":"git相关 linux下安装git yum install -y git clone #克隆指定分支 git clone -b \u0026lt;branchname\u0026gt; xxx.git \u0026lt;DirName\u0026gt; #克隆指定tag git clone -b \u0026lt;tag\u0026gt; --depth=1 xxx.git \u0026lt;DirName\u0026gt; --depth 表示克隆深度, 1 表示只克隆最新的版本. 因为如果项目迭代的版本很多, 克隆会很慢 init git init初始化一个仓库\n#1.新建一个文件夹并初始化为一个仓库 mkdir proj1 cd proj1 git init #2.在当前文件夹下新建一个文件夹并初始化为仓库 git init proj2 workspace workspace即为工作区，当在任何分支下进行代码操作都是在工作区下进行的，如果没有使用git add进行缓存，或进行了缓存，但是工作区或暂存区内的代码和要切换的分支的代码有冲突，都会提示:\nerror: Your local changes to the following files would be overwritten by checkout: file.txt Please commit your changes or stash them before you switch branches. Aborting 工作区和暂存区对所有分支是可见的，也就是说在切换分支之前应该保持工作区、暂存区、HEAD一致\nstash 在使用git checkout切换分支的时候，如果有未commit的内容,那么会报错Please commit your changes or stash them before you switch branches,此时就可以先使用git stash把工作区和暂存区的内容保存起来 ，再切换分支，当回到该分支上时，使用git stash pop把存储的内容恢复到工作区和暂存区\ngit stash 并不会保存未被追踪的文件\n如果使用stash在分支上存储了内容，使用git checkout -b新开分支并不会包stash的内容保存到新开的分支\ngit stash保存的stash在任何分支上都可见，并且也可恢复到任何分支，值得注意的是stash恢复后可能与工作区产生冲突\n#存储工作区和暂存区的内容,保存的stash始终是最顶上的一个，即stash@{0} git stash git stash save \u0026#34;mystash1\u0026#34; #git stash push默认只会stash已追踪的文件，-u参数能stash未被追踪的文件 -m参数可以添加stash信息 git stash push -u -m \u0026#34;mystash1\u0026#34; #查看stash git stash list #恢复指定的stash,apply恢复stash后并不会从stash list中移除 git stash apply stash@{0} git stash apply 0 #恢复指定的stash git stash stash@{0} git stash pop 1 git stash pop stash@{1} #删除指定的stash git stash drop stash@{0} git stash drop 0 #恢复最近一次保存的stash并删除stash,即stash@{0} git stash pop #git stash pop 如果指定stash id那么不会把stash从stash list中移除 git stash pop 0 index index即为暂存区，当使用git add即把文件添加到暂存区\nworkspace和index中的代码对所有的分支都是可见的，并且都可以修改，但是一旦一个分支把index中代码提交了，其他分支就不可见了\nhead head指示某一个分支上的commit，它可以看成是一个游标，可以指向任何地方，不一定是最新的提交\ngit中~和^的区别 ~和^的区别\nbranch #查看本地分支 git branch #查看远程分支 git branch -r #查看本地和远程分支 git branch -a #新建分支 git branch \u0026lt;branchname\u0026gt; #删除分支 git branch -d \u0026lt;branchname\u0026gt; #在删除分支是可能报：error: The branch \u0026#39;s1\u0026#39; is not fully merged. 这是由于要删除的分支内容并没有合并到当前分支，如果确实需要删除，使用-D #另外不能删除当前checkout的分支 git branch -D \u0026lt;branchname\u0026gt; #删除远程分支 git push origin -d \u0026lt;branchname\u0026gt; #重命名本地分支 git branch -m \u0026lt;old_branchname\u0026gt; \u0026lt;new_branchname\u0026gt; checkout #切换分支 git checkout \u0026lt;branchname\u0026gt; #创建并切换分支 git checkout -b \u0026lt;branchname\u0026gt; #把工作区恢复成和暂存区一样的内容 git checkout -- readme.md add git add用于将文件(未追踪/已修改的追踪文件)保存到暂存区\ngit add . #把所有文件添加到暂存区(未追踪和已修改的追踪文件) git add -u #把已追踪修改了的文件添加到暂存区 git add pkg/ #把指定的文件/文件夹添加到暂存区 commit git commit用来将index中的内容提交到分支\ntag 参考: https://blog.csdn.net/jdsjlzx/article/details/98654951\ntag是指向某一个commit的标记，是不可变的\n#对当前HEAD指向的commit打tag git tag v0.0.1 #推送本地tag到远程 git push origin v0.0.1 #一次性把所有tag推送到远程 git push origin --tags #查看tag信息 git show v0.0.1 #查看本地tag git tag / git tag -l #查看远程tag git ls-remote --tags origin 8c972ed958da3505367fc4683ce84b18a39726f4 refs/tags/v0.0.1 8c972ed958da3505367fc4683ce84b18a39726f4 refs/tags/v0.1 #删除本地tag git tag -d v0.0.1 #删除远程tag git push origin :refs/tags/v0.0.1 To github.com:moyuduo/git_learn.git - [deleted] v0.0.1 #使用tag检出分支 git checkout -b branch-v0.1 v0.1 git commit -m \u0026#34;user commit message\u0026#34; #--amend参数可以将最新index追加到上一次提交并可以修改上一次的提交信息，但是值得注意的是会修改上一次提交的commit id git commit --amend mv git mv用于重命名被git跟踪的文件\n#1.如果使用传统的 mv命令进行重命名 mv aaa.txt AAA #git不区别文件名的大小写，也就是说aaa.txt和AAA.txt会被git认为是同一个文件名 $ git status On branch master Changes not staged for commit: (use \u0026#34;git add/rm \u0026lt;file\u0026gt;...\u0026#34; to update what will be committed) (use \u0026#34;git restore \u0026lt;file\u0026gt;...\u0026#34; to discard changes in working directory) deleted: aaa.txt Untracked files: (use \u0026#34;git add \u0026lt;file\u0026gt;...\u0026#34; to include in what will be committed) AAA no changes added to commit (use \u0026#34;git add\u0026#34; and/or \u0026#34;git commit -a\u0026#34;) git add aaa.txt git add AAA $ git status On branch master Changes to be committed: (use \u0026#34;git restore --staged \u0026lt;file\u0026gt;...\u0026#34; to unstage) renamed: aaa.txt -\u0026gt; AAA #git会识别aaa.txt 重命名为了 AAA #2.直接通过git mv重命名 git mv AAA aaa.txt $ git status On branch master Changes to be committed: (use \u0026#34;git restore --staged \u0026lt;file\u0026gt;...\u0026#34; to unstage) renamed: AAA -\u0026gt; aaa.txt rm git rm用于删除已经被git追踪的文件\n#1.使用rm删除后需要使用git add命令添加指定的删除文件才能被git staged rm test git add test #2.使用git rm删除文件，直接被git staged git rm test log #查看 commit 树 --all 查看所有分支，默认只查看当前分支 --graph以图形化的方式显示分支的关系 --oneline值显示commit的id和message忽略作者和时间 git log --all --graph --oneline gitk fetch 把远程分支的代码拉到本地\n#拉取到本地后，会创建一个FETCH_HEAD的log git fetch \u0026lt;remote_host\u0026gt; git fetch \u0026lt;remote_host\u0026gt; \u0026lt;remote_branchname\u0026gt; #拉取远程分支到本地并重命名为local_branchname git fetch \u0026lt;remote_host\u0026gt; \u0026lt;remote_branchname\u0026gt;:\u0026lt;local_branchname\u0026gt; #拉取github的pr到本地进行测试 git fetch origin pull/\u0026lt;ID\u0026gt;/head:\u0026lt;local_branchname\u0026gt; git log -p FETCH_HEAD git checkout -b \u0026lt;local_branch\u0026gt; \u0026lt;remote_host\u0026gt;/\u0026lt;remote_branchname\u0026gt; #or git checkout -b \u0026lt;local_branch\u0026gt; FETCH_HEAD pull pull相当于fetch+merge\n#将当前分支和远程分支关联，关联后可以直接使用git push/pull 推送/拉取代码 git pull --set-upstream \u0026lt;remote_host\u0026gt; \u0026lt;local_branchname\u0026gt; #拉取远程分支到本地创建\u0026lt;local_branch\u0026gt;分支，并把该分支同当前分支合并 git pull \u0026lt;remote_host\u0026gt; \u0026lt;remote_branch\u0026gt;:\u0026lt;local_branch\u0026gt; #拉取远程分支与当前分支合并 git pull \u0026lt;remote_host\u0026gt; \u0026lt;remote_branch\u0026gt; #如果未设置本地分支和远程分支的绑定关系，使用git pull会把所有的远程分支fetch到本地，可以通过git branch -av 查看，需要再和本地合并 git pull git branch -av git merge origin/dev #git pull不管有没有设置本地分支与远程分支相关联，都会把所有的远程分支拉取到本地，如果设置了--set-upstream那个会把当前分支和对应远程分支合并，否则都不会merge，可以通过git brach -vv查看 git pull merge git checkout master git pull git checkout -b feat/xxx #edit on breanch feat/xxx git checkout master #无冲突情况 git merge feat/xxx Updating 92a1fa3..287df05 Fast-forward featb.txt | 1 + file.txt | 1 + 2 files changed, 2 insertions(+) create mode 100644 featb.txt #有冲突情况 git merge feat/xxx Auto-merging featb.txt CONFLICT (content): Merge conflict in featb.txt Automatic merge failed; fix conflicts and then commit the result. 需要手动解决冲突 git add . git commit -m \u0026#34;resolve confilict\u0026#34; rebase 使用git rebase xxx合并分支\n#无冲突 git rebase master Successfully rebased and updated refs/heads/feat/b. #有冲突 git rebase master First, rewinding head to replay your work on top of it... Applying: feat/b Using index info to reconstruct a base tree... M featb.txt Falling back to patching base and 3-way merge... Auto-merging featb.txt CONFLICT (content): Merge conflict in featb.txt error: Failed to merge in the changes. hint: Use \u0026#39;git am --show-current-patch\u0026#39; to see the failed patch Patch failed at 0001 feat/b Resolve all conflicts manually, mark them as resolved with \u0026#34;git add/rm \u0026lt;conflicted_files\u0026gt;\u0026#34;, then run \u0026#34;git rebase --continue\u0026#34;. You can instead skip this commit: run \u0026#34;git rebase --skip\u0026#34;. To abort and get back to the state before \u0026#34;git rebase\u0026#34;, run \u0026#34;git rebase --abort\u0026#34;. 手动解决冲突 git add . git rebase --continue #放弃合并，回滚到合并之前的状态 git rebase --abort 使用git rebase重新编辑commit message\n#基于拿个 commitid 做rebase，会依次从该commitid之后的第一个commit到HEAD直接把所有commit基于前一个commit rebase git rebase \u0026lt;commitid\u0026gt; git rebase -i HEAD~3 pick 70a0b1a init branch feat/a s 4d948a4 init branch feat/a pick 3ad857e feat pick c45f31d ffff Commands: # p, pick \u0026lt;commit\u0026gt; = use commit # r, reword \u0026lt;commit\u0026gt; = use commit, but edit the commit message # e, edit \u0026lt;commit\u0026gt; = use commit, but stop for amending # s, squash \u0026lt;commit\u0026gt; = use commit, but meld into previous commit # f, fixup \u0026lt;commit\u0026gt; = like \u0026#34;squash\u0026#34;, but discard this commit\u0026#39;s log message # x, exec \u0026lt;command\u0026gt; = run command (the rest of the line) using shell # b, break = stop here (continue rebase later with \u0026#39;git rebase --continue\u0026#39;) # d, drop \u0026lt;commit\u0026gt; = remove commit # l, label \u0026lt;label\u0026gt; = label current HEAD with a name # t, reset \u0026lt;label\u0026gt; = reset HEAD to a label # m, merge [-C \u0026lt;commit\u0026gt; | -c \u0026lt;commit\u0026gt;] \u0026lt;label\u0026gt; [# \u0026lt;oneline\u0026gt;] # . create a merge commit using the original merge commit\u0026#39;s # . message (or the oneline, if no original merge commit was # . specified). Use -c \u0026lt;commit\u0026gt; to reword the commit message. :wq 使用git rebase可以把多次commit合并为一次commit,避免在进行git push时推送过多的commit,rebase会改变commit id\n#查看提交的commit信息 git log #使用rebase合并commit #HEAD~3表示合并最近的三次commit #打开文件后修改pick为Commands锁提示的指令 #git rebase -i a91e660d #a91e660d为git log记录的commit号，当前最新提交到该commit号之间的commit进行rebase git rebase -i HEAD~3 pick 70a0b1a init branch feat/a pick 4d948a4 init branch feat/a s 3ad857e feat s c45f31d ffff Commands: # p, pick \u0026lt;commit\u0026gt; = use commit # r, reword \u0026lt;commit\u0026gt; = use commit, but edit the commit message # e, edit \u0026lt;commit\u0026gt; = use commit, but stop for amending # s, squash \u0026lt;commit\u0026gt; = use commit, but meld into previous commit # f, fixup \u0026lt;commit\u0026gt; = like \u0026#34;squash\u0026#34;, but discard this commit\u0026#39;s log message # x, exec \u0026lt;command\u0026gt; = run command (the rest of the line) using shell # b, break = stop here (continue rebase later with \u0026#39;git rebase --continue\u0026#39;) # d, drop \u0026lt;commit\u0026gt; = remove commit # l, label \u0026lt;label\u0026gt; = label current HEAD with a name # t, reset \u0026lt;label\u0026gt; = reset HEAD to a label # m, merge [-C \u0026lt;commit\u0026gt; | -c \u0026lt;commit\u0026gt;] \u0026lt;label\u0026gt; [# \u0026lt;oneline\u0026gt;] # . create a merge commit using the original merge commit\u0026#39;s # . message (or the oneline, if no original merge commit was # . specified). Use -c \u0026lt;commit\u0026gt; to reword the commit message. :wq 使用git rebase把几个不连续的commit合成一个commit\ngit rebase -i HEAD~3 #本来的结构如下，commit自上而下依次为从旧到新 #pick 70a0b1a init branch feat/a #pick 4d948a4 init branch feat/a #pick 3ad857e feat #pick c45f31d ffff #改变commit排列的顺序，把两个不相连的要合并为一个commit的两个commit放一起 pick 70a0b1a init branch feat/a pick 4d948a4 init branch feat/a s c45f31d ffff pick 3ad857e feat Commands: # p, pick \u0026lt;commit\u0026gt; = use commit # r, reword \u0026lt;commit\u0026gt; = use commit, but edit the commit message # e, edit \u0026lt;commit\u0026gt; = use commit, but stop for amending # s, squash \u0026lt;commit\u0026gt; = use commit, but meld into previous commit # f, fixup \u0026lt;commit\u0026gt; = like \u0026#34;squash\u0026#34;, but discard this commit\u0026#39;s log message # x, exec \u0026lt;command\u0026gt; = run command (the rest of the line) using shell # b, break = stop here (continue rebase later with \u0026#39;git rebase --continue\u0026#39;) # d, drop \u0026lt;commit\u0026gt; = remove commit # l, label \u0026lt;label\u0026gt; = label current HEAD with a name # t, reset \u0026lt;label\u0026gt; = reset HEAD to a label # m, merge [-C \u0026lt;commit\u0026gt; | -c \u0026lt;commit\u0026gt;] \u0026lt;label\u0026gt; [# \u0026lt;oneline\u0026gt;] # . create a merge commit using the original merge commit\u0026#39;s # . message (or the oneline, if no original merge commit was # . specified). Use -c \u0026lt;commit\u0026gt; to reword the commit message. push push把本地分支的代码推送到远程指定分支\n#将当前分支和远程分支关联，关联后可以直接使用git push/pull 推送/拉取代码 git push --set-upstream \u0026lt;remote_host\u0026gt; \u0026lt;local_branchname\u0026gt; git push \u0026lt;remote_host\u0026gt; \u0026lt;local_branchname\u0026gt;:\u0026lt;remote_branchname\u0026gt; #如果要推送的本地分支名和远程分支名同名 git push \u0026lt;remote_host\u0026gt; \u0026lt;local_branchname\u0026gt; #也可以使用更加精简的写法,该种写法必须要已经设置了--set-upstream，可以通过git branch -vv查看有没有设置本地分支和远端分支的绑定关系 git push #但是有可能会提示 fatal:The current branch \u0026lt;local_branchname\u0026gt; has no upstream branch 即当前本地分支没有和远程分支绑定，本地没有对应关系 git push --set-upstream orgin \u0026lt;remote_branchname\u0026gt;\t#下次再直接git push就不再提示 #或者修改.git文件夹下面的config文件，.git文件夹针对一个项目的所有分支都是一致的，保存了整个项目的相关信息 [branch \u0026#34;main\u0026#34;] remote = origin merge = refs/heads/main reset重置 #回退到指定版本,默认保留暂存区和工作区内容 git reset HEAD^ #保留工作区和暂存区的内容，回退到指定版本 git reset --soft HEAD^ #不保留工作区和暂存区的内容，回退到指定版本 git reset --hard HEAD^ #回退到前3次提交之前，以此类推，回退到n次提交之前 git reset --soft HEAD~3 #退到/进到 指定commit的sha码 git reset --soft commit_id #把暂存区恢复成HEAD的内容 git reset HEAD git reset HEAD -- readme.md aaa.txt #版本穿梭 git reflog #查看历史，该指令会也会记录版本穿梭的记录 git log --all --graph --oneline #查看所有的commitid也可用于版本穿梭 git reset --hard \u0026lt;reflog id\u0026gt; #回退历史或前进历史，使用git rest之后head指针指向重置的commitid，先于commitid的记录不可见 revert恢复 git log #git revert用于恢复某一次操作的，如某一次commit提交了修改，那个git revert就去除这些修改，但是与git reset不同的是，git reset会消除reset commitid之后的记录，而git revert不会 #它会生成一个新的commit记录revert操作 git revert \u0026lt;commit id\u0026gt; #有冲突 #修改 git add . git revert --continue #放弃回滚 git revert --abort diff查看变动 git diff 显示工作目录已追踪文件与暂存区的差异 git diff –-cached/--staged 显示暂存区文件与本地库之间的差异 git diff commit_id1 commit_id2 比较在 commit_id1 的基础上 commit_id2 做了哪些修改 git diff commit_id 等价于 git diff commit_id HEAD git diff HEAD 显示工作目录与本地库之间的差异 git diff HEAD^ 显示工作目录与上上次提交之间的差异，一般用于在git pull之后查看他人对文件修改情况 $ git diff --name-status #查看表更的文件夹列表 M readme.md git diff -- readme.md aaa.txt #查看指定文件的变更 git diff master dev #比较dev分支的HEAD和master分支HEAD的差异，本质master/dev都是指向一个commitid config 当push项目的时候我们配置的用户信息会上传到库，方便其他开发人员看是谁做了变更\n所以需要我们修改为自己的有效信息，方便别人识别\ngit中有两种配置，一种是local，只针对当前的这个项目，一种是global，针对所有的库，如果local中进行了相关配合，那么优先使用local中的配置\n#查看local、global配置 git config --local --list git config --global --list #更新提交的用户的信息 git config --global user.name litao git config --global user.email taoli@yunify.com #或 git config --local user.name litao git config --local user.email taoli@yunify.com #设置 pull 合并冲突策略为 rebase #仅针对分支有效 git config branch.{branch_name}.rebase true #全局有效 git config --global branch.autosetuprebase always 拉取远程分支到本地 git fetch origin dev git checkout -b dev origin/dev 查看本地分支和远程分支的追踪关系 git branch -vv 设置git不追踪配置文件 git update-index --assume-unchanged /path/file #设置忽略跟踪 git update-index --no-assume-unchanged /path/to/file #恢复跟踪 https://www.cnblogs.com/fengxiaopanblog/p/10503346.html\n","permalink":"https://moyuduo.github.io/posts/git%E7%9B%B8%E5%85%B3/","summary":"git相关 linux下安装git yum install -y git clone #克隆指定分支 git clone -b \u0026lt;branchname\u0026gt; xxx.git \u0026lt;DirName\u0026gt; #克隆指定tag git clone -b \u0026lt;tag\u0026gt; --depth=1 xxx.git \u0026lt;DirName\u0026gt; --depth 表示克隆深度, 1 表示只克隆最新的版本. 因为如果项目迭代的版本很多, 克隆会很慢 init git init初始化一个仓库\n#1.新建一个文件夹并初始化为一个仓库 mkdir proj1 cd proj1 git init #2.在当前文件夹下新建一个文件夹并初始化为仓库 git init proj2 workspace workspace即为工作区，当在任何分支下进行代码操作都是在工作区下进行的，如果没有使用git add进行缓存，或进行了缓存，但是工作区或暂存区内的代码和要切换的分支的代码有冲突，都会提示:\nerror: Your local changes to the following files would be overwritten by checkout: file.txt Please commit your changes or stash them before you switch branches. Aborting 工作区和暂存区对所有分支是可见的，也就是说在切换分支之前应该保持工作区、暂存区、HEAD一致","title":"git相关"},{"content":"go mod依赖管理 go get命令 go get用来获取特点的版本、升级、降级依赖，该命令会修改go.mod文件，在go.mod文件中\n使用exclude排除的包，使用go get命令不能下载下来。\ngo get github.com/gorilla/mux # 匹配最新的一个 tag go get github.com/gorilla/mux@latest # 和上面一样 go get github.com/gorilla/mux@v1.6.2 # 匹配 v1.6.2 go get github.com/gorilla/mux@e3702bed2 # 匹配 v1.6.2 go get github.com/gorilla/mux@c856192 # 匹配 c85619274f5d go get github.com/gorilla/mux@master # 匹配 master 分支 latest匹配最新的tag\nv1.6.2完整版本的写法\nv1、v1.2匹配这个前缀最新的tag，如果最新的版本是1.2.7那么它会匹配到1.2.7\nc856192为版本hash的前缀\ngo mod可以使用模糊版本匹配，但是go.mod文件中只体现完整的版本号\n","permalink":"https://moyuduo.github.io/posts/go-mod%E4%BE%9D%E8%B5%96%E7%AE%A1%E7%90%86/","summary":"go mod依赖管理 go get命令 go get用来获取特点的版本、升级、降级依赖，该命令会修改go.mod文件，在go.mod文件中\n使用exclude排除的包，使用go get命令不能下载下来。\ngo get github.com/gorilla/mux # 匹配最新的一个 tag go get github.com/gorilla/mux@latest # 和上面一样 go get github.com/gorilla/mux@v1.6.2 # 匹配 v1.6.2 go get github.com/gorilla/mux@e3702bed2 # 匹配 v1.6.2 go get github.com/gorilla/mux@c856192 # 匹配 c85619274f5d go get github.com/gorilla/mux@master # 匹配 master 分支 latest匹配最新的tag\nv1.6.2完整版本的写法\nv1、v1.2匹配这个前缀最新的tag，如果最新的版本是1.2.7那么它会匹配到1.2.7\nc856192为版本hash的前缀\ngo mod可以使用模糊版本匹配，但是go.mod文件中只体现完整的版本号","title":"go mod依赖管理"},{"content":"开源go框架 通信 https://github.com/OpenIMSDK/Open-IM-Server ","permalink":"https://moyuduo.github.io/posts/%E5%BC%80%E6%BA%90go%E6%A1%86%E6%9E%B6/","summary":"开源go框架 通信 https://github.com/OpenIMSDK/Open-IM-Server ","title":"go开源框架"},{"content":"go相关 linux下go环境安装 下载go安装包\n# 1.在windows下载后上传linux，golang官网：https://golang.org/dl/ # 2.使用wget下载或curl go_version=1.16.8 wget https://dl.google.com/go/go${go_version}.linux-amd64.tar.gz curl -O https://dl.google.com/go/go${go_version}.linux-amd64.tar.gz 执行tar解压到/usr/loacl目录下（官方推荐），得到go文件夹等\ntar -zxvf go1.16.8.linux-amd64.tar.gz -C /usr/local 添加/usr/loacl/go/bin目录到PATH变量中\nvim /etc/profile #添加 export GOROOT=/usr/local/go export GOPATH=/usr/local/gopath export PATH=$PATH:$GOROOT/bin:$GOPATH 使环境变量生效\nsource /etc/profile 查看go\ngo version go build 在go build 时build 的包必须包含main方法，且包含main方法的文件的package必须是main,否则在运行时会报syntax error near unexpected token newline\u0026rsquo;`错误，build后的文件会自动添加可执行权限\n#使用go build编译包时 go build -o main cmd/add #会报错 #CGO_ENABLED=0 GO111MODULE=on go build -ldflags \u0026#34;-X makef/version.Version=v2.0.0\u0026#34; -o add cmd/add #package cmd/add is not in GOROOT (/storehouse/go/src/cmd/add) #make: *** [add] Error 1 #但是这样可以 go build -o main ./cmd/add #go build 可以使用-gcflags指定all=-N可以指定禁止优化， -l禁止内联, 禁止优化和内联可以让运行时(runtime)中的函数变得更容易调试 go build -gcflags \u0026#34;all=-N -l\u0026#34; -o add ./cmd/add #-ldflags 参数可以在编译的时候对变量进行赋值，常用在编译时添加版本、架构、编译日期等信息 #使用-X参数进行替换，makef为项目名称，如 github.com/moyuduo/repo 不是目录名，为go mod init makef, version是该项目下的一个包， Version为包中的一个变量 go build -ldflags \u0026#34;-X makef/version.Version=$(VERSION)\u0026#34; -o add ./cmd/add go install go install命令和go build类似都是生成可执行的二进制文件，不同的是go build生成的课执行文件放在指定的目录，而go install生成的课执行文件放在$GOPATH/bin目录下\ngo test 一般测试 Go 语言推荐测试文件和源代码文件放在一块，测试文件以 _test.go 结尾。\ncalc.go\npackage main func Add(a int, b int) int { return a + b } calc_test.go\npackage main import \u0026#34;testing\u0026#34; //测试函数必须要以Test为函数名前缀，也可以用下划线方式指定名字, func Test_Add //测试函数的入参必须要是t *testing.T func TestAdd(t *testing.T) { if ans := Add(1, 2); ans != 3 { t.Errorf(\u0026#34;1 + 2 expected be 3, but %d got\u0026#34;, ans) } if ans := Add(-10, -20); ans != -30 { t.Errorf(\u0026#34;-10 + -20 expected be -30, but %d got\u0026#34;, ans) } } #运行当前文件夹下所有的测试，-v表示输出详细信息 go test -v #-run 参数指定运行那个特定的测试，值可以是方法全名也可以是简写 go test -v -run TestAdd go test -v -run Add #使用-cover参数可以查看测试的覆盖率 go test -v -cover pkg #如果go test指定了包名，对于相同的测试会使用缓存 go test -v . / go test -v pkg1 #会使用缓存 Subtests 子测试是 Go 语言内置支持的，可以在某个测试用例中，根据测试场景使用 t.Run创建不同的子测试用例\ncalc_test.go\nfunc TestMul(t *testing.T) { t.Run(\u0026#34;pos\u0026#34;, func(t *testing.T) { if Mul(2, 3) != 6 { t.Fatal(\u0026#34;fail\u0026#34;) } }) t.Run(\u0026#34;neg\u0026#34;, func(t *testing.T) { if Mul(2, -3) != -6 { t.Fatal(\u0026#34;fail\u0026#34;) } }) } 或\nfunc TestMul(t *testing.T) { cases := []struct { Name string A, B, Expected int }{ {\u0026#34;pos\u0026#34;, 2, 3, 6}, {\u0026#34;neg\u0026#34;, 2, -3, -6}, {\u0026#34;zero\u0026#34;, 2, 0, 0}, } for _, c := range cases { t.Run(c.Name, func(t *testing.T) { if ans := Mul(c.A, c.B); ans != c.Expected { t.Fatalf(\u0026#34;%d * %d expected %d, but %d got\u0026#34;, c.A, c.B, c.Expected, ans) } }) } } setup 和 teardown 如果在同一个测试文件中，每一个测试用例运行前后的逻辑是相同的，一般会写在 setup 和 teardown 函数中。例如执行前需要实例化待测试的对象，如果这个对象比较复杂，很适合将这一部分逻辑提取出来；执行后，可能会做一些资源回收类的工作，例如关闭网络连接，释放文件等\nfunc setup() { fmt.Println(\u0026#34;Before all tests\u0026#34;) } func teardown() { fmt.Println(\u0026#34;After all tests\u0026#34;) } func Test1(t *testing.T) { fmt.Println(\u0026#34;I\u0026#39;m test1\u0026#34;) } func Test2(t *testing.T) { fmt.Println(\u0026#34;I\u0026#39;m test2\u0026#34;) } func TestMain(m *testing.M) { setup() //运行所有的测试函数 code := m.Run() teardown() os.Exit(code) } TestMain方法是包内唯一的函数，入参必须为m *testing.M\n#当前包如果有setup，teardown函数，那么使用-run参数指定执行特定的测试也会执行这两个函数 go test -v -run Test1 TCP/HTTP 假设需要测试某个 API 接口的 handler 能够正常工作，例如 helloHandler\nfunc helloHandler(w http.ResponseWriter, r *http.Request) { w.Write([]byte(\u0026#34;hello world\u0026#34;)) } 创建真实的网络连接进行测试\nimport ( \u0026#34;io/ioutil\u0026#34; \u0026#34;net\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;testing\u0026#34; ) func handleError(t *testing.T, err error) { t.Helper() if err != nil { t.Fatal(\u0026#34;failed\u0026#34;, err) } } func TestConn(t *testing.T) { ln, err := net.Listen(\u0026#34;tcp\u0026#34;, \u0026#34;127.0.0.1:0\u0026#34;) handleError(t, err) defer ln.Close() http.HandleFunc(\u0026#34;/hello\u0026#34;, helloHandler) go http.Serve(ln, nil) resp, err := http.Get(\u0026#34;http://\u0026#34; + ln.Addr().String() + \u0026#34;/hello\u0026#34;) handleError(t, err) defer resp.Body.Close() body, err := ioutil.ReadAll(resp.Body) handleError(t, err) if string(body) != \u0026#34;hello world\u0026#34; { t.Fatal(\u0026#34;expected hello world, but got\u0026#34;, string(body)) } } net.Listen(\u0026quot;tcp\u0026quot;, \u0026quot;127.0.0.1:0\u0026quot;)：监听一个未被占用的端口，并返回 Listener httptest 针对 http 开发的场景，使用标准库 net/http/httptest 进行测试更为高效\nimport ( \u0026#34;io/ioutil\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;net/http/httptest\u0026#34; \u0026#34;testing\u0026#34; ) func TestConn(t *testing.T) { //地址可以任意填写 req := httptest.NewRequest(\u0026#34;GET\u0026#34;, \u0026#34;http://example.com\u0026#34;, nil) w := httptest.NewRecorder() helloHandler(w, req) bytes, _ := ioutil.ReadAll(w.Result().Body) if string(bytes) != \u0026#34;hello world\u0026#34; { t.Fatal(\u0026#34;expected hello world, but got\u0026#34;, string(bytes)) } } Benchmark 基准测试函数定义\nfunc BenchmarkXXX(b *testing.B){ // ... } 函数名必须以 Benchmark 开头，后面一般跟待测试的函数名 参数为 b *testing.B 执行基准测试时，需要添加 -bench 参数，接受一个表达式，-bench=^BenchmarkHello$会精准匹配BenchmarkHello基准测试函数，^表示匹配开头，$表示匹配结尾，而如果使用-bench=BenchmarkHello的话会进行模糊匹配，能匹配到BenchmarkHello、BenchmarkHello1、BenchmarkHello2\u0026hellip; 只执行基准测试时需要-run=none 或 -run=^$因为go test默认会执行单元测试，所以使用该命令来过滤单元测试使之不能匹配到任何一个单元测试，那么执行的就是基准测试了 func BenchmarkHello(b *testing.B) { for i := 0; i \u0026lt; b.N; i++ { fmt.Sprintf(\u0026#34;hello\u0026#34;) } } #会运行包下所有的基准测试函数，-bench参数指定要运行的基准测试函数,最后必须指定文件名称 #在linux下-bench=.是可以的，但是在windows下必须-bench=\u0026#34;.\u0026#34; -bench和-run类似可以指定要运行那个基准测试函数 #经测在windows下使用-bench=Hello指定要执行具体的基准测试函数无效，会把文件中所有基准测试函数执行 go test -bench=\u0026#34;.\u0026#34; -run=^$ #也可以使用-v go test -v -bench=\u0026#34;.\u0026#34; -run=^$ #使用-bench表达式来过滤要执行的基准测试 # -bench=^BenchmarkHello$精准匹配基准测试函数BenchmarkHello go test -v -bench=^BenchmarkHello$ -run=none # -bench=^BenchmarkHello会匹配到基准测试函数BenchmarkHello、BenchmarkHello1 go test -v -bench=^BenchmarkHello -run=none # -bench=Hello会匹配到基准测试函数BenchmarkHello、BenchmarkHello1、BenchmarkAHello3 go test -v -bench=Hello -run=^$ #使用-benchmem参数指定输出基准测试的内存申请信息 #如果在基准测试中使用到了其他文件中的函数，还必须要把该函数所在文件包含进来 go test -v -bench=\u0026#34;.\u0026#34; -benchmem -run=none 如果在运行前基准测试需要一些耗时的配置，则可以使用 b.ResetTimer() 先重置定时器\nfunc BenchmarkHello(b *testing.B) { ... // 耗时操作 b.ResetTimer() for i := 0; i \u0026lt; b.N; i++ { fmt.Sprintf(\u0026#34;hello\u0026#34;) } } 使用 RunParallel 测试并发性能\nfunc BenchmarkParallel(b *testing.B) { templ := template.Must(template.New(\u0026#34;test\u0026#34;).Parse(\u0026#34;Hello, {{.}}!\u0026#34;)) b.RunParallel(func(pb *testing.PB) { var buf bytes.Buffer for pb.Next() { // 所有 goroutine 一起，循环一共执行 b.N 次 buf.Reset() templ.Execute(\u0026amp;buf, \u0026#34;World\u0026#34;) } }) } gunit package main import ( \u0026#34;fmt\u0026#34; \u0026#34;testing\u0026#34; \u0026#34;github.com/smartystreets/assertions/should\u0026#34; \u0026#34;github.com/smartystreets/gunit\u0026#34; ) type Example struct { *gunit.Fixture } func TestExamp(t *testing.T) { //gunit.Run方法会并行执行所有以Test开头的测试方法 //gunit.RunSequential方法会串行执行所有测试方法，执行顺序为比较Test之后的字符串大小，执行较大的那个 gunit.RunSequential(new(Example), t) } //以Setup开头的方法会在所有测试开始之前执行，如果有多个以Setup开头的方法，比较Setup之后的字符串大小，执行较大的那个 func (e *Example) SetupAAA() { fmt.Println(\u0026#34;setupAAA\u0026#34;) } func (e *Example) SetupMMM() { fmt.Println(\u0026#34;setupMMM\u0026#34;) } //以Teardown开头的方法会在所有测试结束之后执行，如果有多个以Teardown开头的方法，比较Teardown之后的字符串大小，执行较大的那个 func (e *Example) Teardown() { fmt.Println(\u0026#34;Teardown\u0026#34;) } //以Skip开头的方法会被跳过，不执行测试 func (e *Example) SkipFunc() { fmt.Println(\u0026#34;skip\u0026#34;) } //以Test开头的方法会自动执行 func (e *Example) TestEx() { fmt.Println(\u0026#34;TestEx\u0026#34;) num := 1 e.Assert(e.So(num, should.Equal, 1), fmt.Sprintf(\u0026#34;expect 1 but got %d \\n\u0026#34;, num)) str := \u0026#34;hello worl\u0026#34; e.Assert(e.So(str, should.ContainSubstring, \u0026#34;world\u0026#34;), fmt.Sprintf(\u0026#34;expect string (%s) contains string (world), but not \\n\u0026#34;, str)) } // func (e *Example) TestEx2() { // for { // fmt.Println(\u0026#34;TestEx2\u0026#34;) // time.Sleep(time.Second) // } // } // func (e *Example) TestEx3() { // for { // fmt.Println(\u0026#34;TestEx3\u0026#34;) // time.Sleep(time.Second) // } // } //方法不会执行 func (e *Example) aFunc() { fmt.Println(\u0026#34;aFunc\u0026#34;) } go get命令 go get用来获取特点的版本、升级、降级依赖，该命令会修改go.mod文件，在go.mod文件中\n使用exclude排除的包，使用go get命令不能下载下来。\ngo get github.com/gorilla/mux # 匹配最新的一个 tag go get github.com/gorilla/mux@latest # 和上面一样 go get github.com/gorilla/mux@v1.6.2 # 匹配 v1.6.2 go get github.com/gorilla/mux@e3702bed2 # 匹配 v1.6.2 go get github.com/gorilla/mux@c856192 # 匹配 c85619274f5d go get github.com/gorilla/mux@master # 匹配 master 分支 latest匹配最新的tag\nv1.6.2完整版本的写法\nv1、v1.2匹配这个前缀最新的tag，如果最新的版本是1.2.7那么它会匹配到1.2.7\nc856192为版本hash的前缀\ngo mod可以使用模糊版本匹配，但是go.mod文件中只体现完整的版本号\nclean go clean --modcache用来清除$GOPATH/pkg/mode下缓存的包\ngo grpc proto 根据.ptoto文件生成go文件\nprotoc --go_out=plugins=grpc:./ driver.proto 参考 https://geektutu.com/post/quick-go-test.html\nhttp://c.biancheng.net/view/124.html\nhttps://blog.csdn.net/weixin_34232617/article/details/91854391\n","permalink":"https://moyuduo.github.io/posts/go%E7%9B%B8%E5%85%B3/","summary":"go相关 linux下go环境安装 下载go安装包\n# 1.在windows下载后上传linux，golang官网：https://golang.org/dl/ # 2.使用wget下载或curl go_version=1.16.8 wget https://dl.google.com/go/go${go_version}.linux-amd64.tar.gz curl -O https://dl.google.com/go/go${go_version}.linux-amd64.tar.gz 执行tar解压到/usr/loacl目录下（官方推荐），得到go文件夹等\ntar -zxvf go1.16.8.linux-amd64.tar.gz -C /usr/local 添加/usr/loacl/go/bin目录到PATH变量中\nvim /etc/profile #添加 export GOROOT=/usr/local/go export GOPATH=/usr/local/gopath export PATH=$PATH:$GOROOT/bin:$GOPATH 使环境变量生效\nsource /etc/profile 查看go\ngo version go build 在go build 时build 的包必须包含main方法，且包含main方法的文件的package必须是main,否则在运行时会报syntax error near unexpected token newline\u0026rsquo;`错误，build后的文件会自动添加可执行权限\n#使用go build编译包时 go build -o main cmd/add #会报错 #CGO_ENABLED=0 GO111MODULE=on go build -ldflags \u0026#34;-X makef/version.Version=v2.0.0\u0026#34; -o add cmd/add #package cmd/add is not in GOROOT (/storehouse/go/src/cmd/add) #make: *** [add] Error 1 #但是这样可以 go build -o main .","title":"go相关"},{"content":"HashMap源码分析 简介 HashMap是一个底层用数组+链表实现的存储KV键值对数据结构，它允许null键和null值。\n原理 HashMap的存储规则是，根据K的hashCode运算得到hash值，然后根据hash值运算得到下标，如果数组中该下标没有值就放入，有值就一个一个比较是否hash值相同并且equals也为true，如果是就用value更新原来的value，如果到达最后都没找到相同的，就新增节点，在jdk1.8中进行了优化，当链表长度达到8时，就把链表变为红黑树\n类结构 public class HashMap\u0026lt;K,V\u0026gt; extends AbstractMap\u0026lt;K,V\u0026gt; implements Map\u0026lt;K,V\u0026gt;, Cloneable, Serializable HashMap继承了AbstractMap并重写了里面的方法。\nHashMap实现了Cloneable接口，可以被克隆。\nHashMap实现了Serializable接口，可以被序列化。\n属性 //默认初始化容量16 static final int DEFAULT_INITIAL_CAPACITY = 1 \u0026lt;\u0026lt; 4; //最大容量为2的30此方法 static final int MAXIMUM_CAPACITY = 1 \u0026lt;\u0026lt; 30; //默认加载因子0.75 static final float DEFAULT_LOAD_FACTOR = 0.75f; //链表转成树的阈值 static final int TREEIFY_THRESHOLD = 8; //树转换成链表的阈值 static final int UNTREEIFY_THRESHOLD = 6; //转换成树的最小容量阈值 static final int MIN_TREEIFY_CAPACITY = 64; //保存节点的数组 transient Node\u0026lt;K,V\u0026gt;[] table; //保存的所有节点 transient Set\u0026lt;Map.Entry\u0026lt;K,V\u0026gt;\u0026gt; entrySet; //保存节点个数 transient int size; //修改次数，用于迭代器的快速失败 transient int modCount; //扩容的阈值 int threshold; //加载因子 final float loadFactor; 节点 static class Node\u0026lt;K,V\u0026gt; implements Map.Entry\u0026lt;K,V\u0026gt; { //key的hash值 final int hash; final K key; V value; //后继节点 Node\u0026lt;K,V\u0026gt; next; Node(int hash, K key, V value, Node\u0026lt;K,V\u0026gt; next) { this.hash = hash; this.key = key; this.value = value; this.next = next; } public final K getKey() { return key; } public final V getValue() { return value; } public final String toString() { return key + \u0026#34;=\u0026#34; + value; } public final int hashCode() { return Objects.hashCode(key) ^ Objects.hashCode(value); } public final V setValue(V newValue) { V oldValue = value; value = newValue; return oldValue; } public final boolean equals(Object o) { if (o == this) return true; if (o instanceof Map.Entry) { Map.Entry\u0026lt;?,?\u0026gt; e = (Map.Entry\u0026lt;?,?\u0026gt;)o; if (Objects.equals(key, e.getKey()) \u0026amp;\u0026amp; Objects.equals(value, e.getValue()))//判断相等的条件是key和value都要相等 return true; } return false; } } 构造器 //指定初始化容量和增长因子的构造器 public HashMap(int initialCapacity, float loadFactor) { if (initialCapacity \u0026lt; 0) throw new IllegalArgumentException(\u0026#34;Illegal initial capacity: \u0026#34; + initialCapacity); if (initialCapacity \u0026gt; MAXIMUM_CAPACITY)//如果初始化容量比最大默认容量还大 initialCapacity = MAXIMUM_CAPACITY; if (loadFactor \u0026lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException(\u0026#34;Illegal load factor: \u0026#34; + loadFactor); this.loadFactor = loadFactor; //把指定的初始化大小改成近似这个数的2的n次方形式 this.threshold = tableSizeFor(initialCapacity); } //通过一定的算法得到2的n次方近似于这个数 static final int tableSizeFor(int cap) { int n = cap - 1; n |= n \u0026gt;\u0026gt;\u0026gt; 1; n |= n \u0026gt;\u0026gt;\u0026gt; 2; n |= n \u0026gt;\u0026gt;\u0026gt; 4; n |= n \u0026gt;\u0026gt;\u0026gt; 8; n |= n \u0026gt;\u0026gt;\u0026gt; 16; return (n \u0026lt; 0) ? 1 : (n \u0026gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1; } //指定初始化大小的构造器 public HashMap(int initialCapacity) { this(initialCapacity, DEFAULT_LOAD_FACTOR); } //无参构造器 public HashMap() { this.loadFactor = DEFAULT_LOAD_FACTOR; // all other fields defaulted } //使用Map初始化构造器 public HashMap(Map\u0026lt;? extends K, ? extends V\u0026gt; m) { this.loadFactor = DEFAULT_LOAD_FACTOR; putMapEntries(m, false); } 方法 添加节点方法 put(K,V)添加kv键值对\npublic V put(K key, V value) { return putVal(hash(key), key, value, false, true); } static final int hash(Object key) { int h; //如果key为null，hash为0，否则计算hash的规则是hashCode与（hashCode无符号左移16位） return (key == null) ? 0 : (h = key.hashCode()) ^ (h \u0026gt;\u0026gt;\u0026gt; 16); } final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) { Node\u0026lt;K,V\u0026gt;[] tab; Node\u0026lt;K,V\u0026gt; p; int n, i; if ((tab = table) == null || (n = tab.length) == 0)//如果table还没初始化，或大小为0 n = (tab = resize()).length; if ((p = tab[i = (n - 1) \u0026amp; hash]) == null)////添加节点计算得到的下标位置没有节点 tab[i] = newNode(hash, key, value, null); else {//添加节点计算得到的下标位置已有节点 Node\u0026lt;K,V\u0026gt; e; K k; if (p.hash == hash \u0026amp;\u0026amp; ((k = p.key) == key || (key != null \u0026amp;\u0026amp; key.equals(k))))//如果添加节点的hash和计算下标位置节点的hash相等 并且 添加节点的key与计算下标位置节点的key地址相等或逻辑相等 e = p; else if (p instanceof TreeNode)//如果是树，那么按照树的方法添加 e = ((TreeNode\u0026lt;K,V\u0026gt;)p).putTreeVal(this, tab, hash, key, value); else {//是链表 for (int binCount = 0; ; ++binCount) { if ((e = p.next) == null) {//到达链表的尾部 //添加节点 p.next = newNode(hash, key, value, null); if (binCount \u0026gt;= TREEIFY_THRESHOLD - 1) // 如果链表长度大于等于TREEIFY_THRESHOLD-1，即添加后链表长度大于等于8，那么那链表转换为树 treeifyBin(tab, hash); break; } if (e.hash == hash \u0026amp;\u0026amp; ((k = e.key) == key || (key != null \u0026amp;\u0026amp; key.equals(k)))) break; p = e; } } if (e != null) { // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); //如果是替换旧值，并没有修改modCount return oldValue; } } ++modCount; if (++size \u0026gt; threshold) //添加了元素大于阈值，进行扩容 resize(); afterNodeInsertion(evict); return null; } //初始化或对数组进行二倍扩容 final Node\u0026lt;K,V\u0026gt;[] resize() { Node\u0026lt;K,V\u0026gt;[] oldTab = table; int oldCap = (oldTab == null) ? 0 : oldTab.length; int oldThr = threshold; int newCap, newThr = 0; if (oldCap \u0026gt; 0) { if (oldCap \u0026gt;= MAXIMUM_CAPACITY) {//如果原容量大于最大值 //阈值设置为Integer的最大值 threshold = Integer.MAX_VALUE; return oldTab; } else if ((newCap = oldCap \u0026lt;\u0026lt; 1) \u0026lt; MAXIMUM_CAPACITY \u0026amp;\u0026amp; oldCap \u0026gt;= DEFAULT_INITIAL_CAPACITY)//原容量扩大二倍小于最大容量 并且 原容量要大于等于默认的初始化容量 newThr = oldThr \u0026lt;\u0026lt; 1; // double threshold } else if (oldThr \u0026gt; 0) //用原来的阈值初始化数组大小（构造的时候如果指定了初始化大小是使用threshold来保存的） newCap = oldThr; else { // 原容量为0并且没有指定初始化容量大小，就使用默认值 newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); } if (newThr == 0) { float ft = (float)newCap * loadFactor; newThr = (newCap \u0026lt; MAXIMUM_CAPACITY \u0026amp;\u0026amp; ft \u0026lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); } threshold = newThr; @SuppressWarnings({\u0026#34;rawtypes\u0026#34;,\u0026#34;unchecked\u0026#34;}) //创建一个新容量大小的节点数组 Node\u0026lt;K,V\u0026gt;[] newTab = (Node\u0026lt;K,V\u0026gt;[])new Node[newCap]; table = newTab; if (oldTab != null) {//如果原数组不空 for (int j = 0; j \u0026lt; oldCap; ++j) { Node\u0026lt;K,V\u0026gt; e; if ((e = oldTab[j]) != null) {//如果数组下标位置存放了元素 //help GC? oldTab[j] = null; if (e.next == null)//如果元素没有后继 //e.hash \u0026amp; (newCap - 1) 计算下标位置 //不进行扩容直接添加的计算规则是 hash \u0026amp; (n-1) n就是数组大小 //不管是你自己指定的初始化大小还是默认是初始化大小，都是2的次方（自己指定的如果不是2的次方会被转化为2的次方）而且扩容也是2倍扩容，所以不管新容量还是老容量都是2的次方 newTab[e.hash \u0026amp; (newCap - 1)] = e; else if (e instanceof TreeNode)//如果是红黑树 ((TreeNode\u0026lt;K,V\u0026gt;)e).split(this, newTab, j, oldCap); else { //是链表 //什么4个节点，对应两条链表 //一条链表上的节点通过hash计算的下标是一样的，而按照hash \u0026amp; （newCapacity-1）规则计算下标，只会得到两个下标，一个是原下标，一个是原下标+oldCapacity Node\u0026lt;K,V\u0026gt; loHead = null, loTail = null; Node\u0026lt;K,V\u0026gt; hiHead = null, hiTail = null; Node\u0026lt;K,V\u0026gt; next; do { next = e.next; if ((e.hash \u0026amp; oldCap) == 0) {//精髓\te.hash \u0026amp; oldCap //假如原容量为16那么新容量就为32，此时2号位置的链表通过原来计算公式为hash\u0026amp;（oldCapacity-1）即：1011011001010001000010 //\t\u0026amp; //\t0000000000000000001111\t15 //\t0000000000000000000010 //\t即：\t2号位置 //扩容之后本来应该的下标为\t1011011001010001000010 //\t\u0026amp; ↑ //\t0000000000000000011111\t31 //\t即\t2号位置 //可以看到扩容2倍，由于是\u0026amp;上（capacity-1）所以二进制全为1且比原来多一个1，那么差距就是↑所指那一位是0或1，如果是0那么新下标就是原下标，如果是1那么新下标就是原下标+oldCapacity //如果使用 e.hash \u0026amp; oldCap 可以更快的计算 //\t1011011001010001000010 //\t\u0026amp; //\t0000000000000000010000 //\t0000000000000000000000\t为0说明是原下标 if (loTail == null) loHead = e; else loTail.next = e; loTail = e; } else { //使用的是尾插法，保证了在扩容前先添加的元素，在扩容后的位置也在前面 if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; } } while ((e = next) != null); if (loTail != null) { loTail.next = null; newTab[j] = loHead; } if (hiTail != null) { hiTail.next = null; newTab[j + oldCap] = hiHead; } } } } } return newTab; } 移除节点方法 public V remove(Object key) { Node\u0026lt;K,V\u0026gt; e; //如果移除了返回节点的值，否则没找到返回null return (e = removeNode(hash(key), key, null, false, true)) == null ? null : e.value; } final Node\u0026lt;K,V\u0026gt; removeNode(int hash, Object key, Object value, boolean matchValue, boolean movable) { Node\u0026lt;K,V\u0026gt;[] tab; Node\u0026lt;K,V\u0026gt; p; int n, index; if ((tab = table) != null \u0026amp;\u0026amp; (n = tab.length) \u0026gt; 0 \u0026amp;\u0026amp; (p = tab[index = (n - 1) \u0026amp; hash]) != null) {//数组已经初始化并且大小大于0而且通过hash计算下标位置不空 Node\u0026lt;K,V\u0026gt; node = null, e; K k; V v; if (p.hash == hash \u0026amp;\u0026amp; ((k = p.key) == key || (key != null \u0026amp;\u0026amp; key.equals(k))))//如果hash相等 并且 key地址相等或equals node = p; else if ((e = p.next) != null) {//去后继节点找 if (p instanceof TreeNode)//如果后继节点是树，那么按照树的方法找 node = ((TreeNode\u0026lt;K,V\u0026gt;)p).getTreeNode(hash, key); else {//是链表，遍历找 do { if (e.hash == hash \u0026amp;\u0026amp; ((k = e.key) == key || (key != null \u0026amp;\u0026amp; key.equals(k)))) { node = e; break; } p = e; } while ((e = e.next) != null); } } if (node != null \u0026amp;\u0026amp; (!matchValue || (v = node.value) == value || (value != null \u0026amp;\u0026amp; value.equals(v)))) { if (node instanceof TreeNode) ((TreeNode\u0026lt;K,V\u0026gt;)node).removeTreeNode(this, tab, movable); else if (node == p)//如果是数组中保存的元素 tab[index] = node.next; else //是链表元素，修改链 p.next = node.next; ++modCount; --size; afterNodeRemoval(node); return node; } } return null; } 获取值方法 public V get(Object key) { Node\u0026lt;K,V\u0026gt; e; //如果根据key拿到的节点为null，即没有找到key对应的几点，那么返回null，否则返回找到节点的value值 return (e = getNode(hash(key), key)) == null ? null : e.value; } final Node\u0026lt;K,V\u0026gt; getNode(int hash, Object key) { Node\u0026lt;K,V\u0026gt;[] tab; Node\u0026lt;K,V\u0026gt; first, e; int n; K k; if ((tab = table) != null \u0026amp;\u0026amp; (n = tab.length) \u0026gt; 0 \u0026amp;\u0026amp; (first = tab[(n - 1) \u0026amp; hash]) != null) {//数组已初始化，而且数组大小大于0，且根据hash计算的下标位置不空 if (first.hash == hash \u0026amp;\u0026amp; // always check first node ((k = first.key) == key || (key != null \u0026amp;\u0026amp; key.equals(k))))//首先检查第一个节点是不是 return first; if ((e = first.next) != null) {//找第一个节点的后继 if (first instanceof TreeNode)//如果是树，按照树的方法查找 return ((TreeNode\u0026lt;K,V\u0026gt;)first).getTreeNode(hash, key); do {//是链表，遍历查找 if (e.hash == hash \u0026amp;\u0026amp; ((k = e.key) == key || (key != null \u0026amp;\u0026amp; key.equals(k)))) return e; } while ((e = e.next) != null); } } return null; } 但是HashMap为什么要有modCount这个属性呢？既然不是线程安全的，那么快速失败的意义在哪儿呢？而且如果put方法是key已存在，只是将新值替换旧值，modCount并没有改变，难道你在使用迭代器遍历时，其他线程修改了值，不用快速失败吗？\n","permalink":"https://moyuduo.github.io/posts/hashmap%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/","summary":"HashMap源码分析 简介 HashMap是一个底层用数组+链表实现的存储KV键值对数据结构，它允许null键和null值。\n原理 HashMap的存储规则是，根据K的hashCode运算得到hash值，然后根据hash值运算得到下标，如果数组中该下标没有值就放入，有值就一个一个比较是否hash值相同并且equals也为true，如果是就用value更新原来的value，如果到达最后都没找到相同的，就新增节点，在jdk1.8中进行了优化，当链表长度达到8时，就把链表变为红黑树\n类结构 public class HashMap\u0026lt;K,V\u0026gt; extends AbstractMap\u0026lt;K,V\u0026gt; implements Map\u0026lt;K,V\u0026gt;, Cloneable, Serializable HashMap继承了AbstractMap并重写了里面的方法。\nHashMap实现了Cloneable接口，可以被克隆。\nHashMap实现了Serializable接口，可以被序列化。\n属性 //默认初始化容量16 static final int DEFAULT_INITIAL_CAPACITY = 1 \u0026lt;\u0026lt; 4; //最大容量为2的30此方法 static final int MAXIMUM_CAPACITY = 1 \u0026lt;\u0026lt; 30; //默认加载因子0.75 static final float DEFAULT_LOAD_FACTOR = 0.75f; //链表转成树的阈值 static final int TREEIFY_THRESHOLD = 8; //树转换成链表的阈值 static final int UNTREEIFY_THRESHOLD = 6; //转换成树的最小容量阈值 static final int MIN_TREEIFY_CAPACITY = 64; //保存节点的数组 transient Node\u0026lt;K,V\u0026gt;[] table; //保存的所有节点 transient Set\u0026lt;Map.","title":"HashMap源码分析"},{"content":"HashSet源码分析 简介 HashSet不能存放重复的值，且不保证存放的顺序。\n类结构 public class HashSet\u0026lt;E\u0026gt; extends AbstractSet\u0026lt;E\u0026gt; implements Set\u0026lt;E\u0026gt;, Cloneable, java.io.Serializable HashSet继承自AbstractSet并重写了方法\nHashSet实现可Cloneable接口，可被克隆\nHashSet实现了Serializable接口，可以被序列化\n属性 //维护了一个HashMap，正是用这个HashMap来实现的去重 private transient HashMap\u0026lt;E,Object\u0026gt; map; //用于HashMap存放时的value，节约空间 private static final Object PRESENT = new Object(); 构造器 //无参构造器，初始化了HashMap public HashSet() { map = new HashMap\u0026lt;\u0026gt;(); } //使用集合初始化的构造器 public HashSet(Collection\u0026lt;? extends E\u0026gt; c) { //使用集合的大小计算容量 map = new HashMap\u0026lt;\u0026gt;(Math.max((int) (c.size()/.75f) + 1, 16)); addAll(c); } //指定初始化大小和加载因子的构造器 public HashSet(int initialCapacity, float loadFactor) { map = new HashMap\u0026lt;\u0026gt;(initialCapacity, loadFactor); } //指定初始化大小的构造器 public HashSet(int initialCapacity) { map = new HashMap\u0026lt;\u0026gt;(initialCapacity); } //同指定初始化大小和加载因子的构造器，第三个参数预留 HashSet(int initialCapacity, float loadFactor, boolean dummy) { map = new LinkedHashMap\u0026lt;\u0026gt;(initialCapacity, loadFactor); } 方法 iterator()获取迭代器\npublic Iterator\u0026lt;E\u0026gt; iterator() { //使用的是HashMap的KeySet的迭代器 return map.keySet().iterator(); } contains(Object）方法判断HashSet中是否已经包含该元素了\npublic boolean contains(Object o) { //直接调用HashMap的方法判断是否包含key return map.containsKey(o); } add(E）方法添加元素\npublic boolean add(E e) { //把元素当做是key，value用预设的默认值，即用HashMap不能存放重复key的特性去重 return map.put(e, PRESENT)==null; } remove(Object）方法移除元素\npublic boolean remove(Object o) { //把HashMap中key对应的节点去除 return map.remove(o)==PRESENT; } ","permalink":"https://moyuduo.github.io/posts/hashset%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/","summary":"HashSet源码分析 简介 HashSet不能存放重复的值，且不保证存放的顺序。\n类结构 public class HashSet\u0026lt;E\u0026gt; extends AbstractSet\u0026lt;E\u0026gt; implements Set\u0026lt;E\u0026gt;, Cloneable, java.io.Serializable HashSet继承自AbstractSet并重写了方法\nHashSet实现可Cloneable接口，可被克隆\nHashSet实现了Serializable接口，可以被序列化\n属性 //维护了一个HashMap，正是用这个HashMap来实现的去重 private transient HashMap\u0026lt;E,Object\u0026gt; map; //用于HashMap存放时的value，节约空间 private static final Object PRESENT = new Object(); 构造器 //无参构造器，初始化了HashMap public HashSet() { map = new HashMap\u0026lt;\u0026gt;(); } //使用集合初始化的构造器 public HashSet(Collection\u0026lt;? extends E\u0026gt; c) { //使用集合的大小计算容量 map = new HashMap\u0026lt;\u0026gt;(Math.max((int) (c.size()/.75f) + 1, 16)); addAll(c); } //指定初始化大小和加载因子的构造器 public HashSet(int initialCapacity, float loadFactor) { map = new HashMap\u0026lt;\u0026gt;(initialCapacity, loadFactor); } //指定初始化大小的构造器 public HashSet(int initialCapacity) { map = new HashMap\u0026lt;\u0026gt;(initialCapacity); } //同指定初始化大小和加载因子的构造器，第三个参数预留 HashSet(int initialCapacity, float loadFactor, boolean dummy) { map = new LinkedHashMap\u0026lt;\u0026gt;(initialCapacity, loadFactor); } 方法 iterator()获取迭代器","title":"HashSet源码分析"},{"content":"Hashtable源码分析 类结构 public class Hashtable\u0026lt;K,V\u0026gt; extends Dictionary\u0026lt;K,V\u0026gt; implements Map\u0026lt;K,V\u0026gt;, Cloneable, java.io.Serializable Hashtable继承自Dictionary实现了Map接口。\nHashtable实现了Cloneable可以进行克隆。\nHashtable实现了Serializable可以进行序列化。\n属性 //保存节点的数组bucket private transient Entry\u0026lt;?,?\u0026gt;[] table; //Hashtable中存放元素的个数 private transient int count; //Hashtable进行扩容的阈值 private int threshold; //用于计算阈值的加载因子 private float loadFactor; //进行破坏结构的修改次数，与遍历时的快速失败有关 private transient int modCount = 0; //最大容量，2的31次方-9 private static final int MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8; 节点 private static class Entry\u0026lt;K,V\u0026gt; implements Map.Entry\u0026lt;K,V\u0026gt; { final int hash; final K key; V value; Entry\u0026lt;K,V\u0026gt; next; protected Entry(int hash, K key, V value, Entry\u0026lt;K,V\u0026gt; next) { this.hash = hash; this.key = key; this.value = value; this.next = next; } @SuppressWarnings(\u0026#34;unchecked\u0026#34;) protected Object clone() { return new Entry\u0026lt;\u0026gt;(hash, key, value, (next==null ? null : (Entry\u0026lt;K,V\u0026gt;) next.clone())); } // Map.Entry Ops public K getKey() { return key; } public V getValue() { return value; } public V setValue(V value) { if (value == null) throw new NullPointerException(); V oldValue = this.value; this.value = value; return oldValue; } public boolean equals(Object o) { if (!(o instanceof Map.Entry)) return false; Map.Entry\u0026lt;?,?\u0026gt; e = (Map.Entry\u0026lt;?,?\u0026gt;)o; return (key==null ? e.getKey()==null : key.equals(e.getKey())) \u0026amp;\u0026amp; (value==null ? e.getValue()==null : value.equals(e.getValue())); } public int hashCode() { return hash ^ Objects.hashCode(value); } public String toString() { return key.toString()+\u0026#34;=\u0026#34;+value.toString(); } } 构造器 //指定初始化容量和加载因子的构造器 public Hashtable(int initialCapacity, float loadFactor) { if (initialCapacity \u0026lt; 0) throw new IllegalArgumentException(\u0026#34;Illegal Capacity: \u0026#34;+ initialCapacity); if (loadFactor \u0026lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException(\u0026#34;Illegal Load: \u0026#34;+loadFactor); if (initialCapacity==0) initialCapacity = 1; this.loadFactor = loadFactor; table = new Entry\u0026lt;?,?\u0026gt;[initialCapacity]; threshold = (int)Math.min(initialCapacity * loadFactor, MAX_ARRAY_SIZE + 1); } //指定初始化大小的构造器 public Hashtable(int initialCapacity) { //默认加载因子为0.75 this(initialCapacity, 0.75f); } //默认初始化大小为11，加载因子为0.75 public Hashtable() { this(11, 0.75f); } //使用集合初始化的构造器 public Hashtable(Map\u0026lt;? extends K, ? extends V\u0026gt; t) { this(Math.max(2*t.size(), 11), 0.75f); putAll(t); } 方法 Hashtable的所有方法都加了synchronized关键字，所以是线程安全的\ncontains(Object)方法判断Hashtable中是否包含某个元素\npublic synchronized boolean contains(Object value) { if (value == null) { throw new NullPointerException(); } Entry\u0026lt;?,?\u0026gt; tab[] = table; for (int i = tab.length ; i-- \u0026gt; 0 ;) {//遍历保存元素数组 for (Entry\u0026lt;?,?\u0026gt; e = tab[i] ; e != null ; e = e.next) {//有后继就遍历链表 if (e.value.equals(value)) {//使用保存节点的V的equals方法判断是否相等 return true; } } } return false; } containsKey(Object）判断Hashtable中是否包含这个key\npublic synchronized boolean containsKey(Object key) { Entry\u0026lt;?,?\u0026gt; tab[] = table; int hash = key.hashCode(); //计算下标的公式，如果包含这个key那么一定在数组的这个位置上或后继节点上 int index = (hash \u0026amp; 0x7FFFFFFF) % tab.length; for (Entry\u0026lt;?,?\u0026gt; e = tab[index] ; e != null ; e = e.next) { if ((e.hash == hash) \u0026amp;\u0026amp; e.key.equals(key)) {//hash值要相等并且key要equals return true; } } return false; } get(Object）方法根据key获取值，不能使用null的key，会抛出NullPointerException\npublic synchronized V get(Object key) { Entry\u0026lt;?,?\u0026gt; tab[] = table; //key为null会抛出NullPointerException int hash = key.hashCode(); //计算下标 int index = (hash \u0026amp; 0x7FFFFFFF) % tab.length; for (Entry\u0026lt;?,?\u0026gt; e = tab[index] ; e != null ; e = e.next) { if ((e.hash == hash) \u0026amp;\u0026amp; e.key.equals(key)) { return (V)e.value; } } return null; } put(K，V）向Hashtable中添加元素,可以看到Hashtable不允许key或value为null，抛出NullPointerException\npublic synchronized V put(K key, V value) { // 确保添加的value不空 if (value == null) { throw new NullPointerException(); } // Makes sure the key is not already in the hashtable. Entry\u0026lt;?,?\u0026gt; tab[] = table; //key为null会抛出NullPointerException int hash = key.hashCode(); int index = (hash \u0026amp; 0x7FFFFFFF) % tab.length; @SuppressWarnings(\u0026#34;unchecked\u0026#34;) Entry\u0026lt;K,V\u0026gt; entry = (Entry\u0026lt;K,V\u0026gt;)tab[index];//通过key计算下标，如果该key已经使用，那么一定在该节点或该节点的后继 for(; entry != null ; entry = entry.next) {//遍历 if ((entry.hash == hash) \u0026amp;\u0026amp; entry.key.equals(key)) { V old = entry.value; entry.value = value; return old; } } //如果没找到key对应的节点，说明key没有使用过，那么新增节点保存\u0026lt;K,V\u0026gt; addEntry(hash, key, value, index); return null; } private void addEntry(int hash, K key, V value, int index) { modCount++; Entry\u0026lt;?,?\u0026gt; tab[] = table; if (count \u0026gt;= threshold) {//达到了阈值要进行扩容 // Rehash the table if the threshold is exceeded rehash(); tab = table; hash = key.hashCode(); index = (hash \u0026amp; 0x7FFFFFFF) % tab.length; } // Creates the new entry. @SuppressWarnings(\u0026#34;unchecked\u0026#34;) Entry\u0026lt;K,V\u0026gt; e = (Entry\u0026lt;K,V\u0026gt;) tab[index]; //头插法 tab[index] = new Entry\u0026lt;\u0026gt;(hash, key, value, e); count++; } protected void rehash() { int oldCapacity = table.length; Entry\u0026lt;?,?\u0026gt;[] oldMap = table; // 新容量为老容量的2倍+1 int newCapacity = (oldCapacity \u0026lt;\u0026lt; 1) + 1; if (newCapacity - MAX_ARRAY_SIZE \u0026gt; 0) { if (oldCapacity == MAX_ARRAY_SIZE) // Keep running with MAX_ARRAY_SIZE buckets return; newCapacity = MAX_ARRAY_SIZE; } Entry\u0026lt;?,?\u0026gt;[] newMap = new Entry\u0026lt;?,?\u0026gt;[newCapacity]; modCount++; threshold = (int)Math.min(newCapacity * loadFactor, MAX_ARRAY_SIZE + 1); table = newMap; for (int i = oldCapacity ; i-- \u0026gt; 0 ;) {//遍历原来的保存节点的数组，把原来的节点全部添加到新数组 for (Entry\u0026lt;K,V\u0026gt; old = (Entry\u0026lt;K,V\u0026gt;)oldMap[i] ; old != null ; ) { Entry\u0026lt;K,V\u0026gt; e = old; old = old.next; //重新计算节点保存的下标 int index = (e.hash \u0026amp; 0x7FFFFFFF) % newCapacity; //头插法 //把新计算下标的元素挂到当前元素的next e.next = (Entry\u0026lt;K,V\u0026gt;)newMap[index]; //把当前元素添加到新下标位置 newMap[index] = e; } } } remove(Object）方法根据key移除Hashtable中的节点\npublic synchronized V remove(Object key) { Entry\u0026lt;?,?\u0026gt; tab[] = table; int hash = key.hashCode(); int index = (hash \u0026amp; 0x7FFFFFFF) % tab.length; @SuppressWarnings(\u0026#34;unchecked\u0026#34;) Entry\u0026lt;K,V\u0026gt; e = (Entry\u0026lt;K,V\u0026gt;)tab[index]; for(Entry\u0026lt;K,V\u0026gt; prev = null ; e != null ; prev = e, e = e.next) { if ((e.hash == hash) \u0026amp;\u0026amp; e.key.equals(key)) {//找到要移除的节点 modCount++; if (prev != null) {//如果有前驱把前驱的next指向移除节点的next prev.next = e.next; } else {//没有前驱说明是保存在table数组中的元素，直接把该元素的后继保存到数组 tab[index] = e.next; } count--; V oldValue = e.value; e.value = null; return oldValue; } } return null; } remove(Object，Object）根据key和value移除节点，也需要key和value都不为null\npublic synchronized boolean remove(Object key, Object value) { Objects.requireNonNull(value); Entry\u0026lt;?,?\u0026gt; tab[] = table; int hash = key.hashCode(); int index = (hash \u0026amp; 0x7FFFFFFF) % tab.length; @SuppressWarnings(\u0026#34;unchecked\u0026#34;) Entry\u0026lt;K,V\u0026gt; e = (Entry\u0026lt;K,V\u0026gt;)tab[index]; for (Entry\u0026lt;K,V\u0026gt; prev = null; e != null; prev = e, e = e.next) { if ((e.hash == hash) \u0026amp;\u0026amp; e.key.equals(key) \u0026amp;\u0026amp; e.value.equals(value)) {//通过key和value一起判断 modCount++; if (prev != null) { prev.next = e.next; } else { tab[index] = e.next; } count--; e.value = null; return true; } } return false; } replace(K，V，V）根据K,V把找到节点把原value替换为新value\npublic synchronized boolean replace(K key, V oldValue, V newValue) { Objects.requireNonNull(oldValue); Objects.requireNonNull(newValue); Entry\u0026lt;?,?\u0026gt; tab[] = table; int hash = key.hashCode(); int index = (hash \u0026amp; 0x7FFFFFFF) % tab.length; @SuppressWarnings(\u0026#34;unchecked\u0026#34;) Entry\u0026lt;K,V\u0026gt; e = (Entry\u0026lt;K,V\u0026gt;)tab[index]; for (; e != null; e = e.next) { if ((e.hash == hash) \u0026amp;\u0026amp; e.key.equals(key)) {//根据key找到节点 if (e.value.equals(oldValue)) {//判断原value是不是和参数一致 //替换 e.value = newValue; return true; } else { return false; } } } return false; } replace(K，V）根据key找到节点使用新value替换\npublic synchronized V replace(K key, V value) { Objects.requireNonNull(value); Entry\u0026lt;?,?\u0026gt; tab[] = table; int hash = key.hashCode(); int index = (hash \u0026amp; 0x7FFFFFFF) % tab.length; @SuppressWarnings(\u0026#34;unchecked\u0026#34;) Entry\u0026lt;K,V\u0026gt; e = (Entry\u0026lt;K,V\u0026gt;)tab[index]; for (; e != null; e = e.next) { if ((e.hash == hash) \u0026amp;\u0026amp; e.key.equals(key)) {//使用key判断 V oldValue = e.value; e.value = value; return oldValue; } } return null; } ","permalink":"https://moyuduo.github.io/posts/hashtable%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/","summary":"Hashtable源码分析 类结构 public class Hashtable\u0026lt;K,V\u0026gt; extends Dictionary\u0026lt;K,V\u0026gt; implements Map\u0026lt;K,V\u0026gt;, Cloneable, java.io.Serializable Hashtable继承自Dictionary实现了Map接口。\nHashtable实现了Cloneable可以进行克隆。\nHashtable实现了Serializable可以进行序列化。\n属性 //保存节点的数组bucket private transient Entry\u0026lt;?,?\u0026gt;[] table; //Hashtable中存放元素的个数 private transient int count; //Hashtable进行扩容的阈值 private int threshold; //用于计算阈值的加载因子 private float loadFactor; //进行破坏结构的修改次数，与遍历时的快速失败有关 private transient int modCount = 0; //最大容量，2的31次方-9 private static final int MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8; 节点 private static class Entry\u0026lt;K,V\u0026gt; implements Map.Entry\u0026lt;K,V\u0026gt; { final int hash; final K key; V value; Entry\u0026lt;K,V\u0026gt; next; protected Entry(int hash, K key, V value, Entry\u0026lt;K,V\u0026gt; next) { this.","title":"Hashtable源码分析"},{"content":"概念 chart: 包含创建 kubernetes 应用实例的必要信息 config: 包含应用发布配置信息 release: 是 chart 及其配置的一个运行实例 command repo chart 对应的是一个应用实例的信息，而要安装一个 chart 可以从多个仓库进行安装，repo 提供对仓库的增删\n# 在 https://artifacthub.io/ 上查询要安装的应用有哪些提供安装的 repo helm repo add bitnami https://charts.bitnami.com/bitnami \u0026#34;bitnami\u0026#34; has been added to your repositories helm repo list NAME URL bitnami\thttps://charts.bitnami.com/bitnami # 确定我们可以拿到最新的charts列表 helm repo update # TODO helm repo remove search 从仓库中查找 chart,提供从两种来源查找 chart: 1.https://artifacthub.io/ 使用 helm search hub 命令来进行查找，2.使用 helm repo add 添加的仓库，使用 helm search repo {repo_name}\n# 从 Artifact Hub 中查找 helm search hub etcd # 从添加的仓库中查找 helm search repo bitnami install 安装 chart 包,会把应用安装到本地使用 kubectl 连接到的那个集群中\nhelm install bitnami/mysql --generate-name NAME: mysql-1646288553 LAST DEPLOYED: Thu Mar 3 14:22:43 2022 NAMESPACE: default STATUS: deployed REVISION: 1 TEST SUITE: None NOTES: CHART NAME: mysql CHART VERSION: 8.8.26 APP VERSION: 8.0.28 ** Please be patient while the chart is being deployed ** Tip: Watch the deployment status using the command: kubectl get pods -w --namespace default Services: echo Primary: mysql-1646288553.default.svc.cluster.local:3306 Execute the following to get the administrator credentials: echo Username: root MYSQL_ROOT_PASSWORD=$(kubectl get secret --namespace default mysql-1646288553 -o jsonpath=\u0026#34;{.data.mysql-root-password}\u0026#34; | base64 --decode) To connect to your database: 1. Run a pod that you can use as a client: kubectl run mysql-1646288553-client --rm --tty -i --restart=\u0026#39;Never\u0026#39; --image docker.io/bitnami/mysql:8.0.28-debian-10-r23 --namespace default --command -- bash 2. To connect to primary service (read/write): mysql -h mysql-1646288553.default.svc.cluster.local -uroot -p\u0026#34;$MYSQL_ROOT_PASSWORD\u0026#34; To upgrade this helm chart: 1. Obtain the password as described on the \u0026#39;Administrator credentials\u0026#39; section and set the \u0026#39;root.password\u0026#39; parameter as shown below: ROOT_PASSWORD=$(kubectl get secret --namespace default mysql-1646288553 -o jsonpath=\u0026#34;{.data.mysql-root-password}\u0026#34; | base64 --decode) helm upgrade --namespace default mysql-1646288553 bitnami/mysql --set auth.rootPassword=$ROOT_PASSWORD # 使用自定义配置覆盖默认 chart 参数(可配置参数通过 helm show values 查看) -f 参数/ --set helm install -f values.yaml bitnami/mysql helm install bitnami/mysql --set # --dry-run --debug 参数并不会实际把 chart 安装到集群中，常用于调试 show/inspect 显示一个 chart 的信息\nhelm show chart bitnami/mysql annotations: category: Database apiVersion: v2 appVersion: 8.0.28 dependencies: - name: common repository: https://charts.bitnami.com/bitnami tags: - bitnami-common version: 1.x.x description: MySQL is a fast, reliable, scalable, and easy to use open source relational database system. Designed to handle mission-critical, heavy-load production applications. home: https://github.com/bitnami/charts/tree/master/bitnami/mysql icon: https://bitnami.com/assets/stacks/mysql/img/mysql-stack-220x234.png keywords: - mysql - database - sql - cluster - high availability maintainers: - email: containers@bitnami.com name: Bitnami name: mysql sources: - https://github.com/bitnami/bitnami-docker-mysql - https://mysql.com version: 8.8.26 # 显示 chart 的可配置选项,在定制化 chart 安装时非常有用 helm show values bitnami/mysql ## @section Global parameters ## Global Docker image parameters ## Please, note that this will override the image parameters, including dependencies, configured to use the global value ## Current available global Docker image parameters: imageRegistry, imagePullSecrets and storageClass ## @param global.imageRegistry Global Docker image registry ## @param global.imagePullSecrets [array] Global Docker registry secret names as an array ## @param global.storageClass Global StorageClass for Persistent Volume(s) ## global: imageRegistry: \u0026#34;\u0026#34; ## E.g. ## imagePullSecrets: ## - myRegistryKeySecretName ## imagePullSecrets: [] storageClass: \u0026#34;\u0026#34; ... list 显示 release 列表\nhelm list --all -A NAME NAMESPACE\tREVISION\tUPDATED STATUS CHART APP VERSION mysql-1646288553\tdefault 1 2022-03-03 14:22:43.477160293 +0800 CST\tdeployed\tmysql-8.8.26\t8.0.28 status 显示一个 release 的状态，由于在 helm install 的时候 helm 只负责把资源安装到 kubernetes 集群中，并不会等到所有的资源都运行起来了再退出，所以 status 用来追踪 release\nhelm status {release_name} -n {namespace} uninstall 卸载一个 release\n# --keep-history 会使 helm 跟踪该 release 的版本(即使被删除了),使用 helm status 可以查看，可以使用 helm rollback 来回滚版本 helm uninstall mysql-1646288553 release \u0026#34;mysql-1646288553\u0026#34; uninstalled upgrade 修改 release 配置或升级 chart 版本\nhelm upgrade -f panda.yaml happy-panda bitnami/wordpress helm upgrade happy-panda bitnami/wordpress --set a=1,b=2 get 获取一个 release 的信息\nhelm get values {release_name} helm get values myd-mysql -n nicktming template 用于渲染 chart 生成待部署的 yaml 文件,单并不会部署到 kubenetes 集群中\nhelm template {release_name} {chart_name} create 创建本地 chart\nhelm create mychart1 cd mychart1 tree . ├── charts ├── Chart.yaml #保存了 chart 的一些信息，如 chart 的 name/version 等 ├── templates │ ├── deployment.yaml │ ├── _helpers.tpl #放置模板助手的地方，可以在整个 chart 中重复使用 │ ├── hpa.yaml │ ├── ingress.yaml │ ├── NOTES.txt #chart 的 “帮助文本”。这会在用户运行 helm install 时显示给用户 │ ├── serviceaccount.yaml │ ├── service.yaml │ └── tests │ └── test-connection.yaml └── values.yaml #用于保存用户模板值，供在 yaml 使用 {{ .Values.xxx }} 进行替换 3 directories, 10 files 模板 在 templates 目录下编写的 yaml 文件会被渲染并最终在 helm install 的时候部署到集群中\n在 yaml 文件中可以使用 {{ 和 }} 来插入对象，如 {{ .Release.Name }} 最终就会替换成 release 的名字， .Release 是内置对象\n内置对象 Release: 这个对象描述了 release 本身 Release.Name：release 名称 Release.Time：release 的时间 Release.Namespace：release 的 namespace Release.Service：release 服务的名称 Release.Revision：此 release 的修订版本号，从1开始累加 Release.IsUpgrade：如果当前操作是升级或回滚，则将其设置为 true Release.IsInstall：如果当前操作是安装，则设置为 true Values: 从values.yaml文件和用户提供的文件传入模板的值。默认情况下，Values 是空的 Chart: Chart.yaml文件的内容 Values 内置对象中有一个对象就是 Values，该对象提供对传入 chart 的值的访问，Values 对象的值有4个来源：\nchart 包中的 values.yaml 文件 父 chart 包的 values.yaml 文件 通过 helm install 或者 helm upgrade 的-f或者--values参数传入的自定义的 yaml 文件 通过--set参数传入的值 chart 的 values.yaml 提供的值可以被用户提供的 values 文件覆盖，同样可以被\u0026ndash;set提供的参数所覆盖,优先级: \u0026ndash;set \u0026gt; -f \u0026gt; values.yaml\n模板函数 比如我们需要从.Values中读取的值变成字符串的时候就可以通过调用quote模板函数\napiVersion: v1 kind: ConfigMap metadata: name: {{ .Release.Name }}-configmap data: myvalue: \u0026#34;Hello World\u0026#34; k8s: {{ quote .Values.course.k8s }} python: {{ .Values.course.python }} 更多模板函数参考：\ngo模板函数\nSprig模板函数\n管道 模板语言除了提供了丰富的内置函数之外，其另一个强大的功能就是管道的概念。和UNIX中一样，管道我们通常称为Pipeline，是一个链在一起的一系列模板命令的工具，以紧凑地表达一系列转换。简单来说，管道是可以按顺序完成一系列事情的一种方法\napiVersion: v1 kind: ConfigMap metadata: name: {{ .Release.Name }}-configmap data: myvalue: \u0026#34;Hello World\u0026#34; k8s: {{ .Values.course.k8s | quote }} python: {{ .Values.course.python }} default 函数 default 函数允许我们在模板内部指定默认值，以防止该值被忽略掉了\napiVersion: v1 kind: ConfigMap metadata: name: {{ .Release.Name }}-configmap data: myvalue: {{ .Values.hello | default \u0026#34;Hello World\u0026#34; | quote }} k8s: {{ .Values.course.k8s | upper | quote }} python: {{ .Values.course.python | repeat 5 | quote }} 流程控制 控制流程为我们提供了控制模板生成流程的一种能力，Helm 的模板语言提供了以下几种流程控制：\nif/else 条件块 with 指定范围 range 循环块 除此之外，还提供了一些声明和使用命名模板段的操作:\ndefine在模板中声明一个新的命名模板 template导入一个命名模板 block声明了一种特殊的可填写的模板区域 if/else 基本结构如下:\n{{ if PIPELINE }} # Do something {{ else if OTHER PIPELINE }} # Do something else {{ else }} # Default case {{ end }} 使用条件块就得判断条件是否为真，如果值为下面的几种情况，则管道的结果为 false:\n一个布尔类型的假 一个数字零 一个空的字符串 一个nil（空或null) 一个空的集合（map、slice、tuple、dict、array） 除了上面的这些情况外，其他所有条件都为真\napiVersion: v1 kind: ConfigMap metadata: name: {{ .Release.Name }}-configmap data: {{ if eq .Values.course.python \u0026#34;django\u0026#34; }}web: true{{ end }} 空格控制 上面我们的条件判断语句是在一整行中的，如果平时经常写代码的同学可能非常不习惯了，我们一般会将其格式化为更容易阅读的形式\n{{ if eq .Values.course.python \u0026#34;django\u0026#34; }} web: true {{ end }} 但是渲染出来会有多余的空行，这是因为当模板引擎运行时，它将一些值渲染过后，之前的指令被删除，但它之前所占的位置完全按原样保留剩余的空白了，所以就出现了多余的空行\n可以通过使用在模板标识{{后面添加破折号和空格{{-来表示将空白左移，而在}}前面添加一个空格和破折号-}}表示应该删除右边的空格，另外需要注意的是换行符也是空格！\napiVersion: v1 kind: ConfigMap metadata: name: {{ .Release.Name }}-configmap data: {{- if eq .Values.course.python \u0026#34;django\u0026#34; }} web: true {{- end }} with控制变量作用域 {{ .Release.xxx }}中的.就是表示对当前范围的引用\n{{ with PIPELINE }} # restricted scope {{ end }} 可以使用with来将.范围指向.Values.course\napiVersion: v1 kind: ConfigMap metadata: name: {{ .Release.Name }}-configmap data: {{- with .Values.course }} {{- if eq .python \u0026#34;django\u0026#34; }} web: true {{- end }} {{- end }} range范围 在 Helm 模板语言中，是使用range关键字来进行循环操作\n在values.yaml文件中添加上一个课程列表:\ncourselist: - k8s - python - search - golang person: name: moyuduo age: 21 gender: man human: - man - woman - unknow 修改 ConfigMap 模板文件来循环打印出该列表：\napiVersion: v1 kind: ConfigMap metadata: name: {{ .Release.Name }}-configmap data: courselist: {{- range .Values.courselist }} - {{ . | title | quote }} {{- end }} {{- range $idx,$val := .Values.human }} human{{ $idx }}: {{ $val }} {{- end}} {{- range $key, $value := .Values.person }} {{ $key }}: {{ $value | quote }} {{- end }} 除了 list 或者 tuple，range 还可以用于遍历具有键和值的集合（如map 或 dict）\n变量 {{- with .Values.course }} k8s: {{ .k8s | upper | quote }} python: {{ .python | repeat 3 | quote }} release: {{ .var1 }} {{- end }} 在with语句块内添加了一个.var1对象，但这个模板是错误的，编译的时候会失败，这是因为.var1不在该with语句块限制的作用范围之内，我们可以将该对象赋值给一个变量可以来解决这个问题\napiVersion: v1 kind: ConfigMap metadata: name: {{ .Release.Name }}-configmap data: {{- $var1 := .Release.Name -}} {{- with .Values.course }} k8s: {{ .k8s | upper | quote }} python: {{ .python | repeat 3 | quote }} release: {{ $var1 }} {{- end }} 命名模板 命名模板我们也可以称为子模板，是限定在一个文件内部的模板，然后给一个名称。在使用命名模板的时候有一个需要特别注意的是：模板名称是全局的，如果我们声明了两个相同名称的模板，最后加载的一个模板会覆盖掉另外的模板，由于子 chart 中的模板也是和顶层的模板一起编译的，所以在命名的时候一定要注意，不要重名了。\n为了避免重名，有个通用的约定就是为每个定义的模板添加上 chart 名称：{{define \u0026quot;mychart.labels\u0026quot;}}，define关键字就是用来声明命名模板的，加上 chart 名称就可以避免不同 chart 间的模板出现冲突的情况。\n结构:\n{{ define \u0026#34;ChartName.TplName\u0026#34; }} # 模板内容区域 {{ end }} 可以将该模板嵌入到现有的 ConfigMap 中，然后使用template关键字在需要的地方包含进来即可:\n{{- define \u0026#34;mychart.labels\u0026#34; }} labels: from: helm date: {{ now | htmlDate }} {{- end }} apiVersion: v1 kind: ConfigMap metadata: name: {{ .Release.Name }}-configmap {{- template \u0026#34;mychart.labels\u0026#34; }} data: {{- range $key, $value := .Values.course }} {{ $key }}: {{ $value | quote }} {{- end }} 在创建 chart 包的时候，templates 目录下面默认会生成一个_helpers.tpl文件吗？我们前面也提到过 templates 目录下面除了NOTES.txt文件和以下划线_开头命令的文件之外，都会被当做 kubernetes 的资源清单文件，而这个下划线开头的文件不会被当做资源清单外，还可以被其他 chart 模板中调用，这个就是 Helm 中的 partials 文件，所以其实我们完全就可以将命名模板定义在这些 partials 文件中，默认就是_helpers.tpl文件了\n将上面定义的命名模板移动到 templates/_helpers.tpl 文件中去:\n{{/* 生成基本的 labels 标签 */}} {{- define \u0026#34;mychart.labels\u0026#34; }} labels: from: helm date: {{ now | htmlDate }} {{- end }} 模板范围 我们在里面来使用 chart 对象相关信息：\n{{/* 生成基本的 labels 标签 */}} {{- define \u0026#34;mychart.labels\u0026#34; }} labels: from: helm date: {{ now | htmlDate }} chart: {{ .Chart.Name }} version: {{ .Chart.Version }} {{- end }} 如果这样的直接进行渲染测试的话，是不会得到我们的预期结果的\nchart 的名称和版本都没有正确被渲染，这是因为他们不在我们定义的模板范围内，当命名模板被渲染时，它会接收由 template 调用时传入的作用域，由于我们这里并没有传入对应的作用域，因此模板中我们无法调用到 .Chart 对象，要解决也非常简单，我们只需要在 template 后面加上作用域范围即可:\napiVersion: v1 kind: ConfigMap metadata: name: {{ .Release.Name }}-configmap {{- template \u0026#34;mychart.labels\u0026#34; . }} data: {{- range $key, $value := .Values.course }} {{ $key }}: {{ $value | quote }} {{- end }} 我们在 template 末尾传递了.，表示当前的最顶层的作用范围，如果我们想要在命名模板中使用.Values范围内的数据，当然也是可以的\ninclude函数 将上面的定义的 labels 单独提取出来放置到 _helpers.tpl 文件中:\n{{/* 生成基本的 labels 标签 */}} {{- define \u0026#34;mychart.labels\u0026#34; }} from: helm date: {{ now | htmlDate }} chart: {{ .Chart.Name }} version: {{ .Chart.Version }} {{- end }} 将该命名模板插入到 configmap 模板文件的 labels 部分和 data 部分:\napiVersion: v1 kind: ConfigMap metadata: name: {{ .Release.Name }}-configmap labels: {{- template \u0026#34;mychart.labels\u0026#34; . }} data: {{- range $key, $value := .Values.course }} {{ $key }}: {{ $value | quote }} {{- end }} {{- template \u0026#34;mychart.labels\u0026#34; . }} 渲染后：\n# Source: mychart/templates/configmap.yaml apiVersion: v1 kind: ConfigMap metadata: name: altered-wombat-configmap labels: from: helm date: 2018-09-22 chart: mychart version: 0.1.0 data: k8s: \u0026#34;devops\u0026#34; python: \u0026#34;django\u0026#34; from: helm date: 2018-09-22 chart: mychart version: 0.1.0 可以看到渲染结果是有问题的，不是一个正常的 YAML 文件格式，这是因为template只是表示一个嵌入动作而已，不是一个函数，所以原本命名模板中是怎样的格式就是怎样的格式被嵌入进来了\n为了解决这个问题，Helm 提供了另外一个方案来代替template，那就是使用include函数，在需要控制空格的地方使用indent管道函数来自己控制\napiVersion: v1 kind: ConfigMap metadata: name: {{ .Release.Name }}-configmap labels: {{- include \u0026#34;mychart.labels\u0026#34; . | indent 4 }} data: {{- range $key, $value := .Values.course }} {{ $key }}: {{ $value | quote }} {{- end }} {{- include \u0026#34;mychart.labels\u0026#34; . | indent 2 }} 可以看到不管是 template 或 include 都不会因为在引用模板文件时隔了几个空格就导致引入的内容隔几个空格，还是需要使用 include 引入，并使用 indent 控制空格\nNOTES.txt文件 我们前面在使用 helm install 命令的时候，Helm 都会为我们打印出一大堆介绍信息，这样当别的用户在使用我们的 chart 包的时候就可以根据这些注释信息快速了解我们的 chart 包的使用方法，这些信息就是编写在 NOTES.txt 文件之中的，这个文件是纯文本的，但是它和其他模板一样，具有所有可用的普通模板函数和对象\nThank you for installing {{ .Chart.Name }}. Your release is named {{ .Release.Name }}. To learn more about the release, try: $ helm status {{ .Release.Name }} $ helm get {{ .Release.Name }} 子chart包 在创建 mychart 包的时候，在根目录下面有一个空文件夹 charts 目录吗？这就是我们的子 chart 所在的目录，在该目录下面添加一个新的 chart\ncd chart helm create subchart 值覆盖 删除子 chart template 下的所有文件，并创建一个 ConfigMap 文件\napiVersion: v1 metadat: name: {{ .Release.Name }}-cm data: in: {{ .Values.in }} 修改子chart的values.yaml文件：\nin: subchart 现在 subchart 这个子 chart 就属于 mychart 这个父 chart 了，由于 mychart 是父级，所以我们可以在 mychart 的 values.yaml 文件中直接配置子 chart 中的值，比如我们可以在 mychart/values.yaml 文件中添加上子 chart 的值\nsubchart: in: parent 子 chart 中的值已经被顶层的值给覆盖了。但是在某些场景下面我们还是希望某些值在所有模板中都可以使用，这就需要用到全局 chart 值了\n!!!注意这里父 chart 要覆盖子 chart 中的值，在父 chart 的 values.yaml 中定义值时必须指定子 chart 的名字,如这里的 subchart.in的值仅能替换名为subchart的 chart 中定义的 in的值\n全局值 全局值可以从任何 chart 或者子 chart中进行访问使用，values 对象中有一个保留的属性是Values.global，就可以被用来设置全局值,比如我们在父 chart 的 values.yaml 文件中添加一个全局值:\nglobal: allin: helm 在 values.yaml 文件中添加了一个 global 的属性，这样的话无论在父 chart 中还是在子 chart 中我们都可以通过{{ .Values.global.allin }}来访问这个全局值了\n如果 global中同名的值既在父 chart 中设置了也在子 chart 中设置了，那么会以父 chart 中的为准，如果只在子 chart 中设置了，那么子 chart 中可以引用，父 chart 中不可引用\npackage 打包本地 chart 为 .tgz 文件\nhelm package mychart1 Hooks Helm 也提供了 Hook 的机制，允许 chart 开发人员在 release 的生命周期中的某些节点来进行干预\nTODO\n","permalink":"https://moyuduo.github.io/posts/helm/","summary":"概念 chart: 包含创建 kubernetes 应用实例的必要信息 config: 包含应用发布配置信息 release: 是 chart 及其配置的一个运行实例 command repo chart 对应的是一个应用实例的信息，而要安装一个 chart 可以从多个仓库进行安装，repo 提供对仓库的增删\n# 在 https://artifacthub.io/ 上查询要安装的应用有哪些提供安装的 repo helm repo add bitnami https://charts.bitnami.com/bitnami \u0026#34;bitnami\u0026#34; has been added to your repositories helm repo list NAME URL bitnami\thttps://charts.bitnami.com/bitnami # 确定我们可以拿到最新的charts列表 helm repo update # TODO helm repo remove search 从仓库中查找 chart,提供从两种来源查找 chart: 1.https://artifacthub.io/ 使用 helm search hub 命令来进行查找，2.使用 helm repo add 添加的仓库，使用 helm search repo {repo_name}","title":"helm"},{"content":"iot环境相关 平台服务staging地址 #iot-auth ETCDCTL_API=3 etcdctl put /grpc-lb/iot-auth/v1.0.0/mgmt-staging \u0026#39;{\u0026#34;ServerName\u0026#34;:\u0026#34;iot-auth\u0026#34;,\u0026#34;Addr\u0026#34;:\u0026#34;192.168.14.94:9302\u0026#34;,\u0026#34;Metadata\u0026#34;:{}}\u0026#39; #iot-search ETCDCTL_API=3 etcdctl put /grpc-lb/iot-search/v1.0.0/mgmt-staging \u0026#39;{\u0026#34;ServerName\u0026#34;:\u0026#34;iot-search\u0026#34;,\u0026#34;Addr\u0026#34;:\u0026#34;192.168.14.94:8891\u0026#34;,\u0026#34;Metadata\u0026#34;:{}}\u0026#39; #iot-tag ETCDCTL_API=3 etcdctl put /grpc-lb/iot-tag/v1.0.0/mgmt-staging/192.168.14.94:8899 \u0026#39;{\u0026#34;server_name\u0026#34;:\u0026#34;iot-tag\u0026#34;,\u0026#34;addr\u0026#34;:\u0026#34;192.168.14.94:8899\u0026#34;,\u0026#34;metadata\u0026#34;:{}}\u0026#39; #iot-device ETCDCTL_API=3 etcdctl put /grpc-lb/iot-device/v1.0.0/mgmt-staging \u0026#39;{\u0026#34;ServerName\u0026#34;:\u0026#34;iot-device\u0026#34;,\u0026#34;Addr\u0026#34;:\u0026#34;192.168.21.163:9301\u0026#34;,\u0026#34;Metadata\u0026#34;:{}}\u0026#39; #iot-log ETCDCTL_API=3 etcdctl put /grpc-lb/iot-log/v1.0.0/iot-test2 \u0026#39;{\u0026#34;ServerName\u0026#34;:\u0026#34;iot-log\u0026#34;,\u0026#34;Addr\u0026#34;:\u0026#34;192.168.21.163:9509\u0026#34;,\u0026#34;Metadata\u0026#34;:{}}\u0026#39; ETCDCTL_API=3 etcdctl put /grpc-lb/deploy_rpc_server/v1.0.0/192.168.21.163:20021 \u0026#39;{\u0026#34;Addr\u0026#34;:\u0026#34;192.168.14.94:20021\u0026#34;,\u0026#34;Metadata\u0026#34;:null}\u0026#39; ETCDCTL_API=3 etcdctl put /grpc-lb/deploycore_rpc_server/v1.0.0/192.168.21.163:20025 \u0026#39;{\u0026#34;Addr\u0026#34;:\u0026#34;192.168.21.163:20025\u0026#34;,\u0026#34;Metadata\u0026#34;:null}\u0026#39; ETCDCTL_API=3 etcdctl put /grpc-lb/iot-data-export/v1.0.0/mgmt-staging \u0026#39;{\u0026#34;ServerName\u0026#34;:\u0026#34;iot-data-export\u0026#34;,\u0026#34;Addr\u0026#34;:\u0026#34;192.168.21.163:9505\u0026#34;,\u0026#34;Metadata\u0026#34;:{}}\u0026#39; ETCDCTL_API=3 etcdctl put /grpc-lb/iot-data-server/v1.0.0/mgmt-staging \u0026#39;{\u0026#34;ServerName\u0026#34;:\u0026#34;iot-data-server\u0026#34;,\u0026#34;Addr\u0026#34;:\u0026#34;192.168.21.163:28889\u0026#34;,\u0026#34;Metadata\u0026#34;:{}}\u0026#39; ETCDCTL_API=3 etcdctl put /grpc-lb/iot-dispatch/v1.0.0/mgmt-staging \u0026#39;{\u0026#34;ServerName\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;Addr\u0026#34;:\u0026#34;192.168.21.163:18880\u0026#34;,\u0026#34;Metadata\u0026#34;:null}\u0026#39; ETCDCTL_API=3 etcdctl put /grpc-lb/iot-metering-server/v1.0.0/mgmt-staging/192.168.21.163:9508 \u0026#39;{\u0026#34;server_name\u0026#34;:\u0026#34;iot-metering-server\u0026#34;,\u0026#34;addr\u0026#34;:\u0026#34;192.168.21.163:9508\u0026#34;,\u0026#34;metadata\u0026#34;:{}}\u0026#39; ETCDCTL_API=3 etcdctl put /grpc-lb/iot-shadow/v1.0.0/mgmt-staging/192.168.21.163:20078 \u0026#39;{\u0026#34;server_name\u0026#34;:\u0026#34;iot-shadow\u0026#34;,\u0026#34;addr\u0026#34;:\u0026#34;192.168.21.163:20078\u0026#34;,\u0026#34;metadata\u0026#34;:{}}\u0026#39; ETCDCTL_API=3 etcdctl put /grpc-lb/iot-thing/v1.0.0/mgmt-staging/192.168.21.163:9010 \u0026#39;{\u0026#34;server_name\u0026#34;:\u0026#34;iot-thing\u0026#34;,\u0026#34;addr\u0026#34;:\u0026#34;192.168.21.163:9010\u0026#34;,\u0026#34;metadata\u0026#34;:{}}\u0026#39; ETCDCTL_API=3 etcdctl put /grpc-lb/deployexec_rpc_server/v1.0.0/192.168.21.163:20027 \u0026#39;{\u0026#34;Addr\u0026#34;:\u0026#34;192.168.21.163:20027\u0026#34;,\u0026#34;Metadata\u0026#34;:null}\u0026#39; ETCDCTL_API=3 etcdctl put /grpc-lb/edgerule_rpc_server/v1.0.0/192.168.21.163:20037 \u0026#39;{\u0026#34;Addr\u0026#34;:\u0026#34;192.168.21.163:20037\u0026#34;,\u0026#34;Metadata\u0026#34;:null}\u0026#39; ETCDCTL_API=3 etcdctl put /grpc-lb/edgeview_rpc_server/v1.0.0/192.168.21.163:20039 \u0026#39;{\u0026#34;Addr\u0026#34;:\u0026#34;192.168.21.163:20039\u0026#34;,\u0026#34;Metadata\u0026#34;:null}\u0026#39; ","permalink":"https://moyuduo.github.io/posts/iot%E7%8E%AF%E5%A2%83%E7%9B%B8%E5%85%B3/","summary":"iot环境相关 平台服务staging地址 #iot-auth ETCDCTL_API=3 etcdctl put /grpc-lb/iot-auth/v1.0.0/mgmt-staging \u0026#39;{\u0026#34;ServerName\u0026#34;:\u0026#34;iot-auth\u0026#34;,\u0026#34;Addr\u0026#34;:\u0026#34;192.168.14.94:9302\u0026#34;,\u0026#34;Metadata\u0026#34;:{}}\u0026#39; #iot-search ETCDCTL_API=3 etcdctl put /grpc-lb/iot-search/v1.0.0/mgmt-staging \u0026#39;{\u0026#34;ServerName\u0026#34;:\u0026#34;iot-search\u0026#34;,\u0026#34;Addr\u0026#34;:\u0026#34;192.168.14.94:8891\u0026#34;,\u0026#34;Metadata\u0026#34;:{}}\u0026#39; #iot-tag ETCDCTL_API=3 etcdctl put /grpc-lb/iot-tag/v1.0.0/mgmt-staging/192.168.14.94:8899 \u0026#39;{\u0026#34;server_name\u0026#34;:\u0026#34;iot-tag\u0026#34;,\u0026#34;addr\u0026#34;:\u0026#34;192.168.14.94:8899\u0026#34;,\u0026#34;metadata\u0026#34;:{}}\u0026#39; #iot-device ETCDCTL_API=3 etcdctl put /grpc-lb/iot-device/v1.0.0/mgmt-staging \u0026#39;{\u0026#34;ServerName\u0026#34;:\u0026#34;iot-device\u0026#34;,\u0026#34;Addr\u0026#34;:\u0026#34;192.168.21.163:9301\u0026#34;,\u0026#34;Metadata\u0026#34;:{}}\u0026#39; #iot-log ETCDCTL_API=3 etcdctl put /grpc-lb/iot-log/v1.0.0/iot-test2 \u0026#39;{\u0026#34;ServerName\u0026#34;:\u0026#34;iot-log\u0026#34;,\u0026#34;Addr\u0026#34;:\u0026#34;192.168.21.163:9509\u0026#34;,\u0026#34;Metadata\u0026#34;:{}}\u0026#39; ETCDCTL_API=3 etcdctl put /grpc-lb/deploy_rpc_server/v1.0.0/192.168.21.163:20021 \u0026#39;{\u0026#34;Addr\u0026#34;:\u0026#34;192.168.14.94:20021\u0026#34;,\u0026#34;Metadata\u0026#34;:null}\u0026#39; ETCDCTL_API=3 etcdctl put /grpc-lb/deploycore_rpc_server/v1.0.0/192.168.21.163:20025 \u0026#39;{\u0026#34;Addr\u0026#34;:\u0026#34;192.168.21.163:20025\u0026#34;,\u0026#34;Metadata\u0026#34;:null}\u0026#39; ETCDCTL_API=3 etcdctl put /grpc-lb/iot-data-export/v1.0.0/mgmt-staging \u0026#39;{\u0026#34;ServerName\u0026#34;:\u0026#34;iot-data-export\u0026#34;,\u0026#34;Addr\u0026#34;:\u0026#34;192.168.21.163:9505\u0026#34;,\u0026#34;Metadata\u0026#34;:{}}\u0026#39; ETCDCTL_API=3 etcdctl put /grpc-lb/iot-data-server/v1.0.0/mgmt-staging \u0026#39;{\u0026#34;ServerName\u0026#34;:\u0026#34;iot-data-server\u0026#34;,\u0026#34;Addr\u0026#34;:\u0026#34;192.168.21.163:28889\u0026#34;,\u0026#34;Metadata\u0026#34;:{}}\u0026#39; ETCDCTL_API=3 etcdctl put /grpc-lb/iot-dispatch/v1.0.0/mgmt-staging \u0026#39;{\u0026#34;ServerName\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;Addr\u0026#34;:\u0026#34;192.168.21.163:18880\u0026#34;,\u0026#34;Metadata\u0026#34;:null}\u0026#39; ETCDCTL_API=3 etcdctl put /grpc-lb/iot-metering-server/v1.0.0/mgmt-staging/192.168.21.163:9508 \u0026#39;{\u0026#34;server_name\u0026#34;:\u0026#34;iot-metering-server\u0026#34;,\u0026#34;addr\u0026#34;:\u0026#34;192.168.21.163:9508\u0026#34;,\u0026#34;metadata\u0026#34;:{}}\u0026#39; ETCDCTL_API=3 etcdctl put /grpc-lb/iot-shadow/v1.0.0/mgmt-staging/192.168.21.163:20078 \u0026#39;{\u0026#34;server_name\u0026#34;:\u0026#34;iot-shadow\u0026#34;,\u0026#34;addr\u0026#34;:\u0026#34;192.168.21.163:20078\u0026#34;,\u0026#34;metadata\u0026#34;:{}}\u0026#39; ETCDCTL_API=3 etcdctl put /grpc-lb/iot-thing/v1.","title":"iot环境相关"},{"content":"iot部署流程 依赖处理 如果go.mod文件中有依赖其他的库，而这些库也修改了，那么\nmodule git.internal.yunify.com/manage/iot-deployserver go 1.13 require ( git.internal.yunify.com/manage/common v0.0.0-20210224064702-87d49bb67e50 git.internal.yunify.com/manage/edge-libs v0.0.0-20211209135215-d932b0e2ad57 github.com/go-pg/pg v8.0.6+incompatible github.com/jinzhu/configor v1.2.0 github.com/satori/go.uuid v1.2.0 github.com/stretchr/testify v1.4.0 google.golang.org/grpc v1.23.1 ) #把依赖的库替换成修改后并推送到gitlab的分支名 git.internal.yunify.com/manage/edge-libs feature/xxxx #然后执行go mod download 会把分支名替换 git.internal.yunify.com/manage/edge-libs v0.0.0-20211209135215-d932b0e2ad57 此时会提示go.sum不是最新的，执行go run main.go 会自动生成最新的go.sum\n开发流程： ##1、从master拉取最新代码 git clone master分支的url路径\n##2、从本地master建立新分支,以feat/add-model为例子 git checkout -b feat/add-model\n##3、提交 当前在feat/add-model分支，等代码修改完以后 git add . 或者是git add -A，这个根据情况而定 commit提交，后面跟自己的提交信息，如 git commit -m \u0026ldquo;增加modbus模型\u0026rdquo;\n##4、push到远程自己的分支 这时候就可以在gitlab上看到自己的分支了，可以看看有没有问题 git push origin feat/add-model\n##5、从远程dev拉取分支 git checkout -b dev origin/dev #操作后当前处于dev分支\n##6、将自己的分支合并到dev git merge feat/add-model\n##7、将合并后的代码push到远程dev分支 git push\n##8、此时dev上就是merge后的代码，可以部署测试了 ###（1）如果测试没问题，就可以直接在自己的分支提mr,如feat/add-model ###（2）如果有问题,没问题就不用管了，切换回自己的分支,继续修改 git checkout feat/add-model\n###修改后再次重复操作3，然后切换回dev git checkout dev #然后重复6，7操作，一直到没问题\n使用jenkins部署 http://192.168.20.10:8080/login?from=%2Fview%2Frelease%2Fjob%2Fiot-env-update%2Fbuild%3Fdelay%3D0sec\n账号：mq 密码：mq.123\nkafka磁盘满 进kafka机器，先用docker-compose停掉，kafka，然后删除/var/lib/docker/volumes下面最大的目录，再用docker-compose重启kafka就行了\n","permalink":"https://moyuduo.github.io/posts/iot%E9%83%A8%E7%BD%B2%E6%B5%81%E7%A8%8B/","summary":"iot部署流程 依赖处理 如果go.mod文件中有依赖其他的库，而这些库也修改了，那么\nmodule git.internal.yunify.com/manage/iot-deployserver go 1.13 require ( git.internal.yunify.com/manage/common v0.0.0-20210224064702-87d49bb67e50 git.internal.yunify.com/manage/edge-libs v0.0.0-20211209135215-d932b0e2ad57 github.com/go-pg/pg v8.0.6+incompatible github.com/jinzhu/configor v1.2.0 github.com/satori/go.uuid v1.2.0 github.com/stretchr/testify v1.4.0 google.golang.org/grpc v1.23.1 ) #把依赖的库替换成修改后并推送到gitlab的分支名 git.internal.yunify.com/manage/edge-libs feature/xxxx #然后执行go mod download 会把分支名替换 git.internal.yunify.com/manage/edge-libs v0.0.0-20211209135215-d932b0e2ad57 此时会提示go.sum不是最新的，执行go run main.go 会自动生成最新的go.sum\n开发流程： ##1、从master拉取最新代码 git clone master分支的url路径\n##2、从本地master建立新分支,以feat/add-model为例子 git checkout -b feat/add-model\n##3、提交 当前在feat/add-model分支，等代码修改完以后 git add . 或者是git add -A，这个根据情况而定 commit提交，后面跟自己的提交信息，如 git commit -m \u0026ldquo;增加modbus模型\u0026rdquo;\n##4、push到远程自己的分支 这时候就可以在gitlab上看到自己的分支了，可以看看有没有问题 git push origin feat/add-model\n##5、从远程dev拉取分支 git checkout -b dev origin/dev #操作后当前处于dev分支","title":"iot部署流程"},{"content":"iptables 介绍 iptables是按照规则来办事的，我们就来说说规则（rules），规则其实就是网络管理员预定义的条件，规则一般的定义为”如果数据包头符合这样的条件，就这样处理这个数据包”。规则存储在内核空间的信息包过滤表中，这些规则分别指定了源地址、目的地址、传输协议（如TCP、UDP、ICMP）和服务类型（如HTTP、FTP和SMTP）等。当数据包与规则匹配时，iptables就根据规则所定义的方法来处理这些数据包，如放行（accept）、拒绝（reject）和丢弃（drop）等。配置防火墙的主要工作就是添加、修改和删除这些规则。\n当客户端访问服务器的web服务时，客户端发送报文到网卡，而tcp/ip协议栈是属于内核的一部分，所以，客户端的信息会通过内核的TCP协议传输到用户空间中的web服务中，而此时，客户端报文的目标终点为web服务所监听的套接字（IP：Port）上，当web服务需要响应客户端请求时，web服务发出的响应报文的目标终点则为客户端，这个时候，web服务所监听的IP与端口反而变成了原点，我们说过，netfilter才是真正的防火墙，它是内核的一部分，所以，如果我们想要防火墙能够达到”防火”的目的，则需要在内核中设置关卡，所有进出的报文都要通过这些关卡，经过检查后，符合放行条件的才能放行，符合阻拦条件的则需要被阻止，于是，就出现了input关卡和output关卡，而这些关卡在iptables中不被称为”关卡”,而被称为”链”。\n其实我们上面描述的场景并不完善，因为客户端发来的报文访问的目标地址可能并不是本机，而是其他服务器，当本机的内核支持IP_FORWARD时，我们可以将报文转发给其他服务器，所以，这个时候，我们就会提到iptables中的其他”关卡”，也就是其他”链”，他们就是 “路由前”、”转发”、”路由后”，他们的英文名是\nPREROUTING、FORWARD、POSTROUTING\n也就是说，当我们启用了防火墙功能时，报文需要经过如下关卡，也就是说，根据实际情况的不同，报文经过”链”可能不同。如果报文需要转发，那么报文则不会经过input链发往用户空间，而是直接在内核空间中经过forward链和postrouting链转发出去的。\n根据上图，我们能够想象出某些常用场景中，报文的流向：\n到本机某进程的报文：PREROUTING –\u0026gt; INPUT\n由本机转发的报文：PREROUTING –\u0026gt; FORWARD –\u0026gt; POSTROUTING\n由本机的某进程发出报文（通常为响应报文）：OUTPUT –\u0026gt; POSTROUTING\n链 现在，我们想象一下，这些”关卡”在iptables中为什么被称作”链”呢？我们知道，防火墙的作用就在于对经过的报文匹配”规则”，然后执行对应的”动作”,所以，当报文经过这些关卡的时候，则必须匹配这个关卡上的规则，但是，这个关卡上可能不止有一条规则，而是有很多条规则，当我们把这些规则串到一个链条上的时候，就形成了”链”,所以，我们把每一个”关卡”想象成如下图中的模样 ，这样来说，把他们称为”链”更为合适，每个经过这个”关卡”的报文，都要将这条”链”上的所有规则匹配一遍，如果有符合条件的规则，则执行规则对应的动作。\n表 我们再想想另外一个问题，我们对每个”链”上都放置了一串规则，但是这些规则有些很相似，比如，A类规则都是对IP或者端口的过滤，B类规则是修改报文，那么这个时候，我们是不是能把实现相同功能的规则放在一起呢，必须能的。\n我们把具有相同功能的规则的集合叫做”表”，所以说，不同功能的规则，我们可以放置在不同的表中进行管理，而iptables已经为我们定义了4种表，每种表对应了不同的功能，而我们定义的规则也都逃脱不了这4种功能的范围，所以，学习iptables之前，我们必须先搞明白每种表 的作用。\niptables为我们提供了如下规则的分类，或者说，iptables为我们提供了如下”表”\nfilter表：负责过滤功能，防火墙；内核模块：iptables_filter\nnat表：network address translation，网络地址转换功能；内核模块：iptable_nat\nmangle表：拆解报文，做出修改，并重新封装 的功能；iptable_mangle\nraw表：关闭nat表上启用的连接追踪机制；iptable_raw\n也就是说，我们自定义的所有规则，都是这四种分类中的规则，或者说，所有规则都存在于这4张”表”中。\n链和表的关系 我们需要注意的是，某些”链”中注定不会包含”某类规则”，就像某些”关卡”天生就不具备某些功能一样，比如，A”关卡”只负责打击陆地敌人，没有防空能力，B”关卡”只负责打击空中敌人，没有防御步兵的能力，C”关卡”可能比较NB，既能防空，也能防御陆地敌人，D”关卡”最屌，海陆空都能防。\n那让我们来看看，每个”关卡”都有哪些能力，或者说，让我们看看每个”链”上的规则都存在于哪些”表”中。\n我们还是以图为例，先看看prerouting”链”上的规则都存在于哪些表中。\n这幅图是什么意思呢？它的意思是说，prerouting”链”只拥有nat表、raw表和mangle表所对应的功能，所以，prerouting中的规则只能存放于nat表、raw表和mangle表中。\n根据上述思路，我们来总结一下，每个”关卡”都拥有什么功能，\n或者说，每个”链”中的规则都存在于哪些”表”中。\nPREROUTING 的规则可以存在于：raw表，mangle表，nat表。\nINPUT 的规则可以存在于：mangle表，filter表，（centos7中还有nat表，centos6中没有）。\nFORWARD 的规则可以存在于：mangle表，filter表。\nOUTPUT 的规则可以存在于：raw表mangle表，nat表，filter表。\nPOSTROUTING 的规则可以存在于：mangle表，nat表。\n我们还需要注意一点，因为数据包经过一个”链”的时候，会将当前链的所有规则都匹配一遍，但是匹配时总归要有顺序，我们应该一条一条的去匹配，而且我们说过，相同功能类型的规则会汇聚在一张”表”中，那么，哪些”表”中的规则会放在”链”的最前面执行呢，这时候就需要有一个优先级的问题，我们还拿prerouting”链”做图示。\nprerouting链中的规则存放于三张表中，而这三张表中的规则执行的优先级如下：\nraw –\u0026gt; mangle –\u0026gt; nat\n但是我们知道，iptables为我们定义了4张”表”,当他们处于同一条”链”时，执行的优先级如下。\n优先级次序（由高而低）：\nraw –\u0026gt; mangle –\u0026gt; nat –\u0026gt; filter\n为了更方便的管理，我们还可以在某个表里面创建自定义链，将针对某个应用程序所设置的规则放置在这个自定义链中，但是自定义链接不能直接使用，只能被某个默认的链当做动作去调用才能起作用，我们可以这样想象，自定义链就是一段比较”短”的链子，这条”短”链子上的规则都是针对某个应用程序制定的，但是这条短的链子并不能直接使用，而是需要”焊接”在iptables默认定义链子上，才能被IPtables使用，这就是为什么默认定义的”链”需要把”自定义链”当做”动作”去引用的原因。\n数据经过防火墙流程 链的规则存放于哪些表中（从链到表的对应关系）：\nPREROUTING 的规则可以存在于：raw表，mangle表，nat表。\nINPUT 的规则可以存在于：mangle表，filter表，（centos7中还有nat表，centos6中没有）。\nFORWARD 的规则可以存在于：mangle表，filter表。\nOUTPUT 的规则可以存在于：raw表mangle表，nat表，filter表。\nPOSTROUTING 的规则可以存在于：mangle表，nat表。\n表中的规则可以被哪些链使用（从表到链的对应关系）：\nraw 表中的规则可以被哪些链使用：PREROUTING，OUTPUT\nmangle 表中的规则可以被哪些链使用：PREROUTING，INPUT，FORWARD，OUTPUT，POSTROUTING\nnat 表中的规则可以被哪些链使用：PREROUTING，OUTPUT，POSTROUTING（centos7中还有INPUT，centos6中没有）\nfilter 表中的规则可以被哪些链使用：INPUT，FORWARD，OUTPUT\n规则 规则：根据指定的匹配条件来尝试匹配每个流经此处的报文，一旦匹配成功，则由规则后面指定的处理动作进行处理；\n那么我们来通俗的解释一下什么是iptables的规则，之前打过一个比方，每条”链”都是一个”关卡”，每个通过这个”关卡”的报文都要匹配这个关卡上的规则，如果匹配，则对报文进行对应的处理，比如说，你我二人此刻就好像两个”报文”，你我二人此刻都要入关，可是城主有命，只有器宇轩昂的人才能入关，不符合此条件的人不能入关，于是守关将士按照城主制定的”规则”，开始打量你我二人，最终，你顺利入关了，而我已被拒之门外，因为你符合”器宇轩昂”的标准，所以把你”放行”了，而我不符合标准，所以没有被放行，其实，”器宇轩昂”就是一种”匹配条件”，”放行”就是一种”动作”，”匹配条件”与”动作”组成了规则。\n规则由匹配条件和处理动作组成。\n匹配条件 匹配条件分为基本匹配条件与扩展匹配条件\n基本匹配：\n源地址Source IP，目标地址 Destination IP\n上述内容都可以作为基本匹配条件。\n扩展匹配：\n除了上述的条件可以用于匹配，还有很多其他的条件可以用于匹配，这些条件泛称为扩展条件，这些扩展条件其实也是netfilter中的一部分，只是以模块的形式存在，如果想要使用这些条件，则需要依赖对应的扩展模块。\n源端口Source Port, 目标端口Destination Port\n上述内容都可以作为扩展匹配条件\n处理动作 处理动作在iptables中被称为target（这样说并不准确，我们暂且这样称呼），动作也可以分为基本动作和扩展动作。\n此处列出一些常用的动作，之后的文章会对它们进行详细的示例与总结：\nACCEPT：允许数据包通过。\nDROP：直接丢弃数据包，不给任何回应信息，这时候客户端会感觉自己的请求泥牛入海了，过了超时时间才会有反应。\nREJECT：拒绝数据包通过，必要时会给数据发送端一个响应的信息，客户端刚请求就会收到拒绝的信息。\nSNAT：源地址转换，解决内网用户用同一个公网地址上网的问题。\nMASQUERADE：是SNAT的一种特殊形式，适用于动态的、临时会变的ip上。\nDNAT：目标地址转换。\nREDIRECT：在本机做端口映射。\nLOG：在/var/log/messages文件中记录日志信息，然后将数据包传递给下一条规则，也就是说除了记录以外不对数据包做任何其他操作，仍然让下一条规则去匹配。\n规则查询 查询filter表中的规则\n# -t参数指定要操作的表 # -L参数列出规则 # 如果是查询filter表中的规则可以省略-t filter 默认就是查询filter表 iptables -t filter -L 查询指定表中指定链上的规则\n# 查询指定链只需要在-L参数后指定链的名称即可，注意链的名字是大写的 # 使用-v参数显示更加详细的信息 # 使用-n参数把名称解析为ip，如anywhere =\u0026gt; 0.0.0.0 # 使用--line-number显示规则的行号 iptables -t filter -nvL INPUT --line-number 规则管理 清空指定链的规则\n# 谨慎操作 iptables -F INPUT 添加规则\n# 使用-I参数指定向哪张表插入规则，默认会插入在表的第一行，也可以在表后指定要插入的行号 # 使用-s参数指定报文源地址,如果有多个ip可以用\u0026#34;,\u0026#34;分隔开,除了可以指定ip还可以指定网段如：192.168.0.0/16 # 使用-d参数指定报文目的地址，用法和-s参数相同 # 使用-p参数来指定协议的类型， tcp, udp, udplite, icmp, icmpv6,esp, ah, sctp, mh # 当本机有多个网卡时，我们可以使用 -i 选项去匹配报文是通过哪块网卡流入本机的 # 可以使用-o选项，匹配报文将由哪块网卡流出，没错，-o选项与-i选项是相对的 # 使用-j参数指定动作 iptables -t filter -I INPUT 1 -s 192.168.37.131 -j REJECT #在192.168.37.131机器上ping本机 [root@centos72 ~]# ping 192.168.37.134 -c 1 PING 192.168.37.134 (192.168.37.134) 56(84) bytes of data. From 192.168.37.134 icmp_seq=1 Destination Port Unreachable --- 192.168.37.134 ping statistics --- 1 packets transmitted, 0 received, +1 errors, 100% packet loss, time 0ms # 使用-A参数也可以像表中插入规则，不过同-I参数不同的是-A参数把规则插入到表的末尾 iptables -t filter -A INPUT -s 192.168.37.131 -j REJECT # ！！！如果对同一地址具有两条规则，一条规则是拒绝规则在第一行，第二条规则是接受规则在第二行，那么在接受到该源地址的包时也不会处理，因为匹配到了第一条拒绝规则后执行拒绝动作就不会继续向下匹配规则 # 使用 -m tcp --dport 22指定匹配条件中的目标端口,-m参数指定使用哪个扩展模块，由于这里-p参数或-m参数的模块名相同，这里-m参数可以省略 iptables -t filter -I INPUT -s 192.168.37.131 -p tcp -m tcp --dport 22 -j REJECT #使用 -m tcp --sport xxx 指定匹配条件中的源端口 iptables -t filter -I INPUT -s 192.168.37.131 -p tcp -sport 9999 -j REJECT #--dport或--sport也可以指定端口范围,但是不可以是离散的端口 如5001、6001、7001 iptables -t filter -I INPUT -s 192.168.37.131 -p tcp -dport 5000:6000 -j REJECT #使用-m multiport参数可以指定--dport或--sport为离散的端口 iptables -t filter -I INPUT -s 192.168.37.131 -p tcp -m multiport --dport 5001,6001,7001 -j REJECT iptables -t filter -I INPUT -s 192.168.37.131 -p tcp -m multiport --dport 5001,6001,7001,8000:9000 -j REJECT #使用-m指定扩展模块iprange可以指定源地址或目的地址范围 iptables -t filter -I INPUT -m iprange --src-range 192.168.37.129-192.168.37.133 -j REJECT iptables -t filter -I INPUT -m iprange --dst-range 192.168.37.133-192.168.37.135 -j REJECT #使用-m指定扩展模块string可以过滤包含指定字符串的包 #--algo参数指定用于匹配字符串的算法，可选kmp或bm #--string指定过滤的字符串 iptables -t filter -I INPUT -m string --algo kmp --string xxoo -j REJECT #使用-m指定扩展模块time可以使用时间作为限制,如每天早上9点到下午6点不能看网页 #--timestart指定开始时间 #--timestop指定结束时间 iptables -t filter -I INPUT -m time --timestart=09:00:00 --timestop 18:00:00 -j REJECT #周六日不能看网页 iptables -t filter -I INPUT -m time --weekdays 6,7 -j REJECT #周六早上9点到下午6点不能看网页 iptables -t filter -I INPUT -m time --weekdays 6 --timestart=09:00:00 --timestop 18:00:00 -j REJECT #每月的22号，23号不能上网 iptables -t filter -I INPUT -m time --monthdays 22,23 -j REJECT #2020-10-1到2020-11-1日之间不能上网 iptables -t filter -I INPUT -m time --datestart 2020-10-1 --datestop 2020-11-1 -j REJECT #使用-m指定扩展模块connlimit，可以限制每个IP地址同时链接到server端的链接数量 #--connlimit-above参数指定同一IP最大连接数 iptables -t filter -I INPUT -p tcp --dport 5000 -m connlimit --connlimit-above 1 -j REJECT #使用-m指定扩展模块limit对”报文到达速率”进行限制，可以以秒为单位进行限制，可以对秒（second）、分钟（minute）、小时（hour）、天（day）作为单位进行限制 iptables -t filter -I INPUT -p icmp -m limit --limit 5/minute -j REJECT 删除规则\n# 使用-D参数来删除规则，可以在表后面指定要删除的具体是哪一行的规则 iptables -t filter -D INPUT 3 # 也可以按匹配条件和动作去删除规则 iptable -t filter -D INPUT -s 192.138.37.131 -j REJECT 修改规则\n#比如把一行的规则由REJECT改为DROP # 注意修改的时候也必须带上-s参数指定源地址，可以理解为-R参数是把原来的规则删除了再创建一条，如果不指定-s源地址那么默认就是0.0.0.0，会把所有地址的包都DROP iptables -t filter -R INPUT 1 -s 192.168.37.131 -j DROP 修改链的默认动作\n#使用-nvL参数我们可以看到链的默认动作，比如这里INPUT链的默认动作就是ACCEPT [root@localhost ~]# iptables -nvL INPUT Chain INPUT (policy ACCEPT 0 packets, 0 bytes) #使用-P参数来修改指定链的默认动作 ipatables -t filter -P INPUT DROP 保存规则 在默认的情况下，我们对”防火墙”所做出的修改都是”临时的”，换句话说就是，当重启iptables服务或者重启服务器以后，我们平常添加的规则或者对规则所做出的修改都将消失，为了防止这种情况的发生，我们需要将规则”保存”。\ncentos7中，已经不再使用init风格的脚本启动服务，而是使用unit文件，所以，在centos7中已经不能再使用类似service iptables start这样的命令了，所以service iptables save也无法执行，同时，在centos7中，使用firewall替代了原来的iptables service，不过不用担心，我们只要通过yum源安装iptables与iptables-services即可（iptables一般会被默认安装，但是iptables-services在centos7中一般不会被默认安装），在centos7中安装完iptables-services后，即可像centos6中一样，通过service iptables save命令保存规则了，规则同样保存在/etc/sysconfig/iptables文件中。\ncentos7中配置iptables-service的步骤：\n#配置好yum源以后安装iptables-service # yum install -y iptables-services #停止firewalld # systemctl stop firewalld #禁止firewalld自动启动 # systemctl disable firewalld #启动iptables # systemctl start iptables #将iptables设置为开机自动启动，以后即可通过iptables-service控制iptables服务 # systemctl enable iptables 上述配置过程只需一次，以后即可在centos7中愉快的使用service iptables save命令保存iptables规则了。\n自定义链 当默认链中的规则非常多时，不方便我们管理。想象一下，如果INPUT链中存放了200条规则，这200条规则有针对httpd服务的，有针对sshd服务的，有针对私网IP的，有针对公网IP的，假如，我们突然想要修改针对httpd服务的相关规则，难道我们还要从头看一遍这200条规则，找出哪些规则是针对httpd的吗？这显然不合理。所以，iptables中，可以自定义链，通过自定义链即可解决上述问题。\n假设，我们自定义一条链，链名叫IN_WEB，我们可以将所有针对80端口的入站规则都写入到这条自定义链中，当以后想要修改针对web服务的入站规则时，就直接修改IN_WEB链中的规则就好了，即使默认链中有再多的规则，我们也不会害怕了，因为我们知道，所有针对80端口的入站规则都存放在IN_WEB链中。\n但是需要注意的是，自定义链并不能直接使用，而是需要被默认链引用才能够使用。\n创建自定义链\n#使用-n参数指定要创建自定义链 iptables -t filter -N IN_WEB #查询创建的自定义链,可以看到自定义链未被任何默认链引用 iptables -t filter -nvL Chain IN_WEB (0 references) pkts bytes target prot opt in out source destination 向自定义链中插入规则\niptables -t filter -I IN_WEB -p tcp --dport 8080 -j REJECT iptables -t filter -I IN_WEB -p tcp --dport 9090 -j ACCEPT #查看自定义链中的规则,可以看到此时自定义链仍未被默认链引用，所以该链上的规则不生效 iptables -t filter -nvL IN_WEB Chain IN_WEB (0 references) pkts bytes target prot opt in out source destination 0 0 ACCEPT tcp -- * * 0.0.0.0/0 0.0.0.0/0 tcp dpt:9090 0 0 REJECT tcp -- * * 0.0.0.0/0 0.0.0.0/0 tcp dpt:8080 reject-with icmp-port-unreachable 使用默认链引用自定义链\niptables -t filter -I INPUT -p tcp -m multiport --dport 8080,9090 -j IN_WEB #再次查看自定义链，此时可以看到自定义链就已经被默认链引用一次了 iptables -t filter -nvL IN_WEB Chain IN_WEB (1 references) pkts bytes target prot opt in out source destination 0 0 ACCEPT tcp -- * * 0.0.0.0/0 0.0.0.0/0 tcp dpt:9090 0 0 REJECT tcp -- * * 0.0.0.0/0 0.0.0.0/0 tcp dpt:8080 reject-with icmp-port-unreachable 重命名自定义链\n#重命名 iptables -E IN_WEB WEB #查看 iptables -nvL ... Chain WEB (1 references) pkts bytes target prot opt in out source destination 5 272 ACCEPT tcp -- * * 0.0.0.0/0 0.0.0.0/0 tcp dpt:9090 1 60 REJECT tcp -- * * 0.0.0.0/0 0.0.0.0/0 tcp dpt:8080 reject-with icmp-port-unreachable #查看原来在INPUT链中引用的自定义链，发现的名字也更新了 iptables -nvL INPUT Chain INPUT (policy ACCEPT 304 packets, 84228 bytes) pkts bytes target prot opt in out source destination 6 332 WEB tcp -- * * 0.0.0.0/0 0.0.0.0/0 multiport dports 8080,9090 删除自定义链\n#删除自定义链必须满足两个条件 # 1. 自定义链已经没有默认链引用了 # 2. 自定义链上已经没有任何规则了 #删除自定义链引用 iptables -D INPUT 1 #删除自定义链内的规则 iptables -F WEB #删除自定义链 iptables -X WEB 路由转发 环境：\n主机A和主机B在同一个网段，互相之间能够通信\ncontainer1是在主机B上起的docker容器，主机B能够与container1通信，主机A不能同container1通信\n现在要实现主机A能够与container1通信\n在主机A上添加路由，使得172.17.0.0/16网段的网关为主机B，那么访问该网段的包都会被发送到主机B\n#添加路由 route add -net 172.13.0.0/16 gw 192.168.37.134 #查看路由 route -n 在主机B上开启路由转发功能(默认是关闭的)，开启之后主机B会把接受到的访问172.17.0.0/16为目的地址的包通过docker0网卡转发到对应的容器\n#开启路由转发 echo \u0026#34;1\u0026#34; \u0026gt; /proc/sys/net/ipv4/ip_forward #或 sysctl -w net.ipv4.ip_forward=1 #以上两种方法都是临时生效，要永久生效则需要设置/etc/sysctl.conf文件（centos7中配置/usr/lib/sysctl.d/00-system.conf文件），添加或修改net.ipv4.ip_forward = 1 测试访问\n#在主机A上测试ping ping 172.17.0.3 #测试tcp nc 172.17.0.3 5000 设置转发规则 经过以上配置后主机A可以访问container1是因为主机B上对转发没有做任何限制，默认转发了\n#在主机B上查看转发策略,可以看到没有任何限制并且默认也是ACCEPT [root@localhost ~]# iptables -nvL FORWARD Chain FORWARD (policy ACCEPT 6144 packets, 324K bytes) pkts bytes target prot opt in out source destination 使用白名单机制对转发规则进行限制\n#在filter表的FORWARD链末尾添加一条拒绝所有转发的规则，此时主机A不再能够访问container1 iptables -t filter -A FORWARD -j REJECT 在主机B上添加一条对目标端口8080转发ACCEPT的规则\niptables -t filter -I FORWARD -p tcp --dport 8080 -j ACCEPT 测试在主机A上访问container1,可以发现并不能建立连接，这是为什么呢？是因为我们只放行了外部到container1的8080端口的请求，并没有放行container1的回复包，所以TCP没办法建立连接\nnc 172.17.0.3 8080 在主机B上放行container1 8080端口回复包的转发\niptables -t filter -I FORWARD -p tcp --sport 8080 -j ACCEPT 再次在主机A上测试同container1通信，成功\nnc 172.17.0.3 8080 aaa AAA 从以上步骤中我们可以看到，每放行一个端口，不仅要放行对该端口的请求包，还要放行端口的回复包，需要配置两次，非常麻烦，有没有办法把所有回复包都放行？\niptables -t filter -I FORWARD -m state --state ESTABLISHED,RELATED -j ACCEPT 动作 使用-j可以指定动作，比如\n-j ACCEPT\n-j DROP\n-j REJECT\n其实，”动作”也有自己的选项，我们可以在使用动作时，设置对应的选项\n###REJECT\nREJECT动作的常用选项为–reject-with，可以设置提示信息，当对方被拒绝时，会提示对方为什么被拒绝\n可用值如下\nicmp-net-unreachable\nicmp-host-unreachable\nicmp-port-unreachable,\nicmp-proto-unreachable\nicmp-net-prohibited\nicmp-host-pro-hibited\nicmp-admin-prohibited\n当不设置任何值时，默认值为icmp-port-unreachable。\n#查看,可以看到最后一条规则reject-with是icmp-port-unreachable iptable -nvL FORWARD Chain FORWARD (policy ACCEPT 0 packets, 0 bytes) pkts bytes target prot opt in out source destination 64 3340 ACCEPT tcp -- * * 0.0.0.0/0 0.0.0.0/0 tcp dpt:9090 68 3548 ACCEPT all -- * * 0.0.0.0/0 0.0.0.0/0 state RELATED,ESTABLISHED 30 1578 ACCEPT tcp -- * * 0.0.0.0/0 0.0.0.0/0 tcp spt:8080 41 2214 ACCEPT tcp -- * * 0.0.0.0/0 0.0.0.0/0 tcp dpt:8080 10 600 REJECT all -- * * 0.0.0.0/0 0.0.0.0/0 reject-with icmp-port-unreachable #使用主机A ping container1,匹配到最后一条转发规则所以提示的信息是Destination Port Unreachable [root@centos72 ~]# ping 172.17.0.3 PING 172.17.0.3 (172.17.0.3) 56(84) bytes of data. From 192.168.37.134 icmp_seq=1 Destination Port Unreachable From 192.168.37.134 icmp_seq=2 Destination Port Unreachable #给FORWARD链插入一条拒绝所有转发的规则reject-with设置成icmp-host-unreachable iptables -I FORWARD 5 -j REJECT --reject-with icmp-host-unreachable #再次在主机A上ping container1,可以看到这次的提示信息就是Destination Host Unreachable了 [root@centos72 ~]# ping 172.17.0.3 PING 172.17.0.3 (172.17.0.3) 56(84) bytes of data. From 192.168.37.134 icmp_seq=1 Destination Host Unreachable From 192.168.37.134 icmp_seq=2 Destination Host Unreachable SNAT 环境：\n主机A具有公网IP(使用192.168.37.131模拟),提供web服务\n主机B具有公网IP(使用192.168.37.134模拟)并且具有内网IP(172.17.0.1),为边界路由器\ncontainer1是内网主机，具有私网IP(172.17.0.3)，为内网中的一个用户，该用户需要访问外网的主机A\n在主机B上配置SNAT使得内网主机container1能够访问公网主机A上提供的服务\n确保主机B sysctl -w net.ipv4.ip_forward=1并且filter表FORWARD链中的规则是空的并且默认动作是ACCEPT，此时主机container1不能访问主机A\n[root@localhost ~]# sysctl -w net.ipv4.ip_forward=1 net.ipv4.ip_forward = 1 [root@localhost ~]# iptables -nvL FORWARD Chain FORWARD (policy ACCEPT 0 packets, 0 bytes) pkts bytes target prot opt in out source destination 在主机B上添加SNAT规则\n# --to-source表示将过滤到的包的源IP修改为192.168.37.134 iptables -t nat -A POSTROUTING -s 172.17.0.0/16 -j SNAT --to-source 192.168.37.134 在主机container1上访问主机A的服务\n#主机container1上执行,成功返回了内容 curl 192.168.37.131:8080 HELLO WORLD 查看主机A上服务的日志信息,可以看到记录的日志信息获取到的请求的源地址是192.168.37.134也就是主机B，至此主机B已经成功完成了对cotainer1主机请求的SNAT装换\n[root@centos72 ~]# ./echo-server -p http http server will listen on port: 8080 receive http request from 192.168.37.134:35816 DNAT 公司只有一个公网IP，但是公司的内网中却有很多服务器提供各种服务，我们想要通过公网访问这些服务，改怎么办呢？\n我们对外宣称，公司的公网IP上既提供了web服务，也提供了mysql，不管是访问web服务还是mysql，只要访问这个公网IP就行了，我们利用DNAT，将公网客户端发送过来的报文的目标地址与端口号做了映射，将访问web服务的报文转发到了内网中的container1主机中，将访问远程桌面的报文转发到了内网中的container2主机中\n环境：\n主机A为公网IP(使用192.168.37.131模拟)可以通主机B通信\n主机B具有两块网卡，一块IP为192.168.37.134可以通主机A通信，一块IP为172.17.0.1为内网IP，可以通container1、continer2通信\ncontainer1的IP为172.17.0.3，机器上部署有http服务\ncontainer2的IP为172.17.0.4，机器上部署有mysql\n要达到的效果为访问主机B的IP：8080端口可以访问到container1上部署的http服务，使用主机B的IP：3306可以访问到container2上部署的mysql\n在主机B上配置DNAT使得访问主机B上8080端口的包转发到container1，访问主机B上3306端口的包转发到container2上\n# --to-destination表示把过滤到的包的IP和port改为指定的 iptables -t nat -I PREROUTING -d 192.168.37.134 -p tcp --dport 8080 -j DNAT --to-destination 172.17.0.3:8080 iptables -t nat -I PREROUTING -d 192.168.37.134 -p tcp --dport 3306 -j DNAT --to-destination 172.17.0.4:3306 在主机A上测试访问主机B的IP的8080和3306端口,可以发现http服务和mysql都成功了，并且配置完DNAT也不用再配置SNAT了\ncurl 192.168.37.134:8080 HELLO WORLD mysql -h 192.168.37.134 -P 3306 -u root -p Enter password: ###MASQUERADE\n当我们拨号网上时，每次分配的IP地址往往不同，不会长期分给我们一个固定的IP地址，如果这时，我们想要让内网主机共享公网IP上网，就会很麻烦，因为每次IP地址发生变化以后，我们都要重新配置SNAT规则，这样显示不是很人性化，我们通过MASQUERADE即可解决这个问题，MASQUERADE会动态的将源地址转换为可用的IP地址，其实与SNAT实现的功能完全一致，都是修改源地址，只不过SNAT需要指明将报文的源地址改为哪个IP，而MASQUERADE则不用指定明确的IP，会动态的将报文的源地址修改为指定网卡上可用的IP地址\n环境：\n主机A的IP为192.168.37.131能够通主机B通信\n主机B具有两块网卡，一块的IP是192.168.37.134能够同主机A通信，一块的IP为172.17.0.1能够同container1通信\ncontainer1的IP为172.17.0.3能够同主机B通信\n目标：在主机B上配置MASQUERADE使得container1能够访问主机A上的http服务\n在主机B上配置MASQUERADE\niptables -t nat -I POSTROUTING -s 172.17.0.0/16 -o ens33 -j MASQUERADE 在container1上访问主机A的http服务\nHELLO WORLD 在主机A上查看http服务的日志,可以看到container1上的请求确实是经过了主机B代理\n[root@centos72 ~]# ./echo-server -p http http server will listen on port: 8080 receive http request from 192.168.37.134:43418 REDIRECT 使用REDIRECT动作可以在本机上进行端口映射\n将本机的80端口映射到本机的8080端口上\niptables -t nat -I PREROUTING -p tcp --dport 80 -j REDIRECT --to-ports 8080 在本机上测试访问,不能访问\ncurl 127.0.0.1 在同一局域网的其他主机访问，可以\t??? curl 192.168.37.134 HELLO WORLD 总结 规则的顺序非常重要\n如果报文已经被前面的规则匹配到，IPTABLES则会对报文执行对应的动作，通常是ACCEPT或者REJECT，报文被放行或拒绝以后，即使后面的规则也能匹配到刚才放行或拒绝的报文，也没有机会再对报文执行相应的动作了（前面规则的动作为LOG时除外），所以，针对相同服务的规则，更严格的规则应该放在前面\n当规则中有多个匹配条件时，条件之间默认存在”与”的关系\n如果一条规则中包含了多个匹配条件，那么报文必须同时满足这个规则中的所有匹配条件，报文才能被这条规则匹配到\n在不考虑1的情况下，应该将更容易被匹配到的规则放置在前面\n比如，你写了两条规则，一条针对sshd服务，一条针对web服务。\n假设，一天之内，有20000个请求访问web服务，有200个请求访问sshd服务，\n那么，应该将针对web服务的规则放在前面，针对sshd的规则放在后面，因为访问web服务的请求频率更高。\n如果将sshd的规则放在前面，当报文是访问web服务时，sshd的规则也要白白的验证一遍，由于访问web服务的频率更高，白白耗费的资源就更多。\n如果web服务的规则放在前面，由于访问web服务的频率更高，所以无用功会比较少。\n换句话说就是，在没有顺序要求的情况下，不同类别的规则，被匹配次数多的、匹配频率高的规则应该放在前面\n当IPTABLES所在主机作为网络防火 墙时，在配置规则时，应着重考虑方向性，双向都要考虑，从外到内，从内到外\n在配置IPTABLES白名单时，往往会将链的默认策略设置为ACCEPT，通过在链的最后设置REJECT规则实现白名单机制，而不是将链的默认策略设置为DROP，如果将链的默认策略设置为DROP，当链中的规则被清空时，管理员的请求也将会被DROP掉\n","permalink":"https://moyuduo.github.io/posts/iptables/","summary":"iptables 介绍 iptables是按照规则来办事的，我们就来说说规则（rules），规则其实就是网络管理员预定义的条件，规则一般的定义为”如果数据包头符合这样的条件，就这样处理这个数据包”。规则存储在内核空间的信息包过滤表中，这些规则分别指定了源地址、目的地址、传输协议（如TCP、UDP、ICMP）和服务类型（如HTTP、FTP和SMTP）等。当数据包与规则匹配时，iptables就根据规则所定义的方法来处理这些数据包，如放行（accept）、拒绝（reject）和丢弃（drop）等。配置防火墙的主要工作就是添加、修改和删除这些规则。\n当客户端访问服务器的web服务时，客户端发送报文到网卡，而tcp/ip协议栈是属于内核的一部分，所以，客户端的信息会通过内核的TCP协议传输到用户空间中的web服务中，而此时，客户端报文的目标终点为web服务所监听的套接字（IP：Port）上，当web服务需要响应客户端请求时，web服务发出的响应报文的目标终点则为客户端，这个时候，web服务所监听的IP与端口反而变成了原点，我们说过，netfilter才是真正的防火墙，它是内核的一部分，所以，如果我们想要防火墙能够达到”防火”的目的，则需要在内核中设置关卡，所有进出的报文都要通过这些关卡，经过检查后，符合放行条件的才能放行，符合阻拦条件的则需要被阻止，于是，就出现了input关卡和output关卡，而这些关卡在iptables中不被称为”关卡”,而被称为”链”。\n其实我们上面描述的场景并不完善，因为客户端发来的报文访问的目标地址可能并不是本机，而是其他服务器，当本机的内核支持IP_FORWARD时，我们可以将报文转发给其他服务器，所以，这个时候，我们就会提到iptables中的其他”关卡”，也就是其他”链”，他们就是 “路由前”、”转发”、”路由后”，他们的英文名是\nPREROUTING、FORWARD、POSTROUTING\n也就是说，当我们启用了防火墙功能时，报文需要经过如下关卡，也就是说，根据实际情况的不同，报文经过”链”可能不同。如果报文需要转发，那么报文则不会经过input链发往用户空间，而是直接在内核空间中经过forward链和postrouting链转发出去的。\n根据上图，我们能够想象出某些常用场景中，报文的流向：\n到本机某进程的报文：PREROUTING –\u0026gt; INPUT\n由本机转发的报文：PREROUTING –\u0026gt; FORWARD –\u0026gt; POSTROUTING\n由本机的某进程发出报文（通常为响应报文）：OUTPUT –\u0026gt; POSTROUTING\n链 现在，我们想象一下，这些”关卡”在iptables中为什么被称作”链”呢？我们知道，防火墙的作用就在于对经过的报文匹配”规则”，然后执行对应的”动作”,所以，当报文经过这些关卡的时候，则必须匹配这个关卡上的规则，但是，这个关卡上可能不止有一条规则，而是有很多条规则，当我们把这些规则串到一个链条上的时候，就形成了”链”,所以，我们把每一个”关卡”想象成如下图中的模样 ，这样来说，把他们称为”链”更为合适，每个经过这个”关卡”的报文，都要将这条”链”上的所有规则匹配一遍，如果有符合条件的规则，则执行规则对应的动作。\n表 我们再想想另外一个问题，我们对每个”链”上都放置了一串规则，但是这些规则有些很相似，比如，A类规则都是对IP或者端口的过滤，B类规则是修改报文，那么这个时候，我们是不是能把实现相同功能的规则放在一起呢，必须能的。\n我们把具有相同功能的规则的集合叫做”表”，所以说，不同功能的规则，我们可以放置在不同的表中进行管理，而iptables已经为我们定义了4种表，每种表对应了不同的功能，而我们定义的规则也都逃脱不了这4种功能的范围，所以，学习iptables之前，我们必须先搞明白每种表 的作用。\niptables为我们提供了如下规则的分类，或者说，iptables为我们提供了如下”表”\nfilter表：负责过滤功能，防火墙；内核模块：iptables_filter\nnat表：network address translation，网络地址转换功能；内核模块：iptable_nat\nmangle表：拆解报文，做出修改，并重新封装 的功能；iptable_mangle\nraw表：关闭nat表上启用的连接追踪机制；iptable_raw\n也就是说，我们自定义的所有规则，都是这四种分类中的规则，或者说，所有规则都存在于这4张”表”中。\n链和表的关系 我们需要注意的是，某些”链”中注定不会包含”某类规则”，就像某些”关卡”天生就不具备某些功能一样，比如，A”关卡”只负责打击陆地敌人，没有防空能力，B”关卡”只负责打击空中敌人，没有防御步兵的能力，C”关卡”可能比较NB，既能防空，也能防御陆地敌人，D”关卡”最屌，海陆空都能防。\n那让我们来看看，每个”关卡”都有哪些能力，或者说，让我们看看每个”链”上的规则都存在于哪些”表”中。\n我们还是以图为例，先看看prerouting”链”上的规则都存在于哪些表中。\n这幅图是什么意思呢？它的意思是说，prerouting”链”只拥有nat表、raw表和mangle表所对应的功能，所以，prerouting中的规则只能存放于nat表、raw表和mangle表中。\n根据上述思路，我们来总结一下，每个”关卡”都拥有什么功能，\n或者说，每个”链”中的规则都存在于哪些”表”中。\nPREROUTING 的规则可以存在于：raw表，mangle表，nat表。\nINPUT 的规则可以存在于：mangle表，filter表，（centos7中还有nat表，centos6中没有）。\nFORWARD 的规则可以存在于：mangle表，filter表。\nOUTPUT 的规则可以存在于：raw表mangle表，nat表，filter表。\nPOSTROUTING 的规则可以存在于：mangle表，nat表。\n我们还需要注意一点，因为数据包经过一个”链”的时候，会将当前链的所有规则都匹配一遍，但是匹配时总归要有顺序，我们应该一条一条的去匹配，而且我们说过，相同功能类型的规则会汇聚在一张”表”中，那么，哪些”表”中的规则会放在”链”的最前面执行呢，这时候就需要有一个优先级的问题，我们还拿prerouting”链”做图示。\nprerouting链中的规则存放于三张表中，而这三张表中的规则执行的优先级如下：\nraw –\u0026gt; mangle –\u0026gt; nat\n但是我们知道，iptables为我们定义了4张”表”,当他们处于同一条”链”时，执行的优先级如下。\n优先级次序（由高而低）：\nraw –\u0026gt; mangle –\u0026gt; nat –\u0026gt; filter\n为了更方便的管理，我们还可以在某个表里面创建自定义链，将针对某个应用程序所设置的规则放置在这个自定义链中，但是自定义链接不能直接使用，只能被某个默认的链当做动作去调用才能起作用，我们可以这样想象，自定义链就是一段比较”短”的链子，这条”短”链子上的规则都是针对某个应用程序制定的，但是这条短的链子并不能直接使用，而是需要”焊接”在iptables默认定义链子上，才能被IPtables使用，这就是为什么默认定义的”链”需要把”自定义链”当做”动作”去引用的原因。","title":"iptables"},{"content":"Java8新特性 Lambda表达式 简介 Lambda表达式可以取代大部分匿名内部类，可以优化代码结构。\n可以取代匿名内部类？什么意思呢？\n在以前如果我们需要对集合排序，我们是这样做：\nInteger[] arr= {3,2,1}; Arrays.sort(arr, new Comparator\u0026lt;Integer\u0026gt;() { @Override public int compare(Integer o1, Integer o2) { return o1-o2; } }); System.out.println(Arrays.toString(arr)); 使用Arrays类提供的sort方法传入一个指定排序规则的Comparator，如果我们使用匿名内部类的话，可以看到整个内部类中只用return o1-o2;语句是有用的，其他的都是多余的，为了这一句话我们多写了很多代码。那么，有了Lambda表达式后我们就可以很轻松的解决这个问题了。\njava8中新增了Lambda表达式，现在我们可以这样做：\nInteger[] arr= {3,2,1}; Arrays.sort(arr, (x,y)-\u0026gt;x-y); System.out.println(Arrays.toString(arr)); 那么Lambda是如何实现的呢？我们知道sort方法需要传入一个Comparator，而Comparator是一个接口，那么我们来看看Comparator接口是怎样定义的：\n@FunctionalInterface public interface Comparator\u0026lt;T\u0026gt; { Comparator能够支持Lambda表达式的秘密就是类上标注的@FunctionalInterface注解，被这个注解标注的接口只能有一个抽象方法，我们知道我们写Lambda表达式时并没有指定方法，那么当使用Lambda表达式时我们重新的就是这个方法。\nLambda表达式基本语法 语法形式为 () -\u0026gt; {}，其中 () 用来描述参数列表，{} 用来描述方法体，-\u0026gt; 为 lambda运算符\n接口无参无返回\n@FunctionalInterface interface NoParamNoReturn { void lambda(); } @Test public void test() { NoParamNoReturn noParamNoReturn=()-\u0026gt;{System.out.println(\u0026#34;No param No return\u0026#34;);}; noParamNoReturn.lambda(); } //如果方法内只有一个语句那么{}可以省略 @Test public void test() { NoParamNoReturn noParamNoReturn=()-\u0026gt;System.out.println(\u0026#34;No param No return\u0026#34;); noParamNoReturn.lambda(); } 接口有一个或多个参数无返回\n@FunctionalInterface interface OneParamNoReturn{ void lambda(int x); } @Test public void test() { OneParamNoReturn oneParamNoReturn=(int x)-\u0026gt;System.out.println(x); oneParamNoReturn.lambda(10); } //如果方法只有一个参数那么（）可以省略 //方法参数的类型也可以省略，编译器会根据方法参数类型推断 @Test public void test() { OneParamNoReturn oneParamNoReturn=x-\u0026gt;System.out.println(x); oneParamNoReturn.lambda(10); } 接口无参数有返回值\n@FunctionalInterface interface NoParamHasReturn{ int lambda(); } @Test public void test() { NoParamHasReturn noParamHasReturn=()-\u0026gt;{return 10;}; noParamHasReturn.lambda(); } //当方法只有return语句时，可以省略{}和return @Test public void test() { NoParamHasReturn noParamHasReturn=()-\u0026gt;10; noParamHasReturn.lambda(); } 接口有一个或多个参数有返回值\n@FunctionalInterface interface HasParamHasReturn{ int lambda(int x,int y); } @Test public void test() { HasParamHasReturn hasParamHasReturn=(x,y)-\u0026gt;x+y; hasParamHasReturn.lambda(10, 20); } Lambda表达式引用方法 我们可以使用lambda表达式把接口快速指向一个已经实现了的方法\n语法：方法归属者::方法名\t静态方法的归属者为类名，普通方法归属者为对象\n@FunctionalInterface interface HasParamHasReturn{ int lambda(int x,int y); } public class LambdaTest{ public int add(int x,int y) { return x+y; } //lambda表达式指向对象方法 @Test public void test() { LambdaTest lt=new LambdaTest(); HasParamHasReturn hasParamHasReturn=lt::add; hasParamHasReturn.lambda(10, 20); } public static int sub(int x,int y) { return x-y; } //lambda表达式引用静态方法 @Test public void test12() { HasParamHasReturn hasParamHasReturn=LambdaTest::sub; hasParamHasReturn.lambda(10, 20); } } //类名::实例方法 特殊情况,只有当参数列表为一个参数并且这个参数是方法调用者或多个参数并且第一个参数是调用者其他参数是参数列表 @Test public void test() { BiPredicate\u0026lt;String,String\u0026gt; bp=(x,y)-\u0026gt;x.equals(y); //也可以简写为 BiPredicate\u0026lt;String,String\u0026gt; bp2=String::equals; } lambda表达式引用构造函数创建对象\n语法：类名::new；\nclass User{ String name; int age; public User() {} public User(String name, int age) { super(); this.name = name; this.age = age; } } @FunctionalInterface interface UserCreatorBlankConstruct{ User getUser(); } //使用lambda表达式引用构造器 @Test public void test() { UserCreatorBlankConstruct creator1=User::new; creator1.getUser(); } @FunctionalInterface interface UserCreatorParamConstruct{ User getUser(String name,int age); } @Test public void test13() { UserCreatorParamConstruct creator2=User::new; creator2.getUser(\u0026#34;tom\u0026#34;, 20); } java8为我们提供了4个核心的函数式接口 消费型接口 @FunctionalInterface public interface Consumer\u0026lt;T\u0026gt; { void accept(T t); } 供给型接口\n@FunctionalInterface public interface Supplier\u0026lt;T\u0026gt; { T get(); } 函数型接口\n@FunctionalInterface public interface Function\u0026lt;T, R\u0026gt; { R apply(T t); } 断言型接口\n@FunctionalInterface public interface Predicate\u0026lt;T\u0026gt; { boolean test(T t); } 怎么用呢？\n遍历数组\n@Test public void test() { List\u0026lt;Integer\u0026gt; list=new ArrayList\u0026lt;\u0026gt;(); list.add(1); list.add(3); list.add(5); list.add(7); list.forEach(System.out::println); } 创建对象\n@Test public void test() { Supplier\u0026lt;User\u0026gt; supplier=User::new; User user = supplier.get(); } 去除前后空格并转为大写\n@Test public void test16() { Function\u0026lt;String, String\u0026gt; fun=s-\u0026gt;{s=s.trim();s=s.toUpperCase();return s;}; String apply = fun.apply(\u0026#34; abCd\u0026#34;); } 删除集合元素\n@Test public void test() { List\u0026lt;User\u0026gt; list=new ArrayList\u0026lt;\u0026gt;(); list.add(new User(\u0026#34;tom\u0026#34;,20)); list.add(new User(\u0026#34;jack\u0026#34;,18)); list.add(new User(\u0026#34;marry\u0026#34;,22)); list.removeIf(e-\u0026gt;e.getName()==\u0026#34;jack\u0026#34;); } 那如果我们要用内置函数式接口创建对象，怎么做呢？\n@Test public void test() { Supplier\u0026lt;User\u0026gt; supplier=User::new; User user = supplier.get(); System.out.println(user);//User [name=null, age=0] } 那到底使用的是哪个构造器呢？通过输出创建的对象可以发现调用的是无参构造器，即调用构造器参数个数对应Supplier中get方法的参数个数的构造器\n那么问题又来了，如果我们要使用两个参数的构造器，那Supplier也不行啊，Function的apply方法也只有一个参数，怎么办？那我们去java.util.function包下找找有没有可以用的接口\n@FunctionalInterface public interface BiFunction\u0026lt;T, U, R\u0026gt; { R apply(T t, U u); } //使用内置函数式接口创建对象 @Test public void test20() { BiFunction\u0026lt;String,Integer,User\u0026gt; biFunction=User::new; User user = biFunction.apply(\u0026#34;tom\u0026#34;, 20); System.out.println(user);//User [name=tom, age=20] } 四个基本接口参数个数不够用也可以类似的去java.util.function包下找找有没有申明好的函数式接口\n最后一个问题，我发现\nlist.forEach(System.out::println); 遍历List时，使用的forEach的参数Consumer的accept方法是这么写的，我第一个想到的是，out是System的一个内部类，但是当我点进去，发现是这样的\npublic final static PrintStream out = null; out是一个静态的成员变量，那我的理解就是System.out其实是一个对象\n这样System.out::println的写法其实也就是\t对象名::方法名\n我是这样理解的，如果错了还请赐教！\nStream 介绍 java8添加了一个抽象流Stream，可以让我们像写sql一样操作集合元素。Stream将要处理的元素看做是一种流，\t在管道中传输，并进行处理，最后由终止操作得到处理的结果。\n什么是Stream？ Stream是一个来自特定元素队列并支持聚合操作\n元素是具体类型的对象，形成一个队列。 数据源是流的来源。 聚合操作是类似sql一样的操作，比如filter, map, reduce, find, match, sorted等。 Stream自己不会存储元素。 Stream不会改变源对象。 Stream操作是延迟执行的。 创建流 串行流 stream()：即单线程的方式去操作流\n并行流 parallelStream():即多线程方式去操作流\n@Test public void test() { //1通过Collection提供的stream()和parallelStream()方法 List\u0026lt;String\u0026gt; list = Arrays.asList(\u0026#34;a\u0026#34;,\u0026#34;b\u0026#34;,\u0026#34;c\u0026#34;); Stream\u0026lt;String\u0026gt; stream1 = list.stream(); Stream\u0026lt;String\u0026gt; stream2 = list.parallelStream(); //2通过Arrays的静态方法stream() String[] strs= {\u0026#34;a\u0026#34;,\u0026#34;b\u0026#34;,\u0026#34;c\u0026#34;}; Stream\u0026lt;String\u0026gt; stream3 = Arrays.stream(strs); //3通过Stream类中的静态方法of() Stream\u0026lt;String\u0026gt; stream4 = Stream.of(\u0026#34;a\u0026#34;,\u0026#34;b\u0026#34;,\u0026#34;c\u0026#34;); //4通过Stream类的iterate方法生成无限流 Stream\u0026lt;Integer\u0026gt; stream5 = Stream.iterate(0, (x)-\u0026gt;x+1); //5通过Stream的generate方法生成无限流 Stream.generate(()-\u0026gt;Math.random()); } 中间操作 过滤 使用 filter(Predicate\u0026lt;? super T\u0026gt; predicate)来按照一定规则对流中元素进行过滤\n@Test public void test() { List\u0026lt;Integer\u0026gt; list = Arrays.asList(1,2,3,4,5); Stream\u0026lt;Integer\u0026gt; stream = list.stream(); stream = stream.filter((x)-\u0026gt;x.compareTo(2)\u0026gt;0); stream.forEach(System.out::println); } 输出： 3 4 5 @Test public void test2() { List\u0026lt;Integer\u0026gt; list = Arrays.asList(1,2,3,4,5); Stream\u0026lt;Integer\u0026gt; stream = list.stream(); stream = stream.filter( (x)-\u0026gt;{ System.out.println(x); return x.compareTo(2)\u0026gt;0;} ); } 结果：没有任何输出，这也就是前面说的Stream操作是延迟执行的，只有当终止操作这些中间操作才会依次执行 截断 使元素的个数不超过指定的数目\n@Test public void test() { List\u0026lt;Integer\u0026gt; list = Arrays.asList(1,2,3,4,5); Stream\u0026lt;Integer\u0026gt; stream = list.stream(); stream=stream.limit(3); stream.forEach(System.out::println); } 输出： 1 2 3 可以看到只输出了给定个元素 跳过元素 跳过流中前几个元素\n@Test public void test4() { List\u0026lt;Integer\u0026gt; list = Arrays.asList(1,2,3,4,5); Stream\u0026lt;Integer\u0026gt; stream = list.stream(); stream=stream.skip(2); stream.forEach(System.out::println); } 输出: 3 4 5 跳过了前两个元素 唯一筛选 两个元素通过hashCode()判断两个元素是否相同\n@Test public void test5() { List\u0026lt;Integer\u0026gt; list = Arrays.asList(1,2,3,4,5,5); Stream\u0026lt;Integer\u0026gt; stream = list.stream(); stream.distinct().forEach(System.out::println); } 输出: 1 2 3 4 5 映射 map(method)接受一个方法，把流中的元素按照方法进行转换\n@Test public void test() { List\u0026lt;String\u0026gt; list = Arrays.asList(\u0026#34;a\u0026#34;,\u0026#34;b\u0026#34;,\u0026#34;c\u0026#34;); Stream\u0026lt;String\u0026gt; stream = list.stream(); stream=stream.map((x)-\u0026gt;x.toUpperCase()); stream.forEach(System.out::println); } 输出： A B C flatMap(method)也是接受一个函数作为参数，但是与map，不同的是如果这个函数生成的本来就是流，它会把函数生成流中的元素加到流中\n//这个函数本身就生成流 public static Stream\u0026lt;Character\u0026gt; toStream(String s){ List\u0026lt;Character\u0026gt; list=new ArrayList\u0026lt;Character\u0026gt;(); char[] chs = s.toCharArray(); for (char c : chs) { list.add(c); } Stream\u0026lt;Character\u0026gt; stream = list.stream(); return stream; } @Test public void test() { List\u0026lt;String\u0026gt; list = Arrays.asList(\u0026#34;aaa\u0026#34;,\u0026#34;bbb\u0026#34;,\u0026#34;ccc\u0026#34;); Stream\u0026lt;Stream\u0026lt;Character\u0026gt;\u0026gt; stream = //由于函数本身就生成流，所以流中加入的还是流 list.stream().map(StreamTest::toStream); //遍历的时候需要先从流中取出流，在遍历 stream.forEach((s)-\u0026gt;s.forEach(System.out::println)); } //然而我们可以使用flatMap进行改进 @Test public void test() { List\u0026lt;String\u0026gt; list = Arrays.asList(\u0026#34;aaa\u0026#34;,\u0026#34;bbb\u0026#34;,\u0026#34;ccc\u0026#34;); list.stream().flatMap(StreamTest::toStream).forEach(System.out::println); } 输出： a a a b b b c c c 终止操作 所有匹配 当所有元素都匹配时，allMatch(Predicate\u0026lt;? super T\u0026gt; predicate)才会返回true\n@Test public void test() { List\u0026lt;String\u0026gt; list = Arrays.asList(\u0026#34;aaa\u0026#34;,\u0026#34;bbb\u0026#34;,\u0026#34;ccc\u0026#34;); boolean allMatch = list.stream().allMatch((s)-\u0026gt;s.length()\u0026gt;2); System.out.println(allMatch); } 输出： true 任一匹配 当Stream中任一一个元素匹配时，anyMatch(Predicate\u0026lt;? super T\u0026gt; predicate)返回true\n@Test public void test() { List\u0026lt;String\u0026gt; list = Arrays.asList(\u0026#34;aaa\u0026#34;,\u0026#34;bbb\u0026#34;,\u0026#34;ccc\u0026#34;); boolean anyMatch = list.stream().anyMatch((s)-\u0026gt;s.equals(\u0026#34;bbb\u0026#34;)); System.out.println(anyMatch); } 输出： true 所有不匹配 当Stream中所有的元素都不匹配时，noneMatch(Predicate\u0026lt;? super T\u0026gt; predicate)返回true\n@Test public void test() { List\u0026lt;String\u0026gt; list = Arrays.asList(\u0026#34;aaa\u0026#34;,\u0026#34;bbb\u0026#34;,\u0026#34;ccc\u0026#34;); boolean noneMatch = list.stream().noneMatch((s)-\u0026gt;s.equals(\u0026#34;ddd\u0026#34;)); System.out.println(noneMatch); } 输出： true 第一个元素 返回当前流中的第一个元素\n@Test public void test() { List\u0026lt;Integer\u0026gt; list = Arrays.asList(1,2,3,4,5); Optional\u0026lt;Integer\u0026gt; findFirst = list.stream().findFirst(); System.out.println(findFirst.get()); } 输出： 1 任一一个元素 返回当前流中的任一一个元素\n@Test public void test() { List\u0026lt;Integer\u0026gt; list = Arrays.asList(1,2,3,4,5); Optional\u0026lt;Integer\u0026gt; findAny = list.stream().findAny(); System.out.println(findAny.get()); } 输出： 1 //使用并行流试试 @Test public void test13() { List\u0026lt;Integer\u0026gt; list = Arrays.asList(1,2,3,4,5); Optional\u0026lt;Integer\u0026gt; findAny = list.parallelStream().findAny(); System.out.println(findAny.get()); } 输出： 3 流中元素个数 返回流中的元素个数\n@Test public void test14() { List\u0026lt;Integer\u0026gt; list = Arrays.asList(1,2,3,4,5); long count = list.stream().count(); System.out.println(count); } 输出： 5 流中的最大值 返回流中元素的最大值\n@Test public void test15() { List\u0026lt;Integer\u0026gt; list = Arrays.asList(1,2,3,4,5); Optional\u0026lt;Integer\u0026gt; max = list.stream().max(Integer::compare); System.out.println(max.get()); } 输出： 5 流中的最小值 返回流中的最小值\n@Test public void test16() { List\u0026lt;Integer\u0026gt; list = Arrays.asList(1,2,3,4,5); Optional\u0026lt;Integer\u0026gt; min = list.stream().min(Integer::compare); System.out.println(min.get()); } 输出： 1 规约 将流中的元素反复结合得到一个最终值\n@Test public void test() { List\u0026lt;Integer\u0026gt; list = Arrays.asList(1,2,3,4,5); Optional\u0026lt;Integer\u0026gt; reduce = list.stream().reduce(Integer::sum); System.out.println(reduce.get()); Integer reduce2 = list.stream().reduce(0, (x,y)-\u0026gt;{ System.out.println(x+\u0026#34;-\u0026gt;\u0026#34;+y); return x+y; }); System.out.println(reduce2); } 输出： 15 0-\u0026gt;1 1-\u0026gt;2 3-\u0026gt;3 6-\u0026gt;4 10-\u0026gt;5 15 可以看到当使用(T identity, BinaryOperator accumulator)时，identity即为最初和流中元素进行运算的，所以值不能为空，所以返回的不是Optional\n收集 将流转换成其他形式\n@Test public void test() { List\u0026lt;Integer\u0026gt; list = Arrays.asList(1,2,3,4,5,5); Set\u0026lt;Integer\u0026gt; collect = list.stream().collect(Collectors.toSet()); System.out.println(collect); } 输出： [1, 2, 3, 4, 5] @Test public void test() { List\u0026lt;Integer\u0026gt; list = Arrays.asList(1,2,3,4,5,5); Optional\u0026lt;Integer\u0026gt; collect = list.stream().collect(Collectors.maxBy(Integer::compareTo)); System.out.println(collect.get()); } 输出： 5 class Stu{ String name; Integer age; String gender; public Stu(String name, Integer age, String gender) { super(); this.name = name; this.age = age; this.gender = gender; } public String getName() { return name; } public void setName(String name) { this.name = name; } public Integer getAge() { return age; } public void setAge(Integer age) { this.age = age; } public String getGender() { return gender; } public void setGender(String gender) { this.gender = gender; } @Override public String toString() { return \u0026#34;Stu [name=\u0026#34; + name + \u0026#34;, age=\u0026#34; + age + \u0026#34;, gender=\u0026#34; + gender + \u0026#34;]\u0026#34;; } } //一级分组 @Test public void test() { List\u0026lt;Stu\u0026gt; list = Arrays.asList( new Stu(\u0026#34;张三\u0026#34;,20,\u0026#34;男\u0026#34;), new Stu(\u0026#34;李四\u0026#34;,22,\u0026#34;女\u0026#34;), new Stu(\u0026#34;王五\u0026#34;,18,\u0026#34;男\u0026#34;), new Stu(\u0026#34;赵六\u0026#34;,20,\u0026#34;女\u0026#34;), new Stu(\u0026#34;田七\u0026#34;,22,\u0026#34;女\u0026#34;) ); Map\u0026lt;String, List\u0026lt;Stu\u0026gt;\u0026gt; collect = list.stream().collect(Collectors.groupingBy(Stu::getGender)); System.out.println(collect); } 输出： {女=[Stu [name=李四, age=22, gender=女], Stu [name=赵六, age=20, gender=女], Stu [name=田七, age=22, gender=女]], 男=[Stu [name=张三, age=20, gender=男], Stu [name=王五, age=18, gender=男]]} //二级分组 @Test public void test21() { List\u0026lt;Stu\u0026gt; list = Arrays.asList( new Stu(\u0026#34;张三\u0026#34;,20,\u0026#34;男\u0026#34;), new Stu(\u0026#34;李四\u0026#34;,22,\u0026#34;女\u0026#34;), new Stu(\u0026#34;王五\u0026#34;,18,\u0026#34;男\u0026#34;), new Stu(\u0026#34;赵六\u0026#34;,20,\u0026#34;女\u0026#34;), new Stu(\u0026#34;田七\u0026#34;,22,\u0026#34;女\u0026#34;) ); Map\u0026lt;Integer, Map\u0026lt;String, List\u0026lt;Stu\u0026gt;\u0026gt;\u0026gt; collect = list.stream() .collect(Collectors.groupingBy(Stu::getAge, Collectors.groupingBy(Stu::getGender))); System.out.println(collect); } 输出： {18={男=[Stu [name=王五, age=18, gender=男]]}, 20={女=[Stu [name=赵六, age=20, gender=女]], 男=[Stu [name=张三, age=20, gender=男]]}, 22={女=[Stu [name=李四, age=22, gender=女], Stu [name=田七, age=22, gender=女]]}} //分区 @Test public void test22() { List\u0026lt;Stu\u0026gt; list = Arrays.asList( new Stu(\u0026#34;张三\u0026#34;,20,\u0026#34;男\u0026#34;), new Stu(\u0026#34;李四\u0026#34;,22,\u0026#34;女\u0026#34;), new Stu(\u0026#34;王五\u0026#34;,18,\u0026#34;男\u0026#34;), new Stu(\u0026#34;赵六\u0026#34;,20,\u0026#34;女\u0026#34;), new Stu(\u0026#34;田七\u0026#34;,22,\u0026#34;女\u0026#34;) ); Map\u0026lt;Boolean, List\u0026lt;Stu\u0026gt;\u0026gt; collect = list.stream() .collect(Collectors.partitioningBy((e)-\u0026gt;((Stu)e).getAge()\u0026gt;20)); System.out.println(collect); } 输出： {false=[Stu [name=张三, age=20, gender=男], Stu [name=王五, age=18, gender=男], Stu [name=赵六, age=20, gender=女]], true=[Stu [name=李四, age=22, gender=女], Stu [name=田七, age=22, gender=女]]} 接口默认方法和静态方法 默认方法 interface MyInterface1 { default String method1() { return \u0026#34;myInterface1 default method\u0026#34;; } } class MyClass{ public String method1() { return \u0026#34;myClass method\u0026#34;; } } /** * 父类和接口中都有相同的方法，默认使用父类的方法，即类优先 * @author 莫雨朵 * */ class MySubClass1 extends MyClass implements MyInterface1{ } @Test public void test1() { MySubClass1 mySubClass1=new MySubClass1(); System.out.println(mySubClass1.method1());//myClass method } 如果类的父类的方法和接口中方法名字相同且参数一致，子类还没有重写方法，那么默认使用父类的方法，即类优先\ninterface MyInterface1 { default String method1() { return \u0026#34;myInterface1 default method\u0026#34;; } } interface MyInterface2 { default String method1() { return \u0026#34;myInterface2 default method\u0026#34;; } } /** * 如果类实现的接口中有名字相同参数类型一致的默认方法，那么在类中必须重写 * @author 莫雨朵 * */ class MySubClass2 implements MyInterface1,MyInterface2{ @Override public String method1() { return MyInterface1.super.method1(); } } @Test public void test2() { MySubClass2 mySubClass2=new MySubClass2(); System.out.println(mySubClass2.method1());//myInterface1 default method } 如果类实现的接口中有名字相同参数类型一致的默认方法，那么在类中必须重写\n静态方法 interface MyInterface1 {\tstatic String method2() { return \u0026#34;interface static method\u0026#34;; } } @Test public void test3() { System.out.println(MyInterface1.method2());//interface static method } 时间 java8以前使用的时间很多方法都已经废弃了，而且不是线程安全的，java8提供了一系列的时间类，这些时间类都是线程安全的\nLocalDate、LocalTime、LocalDateTime 这三个关于时间的类在使用上都类似\n/** * LocalDate */ @Test public void test1() { LocalDate date1 = LocalDate.now(); System.out.println(date1);//2020-03-30 LocalDate plusYears = date1.plusYears(1); System.out.println(plusYears);//2021-03-30 LocalDate minusDays = date1.minusDays(2); System.out.println(minusDays);//2020-03-28 LocalDate date2 = LocalDate.of(2019, 3, 30); System.out.println(date2.getYear());//2019 } /** * LocalTime */ @Test public void test2() { LocalTime now = LocalTime.now(); System.out.println(now);//21:15:23.418 int minute = now.getMinute(); System.out.println(minute);//15 int second = now.getSecond(); System.out.println(second);//23 LocalTime of = LocalTime.of(10, 10, 10); System.out.println(of);//10:10:10 LocalTime minusMinutes = of.minusMinutes(2); System.out.println(minusMinutes);//10:08:10 LocalTime plusHours = of.plusHours(2); System.out.println(plusHours);//12:10:10 } /** * LocalDateTime */ @Test public void test3() { LocalDateTime now = LocalDateTime.now(); System.out.println(now);//2020-03-30T21:20:37.961 int minute = now.getMinute(); System.out.println(minute);//20 LocalDateTime plusMinutes = now.plusMinutes(20); System.out.println(plusMinutes);//2020-03-30T21:40:37.961 LocalDateTime minusYears = now.minusYears(2); System.out.println(minusYears);//2018-03-30T21:20:37.961 LocalDateTime of = LocalDateTime.of(2021, 3, 30, 21, 19, 50); System.out.println(of);//2021-03-30T21:19:50 } 时间戳 /** * Instant */ @Test public void test4() { Instant now = Instant.now(); System.out.println(now);//2020-03-30T13:26:10.640Z Instant plusSeconds = now.plusSeconds(10); System.out.println(plusSeconds);//2020-03-30T13:26:20.640Z //获取时间戳相对于1970年0时0分0秒的毫秒数 long epochMilli = plusSeconds.toEpochMilli(); System.out.println(epochMilli);//1585574780640 } Duration获取时间间隔 /** * Duration */ @Test public void test5() { Instant start = Instant.now(); Instant end = start.plusSeconds(10); Duration duration = Duration.between(start, end); long seconds = duration.getSeconds(); //获取时间间隔的秒数 System.out.println(seconds);//10 //获取时间间隔的毫秒数 long millis = duration.toMillis(); System.out.println(millis);//10000 } Peroid获取日期间隔 @Test public void test6() { LocalDate date1 = LocalDate.now(); LocalDate date2 = date1.plusYears(2); Period period = Period.between(date1, date2); //获取两时间间隔的月数,指两个月份的间隔数，并不是时间间隔的总月数 int months = period.getMonths(); System.out.println(months);//0 } TemporalAdjuster矫正日期 @Test public void test7() { LocalDate date1 = LocalDate.now(); System.out.println(date1);//2020-03-31 //TemporalAdjusters类中封装了一些常用地时间矫正方法 TemporalAdjuster next = TemporalAdjusters.next(DayOfWeek.FRIDAY); LocalDate date2 = date1.with(next); System.out.println(date2);//2020-04-03 //自定义时间矫正器 LocalDate date3 = date1.with(x-\u0026gt;{ LocalDate ld=(LocalDate)x; DayOfWeek dayOfWeek = ld.getDayOfWeek(); if(dayOfWeek.equals(DayOfWeek.FRIDAY)) { return ld.plusDays(3); }else if(dayOfWeek.equals(DayOfWeek.SATURDAY)) { return ld.plusDays(2); }else { return ld.plusDays(1); } }); System.out.println(date3);//2020-04-01 } 由于TemporalAdjuster是一个函数式接口，所以我们可以使用lambda表达式自定义矫正规则\n@FunctionalInterface public interface TemporalAdjuster { Temporal adjustInto(Temporal temporal); } DateTimeFormatter格式化日期时间 @Test public void test8() { LocalDateTime dateTime1 = LocalDateTime.now(); System.out.println(dateTime1);//2020-03-31T18:28:04.256 DateTimeFormatter formatter1 = DateTimeFormatter.ISO_DATE; String format1 = dateTime1.format(formatter1); System.out.println(format1);//2020-03-31 DateTimeFormatter formatter2 = DateTimeFormatter.ofPattern(\u0026#34;yyyy年MM月dd日HH时mm分ss秒\u0026#34;); String format2 = dateTime1.format(formatter2); System.out.println(format2);//2020年03月31日18时28分04秒 LocalDateTime dateTime2 = LocalDateTime.parse(format2, formatter2); System.out.println(dateTime2);//2020-03-31T18:28:04 } ZoneDate @Test public void test9() { //获取可用时区 ZoneId.getAvailableZoneIds().forEach(System.out::println); LocalDate date1 = LocalDate.now(ZoneId.of(\u0026#34;Asia/Tokyo\u0026#34;)); System.out.println(date1);//2020-03-31 } ZoneTime @Test public void test10() { LocalTime time1 = LocalTime.now(ZoneId.of(\u0026#34;Asia/Tokyo\u0026#34;)); System.out.println(time1);//19:44:15.228 OffsetTime atOffset = time1.atOffset(ZoneOffset.ofHours(2)); System.out.println(atOffset);//19:44:15.228+02:00 } ZoneDateTime @Test public void test11() { LocalDateTime dateTime1 = LocalDateTime.now(ZoneId.of(\u0026#34;Asia/Shanghai\u0026#34;)); System.out.println(dateTime1);//2020-03-31T18:51:07.136 ZonedDateTime atZone = dateTime1.atZone(ZoneId.of(\u0026#34;Asia/Shanghai\u0026#34;)); System.out.println(atZone);//2020-03-31T18:51:07.136+08:00[Asia/Shanghai]\t+09:00表示时间比格林尼治时间快9小时 } 重复注解 @Retention(RetentionPolicy.RUNTIME) @Target(ElementType.METHOD) public @interface MAnnotation { String name() default \u0026#34;\u0026#34;; int age(); } public class AnnotataionTest { @Test public void test() throws Exception { Class\u0026lt;AnnotataionTest\u0026gt; clazz=AnnotataionTest.class; Method method = clazz.getMethod(\u0026#34;good\u0026#34;, null); MAnnotation annotation = method.getAnnotation(MAnnotation.class); System.out.println(annotation.name()+\u0026#34;:\u0026#34;+annotation.age()); } @MAnnotation(name=\u0026#34;tom\u0026#34;,age=20) public void good() { } } 以前我们是这样使用注解，当要在一个方法上标注两个相同的注解时会报错，java8允许使用一个注解来存储注解，可以实现一个注解重复标注\n@Retention(RetentionPolicy.RUNTIME) @Target(ElementType.METHOD) @Repeatable(MAnnotations.class)//使用@Repeatable来标注存储注解的注解 public @interface MAnnotation { String name() default \u0026#34;\u0026#34;; int age(); } @Retention(RetentionPolicy.RUNTIME) @Target(ElementType.METHOD) public @interface MAnnotations { MAnnotation[] value(); } public class AnnotataionTest { @Test public void test() throws Exception { Class\u0026lt;AnnotataionTest\u0026gt; clazz=AnnotataionTest.class; Method method = clazz.getMethod(\u0026#34;good\u0026#34;); MAnnotation[] mAnnotations = method.getAnnotationsByType(MAnnotation.class); for (MAnnotation annotation : mAnnotations) { System.out.println(annotation.name()+\u0026#34;:\u0026#34;+annotation.age()); } } @MAnnotation(name=\u0026#34;tom\u0026#34;,age=20) @MAnnotation(name=\u0026#34;jack\u0026#34;,age=25) public void good() { } } ","permalink":"https://moyuduo.github.io/posts/java8%E6%96%B0%E7%89%B9%E6%80%A7/","summary":"Java8新特性 Lambda表达式 简介 Lambda表达式可以取代大部分匿名内部类，可以优化代码结构。\n可以取代匿名内部类？什么意思呢？\n在以前如果我们需要对集合排序，我们是这样做：\nInteger[] arr= {3,2,1}; Arrays.sort(arr, new Comparator\u0026lt;Integer\u0026gt;() { @Override public int compare(Integer o1, Integer o2) { return o1-o2; } }); System.out.println(Arrays.toString(arr)); 使用Arrays类提供的sort方法传入一个指定排序规则的Comparator，如果我们使用匿名内部类的话，可以看到整个内部类中只用return o1-o2;语句是有用的，其他的都是多余的，为了这一句话我们多写了很多代码。那么，有了Lambda表达式后我们就可以很轻松的解决这个问题了。\njava8中新增了Lambda表达式，现在我们可以这样做：\nInteger[] arr= {3,2,1}; Arrays.sort(arr, (x,y)-\u0026gt;x-y); System.out.println(Arrays.toString(arr)); 那么Lambda是如何实现的呢？我们知道sort方法需要传入一个Comparator，而Comparator是一个接口，那么我们来看看Comparator接口是怎样定义的：\n@FunctionalInterface public interface Comparator\u0026lt;T\u0026gt; { Comparator能够支持Lambda表达式的秘密就是类上标注的@FunctionalInterface注解，被这个注解标注的接口只能有一个抽象方法，我们知道我们写Lambda表达式时并没有指定方法，那么当使用Lambda表达式时我们重新的就是这个方法。\nLambda表达式基本语法 语法形式为 () -\u0026gt; {}，其中 () 用来描述参数列表，{} 用来描述方法体，-\u0026gt; 为 lambda运算符\n接口无参无返回\n@FunctionalInterface interface NoParamNoReturn { void lambda(); } @Test public void test() { NoParamNoReturn noParamNoReturn=()-\u0026gt;{System.out.println(\u0026#34;No param No return\u0026#34;);}; noParamNoReturn.","title":"Java8新特性"},{"content":"java克隆 为什么需要克隆 我们在很多时候需要使用一个对象去记录另外一个对象的当前状态，对象中可能会有很多属性，如果我们一个一个去设置，不仅不方便，而且效率很低,我们看一个初学者可能遇到的问题\nclass Person{ String name; int age; public Person() {} public Person(String name, int age) { super(); this.name = name; this.age = age; } @Override public String toString() { return \u0026#34;Person [name=\u0026#34; + name + \u0026#34;, age=\u0026#34; + age + \u0026#34;]\u0026#34;; } } @Test public void test2() { Person p1=new Person(\u0026#34;tom\u0026#34;,20); Person p2=p1; System.out.println(p1); System.out.println(p2); System.out.println(\u0026#34;---------\u0026#34;); p1.age=30; System.out.println(p1); System.out.println(p2); } 输出： Person [name=tom, age=20] Person [name=tom, age=20] --------- Person [name=tom, age=30] Person [name=tom, age=30] 也许有的人认为Person p2=p1这样的方式就可以克隆一个对象，这种想法是错误的，这种使用等号赋值的方式只是将p1的地址赋值给了p2对象，那么p1和p2都指向了堆中的同一个对象，所以，修改p1那么p2也就变了\n如果一个一个属性的去手动设置不仅麻烦，而且属性可能也有属性，修改起来不容易\npublic void test2() { Person p1=new Person(\u0026#34;tom\u0026#34;,20); Person p2=new Person(); p2.age=p1.age; p2.name=p1.name; } 这里Person的属性层级很简单，修改起来看起来很简单，但是如果Person多了一个Address类型的属性，那么手动修改就必须要去new一个Address并赋值属性，假如属性的嵌套层级深了，就很难了\n所以我们可以使用Object提供的clone方法来克隆对象，由于clone方法是用protected关键字修饰的，我们如果想在类外使用就需要重写父类的方法，Object的clone方法是一个native关键字修饰的方法，即调用其他语言的方法，效率很高，值得注意的一点是要克隆对象的类必须实现Cloneable接口，这个接口是一个标记接口，里面并没有定义任何方法，如果没事实现Cloneable接口使用clone方法，会抛出CloneNotSupportedException异常\n浅克隆 如果原型对象的属性是值类型，那么复制一份给克隆对象，如果属性是引用类型，那么把属性的引用赋值给克隆对象\nclass Person implements Cloneable{//必须实现Cloneable接口 String name; int age; public Person() {} public Person(String name, int age) { super(); this.name = name; this.age = age; } @Override public String toString() { return \u0026#34;Person [name=\u0026#34; + name + \u0026#34;, age=\u0026#34; + age + \u0026#34;]\u0026#34;; } @Override protected Object clone(){ Person p=null; try { p=(Person)super.clone(); }catch(CloneNotSupportedException e) {//实现了Cloneable接口这个异常就不可能发生 e.printStackTrace(); } return p; } } @Test public void test2() { Person p1=new Person(\u0026#34;tom\u0026#34;,20); Person p2=(Person)p1.clone(); System.out.println(p1); System.out.println(p2); System.out.println(\u0026#34;---------\u0026#34;); p1.age=30; System.out.println(p1); System.out.println(p2); } 输出： Person [name=tom, age=20] Person [name=tom, age=20] --------- Person [name=tom, age=30] Person [name=tom, age=20] 这种Object提供的clone在类中的属性全是值类型的时候不会出现问题，但是如果类属性有引用类型就会出现问题\nclass Person implements Cloneable{ String name; int age; Address address; public Person() {} public Person(String name, int age,Address addr) { super(); this.name = name; this.age = age; this.address=addr; } @Override public String toString() { return \u0026#34;Person [name=\u0026#34; + name + \u0026#34;, age=\u0026#34; + age + \u0026#34;, address=\u0026#34; + address + \u0026#34;]\u0026#34;; } @Override protected Object clone(){ Person p=null; try { p=(Person)super.clone(); }catch(CloneNotSupportedException e) { e.printStackTrace(); } return p; } } class Address{ String addr; public Address(String addr) { super(); this.addr = addr; } @Override public String toString() { return \u0026#34;Address [addr=\u0026#34; + addr + \u0026#34;]\u0026#34;; } } @Test public void test2() { Address addr=new Address(\u0026#34;成都市郫都区\u0026#34;); Person p1=new Person(\u0026#34;tom\u0026#34;,20,addr); Person p2=(Person)p1.clone(); System.out.println(p1); System.out.println(p2); System.out.println(\u0026#34;---------\u0026#34;); p1.address.addr=\u0026#34;成都市金牛区\u0026#34;; System.out.println(p1); System.out.println(p2); } 输出： Person [name=tom, age=20, address=Address [addr=成都市郫都区]] Person [name=tom, age=20, address=Address [addr=成都市郫都区]] --------- Person [name=tom, age=20, address=Address [addr=成都市金牛区]] Person [name=tom, age=20, address=Address [addr=成都市金牛区]] 修改p1的address根据p1克隆出来的p2的address也改变了，这就是所说的当克隆对象的属性是引用类型时，只会复制它的引用，而这种情况一般是我们不希望的，所以需要使用深克隆\n深克隆 1.克隆对象所有的引用类型都重写clone方法 这里所说的引用类型重写clone方法，是指克隆对象本身属性是引用类型的必须重写clone方法且引用类型中的引用类型也必要要重写，且必须在clone方法中显式条用\nclass Person implements Cloneable{ String name; int age; Address address;//这个属性是引用类型，必须实现Cloneable接口重写clone方法 public Person() {} public Person(String name, int age,Address addr) { super(); this.name = name; this.age = age; this.address=addr; } @Override public String toString() { return \u0026#34;Person [name=\u0026#34; + name + \u0026#34;, age=\u0026#34; + age + \u0026#34;, address=\u0026#34; + address + \u0026#34;]\u0026#34;; } @Override protected Object clone(){ Person p=null; try { p=(Person)super.clone(); }catch(CloneNotSupportedException e) { e.printStackTrace(); } //显式调用克隆引用数据类型 p.address=(Address)address.clone(); return p; } } class Address implements Cloneable{ String addr; public Address(String addr) { super(); this.addr = addr; } @Override public String toString() { return \u0026#34;Address [addr=\u0026#34; + addr + \u0026#34;]\u0026#34;; } @Override protected Object clone() { Address addr=null; try { addr=(Address)super.clone(); }catch(CloneNotSupportedException e) { e.printStackTrace(); } return addr; } } @Test public void test2() { Address addr=new Address(\u0026#34;成都市郫都区\u0026#34;); Person p1=new Person(\u0026#34;tom\u0026#34;,20,addr); Person p2=(Person)p1.clone(); System.out.println(p1); System.out.println(p2); System.out.println(\u0026#34;---------\u0026#34;); p1.address.addr=\u0026#34;成都市金牛区\u0026#34;; System.out.println(p1); System.out.println(p2); } 输出： Person [name=tom, age=20, address=Address [addr=成都市郫都区]] Person [name=tom, age=20, address=Address [addr=成都市郫都区]] --------- Person [name=tom, age=20, address=Address [addr=成都市金牛区]] Person [name=tom, age=20, address=Address [addr=成都市金牛区]] 使用序列化方法 需要克隆的对象类必须实现Serializable接口，这个接口也是一个标记接口，接口中没有任何方法，这个方法的实现类表示可以将这个类的对象写入到IO流中，那么久可以把对象在网络中发送或保存到本地磁盘\nclass Person implements Cloneable,Serializable{ /** * */ private static final long serialVersionUID = 8990580911834489134L; String name; int age; Address address; public Person() {} public Person(String name, int age,Address addr) { super(); this.name = name; this.age = age; this.address=addr; } @Override public String toString() { return \u0026#34;Person [name=\u0026#34; + name + \u0026#34;, age=\u0026#34; + age + \u0026#34;, address=\u0026#34; + address + \u0026#34;]\u0026#34;; } @Override protected Object clone(){ Person p=null; try { //将对象写入流中 ByteArrayOutputStream baos=new ByteArrayOutputStream(); ObjectOutputStream oos=new ObjectOutputStream(baos); oos.writeObject(this); //将对象从流中读取出来 ByteArrayInputStream bais=new ByteArrayInputStream(baos.toByteArray()); ObjectInputStream ois=new ObjectInputStream(bais); p=(Person)ois.readObject(); } catch (ClassNotFoundException e) { e.printStackTrace(); } catch (IOException e) { e.printStackTrace(); } return p; } } class Address implements Serializable{ /** * */ private static final long serialVersionUID = 328854588872604721L; String addr; public Address(String addr) { super(); this.addr = addr; } @Override public String toString() { return \u0026#34;Address [addr=\u0026#34; + addr + \u0026#34;]\u0026#34;; } } @Test public void test2() { Address addr=new Address(\u0026#34;成都市郫都区\u0026#34;); Person p1=new Person(\u0026#34;tom\u0026#34;,20,addr); Person p2=(Person)p1.clone(); System.out.println(p1); System.out.println(p2); System.out.println(\u0026#34;---------\u0026#34;); p1.address.addr=\u0026#34;成都市金牛区\u0026#34;; System.out.println(p1); System.out.println(p2); } 输出： Person [name=tom, age=20, address=Address [addr=成都市郫都区]] Person [name=tom, age=20, address=Address [addr=成都市郫都区]] --------- Person [name=tom, age=20, address=Address [addr=成都市金牛区]] Person [name=tom, age=20, address=Address [addr=成都市郫都区]] ","permalink":"https://moyuduo.github.io/posts/java%E5%85%8B%E9%9A%86/","summary":"java克隆 为什么需要克隆 我们在很多时候需要使用一个对象去记录另外一个对象的当前状态，对象中可能会有很多属性，如果我们一个一个去设置，不仅不方便，而且效率很低,我们看一个初学者可能遇到的问题\nclass Person{ String name; int age; public Person() {} public Person(String name, int age) { super(); this.name = name; this.age = age; } @Override public String toString() { return \u0026#34;Person [name=\u0026#34; + name + \u0026#34;, age=\u0026#34; + age + \u0026#34;]\u0026#34;; } } @Test public void test2() { Person p1=new Person(\u0026#34;tom\u0026#34;,20); Person p2=p1; System.out.println(p1); System.out.println(p2); System.out.println(\u0026#34;---------\u0026#34;); p1.age=30; System.out.println(p1); System.out.println(p2); } 输出： Person [name=tom, age=20] Person [name=tom, age=20] --------- Person [name=tom, age=30] Person [name=tom, age=30] 也许有的人认为Person p2=p1这样的方式就可以克隆一个对象，这种想法是错误的，这种使用等号赋值的方式只是将p1的地址赋值给了p2对象，那么p1和p2都指向了堆中的同一个对象，所以，修改p1那么p2也就变了","title":"java克隆"},{"content":"Java序列化Serialize 序列化与反序列化 序列化：把对象写入到流中\n反序列化：把对象从流中读取出来\n什么情况下序列化 对象需要通过网络进行传输 需要持久化对象到磁盘 需要持久化对象到数据库（把对象通过字节流的方式存储） 序列化的实现方式 实现Serializable接口 Serializable是一个标记接口，接口中没有任何方法 需要序列化的对象除基本数据类型属性外其他属性也必须实现Serializable接口 public class Student implements Serializable{ private static final long serialVersionUID = 2992794326818594180L; private String name; private int age; //省略constructor、setter、getter、toString } @Test public void test1() throws Exception { Student s1=new Student(\u0026#34;tom\u0026#34;,20); System.out.println(s1); ObjectOutputStream oos=new ObjectOutputStream(new FileOutputStream(\u0026#34;D:/student.txt\u0026#34;)); oos.writeObject(s1); ObjectInputStream ois=new ObjectInputStream(new FileInputStream(\u0026#34;D:/student.txt\u0026#34;)); Student s2=(Student)ois.readObject(); System.out.println(s2); } 输出： Student [name=tom, age=20] Student [name=tom, age=20] 如果序列化对象的非基本数据类型属性没有实现Serialize接口，会抛出NotSerializableException异常\npublic class Student implements Serializable{ private static final long serialVersionUID = 2992794326818594180L; private String name; private int age; private School school; //省略constructor、setter、getter、toString } class School{ private String name; //省略constructor、setter、getter、toString } public static void main(String[] args) throws FileNotFoundException, IOException, ClassNotFoundException { Student s1=new Student(\u0026#34;tom\u0026#34;,20,new School(\u0026#34;xw\u0026#34;)); System.out.println(s1); ObjectOutputStream oos=new ObjectOutputStream(new FileOutputStream(\u0026#34;D:/student.txt\u0026#34;)); oos.writeObject(s1); ObjectInputStream ois=new ObjectInputStream(new FileInputStream(\u0026#34;D:/student.txt\u0026#34;)); Student s2=(Student)ois.readObject(); System.out.println(s2); } 输出： java.io.NotSerializableException: com.moyuduo.analyze.School 实现Externaliable接口并实现方法 序列化对象的非基本数据类型外其他类型必须实现Serializable接口或Externaliable接口 实现Externaliable的类必须提供无参构造器，因为在反序列化的时候需要使用无参构造器创建对象 这种方式比实现Serializable接口略复杂，但是可以实现更加复杂的控制，因为实现Externaliable接口重写方法需要我们自己指定序列化规则（可以对序列化进行加密产生字节）和反序列化规则（序列化规则的逆过程）\n实现Externaliable接口方式比实现Serializable接口方式的效率高\npublic class Student implements Externalizable{ private String name; private int age; private School school; public Student() {//必须加无参构造器 System.out.println(\u0026#34;Student无参构造器\u0026#34;); } //省略有参constructor、setter、getter、toString @Override public void writeExternal(ObjectOutput out) throws IOException { out.writeObject(new StringBuffer(this.name).reverse().toString()); out.writeInt(this.age); out.writeObject(this.school); } @Override public void readExternal(ObjectInput in) throws IOException, ClassNotFoundException { this.name=new StringBuffer((String)in.readObject()).reverse().toString(); this.age=in.readInt(); this.school=(School)in.readObject(); } } class School implements Externalizable{ private String name; public School() { System.out.println(\u0026#34;School无参构造器\u0026#34;); } //省略有参constructor、setter、getter、toString @Override public void writeExternal(ObjectOutput out) throws IOException { out.writeObject(new StringBuffer(this.name).reverse().toString()); } @Override public void readExternal(ObjectInput in) throws IOException, ClassNotFoundException { this.name=new StringBuffer((String)in.readObject()).reverse().toString(); } } public static void main(String[] args) throws Exception { Student s1=new Student(\u0026#34;tom\u0026#34;,20,new School(\u0026#34;xh\u0026#34;)); System.out.println(s1); ObjectOutputStream oos=new ObjectOutputStream(new FileOutputStream(\u0026#34;D:/student.txt\u0026#34;)); oos.writeObject(s1); oos.close(); ObjectInputStream ois=new ObjectInputStream(new FileInputStream(\u0026#34;D:/student.txt\u0026#34;)); Student s2=(Student)ois.readObject(); System.out.println(s2); ois.close(); } 输出： Student [name=tom, age=20, school=School [name=xh]] Student无参构造器 School无参构造器 Student [name=tom, age=20, school=School [name=xh]] 部分属性序列化 使用transient关键字 被transient关键字修饰的属性，在对象序列化时不会序列化，而且反序列化得到的该属性值是默认值\npublic class Student implements Serializable{ private static final long serialVersionUID = 1L; private String name; private transient int age; //省略constructor、setter、getter、toString } public static void main(String[] args) throws Exception{ Student s=new Student(\u0026#34;tom\u0026#34;,20); System.out.println(s); ObjectOutputStream oos=new ObjectOutputStream(new FileOutputStream(\u0026#34;D:/student.txt\u0026#34;)); oos.writeObject(s); oos.close(); ObjectInputStream ois=new ObjectInputStream(new FileInputStream(\u0026#34;D:/student.txt\u0026#34;)); Student s2=(Student)ois.readObject(); System.out.println(s2); ois.close(); } 输出： Student [name=tom, age=20] Student [name=tom, age=0] 自定义属性序列化 可以实现Externalizable接口并在序列化方法writeExternal中序列化需要的属性 可以实现Serializable接口，并自己定义 private void writeObject(java.io.ObjectOutputStream out) throws IOException； private void readObject(java.io.ObjectInputStream in) throws IOException,ClassNotFoundException; private void readObjectNoData() throws ObjectStreamException; writeObject方法序列化需要的属性\npublic class Student implements Serializable{ private static final long serialVersionUID = 1L; private String name; private int age; //省略constructor、setter、getter、toString private void writeObject(ObjectOutputStream out) throws IOException{ out.writeObject(this.name); } private void readObject(ObjectInputStream in) throws IOException,ClassNotFoundException{ this.name=(String)in.readObject(); } } public static void main(String[] args) throws Exception{ Student s=new Student(\u0026#34;tom\u0026#34;,20); System.out.println(s); ObjectOutputStream oos=new ObjectOutputStream(new FileOutputStream(\u0026#34;D:/student.txt\u0026#34;)); oos.writeObject(s); oos.close(); ObjectInputStream ois=new ObjectInputStream(new FileInputStream(\u0026#34;D:/student.txt\u0026#34;)); Student s2=(Student)ois.readObject(); System.out.println(s2); ois.close(); } 输出： Student [name=tom, age=20] Student [name=tom, age=0] 序列化对象的static属性 在对象进行序列化时，被static修饰的属性并不会进行序列化\npublic class Student implements Serializable{ private static final long serialVersionUID = 1L; private String name; public static int age; //省略constructor、setter、getter、toString } public static void main(String[] args) throws Exception{ Student s=new Student(\u0026#34;tom\u0026#34;); Student.age=20; System.out.println(s); ObjectOutputStream oos=new ObjectOutputStream(new FileOutputStream(\u0026#34;D:/student.txt\u0026#34;)); oos.writeObject(s); oos.close(); Student.age=30; ObjectInputStream ois=new ObjectInputStream(new FileInputStream(\u0026#34;D:/student.txt\u0026#34;)); Student s2=(Student)ois.readObject(); System.out.println(s2); ois.close(); } 输出： Student [name=tom,age=20] Student [name=tom,age=30] 可以看到Student的static属性age并没有被序列化输出\n实现Serializable的类需要提供一个serialVersionUID serialVersionUID是用于确定版本信息的，如果不指定JVM会根据类信息自动生成一个，JVM会根据两个serialVersionUID判断是否是同一个类，如果serialVersionUID不一致，会抛出InvalidClassException异常\n一般建议显式指定serialVersionUID，如果类中添加了新的属性，而想进行向下兼容的话，可以不改变serialVersionUID，那么反序列化后新添加的属性就是默认值\n如果删除了类的属性，就需要修改serialVersionUID\npublic class Student implements Serializable{ private static final long serialVersionUID = 1L; private String name; private int age; //省略constructor、setter、getter、toString } //把对象写出去 @Test public void test4() throws IOException { Student s=new Student(\u0026#34;tom\u0026#34;,20); System.out.println(s); ObjectOutputStream oos=new ObjectOutputStream(new FileOutputStream(\u0026#34;D:/student.txt\u0026#34;)); oos.writeObject(s); oos.close(); } //删除Student的age属性,并修改serialVersionUID public class Student implements Serializable{ private static final long serialVersionUID = 2L; private String name; //省略constructor、setter、getter、toString } //读取对象 public static void main(String[] args) throws Exception{ Student s=new Student(\u0026#34;tom\u0026#34;); ObjectInputStream ois=new ObjectInputStream(new FileInputStream(\u0026#34;D:/student.txt\u0026#34;)); Student s2=(Student)ois.readObject(); System.out.println(s2); ois.close(); } 输出： Exception in thread \u0026#34;main\u0026#34; java.io.InvalidClassException: com.moyuduo.analyze.Student; local class incompatible: stream classdesc serialVersionUID = 1, local class serialVersionUID = 2 ","permalink":"https://moyuduo.github.io/posts/java%E5%BA%8F%E5%88%97%E5%8C%96serialize/","summary":"Java序列化Serialize 序列化与反序列化 序列化：把对象写入到流中\n反序列化：把对象从流中读取出来\n什么情况下序列化 对象需要通过网络进行传输 需要持久化对象到磁盘 需要持久化对象到数据库（把对象通过字节流的方式存储） 序列化的实现方式 实现Serializable接口 Serializable是一个标记接口，接口中没有任何方法 需要序列化的对象除基本数据类型属性外其他属性也必须实现Serializable接口 public class Student implements Serializable{ private static final long serialVersionUID = 2992794326818594180L; private String name; private int age; //省略constructor、setter、getter、toString } @Test public void test1() throws Exception { Student s1=new Student(\u0026#34;tom\u0026#34;,20); System.out.println(s1); ObjectOutputStream oos=new ObjectOutputStream(new FileOutputStream(\u0026#34;D:/student.txt\u0026#34;)); oos.writeObject(s1); ObjectInputStream ois=new ObjectInputStream(new FileInputStream(\u0026#34;D:/student.txt\u0026#34;)); Student s2=(Student)ois.readObject(); System.out.println(s2); } 输出： Student [name=tom, age=20] Student [name=tom, age=20] 如果序列化对象的非基本数据类型属性没有实现Serialize接口，会抛出NotSerializableException异常\npublic class Student implements Serializable{ private static final long serialVersionUID = 2992794326818594180L; private String name; private int age; private School school; //省略constructor、setter、getter、toString } class School{ private String name; //省略constructor、setter、getter、toString } public static void main(String[] args) throws FileNotFoundException, IOException, ClassNotFoundException { Student s1=new Student(\u0026#34;tom\u0026#34;,20,new School(\u0026#34;xw\u0026#34;)); System.","title":"Java序列化Serialize"},{"content":"JVM学习笔记 JVM结构 Java虚拟机终止的情况 程序正常执行完成 程序显式调用System.exit()方法 程序中出现了异常或错误 操作系统底层出现了错误 Java类的加载、连接、初始化 加载：加载类的字节码文件到内存\n连接\n验证：验证字节码文件的正确性\n主要验证 1类文件结构\n​\t2语义检查\n​\t3字节码验证\n​\t4二进制兼容性验证（老版本.class文件可以运行在新版本上）\n准备：为类静态变量分配地址空间，并初始化为默认值\n解析：把变量的字符引用替换为直接引用\n初始化：为类的静态变量赋值\n加载 JVM允许使用某个类之间提前加载他们，如果遇到.class文件缺失等错误，并不会立即报错，只有当类被第一次主动使用时才抛出错误\n加载器根据是否是用户自定义的可以分为\n系统自带类加载器 启动类加载器（BootStrap）没有父加载器，使用c++实现，主要是用来加载JRE/lib/rt.jar中类 扩展类记载器（Ext）主要加载JRE/lib/ext/*.jar中的类 应用类加载器（App）主要加载类路径下用户自定义的类 用户自定义加载器 用于加载指定路径的.class文件 类加载的双亲委托机制 加载器在逻辑上形成一种树形结构\n加载器之间的父子关系实际上是加载器之间的包含关系，并不是继承关系\n双亲委托机制的优点 双亲委托机制的优点是能提高软件的安全性。在这种机制下，用户自定义的加载器不能加载应该由父加载器加载的可靠的类，从而防止了恶意代码代替父加载器的可靠代码。如：用户自定义的类加载器要去加载rt.jar下的类，根据双新委托模型，rt.jar下的类总是由启动类加载器进行加载，所有保证了jdk核心类库的绝对安全。\n类加载器命名空间 同一个命名空间中的类是相互可见的。子加载器的命名空间包含所有父加载器命名空间，因此子加载器可以看见父加载器加载的类，父加载器不能看见子加载器加载的类。如果两个加载器之间没有父子关系，那么他们各自加载的类也是不可见的。\n当前类加载 每个类都有自己的类加载器（即加载自身的类加载器）,并且使用这个类加载器去加载依赖的其他类：如果ClassX类依赖ClassY，那么会使用ClassX的类加载器去加载ClassY\n线程的类加载器 每个线程也具有类加载器，可以通过setContextClassLoader方法区设置线程的类加载器，如果没有进行设置，那么会默认是父线程的类加载器，java初始化线程的类加载器是系统类加载器\n线程上下文加载器 在jdk中定义了很多服务提供接口，如jdbc的Statement接口，具体的实现是有数据库厂商完成的，根据双亲委托模型Statement接口是使用启动类加载器进行加载的，而第三方数据库driver是在类路径下的，启动类加载器无法进行加载，这种情况下双亲委托模型就出现了问题，通过设置线程的上下文加载器，父ClassLoader可以使用当前线程的ClassLoader去加载类，这就改变了双亲委托模型中父加载器不能加载子加载器加载的类的局面\n当高层提供了统一的接口让底层去实现，同时又需要在高层加载（或实例化）底层类时，就需要通过线程上下文类加载器来帮助高层的类加载器加载该类\n获取类加载器 //获取当前类的ClassLoader clazz.getClassLoader(); //获取当前线程的ClassLoader Thread.currentThread().getContextClassLoader(); //获取系统ClassLoader ClassLoader.getSystemClassLoader(); //获取调用者的ClassLoader DriverManager.getCallerClassLoader(); 初始化 Java虚拟机在类或接口“首次主动使用”的时候初始化\n主动使用：1. 创建类的实例\n​\t2.访问类或接口的静态变量\n​\t3.调用类的静态方法\n​\t4.反射，Class.forName(\u0026ldquo;xxx\u0026rdquo;);\n​\t5.初始化一个类的子类\n​\t6.启动类(包含main方法的类)\n​\t7.java.lang.invoke.MethodHandle实例解析结果REF_getStatic,REF_putStatic,REF_invokeStatic句柄对应的类没有初始化，则初始化\npublic class Test1 { public static void main(String[] args) { System.out.println(Child.str1); } } class Parent{ public static String str1=\u0026#34;hello\u0026#34;; static { System.out.println(\u0026#34;Parent Static Block\u0026#34;); } } class Child extends Parent{ public static String str2=\u0026#34;world\u0026#34;; static { System.out.println(\u0026#34;Child Static Block\u0026#34;); } } 输出： Parent Static Block hello 调用Child.str1并没用输出Child的静态代码块，可以得出这样一个结论，对应静态变量，只会去初始化定义该变量的类，即只主动使用了Parent类\npublic class Test2 { public static void main(String[] args) { System.out.println(Parent2.str); } } class Parent2{ public static final String str=\u0026#34;hello\u0026#34;; static { System.out.println(\u0026#34;parent2 static block\u0026#34;); } } 输出： hello 在一个类中使用另一个类static final修饰的变量时，会把该变量推送至调用这个变量方法的类的常量池中，而不会去初始化这个类，并且是在编译期进行的\npublic class Test3 { public static void main(String[] args) { System.out.println(Parent3.str); } } class Parent3{ public static final String str=UUID.randomUUID().toString(); static { System.out.println(\u0026#34;parent3 static block\u0026#34;); } } 输出： parent3 static block f7e58be0-7e43-4a3a-870f-90e8fdbe8b48 对于static final修饰的变量在编译时不是常量的情况，会导致该类的初始化，所以static代码块会执行\n理解准备阶段和初始化阶段\npublic class Test4 { public static void main(String[] args) { Singleton instance = Singleton.getInstance(); System.out.println(\u0026#34;a:\u0026#34;+instance.a); System.out.println(\u0026#34;b:\u0026#34;+instance.b); } } class Singleton{ public static int a; private static Singleton instance=new Singleton(); public static int b=0; private Singleton() { a++; b++; System.out.println(a); System.out.println(b); } public static Singleton getInstance() { return instance; } } 输出： 1 1 a:1 b:0 Singleton.getInstance();会导致对Singleton类的首次主动使用，那么就会去初始化Singleton类，在初始化之前，已经完成了连接阶段中的准备阶段，所以此时a为默认值0，instance为默认值null，b为默认值0，进行初始化阶段时是顺序执行的，首先执行public static int a;语句，并没有赋值，接着执行private static Singleton instance=new Singleton();语句，此时调用构造方法对a++，b++，所以输出1和1，在执行public static int b=0;语句，此时有赋值，那么把b的值赋值为了0，所以拿到的instance的a为1，b为0\n类初始化步骤 如果这个类还没有被加载和连接，那么进行加载和连接 如果类存在直接父类，并且这个类还没有被初始化，那么先初始化父类，在初始化自己 依次顺序执行类中的初始化语句 类在进行初始化时，要求它的所有父类都已经初始化 类初始化时，并不要求它所实现的所有接口都初始化，只有当使用到接口才初始化 初始化接口时，并不要求初始化它的父接口 实例化 为对象分配空间 为成员变量赋默认值 为成员变量赋正确的初始值 如果没有构造方法，那么生成默认初始化方法 回收 卸载 当类被加载、连接、初始化之后它的生命周期就开始了。当类的Class对象不再被引用，即不可触及，那么Class对象就会结束生命周期，类在方法区的数据（类的静态变量）也会被卸载。\n由java虚拟机自带的类加载器加载的类，在虚拟机的生命周期中，始终不会被卸载。这是因为java虚拟机会引用这些类加载器，这些类加载器会始终引用他们所加载的类，因此这些Class对象始终不会被卸载。\n由用户自定义加载器加载的类是可以被卸载的。\n内存划分 程序计数器 程序计数器是线程私有的。\n存储指向下一条指令的地址。即要执行的代码。\n虚拟机栈（java栈） 虚拟机栈是线程私有空间。\n虚拟机栈中没有GC。因为方法执行就入栈，执行完了就出栈了。\n栈是运行的单位，而堆是存储的单位。\n栈内保存了一个个栈帧，一个栈帧对应一个java方法\n可以通过**-Xss**256k参数来设置栈的大小\n栈帧的内部结构：\n局部变量表\n被定义为一个数字数组，主要存储方法的参数和在方法体中定义的局部变量，这些参数的类型包括基本数据类型、对象引用、returnAddress类型。由于局部变量表示在线程私有的栈空间中，所以不存在数据安全问题。局部变量表的大小在编译器就被确定下来，在方法运行期不会改变。如果是非静态方法，那么局部变量表的0号位置放置的是this。相较于类变量，局部变量并不会赋默认值，所以在使用之间应该显式赋值。\n局部变量表中的变量是垃圾回收的根节点，只要被局部变量表中变量直接或间接引用的对象都不会被回收。\n操作数栈\n主要用于保存计算过程的中间结果，同时作为计算过程中变量的临时存储空间，操作数栈是JVM执行引擎的一个工作空间，当一个方法执行的时候，一个新的栈帧会被创建出来，这个方法的操作数栈是空的，没一个操作数栈的栈深度是确定的，在编译期就被确定下来。\n动态链接\n每一个栈帧内都包含一个指向该栈帧所属方法的引用，这个引用的目的是使当前方法的代码能够实现动态链接。动态链接就是指向方法区中对应方法的一个引用，有了这个引用就不需要再每个栈帧中存放方法的具体信息。\n方法返回地址\n方法返回地址记录的是调用者程序计数器的值，即调用方法的指令的下一条指令的地址\n一些附加信息\n可能存在一些附加信息，如程序调试附加信息\n本地方法栈 主要用于处理java中调用c或C++实现的本地方法。\n本地方法栈也没有GC。\nHotSpot虚拟机把本地方法栈和java虚拟机栈合二为一。\n堆 堆内存是所有线程共享的。\n堆空间在物理内存上可能是连续的也可能是不连续的。\n通过**-Xms**5m参数指定堆空间初始5m\n通过**-Xmx**5m参数指定堆空间最大5m\n通过-XX:+HeapDumpOnOutOfMemoryError参数指定堆上发生内存溢出输入日志\n通过-XX:+PrintGCDetails参数打印GC回收信息\njdk1.8之后堆内存在逻辑上分为三部分：新生代+老年代+元空间\n-XX:NewRatio=2参数用来设置老年代和新生代的空间比值，默认为2，即老年代空间/新生代空间=2\n在HotSpot中Eden区和Survivor0和Survivor1空间的比列是8:1:1\n-XX:SurvivorRatio=8参数可用于设置Eden区和Survivor区空间比值，Survivor0区和Survivor1区大小相等\n-Xmn100m参数可用用来设置新生空间大小\n对象分配的一般过程 对象最先被创建在Eden区，如果Eden区被放满，程序还需要创建对象时，JVM的垃圾回收器（Minor GC）会对Eden去进行垃圾回收，将Eden区不再被引用的对象销毁，再创建新的对象，此时Eden区中没有被垃圾回收器回收的幸存对象会被晋升到幸存者0区并且对象有一个年龄标识，当垃圾回收器再次被触发时，如果幸存者0区的对象还是没有被回收，那么会放到幸存者1区，并且年龄标志增加，如果下次垃圾回收器触发时，幸存者1区的对象还没有被回收，那么会放置在幸存者0区，年龄标志增加，依次循环往复，当达到一定的次数后，对象被放置在老年区（默认15可以设置）-XX:MaxTenuringThreshold=15\n如果对象在Eden区放不下，并且在Survivor去也放不下，是有可能在老年区先通过Major GC后如果放的下的话直接放入老年区。\n如果创建对象Eden区已满，Survivor区也满，有可能Survivor区对象没有达到晋升年龄就晋升到老年区。\nSurvivor区满并不会触发GC，只有Eden区满才会触发GC，如果Survivor区也满，会顺便回收。\n方法区 方法区主要存储已被加载的类型信息、常量、静态变量、即时编译器编译后的代码缓存等。\n方法区是线程共享的。\n方法区的大小决定了系统可以存放多少类，如果系统定义了太多的类（加载大量的jar包、tomcat部署war包过多），会导致方法区溢出。\n在关闭JVM时会释放方法区的内存。\n在jdk1.7及以前，把方法区称为永久代（PermGen）。jdk1.8开始，使用元空间（MetaSpace）取代永久代。\n堆和方法区示意图：\n元空间和永久代的本质类似，都是对JVM规范中方法区的实现。不过元空间和永久代的区别在于：元空间不在虚拟机中设置内存，而是使用本地内存。\n对于永久代方式实现方法区的，可以通过-XX:PermSize=20.75m来设置初始的永久代大小，默认值为20.72M，对于最大永久代大小，可以通过-XX:MaxPermSize=82m来设置，32位机器默认64M，64位机器默认82M\n对于元空间方法实现方法区的，可以通过-XX:MetaspaceSize=21m设置初始大小，默认为21M，通过-XX:MaxMetaspaceSize=-1设置最大元空间大小，默认为-1，即没有限制\n通过-XX:MetaspaceSize=21m设置的值被称为高水平线，一旦触及了这个水平线，那么就会触发Full GC来回收没用的类，然后调整这个水平线，可能是增加也可能是减少，这取决于Full GC释放了多少空间，如果是提高，最大值也不能超过-XX:MaxMetaspace=-1设置的这个值，如果这个高水平线设置得过低，那么水平线就会调整多次，会频繁触发Full GC，为了避免频繁的GC，建议将这个高水平值设置为一个较大的值。\n方法区的演变 jdk1.6及以前 有永久代，类型信息、域信息、方法信息、运行时常量池、静态变量都存放在永久代上 jdk1.7 有永久代，但是运行时常量池中的字符串常量池、静态变量被移动到堆中 jdk1.8及以后 无永久代，类型信息、常量、域信息、方法信息存放在本地内存的元空间，字符串常量池和静态变量任然存放在堆上 直接内存 直接内存不是JVM虚拟机运行时数据区的一部分，它是在java堆外直接向系统申请的内存区间，通常它的读写性能会比java堆高。\n可以通过-XX:MaxDirectMemorySize=10m设置最大直接内存大小\n栈、堆、方法区之间的交互关系 Person p=new Person(); ↑ ↑ ↑ 方法区 栈 堆 方法区的垃圾回收 主要回收的内容：常量池中废弃的常量和不再使用的类\n对象实例化 步骤：\n判断类是否已经加载、连接、初始化，如果没有加载，那么先进行加载 为对象分配空间 处理并发安全问题（采用CAS或TLAB） 初始化分配空间，为对象的属性赋默认值 设置对象头 执行init方法进行初始化 对象在堆中的内存布局 推中对象主要包含三部分：\n对象头，有包含两部分，运行时元数据和类型指针，运行元时数据包括哈希值、GC分代年龄、锁标志，类型指针用于指向方法区中对象的类 实例数据，类的实例数据和父类的实例数据，先存放父类的属性然后存放当前类 对齐填充，不是必须的，起到填充的作用 对象访问方法 句柄访问 优点：由于实例数据是存储在实例池中，当在GC时需要移动对象位置时，不需要移动实例数据\n缺点：需要多使用空间来保存实例数据指针\n直接指针(HotSpot使用) 优点：实例数据直接和对象存储在一起，相较于句柄访问方式，节约空间\n缺点：当触发GC需要移动对象时，实例数据页需要一起移动，相较于句柄访问性能略差\n执行引擎 执行引擎的任务就是讲字节码指令解释/编译为对应平台的本地机器指令。\n执行引擎包括解释器和JIT编译器。\n解释器：将字节码文件解释为机器码并执行。采用解释器的执行硬引擎的优点是响应时间快，适合用于客户端。\nJIT编译器：将字节码文件生成机器码指令，并缓存，当下次再次执行代码时，直接指向字节码，不需要再将字节码解释为机器码的过程。JIT对于经常执行的代码效率很好，适合服务器端执行引擎，确定是首次启动是时间长。\nHotSpot的执行引擎采用解释器和JIT编译器并存的架构，原因在于解释器在执行字节码，由于不需要缓存机器码，所以响应快，它的缺点是每次执行时都需要将字节码解释为机器码，对于经常执行的代码，性能不好，所以引入了JIT编译器，这样用于经常执行代码的优化。\n垃圾回收算法 标记阶段 目的：判断对象是否存活\n一个对象不被任何一个对象引用时，会被标记死亡，只有被标记为已经死亡的对象，GC才会执行垃圾回收，释放其所占的内存空间\n引用计数算法 每个对象保存一个整型的引用计数器，用于记录对象被引用的情况。\n对于一个对象A，只要有任何一个对象引用了A，则A的引用计数器就+1；当引用失效时，引用计数器-1.对象A的引用计数器为0，即表示A没有任何对象引用A，可以进行回收。\n优点：\n​\t简单\n​\t高效\n缺点：\n​\t需要使用单独的字段存储计数器，增加了存储空间的开销\n​\t每次赋值都要更新程序计数器，增加了时间开销\n​\t无法处理循环引用问题，由于这一条缺陷，导致java在垃圾回收器中没有使用这个算法（主要）\n可达性分析算法(根搜索算法) 可达性分析算法是以根对象集合（GC Roots）为起始点，按照从上至下的方式搜索根对象集合所连接的目标对象是否可达。\n使用可达性分析算法后 ，内存中的存活对象都会被根对象集合直接或间接连接着，搜索锁走过的路径称为引用链。\n如果目标对象没有任何的引用链，那么对象是不可达的，就意味着对象已经死亡，会被标记为垃圾对象。\n在可达性分析算法中，只有能够被根对象集合直接或间接连接的对象才是存活的对象。\nGC Root包含的元素：\n虚拟机栈中引用的对象：方法的参数、局部变量 本地方法栈内引用的对象 方法区中类的静态数据：类的引用型静态变量 方法区中的常量引用对象：字符串常量池里的引用 所有被synchronize持有的对象 java虚拟机内部引用：基本数据类型对应的Class对象、异常对象、系统类加载器 清除阶段 目标：清除已经被标记为垃圾的对象\n标记-清除算法（Mark—Sweep） 执行过程：\n​\t当堆中有效空间要被耗尽时，会停止整个程序（STW）,然后进行两项工作，第一项是标记，第二项是清除。\n​\t标记：垃圾收集器（GC）从根节点（GC Roots）开始遍历，标记所有被引用的对象。\n​\t清除：垃圾收集器（GC）对堆内存从头到尾进行线性遍历，如果某个对象没有被标记，则将其回收。\n注意：标记阶段标记的是有被其他对象引用的对象\n优点：\n​ 缺点：\n效率不高 在进行垃圾清理（GC）的时候需要停止整个应用程序 这种方式清理出来的内存不是连续的，会产生碎片，需要维护一个空闲列表。 复制算法（Copying） 执行过程：\n​\t将内存块分成两块，每次只使用其中一块，在进行垃圾回收时，将正使用的内存块中活着的对象复制到未被使用的内存块中，之后清除正在使用内存块中的所有对象，交换两内存块的角色，完成垃圾回收。\n优点：\n没有标记和清除的过程，更加高效 复制过去以后保证了空间的连续性，不会出现碎片 缺点：\n需要两倍的内存空间 保证对象复制前后的对象引用关系，开销不小 注意：如果系统的垃圾很多，那么需要移动的对象相对较少，复制算法才更加高效\n标记-压缩算法（Mark-Compact） 背景：\n​\t标记-清除算法的确可以应用到老年代中，但是该算法不仅效率低下而且会产生碎片问题，设计者在标记-清除算法的基础上进行改进，产生了标记-压缩算法。\n执行过程：\n​\t1.标记所有被引用的对象\n​\t2.将所有存活的对象压缩存放在内存的一端，顺序排放\n​\t3.清除边界外所有对象\n优点：\n清除了标记-清除算法中内存分散的问题，当创建对象的时候JVM只需要修改一个指针 消除了复制算法中内存减半的高额代价 缺点：\n从效率上来说，标记整理算法效率要低于标记-清除算法和复制算法。 移动对象时，如果该对象被其他对象引用，要调整引用地址。 需要暂停程序的时间更长 三种清除算法比较 Mark-Sweep Mark-Compact Copying 速度 中等 最慢 最快 空间开销 少 少 2倍活对象空间 移动对象 否 是 是 为了兼顾所有指标，标记-压缩算法相对来说更加好一些，但是它的效率比较差，比复制算法多个一个标记阶段，比标记-清除算法多个一个内存整理阶段。\n增量收集算法 背景：\n​\t标记-清除算法、复制算法、标记-压缩算法在垃圾回收过程中，应用软甲将处于一种Stop the World的状态。在这种状态下所有的线程都会挂起，暂停一切正常工作，等待垃圾回收的完成。如果垃圾回收的时间过长，应用程序会被挂起很久，将严重影响用户体验和系统的稳定性。为了解决这个问题，即对实时垃圾收集算法的研究导致了增量收集算法的诞生。\n基本思想：\n​\t如果一次性将所有的垃圾进行处理，需要造成系统长时间的停顿，那么就可以让垃圾收集线程和应用程序线程交替执行。每次，垃圾收集线程只收集一片小的内存空间，接着切换到用户线程。反复依次，直到垃圾收集完成。\n缺点：\n​\t使用这种方式，由于在垃圾回收过程中，间断性地执行应用程序线程，所以能减少系统的停顿时间。但是，因为线程切换和上下文切换的消耗，会使垃圾回收的总体成本上升，造成系统的吞吐量下降。\n并发和并行 并发：在一段时间里，多个程序在一个cpu上快速切换地运行，看似所有程序同时在执行。\n并行：当系统有一个以上cpu时，一个cpu（cpu具有多核，也可能是一个核心）执行一个进程，另一个cpu执行另外一个进程，两个进程不互相抢占资源，称为并行。\n安全点和安全区域 程序在执行的时候，并非在所有的位置都能停下来，只有在特定的位置才能停下来GC，这些位置就是“安全点”。\n安全点很重要，如果太少可能导致GC等待时间太长，如果太多会导致运行时性能，通常选择一些执行时间比较长的点设置安全点。\n安全点机制保证了程序执行时，在不太长的时间内就可能遇到可进入GC的安全点。但是程序如果不执行，如：线程的sleep和blocked，这是线程无法响应JVM的中断请求，运行到安全点，JVM也不可能把线程唤醒，对于这种情况就需要安全区域。\n安全区域是指一段代码片段中，对象的引用关系不会发生变化，在这个区域中的任何位置执行GC都是安全的。\n引用 在jdk1.2之后，Java对引用的概念进行了扩充，将引用分为强引用、软引用、弱引用。虚引用四种，这四种引用的强度依次减弱。\n强引用：在程序代码中普遍存在的引用赋值，如：Object obj=new Object（）；这种引用关系。无论在什么情况下，垃圾回收器永远不会回收掉这种引用。 软引用：在系统将要发生内存溢出之前，将会把这些对象列入回收范围进行二次回收。如果这次回收之后还没有足够的内存，才会抛出内存溢出。 弱引用：被弱引用关联的对象只能生存到下一次垃圾回收之前，当进行垃圾回收时，不管内存空间是否足够，都会回收掉被弱引用关联的对象。 虚引用：为一个对象设置虚引用的唯一目的就是能在对象被回收时收到一个系统通知。 强引用 在java程序中，强引用时最常见的引用类型，也是默认的引用类型。\n强引用的对象是可触及的，垃圾回收器就永远不会回收掉被引用的对象。\n特点：\n​\t可以访问目标对象。\n​\t强引用指向的对象任何时候都不会被回收。\n​\t强引用可能导致内存泄漏。\n软引用 软引用用来描述一些还有用，但非必须的对象。只被软引用关联着的对象，在系统将要发生内存溢出前把这些对象列入回收范围进行二次回收，如果这是内存还不够，才抛出内存溢出。\n在内存足够时，不会回收可触及的软引用对象，内存不够内，才回收软引用对象。\npublic static void main(String[] args) { User u=new User(\u0026#34;zhangsan\u0026#34;, 20); SoftReference\u0026lt;User\u0026gt; softReference=new SoftReference\u0026lt;User\u0026gt;(u); //把强引用消除 u=null; System.out.println(softReference.get()); try { byte[] bytes=new byte[7*1024*1024]; }catch(Exception e) { e.printStackTrace(); }finally { System.out.println(softReference.get()); } } 在没有设置堆内存的情况下，输出： User [name=zhangsan, age=20] User [name=zhangsan, age=20] 由于堆内存足够，那么软引用对象不会被回收 设置参数：-Xms10m -Xmx10m 输出： User [name=zhangsan, age=20] null 说明在堆内存不够的情况下，软引用的对象是会被 弱引用 只被弱引用关联的对象只能存活到下一次垃圾收集为止。\npublic static void main(String[] args) throws InterruptedException { User u=new User(\u0026#34;zhangsan\u0026#34;, 20); WeakReference\u0026lt;User\u0026gt; weakReference=new WeakReference\u0026lt;User\u0026gt;(u); //把强引用清除 u=null; System.out.println(weakReference.get()); //模拟一次GC System.gc(); Thread.sleep(3*1000); System.out.println(weakReference.get()); } 在堆内存足够的情况下，输出： User [name=zhangsan, age=20] null 说明弱引用关联的对象只能存活到下一次GC 虚引用 一个对象是否有虚引用完全不会决定对象的生命周期。如果一个对象只有虚引用，和没有引用一样。\n为一个对象设置虚引用的唯一作用是追踪对象的回收时间。\n虚引用创建是必须提供一个引用队列作为参数，当垃圾回收器准备回收对象时，如果发现是虚引用，就会在回收对象后把虚引用加入引用队列，以通知应用程序对象的回收情况。\npublic class Test4 { private static ReferenceQueue\u0026lt;User\u0026gt; queue=null; private static class CheckReferenceQueue extends Thread{ public void run() { while(true) { if(queue!=null) { Reference\u0026lt;? extends User\u0026gt; remove=null; try { remove = queue.remove(); } catch (InterruptedException e) { e.printStackTrace(); } if(remove!=null) { System.out.println(\u0026#34;接收到通知\u0026#34;); } } } }; } public static void main(String[] args) throws InterruptedException { queue=new ReferenceQueue\u0026lt;\u0026gt;(); Thread t=new CheckReferenceQueue(); t.setDaemon(true); t.start(); User u=new User(\u0026#34;zhangsan\u0026#34;,20); PhantomReference\u0026lt;User\u0026gt; phantomReference=new PhantomReference\u0026lt;User\u0026gt;(u, queue); //清除强引用 u=null; System.out.println(phantomReference.get()); System.gc(); Thread.sleep(3*1000); System.out.println(phantomReference.get()); } } 输出： null 接收到通知 null 垃圾回收器 垃圾回收器分类 串行回收器：Serial、Serial Old 并行回收器：ParNew、Parallel Scavenge、Parallel Old 并发回收器：CMS、G1 垃圾收集器与分代之间的关系 垃圾回收器组合关系 查看默认垃圾回收器 使用-XX:+PrintCommandLineFlags参数或jinfo -flag 参数 线程 可以查看JVM中使用的垃圾回收器情况\njdk1.8中使用的是Parallel GC和Parallel Old GC\njdk1.9中只使用了G1垃圾收集器\nSerial收集器 serial收集器采用复制算法、串行回收和“Stop The World”机制的方式执行内存回收。\nSerial Old收集器 serial old收集器同样采用串行回收和“Stop The World”机制，不过内存回收算法使用的是标记-压缩算法。\nSerial Old是运行在Client模式下默认的老年代垃圾收集器 Serial Old在Server模式下主要有两个用途：①与新生代Parallel Scavenge配合使用。②作为老年代CMS收集器的后备垃圾收集器 在HotSpot虚拟机中，可以使用-XX：+UseSerialGC指定新生代使用Serial GC、老年代使用Serial Old GC。\nParNew收集器 如果说serial gc是新生代的单线程垃圾收集器，那么parnew收集器就是serial gc的多线程版本。\nPar是Parallel的简写，New是说该收集器只能处理新生代\nParNew收集器除了采用并行回收方式外，与Serial GC之间几乎没有区别，ParNew G同样是使用复制算法和“Stop The World”机制。\n对于新生代，回收次数频繁，使用多线程并行方式更高效。 对于老年代，回收次数少，使用串行方式更加节省资源。 可以使用-XX:+UseParNewGC手动指定新生代使用ParNew收集器进行内存回收\n使用-XX:ParallelGCThreads参数限制线程数量，默认和CPU相同的线程数\nParallel Scavenge收集器 Parallel Scavenge收集器是新生代垃圾收集器\nParallel Scavenge收集器基于多线程，采用复制算法、并行回收和“Stop The World”机制。\n可以使用-XX：+UseParallelGC指定新生代使用Parallel GC，老年代使用Parallel old收集器\n使用-XX:ParallelGCThreads参数限制线程数量，默认和CPU相同的线程数\nParallel Old收集器 Parallel Old收集器是老年代垃圾收集器\nParallel Old收集器也是基于多线程的，配合Parallel收集器使用，它采用标记-压缩算法和“Stop The World”机制。\n使用参数-XX:+UseParallelOldGC指定老年代使用Parallel Old收集器,新生代使用Parallel收集器\nCMS收集器 CMS(Concurrent-Mark-Sweep)收集器是HotSpot虚拟机中第一款真正意义上 的并发收集器，它第一次实现垃圾收集线程与用户线程同时工作。\nCMS收集器的关注点是尽可能缩短垃圾收集时用户线程的停顿时间。停顿时间越短，就越适合与用户交互的程序。\nCMS收集器采用标记-清除算法。\n初始标记阶段：在这个阶段，程序中所有的工作线程都会“Stop The World”，这个阶段的任务仅仅是标记处GC Roots能够直接关联的对象。 并发标记阶段：从GC Root的直接关联对象开始遍历整个对象图，这个过程用时较长，但是不需要停止用户线程。 重新标记阶段：在并发标记阶段中，程序的工作线程和垃圾收集线程同时运行，这个阶段时为了修正并发标记阶段，因为程序继续运行而导致的标记变动，这个阶段和初始标记一样也会“Stop The World”，这个阶段的停顿时间通常比初始标记阶段稍长，但是比并发标记阶段短。 并发清理阶段：此阶段的任务是清除掉标记阶段判断依据死亡的对象，释放内存空间。由于不需要移动对象，所以这个阶段是可以与程序工作线程同时进行的。 由于垃圾收集阶段用户线程没有中断，所以在CMS回收过程中，应当确保应用程序线程有足够的内存可用。CMS收集器不能像其他收集器内存几乎填满才进行回收，它必须在内存达到一个阈值就开始执行垃圾收集。\n缺点：\nCMS收集器采用的标记-清除算法所以会产生内存碎片，可能在并发清除后，无法为大对象分配空间，从而触发Full GC\nCMS由于是并发的收集器，由于垃圾收集的时候垃圾收集线程和用户线程同时执行，减少了系统的并发吞吐量\nCMS收集器无法处理浮动垃圾。在并发标记阶段，用于垃圾收集线程和用户线程是同时执行的，那么在并发标记阶段产生的新垃圾对象，CMS无法对这些垃圾进行标记，最终会导致这些垃圾没有及时被回收。\n使用：\n可以使用-XX:+UseConcMarkSweepGC来开启老年代用时CMS垃圾收集器，如果设置这个参数，那么年轻代默认使用ParNew垃圾收集器\nG1收集器 G1收集器的目标是在可控的暂停时间内，尽可能的提高吞吐量。\nG1垃圾收集器针对新生代使用的是复制算法，老年代使用的是标记-压缩算法。\nG1收集器是一个并行回收器，它把堆内存划分为一个个region，这个region在物理上是不连续的，使用不同的region来表示Eden、Survivor 0、Survivor 1和 Tenured，G1收集器把堆内存划分为region避免了在堆中进行全区域垃圾收集，G1跟踪各个region里面垃圾堆积的大小，维护一个优先列表，每次根据允许的收集时间，优先收集回收价值最大的region。\nG1收集器是一款面向服务端的垃圾收集器，主要针对配备多核cpu及大容量内存的机器，在允许的延迟范围内，兼具高吞吐量的特性。\nG1收集器在jdk1.7正式启用，在jdk1.9成为默认垃圾收集器，取代了CMS收集器和Parallel+Parallel Old的组合。\n使用：\n可以使用-XX:+UseG1GC来开启使用G1收集器\nG1收集器回收过程：\n年轻代 老年代并发标记过程 混合回收 当年轻代的Eden区用尽时开始年轻代的回收：G1的年轻代收集阶段是一个并行的独占式收集器，在这个阶段会停止所有的引用程序线程，启动多线程进行回收，然后将存活对象移动到Survivor去或Tenured或Survivor、Tenured。\n当堆内存使用到了45%，就开始老年代的并发标记过程。标记完成马上开始混合回收，和其他收集器不同的是，G1收集器的老年代回收不需要回收所以老年代，而只需要回收一部分老年代region，然后把存活的对象移动到空闲区域，这个区域也就成为另一个老年代的region\nRemembered Set\n问题：\n一个region不可能是谷孤立的，一个region中的对象可能被其他任意的region中的对象引用，判断对象是否存活，是否要遍历整个堆呢？\n解决：\n无论是G1收集器还是其他收集器，JVM都使用Remembered Set来避免全表扫描。在G1收集器中，每一个region都有一个对应的Remembered Set，每次Reference类型数据写操作时，会产生一个Write Barrier暂时中断操作，检查将要写入的引用对象是否和该Reference类型数据在不同的region，如果不在，通过CardTable把相关的引用记录添加到引用对象所在region的Remembered Set中。当进行垃圾收集时，在GC根节点的枚举范围加入Remember Set，这样就可以保证不进行全局扫描，也不会有遗漏。\n几种收集器的比较 导出GC日志 使用-Xloggc:./logs/gc.log来把GC日志保存到外部文件\n","permalink":"https://moyuduo.github.io/posts/jvm%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/","summary":"JVM学习笔记 JVM结构 Java虚拟机终止的情况 程序正常执行完成 程序显式调用System.exit()方法 程序中出现了异常或错误 操作系统底层出现了错误 Java类的加载、连接、初始化 加载：加载类的字节码文件到内存\n连接\n验证：验证字节码文件的正确性\n主要验证 1类文件结构\n​\t2语义检查\n​\t3字节码验证\n​\t4二进制兼容性验证（老版本.class文件可以运行在新版本上）\n准备：为类静态变量分配地址空间，并初始化为默认值\n解析：把变量的字符引用替换为直接引用\n初始化：为类的静态变量赋值\n加载 JVM允许使用某个类之间提前加载他们，如果遇到.class文件缺失等错误，并不会立即报错，只有当类被第一次主动使用时才抛出错误\n加载器根据是否是用户自定义的可以分为\n系统自带类加载器 启动类加载器（BootStrap）没有父加载器，使用c++实现，主要是用来加载JRE/lib/rt.jar中类 扩展类记载器（Ext）主要加载JRE/lib/ext/*.jar中的类 应用类加载器（App）主要加载类路径下用户自定义的类 用户自定义加载器 用于加载指定路径的.class文件 类加载的双亲委托机制 加载器在逻辑上形成一种树形结构\n加载器之间的父子关系实际上是加载器之间的包含关系，并不是继承关系\n双亲委托机制的优点 双亲委托机制的优点是能提高软件的安全性。在这种机制下，用户自定义的加载器不能加载应该由父加载器加载的可靠的类，从而防止了恶意代码代替父加载器的可靠代码。如：用户自定义的类加载器要去加载rt.jar下的类，根据双新委托模型，rt.jar下的类总是由启动类加载器进行加载，所有保证了jdk核心类库的绝对安全。\n类加载器命名空间 同一个命名空间中的类是相互可见的。子加载器的命名空间包含所有父加载器命名空间，因此子加载器可以看见父加载器加载的类，父加载器不能看见子加载器加载的类。如果两个加载器之间没有父子关系，那么他们各自加载的类也是不可见的。\n当前类加载 每个类都有自己的类加载器（即加载自身的类加载器）,并且使用这个类加载器去加载依赖的其他类：如果ClassX类依赖ClassY，那么会使用ClassX的类加载器去加载ClassY\n线程的类加载器 每个线程也具有类加载器，可以通过setContextClassLoader方法区设置线程的类加载器，如果没有进行设置，那么会默认是父线程的类加载器，java初始化线程的类加载器是系统类加载器\n线程上下文加载器 在jdk中定义了很多服务提供接口，如jdbc的Statement接口，具体的实现是有数据库厂商完成的，根据双亲委托模型Statement接口是使用启动类加载器进行加载的，而第三方数据库driver是在类路径下的，启动类加载器无法进行加载，这种情况下双亲委托模型就出现了问题，通过设置线程的上下文加载器，父ClassLoader可以使用当前线程的ClassLoader去加载类，这就改变了双亲委托模型中父加载器不能加载子加载器加载的类的局面\n当高层提供了统一的接口让底层去实现，同时又需要在高层加载（或实例化）底层类时，就需要通过线程上下文类加载器来帮助高层的类加载器加载该类\n获取类加载器 //获取当前类的ClassLoader clazz.getClassLoader(); //获取当前线程的ClassLoader Thread.currentThread().getContextClassLoader(); //获取系统ClassLoader ClassLoader.getSystemClassLoader(); //获取调用者的ClassLoader DriverManager.getCallerClassLoader(); 初始化 Java虚拟机在类或接口“首次主动使用”的时候初始化\n主动使用：1. 创建类的实例\n​\t2.访问类或接口的静态变量\n​\t3.调用类的静态方法\n​\t4.反射，Class.forName(\u0026ldquo;xxx\u0026rdquo;);\n​\t5.初始化一个类的子类\n​\t6.启动类(包含main方法的类)\n​\t7.java.lang.invoke.MethodHandle实例解析结果REF_getStatic,REF_putStatic,REF_invokeStatic句柄对应的类没有初始化，则初始化","title":"JVM学习笔记"},{"content":"k3s k3s是一个轻量级低消耗的k8s发行版，之所以轻量级是因为k3s删除了旧的非必要的代码并且把k8s的组件打包到了一个进程内，减少了进程间通信的消耗，同时，k3s引入了sqlite、mysql、pg、etcd作为可选的数据持久化存储，内置Flannel网络插件和Helm chart包管理增强了k8s的能力。\nk3s的单节点架构 在单节点架构中，使用内嵌的sqlite作为数据持久化数据库，保存在/var/lib/rancher/k3s/server/db/state.db文件中。\n高可用架构 在高可用架构中，多个server需要使用到外部的数据库，支持mysql、pg、etcd。默认使用的是etcd作为数据持久化的数据库。保存在/var/lib/rancher/k3s/server/db/etcd目录下。\n负载均衡 在k8s的Service资源中，常用的type有ClusterIP、NodePort两个，还有一种不常用的LoadBalancer类型，这种类型的策略是使用云提供商的负载局衡器，可以向外部暴露服务。k3s对这种类型进行了扩展，使得type为LoadBalancer类型的Service直接可以通过宿主机直接访问。\napiVersion: v1 kind: Service metadata: name: k3d-nginx-service-lb spec: type: LoadBalancer selector: app: k3d-nginx ports: - protocol: TCP port: 8888 targetPort: 80 iptable -t nat -nvL|grep DNAT crictl exec -it 使用docker创建k3s集群 docker run -d --name k3s-s1 -e K3S_TOKEN=moyuduo123 -e K3S-KUBECONFIG_OUTPUT=/output/kubeconfig.yaml -e CRI_CONFIG_FILE=/var/lib/rancher/k3s/agent/etc/crictl. rancher/k3s:v1.21.7-k3s1 server --cluster-init --tls-san 0.0.0.0 docker run -d --name k3s-a1 -e K3S_TOKEN=moyuduo123 -e K3S_URL=https://k3s-s1:6443 rancher/k3s:v1.21.7-k3s1 agent --snapshotter=native k3d k3d是在k3s的基础上，把k3s运行在容器中来创建k8s的组件，所以在单台宿主机上就可以搭建k8s集群，由于k3s移除了非必要k8s的组件如CloudProvider、把k8s的组件打包进单个二进制文件，所以k3s的二进制包大小和运行开销都比k8s小。\n目前k3d主要具有以下功能：\n支持动态创建master和worker的节点数\nk3d cluster create cluster1 --servers 1 --agents 2 k3d node create extraWorker --cluster cluster1 --role agent 支持数据持久化\nk3d单节点集群使用内嵌的sqlite作为数据存储，高可用的k3s集群使用内嵌的etcd作为数据存储\n支持通过端口转发实现宿主机访问\nhttps://k3d.io/v5.4.1/usage/exposing_services/\nk3d node edit k3d-cluster1-serverlb --port-add 9090:80 apiVersion: apps/v1 kind: Deployment metadata: name: k3d-nginx-deploy labels: k8s-app: k3d-nginx-demo spec: replicas: 2 selector: matchLabels: app: k3d-nginx template: metadata: labels: app: k3d-nginx spec: containers: - name: nginx image: nginx ports: - containerPort: 80 --- apiVersion: v1 kind: Service metadata: name: k3d-nginx-service spec: selector: app: k3d-nginx ports: - protocol: TCP port: 80 targetPort: 80 name: nginx-app-http --- apiVersion: extensions/v1beta1 kind: Ingress metadata: name: k3d-nginx-ingress annotations: ingress.kubernetes.io/ssl-redirect: \u0026#34;false\u0026#34; spec: rules: - http: paths: - path: / backend: serviceName: k3d-nginx-service servicePort: 80 curl k3d-nginx-service curl k3d-nginx-service.default curl k3d-nginx-service.default.svc.cluster.local 内置Helm包管理机制\n使用k3d创建可供外网访问的集群 k3d cluster create dev-cluster1 --servers 1 --agents 2 --k3s-arg \u0026#34;--tls-san=139.198.9.172@server:0\u0026#34; 使用autok3s创建k3d集群 #下载autok3s命令 curl -sS http://rancher-mirror.cnrancher.com/autok3s/install.sh | INSTALL_AUTOK3S_MIRROR=cn sh autok3s -d create -p k3d --name myk3s --master 1 --worker 1 autok3s describe -p k3d -n myk3s autok3s -d join -p k3d -n myk3s --worker 1 autok3s -d delete -p k3d -n myk3s autok3s config use-context k3d-myk3s autok3s kubectl get pod -A ","permalink":"https://moyuduo.github.io/posts/k3s/","summary":"k3s k3s是一个轻量级低消耗的k8s发行版，之所以轻量级是因为k3s删除了旧的非必要的代码并且把k8s的组件打包到了一个进程内，减少了进程间通信的消耗，同时，k3s引入了sqlite、mysql、pg、etcd作为可选的数据持久化存储，内置Flannel网络插件和Helm chart包管理增强了k8s的能力。\nk3s的单节点架构 在单节点架构中，使用内嵌的sqlite作为数据持久化数据库，保存在/var/lib/rancher/k3s/server/db/state.db文件中。\n高可用架构 在高可用架构中，多个server需要使用到外部的数据库，支持mysql、pg、etcd。默认使用的是etcd作为数据持久化的数据库。保存在/var/lib/rancher/k3s/server/db/etcd目录下。\n负载均衡 在k8s的Service资源中，常用的type有ClusterIP、NodePort两个，还有一种不常用的LoadBalancer类型，这种类型的策略是使用云提供商的负载局衡器，可以向外部暴露服务。k3s对这种类型进行了扩展，使得type为LoadBalancer类型的Service直接可以通过宿主机直接访问。\napiVersion: v1 kind: Service metadata: name: k3d-nginx-service-lb spec: type: LoadBalancer selector: app: k3d-nginx ports: - protocol: TCP port: 8888 targetPort: 80 iptable -t nat -nvL|grep DNAT crictl exec -it 使用docker创建k3s集群 docker run -d --name k3s-s1 -e K3S_TOKEN=moyuduo123 -e K3S-KUBECONFIG_OUTPUT=/output/kubeconfig.yaml -e CRI_CONFIG_FILE=/var/lib/rancher/k3s/agent/etc/crictl. rancher/k3s:v1.21.7-k3s1 server --cluster-init --tls-san 0.0.0.0 docker run -d --name k3s-a1 -e K3S_TOKEN=moyuduo123 -e K3S_URL=https://k3s-s1:6443 rancher/k3s:v1.21.7-k3s1 agent --snapshotter=native k3d k3d是在k3s的基础上，把k3s运行在容器中来创建k8s的组件，所以在单台宿主机上就可以搭建k8s集群，由于k3s移除了非必要k8s的组件如CloudProvider、把k8s的组件打包进单个二进制文件，所以k3s的二进制包大小和运行开销都比k8s小。\n目前k3d主要具有以下功能：","title":"k3s"},{"content":"使用 busybox 访问集群内部 kubectl run busybox --rm=true --image=busybox --restart=Never -it 通过-o jsonpath=\u0026quot;{.data.token}\u0026quot;来获取资源的部分属性 k get secret admin-user-token-8v2sr -n kubernetes-dashboard -o jsonpath=\u0026#34;{.data.token}\u0026#34; | base64 -d ","permalink":"https://moyuduo.github.io/posts/k8s/","summary":"使用 busybox 访问集群内部 kubectl run busybox --rm=true --image=busybox --restart=Never -it 通过-o jsonpath=\u0026quot;{.data.token}\u0026quot;来获取资源的部分属性 k get secret admin-user-token-8v2sr -n kubernetes-dashboard -o jsonpath=\u0026#34;{.data.token}\u0026#34; | base64 -d ","title":"k8s"},{"content":"k8s code-generator 创建项目 #在GOPATH之外创建go project mkdir project cd project go mod init 创建目录 cd project mkdir -p apis/{group}/{version} 在新建的apis/{group}目录下新建register.go文件 package moyuduo const ( GroupName = \u0026#34;moyuduo.com\u0026#34; Version = \u0026#34;v1\u0026#34; ) 在apis/{group}/{version}目录下新建doc.go文件 // +k8s:deepcopy-gen=package // +groupName=moyuduo package v1 在apis/{group}/{version}目录下新建types.go文件 package v1 import ( metav1 \u0026#34;k8s.io/apimachinery/pkg/apis/meta/v1\u0026#34; ) // +genclient // +genclient:noStatus // +k8s:deepcopy-gen:interfaces=k8s.io/apimachinery/pkg/runtime.Object type Student struct { metav1.TypeMeta `json:\u0026#34;,inline\u0026#34;` metav1.ObjectMeta `json:\u0026#34;metadata,omitempty\u0026#34;` Spec StudentSpec `json:\u0026#34;spec\u0026#34;` } type StudentSpec struct { name string `json:\u0026#34;name\u0026#34;` school string `json:\u0026#34;school\u0026#34;` } // +k8s:deepcopy-gen:interfaces=k8s.io/apimachinery/pkg/runtime.Object // StudentList is a list of Student resources type StudentList struct { metav1.TypeMeta `json:\u0026#34;,inline\u0026#34;` metav1.ListMeta `json:\u0026#34;metadata\u0026#34;` Items []Student `json:\u0026#34;items\u0026#34;` } 在apis/{group}/{version}目录下新建register.go文件 package v1 import ( metav1 \u0026#34;k8s.io/apimachinery/pkg/apis/meta/v1\u0026#34; \u0026#34;k8s.io/apimachinery/pkg/runtime\u0026#34; \u0026#34;k8s.io/apimachinery/pkg/runtime/schema\u0026#34; \u0026#34;k8s_customize_controller/pkg/apis/moyuduo\u0026#34; ) var SchemeGroupVersion = schema.GroupVersion{ Group: moyuduo.GroupName, Version: moyuduo.Version, } var ( SchemeBuilder = runtime.NewSchemeBuilder(addKnownTypes) AddToScheme = SchemeBuilder.AddToScheme ) func Resource(resource string) schema.GroupResource { return SchemeGroupVersion.WithResource(resource).GroupResource() } func Kind(kind string) schema.GroupKind { return SchemeGroupVersion.WithKind(kind).GroupKind() } func addKnownTypes(scheme *runtime.Scheme) error { scheme.AddKnownTypes( SchemeGroupVersion, \u0026amp;Student{}, \u0026amp;StudentList{}, ) // register the type in the scheme metav1.AddToGroupVersion(scheme, SchemeGroupVersion) return nil } 查看目录结构 [root@centos72-k8s k8s_customize_controller]# pwd /root/k8s/k8s_customize_controller [root@centos72-k8s k8s_customize_controller]# tree . ├── go.mod ├── go.sum └── pkg └── apis └── bolingcavalry ├── register.go └── v1 ├── doc.go ├── register.go └── types.go 4 directories, 6 files [root@centos72-k8s k8s_customize_controller]# 执行脚本生成文件 #clone code-generator 项目后设置环境变量 [root@centos72-k8s k8s_customize_controller]# execDir=/storehouse/k8s/code-generator #执行脚本 ${execDir}/generate-groups.sh all /pkg/clients ./pkg/apis moyuduo:v1 --output-base=./ -h ${execDir}/hack/boilerplate.go.txt -v 10 ${execDir}/generate_group.sh all github.com/kubesphere/kubeocean2/pkg/client github.com/kubesphere/kubeocean2/pkg/apis \u0026#34;clusterapi:v1beta1\u0026#34; --output-base=./ -h ${execDir}/boilerplate.go.txt -v 10 ${execDir}/generate_group.sh all github.com/KubeSphereCloud/ks-store/pkg/client github.com/KubeSphereCloud/ks-store/pkg/kapis \u0026#34;cluster:v1alpha1 kubeocean:v1alpha1\u0026#34; --output-base=./ -h ${execDir}/boilerplate.go.txt -v 10 rm -rf ./pkg/client rm -rf ./pkg/kapis/cluster/v1alpha1/zz_generated.deepcopy.go rm -rf ./pkg/kapis/kubeocean/v1alpha1/zz_generated.deepcopy.go cp -r ./github.com/KubeSphereCloud/ks-store/pkg/client ./pkg/ cp -r ./github.com/KubeSphereCloud/ks-store/pkg/kapis/cluster/v1alpha1/zz_generated.deepcopy.go ./pkg/kapis/cluster/v1alpha1/ cp -r ./github.com/KubeSphereCloud/ks-store/pkg/kapis/kubeocean/v1alpha1/zz_generated.deepcopy.go ./pkg/kapis/kubeocean/v1alpha1/ rm -rf ./github.com ","permalink":"https://moyuduo.github.io/posts/k8s-code-generator/","summary":"k8s code-generator 创建项目 #在GOPATH之外创建go project mkdir project cd project go mod init 创建目录 cd project mkdir -p apis/{group}/{version} 在新建的apis/{group}目录下新建register.go文件 package moyuduo const ( GroupName = \u0026#34;moyuduo.com\u0026#34; Version = \u0026#34;v1\u0026#34; ) 在apis/{group}/{version}目录下新建doc.go文件 // +k8s:deepcopy-gen=package // +groupName=moyuduo package v1 在apis/{group}/{version}目录下新建types.go文件 package v1 import ( metav1 \u0026#34;k8s.io/apimachinery/pkg/apis/meta/v1\u0026#34; ) // +genclient // +genclient:noStatus // +k8s:deepcopy-gen:interfaces=k8s.io/apimachinery/pkg/runtime.Object type Student struct { metav1.TypeMeta `json:\u0026#34;,inline\u0026#34;` metav1.ObjectMeta `json:\u0026#34;metadata,omitempty\u0026#34;` Spec StudentSpec `json:\u0026#34;spec\u0026#34;` } type StudentSpec struct { name string `json:\u0026#34;name\u0026#34;` school string `json:\u0026#34;school\u0026#34;` } // +k8s:deepcopy-gen:interfaces=k8s.","title":"k8s code-generator"},{"content":"kafka相关 安装 安装JDK1.8\nyum install -y java-1.8.0* #使用java -version出现以下命令说明安装成功 openjdk version \u0026#34;1.8.0_302\u0026#34; OpenJDK Runtime Environment (build 1.8.0_302-b08) OpenJDK 64-Bit Server VM (build 25.302-b08, mixed mode) 安装zookeeper\n#创建zookeeper安装目录 mkdir -p /opt/zookeeper #进入目录 cd /opt/zookeeper #下载安装包 wget https://mirrors.aliyun.com/apache/zookeeper/zookeeper-3.6.3/apache-zookeeper-3.6.3-bin.tar.gz #解压 tar -zxvf apache-zookeeper-3.6.3-bin.tar.gz #进入配置文件目录 cd /opt/zookeeper/apache-zookeeper-3.6.3-bin/conf #复制配置文件 cp zoo_sample.cfg zoo.cfg #修改配置 #客户端会话超时时间 tickTime=2000 #客户端初始化可接受多少个心跳监测，默认10，即10*tickTime(默认2000)，表示20s没有连接上集群的配置则连接失败 initLimit=10 #Leader和follwer之间，允许多少个请求应答长度，默认5，即5*tickTime(默认2000)，表示默认10sLeader和Follwer之间如果消息5次没有发送成功就不尝试了 syncLimit=5 #存储快照文件的目录 dataDir=/opt/zookeeper/zoodata #事务日志存储的目录 dataLogDir=/opt/zookeeper/zoodatalog #服务端口 clientPort=2181 #server.X=A:B:C\tX是一个数字，表示这是第几号server\tA是该server所在的IP地址\tB配置该server和集群中的leader交换消息所使用的端口\tC配置选举leader时所使用的端口 server.1=127.0.0.1:2888:3888 #集群配置 server.1=192.168.37.151:2888:3888 server.2=192.168.37.152:2888:3888 server.3=192.168.37.153:2888:3888 #创建dataDir目录 mkdir -p /opt/zookeeper/zoodata #进入dataDir目录 cd /opt/zookeeper/zoodata #把节点号写入myid文件，不同节点各自配置 echo 1 \u0026gt; myid #配置防火墙 firewall-cmd --zone=public --add-port=2181/tcp --permanent firewall-cmd --zone=public --add-port=2888/tcp --permanent firewall-cmd --zone=public --add-port=3888/tcp --permanent firewall-cmd --reload #进入zookeeper执行目录 cd /opt/zookeeper/apache-zookeeper-3.6.3-bin/bin #启动zookeeper ./zkServer.sh start #重启 ./zkServer.sh restart #关闭 ./zkServer.sh stop #查看状态 ./zkServer.sh status #客户端连接zookeeper ./zkCli.sh 参考：https://ken.io/note/zookeeper-cluster-deploy-guide\n3.kafka安装\n#创建安装目录 mkdir -p /opt/kafka #进入安装目录 cd /opt/kafka #下载kafka安装 wget https://mirrors.aliyun.com/apache/kafka/2.7.1/kafka_2.13-2.7.1.tgz #解压 tar -zxvf kafka_2.13-2.7.1.tgz #进入配置文件目录 cd kafka_2.13-2.7.1/config/ #备份配置文件 cp server.properties server.properties.bak #修改配置文件 vim server.properties #当前节点在集群中的唯一标识 broker.id=1 #服务监听端口 listeners=PLAINTEXT://127.0.0.1:9092 #提供给生产者、消费者的端口 advertised.listeners=PLAINTEXT://127.0.0.1:9092 #连接地址，如有集群需配置 zookeeper.connect=127.0.0.1:2181 #连接超时时间 zookeeper.connection.timeout.ms=18000 :wq #开放端口 firewall-cmd --add-port=9092/tcp --permanent #重新加载防火墙配置 firewall-cmd --reload #进入kafka执行目录 cd /opt/kafka/kafka_2.13-2.7.1/bin #后台启动kafka内置的zookeeper ./bin/zookeeper-server-start.sh -daemon config/zookeeper.properties #关闭zookeeper ./bin/zookeeper-server-stop.sh -daemon config/zookeeper.properties cd /opt/kafka/kafka_2.13-2.7.1 #启动kafka,如果在去启动时报错 The Cluster ID 4cffC36ERj6MTJ_mZkKafA doesn\u0026#39;t match stored clusterId 可能是之前使用的 zookeeper 和现在的不是同一个，解决办法是删除 server.properties 中配置的 logDir 下的 meta.properties 文件 ./bin/kafka-server-start.sh -daemon config/server.properties #关闭kafka ./bin/kafka-server-stop.sh config/server.properties #创建topic #partitions表示在几个分区上创建topic #replication-factor表示在每个分区上副本的数量 ./kafka-topics.sh --create --zookeeper 127.0.0.1:2181 --replication-factor 1 --partitions 1 --topic topic1 #查看topic信息 ./kafka-topics.sh --describe --zookeeper 127.0.0.1:2181 --topic topic1 #启动控制台生产者 ./kafka-console-producer.sh --broker-list 127.0.0.1:9092 --topic topic1 #启动控制台消费者 ./kafka-console-consumer.sh --bootstrap-server 127.0.0.1:9092 --topic topic1 --from-beginning #3个broker情况下创建topic指定4个副本会报错，原因是replication的数量不能大于broker数，可以想象的是replication是针对每一个分区来说的，如果一个分区的副本数等于broker数的话那个意味着每个broker上都有一个该分区的副本，如果大于broker数，那么该分区在某些broker上会存在多个副本，没有必要 ./kafka-topics.sh --create --topic myd4 --partitions 3 -replication-factor 4 --zookeeper kafka1:2181 Error while executing topic command : Replication factor: 4 larger than available brokers: 3. 参考：https://www.cnblogs.com/kentalk/p/kafka-cluster-deploy-guide.html\n配置远程访问 cd kafka安装路径/config/server.properties 修改对应位置为 listeners=PLAINTEXT://:9092 advertised.listeners=PLAINTEXT://服务器ip:9092 基准测试 ./kafka-topics.sh --zookeeper 139.198.11.13:2181 --create --topic benchmark --partitions 1 --replication-factor 1 ./kafka-producer-perf-test.sh --topic benchmark --num-records 500000 --throughput -1 --record-size 1000 --producer-props bootstrap.servers=139.198.11.13:9092 acks=1 ./kafka-consumer-perf-test.sh --broker-list 139.198.11.13:9092 --topic benchmark --fetch-seze 1048576 --messages 500000 kafka-eagle管理工具 去官网https://www.kafka-eagle.org/下载tar安装包\n#上传tar包到kafka-eagle安装目录 tar -zxvf kafka-eagle-bin-2.0.6.tar.gz cd kafka-eagle-bin-2.0.6.tar tar -zxvf kafka-eagle-web-2.0.6-bin.tar.gz 设置环境变量\nvim /etc/profile #kafka-eagle export KE_HOME= xxx PATH=$PATH:$KE_HOME/bin #java export JAVA_HOME= xxx PATH=$PATH:$JAVA_HOME/bin :wq #更新环境变量 source /etc/profile 修改kafka-eagle配置文件\ncd $KE_HOME/conf vim system-config.properties ###################################### # multi zookeeper\u0026amp;kafka cluster list # zookeeper和kafka集群配置 ###################################### kafka.eagle.zk.cluster.alias=cluster1 cluster1.zk.list=192.168.37.151:2181,192.168.37.152:2182,192.168.37.153:2183 ###################################### # kafka eagle webui port # web页面访问端口号 ###################################### kafka.eagle.webui.port=8048 ###################################### # kafka jdbc driver address # kafka默认使用sqlite数据库，Centos自带，注意配置下数据库存放路径就行 ###################################### kafka.eagle.driver=org.sqlite.JDBC kafka.eagle.url=jdbc:sqlite:/opt/kafka-eagle/db/ke.db kafka.eagle.username=root kafka.eagle.password=www.kafka-eagle.org 开放端口供外部访问\nfirewall-cmd --add-port=8048/tcp --permanent firewall-cmd --reload 启动kafka-eagle\ncd $KE_HOME/bin ./ke.sh start #出现以下内容则成功 Welcome to __ __ ___ ____ __ __ ___ ______ ___ ______ __ ______ / //_/ / | / __/ / //_/ / | / ____/ / | / ____/ / / / ____/ / ,\u0026lt; / /| | / /_ / ,\u0026lt; / /| | / __/ / /| | / / __ / / / __/ / /| | / ___ | / __/ / /| | / ___ | / /___ / ___ |/ /_/ / / /___ / /___ /_/ |_| /_/ |_|/_/ /_/ |_| /_/ |_| /_____/ /_/ |_|\\____/ /_____//_____/ Version 2.0.6 -- Copyright 2016-2021 ******************************************************************* * Kafka Eagle Service has started success. * Welcome, Now you can visit \u0026#39;http://127.0.0.1:8048\u0026#39; * Account:admin ,Password:123456 kafka架构 Producer: 消息的生产者，像 broker 中发送消息 Consumer: 消息的消费者，从 broker 中消费消息 Broker：一台 kafka 服务器就是一个 broker，一个 kafka 集群由多个 broker 组成，一个 broker 包含多个 topic Topic：理解成一个队列，Producer 和 Consumer 都是面向 topic 的 ConsumerGroup: 多个对同一个 topic 进行消费的 Consumer 组成一个组，一个消费者组内的一个消费者只能消费一个分区，不同的分区由不同的消费者进行消费，消费者组内的消费者的消费能保证分区有序性，但是不能保证全局有序。 Partition: 为了实现扩展性，一个 topic 可以分布到多个 broker 上，一个 topic 可以分为多个 partition，每个 partition 是一个有序队列 Replica：副本，为了保证某一个 broker 故障后，分布在该节点上的 topic 的 partition 中的数据不会丢失，一个 topic 的每个 partition 都可以有若干 replica 分布在其他 broker上，replica 又分为 leader 和 follower Leader：每个 topic 的 partition 有多个 replica，其中一个为 leader，Producer 生产数据、Consumer 消费数据都是从 leader 上 Follower：topic 的 partition 的 follower，负责从 leader 处同步数据，并在 leader 发生故障后竞选为 leader kafka工作流程 在 kafka 中生产者生产消息和消费者消费消息都是面向 topic 的 topic 是一个逻辑上的概念，partition 是物理上的概念，每个 partition 对应一个.log文件，该文件中保存的就是生成者生产的数据。生产者生产的数据会被不断的追加到这个文件中，并且对于每个.log文件都有一个.index文件来保存当前.log文件的 offset 以便快速定位到数据 消费者组中的每一个消费者都会实时记录自己消费到哪个 offset 了，以便在出错回复时能从上次消费的地方消费和不会重复消费数据 kafka文件存储机制 由于生产者生产消息会不断追加到.log文件中，为了防止.log文件过大导致定位效率低下，kafka 采用分片和索引机制提高检索效率，将每个 partition 分为多个 segment。每个 segment 对应两个文件.log文件和.index文件，所有 segment 的文件位于一个topic_name + partition_number命名的文件夹下，当每个.log文件的大小大于 server.properties文件中定义的log.segment.bytes值(默认为1G)时，会新增一个 segment,并且文件名为 offset,当 segment 创建的时间大于server.properties中定义的log.retention.hours的值(默认为7天)该 segment 会被删除 00000000000000000000.indexindex 文件的格式为 offset 命名，最多可保存 20 位 .log 文件和 .index 文件 创建topic时的分区策略 创建topic时的副本分配策略 生产者分区写入策略 当生产者向一个 topic 中写入数据时，由于 topic 只是一个逻辑上的概念，而 partition 是物理上的概念，所以数据必然是写入到一个 partition 上，而一个 topic 由多个 partition 组成，那么生产者在发送消息时是具体将消息写入到了那个 partition 中呢?\n指定分区策略，消费者在发送消息时指定发送到哪个 partition 随机策略，随机发送到一个 partition ，会导致数据倾斜 轮询策略，生产者在发送消息时首先生成一个 random_number ，然后使用random_number % partition_number 作为第一个发送到的分区，以后的消息就轮流发送到每个分区上 按 key 分区策略，这种策略是在发送消息时指定一个 key，使用 key.hash % partition_number选择发送到的分区，这种策略能够保证相同的 key 的所有消息都能发送打同一个 partition，缺点是会造成数据倾斜 自定义策略，实现 Partitioner 接口 乱序问题 不管生产者使用 随机策略、轮询策略虽然消息在同一个分区中是局部有序的，但是不同分区之间由于消费者的消费速度一同，所以从整体上来看是乱序的，虽然按 key 分区策略能保证有序，但是有会造成数据的倾斜，除此之外把 topic 的分区设置成1也能保证有序，但是这样就失去了 kafka 的分布式特性和可扩展性\nkafka生产者生产消息的可靠性 幂等性 一个相同的操作进行两次会得到同样的结果，如发送两次相同的 http 请求，在 kafka 中生产者发送了生产消息到 topic 上，那么如何保证收到了这个消息？如果 server 收到了消息会进行ack的话，如何保证生产者这没有收到这个 ack 之前有发送了一遍上一次的消息后，server 收到了不会重复保存？\n消息可靠性 为了保证数据的可靠性，kafka 在收到了生产者发送的消息后会进行 ack，如果生产者在指定的时间内没有收到 ack，那么会重新发送上一次的消息。生产者在发送消息时会携带一个 pid(Producer Id)和一个 seqid(自增Id), kafka 在收到消息后会保存生产者发送过来的 pid 和 seqid,如果 kafka 接受到一条消息，消息的 seqid 小于等于 kafka 保存的对应 pid 对应 sqlid，即这条消息已经被 kafka保存，kafka 不会重复保存这条消息\nacks设置 acks=0: 生产者不等待分区返回 ack，存在丢数据风险 acks=1：生产者等待分区 leader 同步完成之后返回 ack，如果分区 follower 在 leader 返回 ack 之后故障，而此时 follower 还没同步数据将导致数据丢失 acks=-1：消费者分区的 leader 和 follower(ISR 中的 follower) 都同步完数据之后返回 ack。但是如在在 follower 同步完成后，leader 返回 ack 前 leader 故障那么会导致数据重复。如果 ISR 中当前只有 leader，那么 leader 同步完后就返回 ack 了但是 follower 还没同步完成，也可能导致丢失数据 kafka 对消息进行 ack 有两种方案 分区半数以上的 replica 同步成功后进行 ack，优点是延时低，缺点是选举新的 leader 时，如果要容忍 n台节点故障需要部署 2n+1 台\n所有 replica 同步完成后进行 ack，优点是选举新的 leader 时容忍 n 台故障，只需要 n+1 个节点，缺点是延时高\nkafka 选择第二种方案对消息进行 ack\n高延时怎么解决？ 每个分区维护一个动态的ISR(in-sync replica set)即和 leader 保持同步的 follower 的集合，当 ISR 中的 follower 同步完数据后会对消息进行 ack，如果 ISR 中的 follower 同 leader 进行同步的时间过长，那么该 follower 会被踢出 ISR该时间阈值由replica.lag.time.max.ms指定，如果在 ISR 之外的 follower 同 ISR 同步的时间较短，那么该 follower 能够加入 ISR，leader 故障后从 ISR 中选择新的 leader\n故障恢复 LEO(Log End Offset):指的是每个副本最大的 offset\nHW(High Watermark):指的是消费者能见到的最大的 offset，ISR 队列中最小的 LEO。\nleader故障 leader 发生故障后会从 ISR 中选择一个 follower 作为 leader，为保证数据一致性，其余的 follower 会把 log 文件中高于 HW 的一部分截取掉，重新从 leader 中同步\nfollower故障 follower 发生故障后会被临时踢出 ISR，待该 follower 恢复后，follower 会读取本地磁盘 记录的上次的 HW，并将 log 文件高于 HW 的部分截取掉，从 HW 开始向 leader 进行同步。 等该 follower 的 LEO 大于等于该 Partition 的 HW，即 follower 追上 leader 之后，就可以重 新加入 ISR 了\nExactly Onece 消费者分区消费策略 分区的物理存储 生产者消息不丢失 ack\n消费者消息不丢失 控制offset\n默认的自动提交offset会出现消息丢失\n即使控制消息保存成功，也有可能出现消息重复消费\n##kafka事务\n","permalink":"https://moyuduo.github.io/posts/kafka%E7%9B%B8%E5%85%B3/","summary":"kafka相关 安装 安装JDK1.8\nyum install -y java-1.8.0* #使用java -version出现以下命令说明安装成功 openjdk version \u0026#34;1.8.0_302\u0026#34; OpenJDK Runtime Environment (build 1.8.0_302-b08) OpenJDK 64-Bit Server VM (build 25.302-b08, mixed mode) 安装zookeeper\n#创建zookeeper安装目录 mkdir -p /opt/zookeeper #进入目录 cd /opt/zookeeper #下载安装包 wget https://mirrors.aliyun.com/apache/zookeeper/zookeeper-3.6.3/apache-zookeeper-3.6.3-bin.tar.gz #解压 tar -zxvf apache-zookeeper-3.6.3-bin.tar.gz #进入配置文件目录 cd /opt/zookeeper/apache-zookeeper-3.6.3-bin/conf #复制配置文件 cp zoo_sample.cfg zoo.cfg #修改配置 #客户端会话超时时间 tickTime=2000 #客户端初始化可接受多少个心跳监测，默认10，即10*tickTime(默认2000)，表示20s没有连接上集群的配置则连接失败 initLimit=10 #Leader和follwer之间，允许多少个请求应答长度，默认5，即5*tickTime(默认2000)，表示默认10sLeader和Follwer之间如果消息5次没有发送成功就不尝试了 syncLimit=5 #存储快照文件的目录 dataDir=/opt/zookeeper/zoodata #事务日志存储的目录 dataLogDir=/opt/zookeeper/zoodatalog #服务端口 clientPort=2181 #server.X=A:B:C\tX是一个数字，表示这是第几号server\tA是该server所在的IP地址\tB配置该server和集群中的leader交换消息所使用的端口\tC配置选举leader时所使用的端口 server.1=127.0.0.1:2888:3888 #集群配置 server.1=192.168.37.151:2888:3888 server.2=192.168.37.152:2888:3888 server.3=192.168.37.153:2888:3888 #创建dataDir目录 mkdir -p /opt/zookeeper/zoodata #进入dataDir目录 cd /opt/zookeeper/zoodata #把节点号写入myid文件，不同节点各自配置 echo 1 \u0026gt; myid #配置防火墙 firewall-cmd --zone=public --add-port=2181/tcp --permanent firewall-cmd --zone=public --add-port=2888/tcp --permanent firewall-cmd --zone=public --add-port=3888/tcp --permanent firewall-cmd --reload #进入zookeeper执行目录 cd /opt/zookeeper/apache-zookeeper-3.","title":"kafka相关"},{"content":"获取namespace: url:http://139.198.112.218:31880/api/v1alpha1/namespaces method:get\nresp:\n{ \u0026#34;metadata\u0026#34;:{ \u0026#34;resourceVersion\u0026#34;:\u0026#34;15319237\u0026#34; }, \u0026#34;items\u0026#34;:[ { \u0026#34;metadata\u0026#34;:{ \u0026#34;name\u0026#34;:\u0026#34;default\u0026#34;, \u0026#34;uid\u0026#34;:\u0026#34;e3c6a8af-9d8a-412e-bca9-893635d545a6\u0026#34;, \u0026#34;resourceVersion\u0026#34;:\u0026#34;205\u0026#34;, \u0026#34;creationTimestamp\u0026#34;:\u0026#34;2021-10-07T04:16:49Z\u0026#34;, \u0026#34;labels\u0026#34;:{ \u0026#34;kubernetes.io/metadata.name\u0026#34;:\u0026#34;default\u0026#34; }, \u0026#34;managedFields\u0026#34;:[ { \u0026#34;manager\u0026#34;:\u0026#34;kube-apiserver\u0026#34;, \u0026#34;operation\u0026#34;:\u0026#34;Update\u0026#34;, \u0026#34;apiVersion\u0026#34;:\u0026#34;v1\u0026#34;, \u0026#34;time\u0026#34;:\u0026#34;2021-10-07T04:16:49Z\u0026#34;, \u0026#34;fieldsType\u0026#34;:\u0026#34;FieldsV1\u0026#34;, \u0026#34;fieldsV1\u0026#34;:{ \u0026#34;f:metadata\u0026#34;:{ \u0026#34;f:labels\u0026#34;:{ \u0026#34;.\u0026#34;:{ }, \u0026#34;f:kubernetes.io/metadata.name\u0026#34;:{ } } } } } ] }, \u0026#34;spec\u0026#34;:{ \u0026#34;finalizers\u0026#34;:[ \u0026#34;kubernetes\u0026#34; ] }, \u0026#34;status\u0026#34;:{ \u0026#34;phase\u0026#34;:\u0026#34;Active\u0026#34; } }, { \u0026#34;metadata\u0026#34;:{ \u0026#34;name\u0026#34;:\u0026#34;ingress-nginx\u0026#34;, \u0026#34;uid\u0026#34;:\u0026#34;db2263b3-992c-4aeb-99c8-3de1b66a91d9\u0026#34;, \u0026#34;resourceVersion\u0026#34;:\u0026#34;5156\u0026#34;, \u0026#34;creationTimestamp\u0026#34;:\u0026#34;2021-10-07T04:48:20Z\u0026#34;, \u0026#34;labels\u0026#34;:{ \u0026#34;app.kubernetes.io/instance\u0026#34;:\u0026#34;ingress-nginx\u0026#34;, \u0026#34;app.kubernetes.io/name\u0026#34;:\u0026#34;ingress-nginx\u0026#34;, \u0026#34;kubernetes.io/metadata.name\u0026#34;:\u0026#34;ingress-nginx\u0026#34; }, \u0026#34;annotations\u0026#34;:{ \u0026#34;kubectl.kubernetes.io/last-applied-configuration\u0026#34;:\u0026#34;{\\\u0026#34;apiVersion\\\u0026#34;:\\\u0026#34;v1\\\u0026#34;,\\\u0026#34;kind\\\u0026#34;:\\\u0026#34;Namespace\\\u0026#34;,\\\u0026#34;metadata\\\u0026#34;:{\\\u0026#34;annotations\\\u0026#34;:{},\\\u0026#34;labels\\\u0026#34;:{\\\u0026#34;app.kubernetes.io/instance\\\u0026#34;:\\\u0026#34;ingress-nginx\\\u0026#34;,\\\u0026#34;app.kubernetes.io/name\\\u0026#34;:\\\u0026#34;ingress-nginx\\\u0026#34;},\\\u0026#34;name\\\u0026#34;:\\\u0026#34;ingress-nginx\\\u0026#34;}}\\n\u0026#34; }, \u0026#34;managedFields\u0026#34;:[ { \u0026#34;manager\u0026#34;:\u0026#34;kubectl-client-side-apply\u0026#34;, \u0026#34;operation\u0026#34;:\u0026#34;Update\u0026#34;, \u0026#34;apiVersion\u0026#34;:\u0026#34;v1\u0026#34;, \u0026#34;time\u0026#34;:\u0026#34;2021-10-07T04:48:20Z\u0026#34;, \u0026#34;fieldsType\u0026#34;:\u0026#34;FieldsV1\u0026#34;, \u0026#34;fieldsV1\u0026#34;:{ \u0026#34;f:metadata\u0026#34;:{ \u0026#34;f:annotations\u0026#34;:{ \u0026#34;.\u0026#34;:{ }, \u0026#34;f:kubectl.kubernetes.io/last-applied-configuration\u0026#34;:{ } }, \u0026#34;f:labels\u0026#34;:{ \u0026#34;.\u0026#34;:{ }, \u0026#34;f:app.kubernetes.io/instance\u0026#34;:{ }, \u0026#34;f:app.kubernetes.io/name\u0026#34;:{ }, \u0026#34;f:kubernetes.io/metadata.name\u0026#34;:{ } } } } } ] }, \u0026#34;spec\u0026#34;:{ \u0026#34;finalizers\u0026#34;:[ \u0026#34;kubernetes\u0026#34; ] }, \u0026#34;status\u0026#34;:{ \u0026#34;phase\u0026#34;:\u0026#34;Active\u0026#34; } }, { \u0026#34;metadata\u0026#34;:{ \u0026#34;name\u0026#34;:\u0026#34;kube-node-lease\u0026#34;, \u0026#34;uid\u0026#34;:\u0026#34;c582c2a7-6891-4746-9b44-53e9b8215a31\u0026#34;, \u0026#34;resourceVersion\u0026#34;:\u0026#34;18\u0026#34;, \u0026#34;creationTimestamp\u0026#34;:\u0026#34;2021-10-07T04:16:48Z\u0026#34;, \u0026#34;labels\u0026#34;:{ \u0026#34;kubernetes.io/metadata.name\u0026#34;:\u0026#34;kube-node-lease\u0026#34; }, \u0026#34;managedFields\u0026#34;:[ { \u0026#34;manager\u0026#34;:\u0026#34;kube-apiserver\u0026#34;, \u0026#34;operation\u0026#34;:\u0026#34;Update\u0026#34;, \u0026#34;apiVersion\u0026#34;:\u0026#34;v1\u0026#34;, \u0026#34;time\u0026#34;:\u0026#34;2021-10-07T04:16:48Z\u0026#34;, \u0026#34;fieldsType\u0026#34;:\u0026#34;FieldsV1\u0026#34;, \u0026#34;fieldsV1\u0026#34;:{ \u0026#34;f:metadata\u0026#34;:{ \u0026#34;f:labels\u0026#34;:{ \u0026#34;.\u0026#34;:{ }, \u0026#34;f:kubernetes.io/metadata.name\u0026#34;:{ } } } } } ] }, \u0026#34;spec\u0026#34;:{ \u0026#34;finalizers\u0026#34;:[ \u0026#34;kubernetes\u0026#34; ] }, \u0026#34;status\u0026#34;:{ \u0026#34;phase\u0026#34;:\u0026#34;Active\u0026#34; } }, { \u0026#34;metadata\u0026#34;:{ \u0026#34;name\u0026#34;:\u0026#34;kube-public\u0026#34;, \u0026#34;uid\u0026#34;:\u0026#34;a7f98ab9-eff9-4a11-b43c-8380fc729015\u0026#34;, \u0026#34;resourceVersion\u0026#34;:\u0026#34;14\u0026#34;, \u0026#34;creationTimestamp\u0026#34;:\u0026#34;2021-10-07T04:16:48Z\u0026#34;, \u0026#34;labels\u0026#34;:{ \u0026#34;kubernetes.io/metadata.name\u0026#34;:\u0026#34;kube-public\u0026#34; }, \u0026#34;managedFields\u0026#34;:[ { \u0026#34;manager\u0026#34;:\u0026#34;kube-apiserver\u0026#34;, \u0026#34;operation\u0026#34;:\u0026#34;Update\u0026#34;, \u0026#34;apiVersion\u0026#34;:\u0026#34;v1\u0026#34;, \u0026#34;time\u0026#34;:\u0026#34;2021-10-07T04:16:48Z\u0026#34;, \u0026#34;fieldsType\u0026#34;:\u0026#34;FieldsV1\u0026#34;, \u0026#34;fieldsV1\u0026#34;:{ \u0026#34;f:metadata\u0026#34;:{ \u0026#34;f:labels\u0026#34;:{ \u0026#34;.\u0026#34;:{ }, \u0026#34;f:kubernetes.io/metadata.name\u0026#34;:{ } } } } } ] }, \u0026#34;spec\u0026#34;:{ \u0026#34;finalizers\u0026#34;:[ \u0026#34;kubernetes\u0026#34; ] }, \u0026#34;status\u0026#34;:{ \u0026#34;phase\u0026#34;:\u0026#34;Active\u0026#34; } }, { \u0026#34;metadata\u0026#34;:{ \u0026#34;name\u0026#34;:\u0026#34;kube-system\u0026#34;, \u0026#34;uid\u0026#34;:\u0026#34;9cb0531e-553a-41ea-a08c-9dd754f171b1\u0026#34;, \u0026#34;resourceVersion\u0026#34;:\u0026#34;11\u0026#34;, \u0026#34;creationTimestamp\u0026#34;:\u0026#34;2021-10-07T04:16:48Z\u0026#34;, \u0026#34;labels\u0026#34;:{ \u0026#34;kubernetes.io/metadata.name\u0026#34;:\u0026#34;kube-system\u0026#34; }, \u0026#34;managedFields\u0026#34;:[ { \u0026#34;manager\u0026#34;:\u0026#34;kube-apiserver\u0026#34;, \u0026#34;operation\u0026#34;:\u0026#34;Update\u0026#34;, \u0026#34;apiVersion\u0026#34;:\u0026#34;v1\u0026#34;, \u0026#34;time\u0026#34;:\u0026#34;2021-10-07T04:16:48Z\u0026#34;, \u0026#34;fieldsType\u0026#34;:\u0026#34;FieldsV1\u0026#34;, \u0026#34;fieldsV1\u0026#34;:{ \u0026#34;f:metadata\u0026#34;:{ \u0026#34;f:labels\u0026#34;:{ \u0026#34;.\u0026#34;:{ }, \u0026#34;f:kubernetes.io/metadata.name\u0026#34;:{ } } } } } ] }, \u0026#34;spec\u0026#34;:{ \u0026#34;finalizers\u0026#34;:[ \u0026#34;kubernetes\u0026#34; ] }, \u0026#34;status\u0026#34;:{ \u0026#34;phase\u0026#34;:\u0026#34;Active\u0026#34; } }, { \u0026#34;metadata\u0026#34;:{ \u0026#34;name\u0026#34;:\u0026#34;kubeocean-system\u0026#34;, \u0026#34;uid\u0026#34;:\u0026#34;9b6016a9-b348-4dc6-8670-bfb24a131e55\u0026#34;, \u0026#34;resourceVersion\u0026#34;:\u0026#34;3315\u0026#34;, \u0026#34;creationTimestamp\u0026#34;:\u0026#34;2021-10-07T04:38:59Z\u0026#34;, \u0026#34;labels\u0026#34;:{ \u0026#34;control-plane\u0026#34;:\u0026#34;controller-manager\u0026#34;, \u0026#34;kubernetes.io/metadata.name\u0026#34;:\u0026#34;kubeocean-system\u0026#34; }, \u0026#34;annotations\u0026#34;:{ \u0026#34;kubectl.kubernetes.io/last-applied-configuration\u0026#34;:\u0026#34;{\\\u0026#34;apiVersion\\\u0026#34;:\\\u0026#34;v1\\\u0026#34;,\\\u0026#34;kind\\\u0026#34;:\\\u0026#34;Namespace\\\u0026#34;,\\\u0026#34;metadata\\\u0026#34;:{\\\u0026#34;annotations\\\u0026#34;:{},\\\u0026#34;labels\\\u0026#34;:{\\\u0026#34;control-plane\\\u0026#34;:\\\u0026#34;controller-manager\\\u0026#34;},\\\u0026#34;name\\\u0026#34;:\\\u0026#34;kubeocean-system\\\u0026#34;}}\\n\u0026#34; }, \u0026#34;managedFields\u0026#34;:[ { \u0026#34;manager\u0026#34;:\u0026#34;kubectl-client-side-apply\u0026#34;, \u0026#34;operation\u0026#34;:\u0026#34;Update\u0026#34;, \u0026#34;apiVersion\u0026#34;:\u0026#34;v1\u0026#34;, \u0026#34;time\u0026#34;:\u0026#34;2021-10-07T04:38:59Z\u0026#34;, \u0026#34;fieldsType\u0026#34;:\u0026#34;FieldsV1\u0026#34;, \u0026#34;fieldsV1\u0026#34;:{ \u0026#34;f:metadata\u0026#34;:{ \u0026#34;f:annotations\u0026#34;:{ \u0026#34;.\u0026#34;:{ }, \u0026#34;f:kubectl.kubernetes.io/last-applied-configuration\u0026#34;:{ } }, \u0026#34;f:labels\u0026#34;:{ \u0026#34;.\u0026#34;:{ }, \u0026#34;f:control-plane\u0026#34;:{ }, \u0026#34;f:kubernetes.io/metadata.name\u0026#34;:{ } } } } } ] }, \u0026#34;spec\u0026#34;:{ \u0026#34;finalizers\u0026#34;:[ \u0026#34;kubernetes\u0026#34; ] }, \u0026#34;status\u0026#34;:{ \u0026#34;phase\u0026#34;:\u0026#34;Active\u0026#34; } }, { \u0026#34;metadata\u0026#34;:{ \u0026#34;name\u0026#34;:\u0026#34;test\u0026#34;, \u0026#34;uid\u0026#34;:\u0026#34;d6cdc999-c51d-4a5a-8adf-aa6ef1001e00\u0026#34;, \u0026#34;resourceVersion\u0026#34;:\u0026#34;13269673\u0026#34;, \u0026#34;creationTimestamp\u0026#34;:\u0026#34;2022-01-11T05:46:40Z\u0026#34;, \u0026#34;labels\u0026#34;:{ \u0026#34;kubernetes.io/metadata.name\u0026#34;:\u0026#34;test\u0026#34; }, \u0026#34;managedFields\u0026#34;:[ { \u0026#34;manager\u0026#34;:\u0026#34;kubectl-create\u0026#34;, \u0026#34;operation\u0026#34;:\u0026#34;Update\u0026#34;, \u0026#34;apiVersion\u0026#34;:\u0026#34;v1\u0026#34;, \u0026#34;time\u0026#34;:\u0026#34;2022-01-11T05:46:40Z\u0026#34;, \u0026#34;fieldsType\u0026#34;:\u0026#34;FieldsV1\u0026#34;, \u0026#34;fieldsV1\u0026#34;:{ \u0026#34;f:metadata\u0026#34;:{ \u0026#34;f:labels\u0026#34;:{ \u0026#34;.\u0026#34;:{ }, \u0026#34;f:kubernetes.io/metadata.name\u0026#34;:{ } } } } } ] }, \u0026#34;spec\u0026#34;:{ \u0026#34;finalizers\u0026#34;:[ \u0026#34;kubernetes\u0026#34; ] }, \u0026#34;status\u0026#34;:{ \u0026#34;phase\u0026#34;:\u0026#34;Active\u0026#34; } } ] } 创建集群 pkg/cluster/handler/cluster.go CreateCluster\nurl:http://139.198.112.218:31880/api/v1alpha1/cluster/default/taoli-test\nmethod:post\nparams:\n{ \u0026#34;apiVersion\u0026#34;:\u0026#34;kubeocean.kubesphere.io/v1alpha1\u0026#34;, \u0026#34;kind\u0026#34;:\u0026#34;DolphinCluster\u0026#34;, \u0026#34;metadata\u0026#34;:{ \u0026#34;name\u0026#34;:\u0026#34;taoli-test\u0026#34;, \u0026#34;namespace\u0026#34;:\u0026#34;default\u0026#34; }, \u0026#34;spec\u0026#34;:{ \u0026#34;controlPlane\u0026#34;:[ { \u0026#34;name\u0026#34;:\u0026#34;master1-taoli-test\u0026#34;, \u0026#34;resources\u0026#34;:{ \u0026#34;requests\u0026#34;:{ \u0026#34;memory\u0026#34;:\u0026#34;1000Mi\u0026#34;, \u0026#34;cpu\u0026#34;:\u0026#34;250m\u0026#34; }, \u0026#34;limits\u0026#34;:{ \u0026#34;memory\u0026#34;:\u0026#34;2Gi\u0026#34;, \u0026#34;cpu\u0026#34;:\u0026#34;2\u0026#34; } } } ], \u0026#34;worker\u0026#34;:[ { \u0026#34;name\u0026#34;:\u0026#34;worker1-taoli-test\u0026#34;, \u0026#34;resources\u0026#34;:{ \u0026#34;requests\u0026#34;:{ \u0026#34;memory\u0026#34;:\u0026#34;100Mi\u0026#34;, \u0026#34;cpu\u0026#34;:\u0026#34;250m\u0026#34; }, \u0026#34;limits\u0026#34;:{ \u0026#34;memory\u0026#34;:\u0026#34;4Gi\u0026#34;, \u0026#34;cpu\u0026#34;:\u0026#34;4\u0026#34; } } } ], \u0026#34;externalDomain\u0026#34;:\u0026#34;139.198.112.218.nip.io\u0026#34;, \u0026#34;externalPort\u0026#34;:50443 } } resp:\n{ \u0026#34;metadata\u0026#34;:{ \u0026#34;name\u0026#34;:\u0026#34;taoli-test\u0026#34;, \u0026#34;namespace\u0026#34;:\u0026#34;default\u0026#34;, \u0026#34;uid\u0026#34;:\u0026#34;514fdc27-b4b9-4fc4-bc55-8235599ef0fb\u0026#34;, \u0026#34;resourceVersion\u0026#34;:\u0026#34;15324272\u0026#34;, \u0026#34;generation\u0026#34;:1, \u0026#34;creationTimestamp\u0026#34;:\u0026#34;2022-01-19T02:51:17Z\u0026#34;, \u0026#34;managedFields\u0026#34;:[ { \u0026#34;manager\u0026#34;:\u0026#34;ko-apiserver\u0026#34;, \u0026#34;operation\u0026#34;:\u0026#34;Update\u0026#34;, \u0026#34;apiVersion\u0026#34;:\u0026#34;kubeocean.kubesphere.io/v1alpha1\u0026#34;, \u0026#34;time\u0026#34;:\u0026#34;2022-01-19T02:51:17Z\u0026#34;, \u0026#34;fieldsType\u0026#34;:\u0026#34;FieldsV1\u0026#34;, \u0026#34;fieldsV1\u0026#34;:{ \u0026#34;f:spec\u0026#34;:{ \u0026#34;.\u0026#34;:{ }, \u0026#34;f:controlPlane\u0026#34;:{ }, \u0026#34;f:externalDomain\u0026#34;:{ }, \u0026#34;f:externalPort\u0026#34;:{ }, \u0026#34;f:worker\u0026#34;:{ } } } } ] }, \u0026#34;spec\u0026#34;:{ \u0026#34;controlPlane\u0026#34;:[ { \u0026#34;resources\u0026#34;:{ \u0026#34;limits\u0026#34;:{ \u0026#34;cpu\u0026#34;:\u0026#34;2\u0026#34;, \u0026#34;memory\u0026#34;:\u0026#34;2Gi\u0026#34; }, \u0026#34;requests\u0026#34;:{ \u0026#34;cpu\u0026#34;:\u0026#34;250m\u0026#34;, \u0026#34;memory\u0026#34;:\u0026#34;100Mi\u0026#34; } }, \u0026#34;name\u0026#34;:\u0026#34;master1-taoli-test\u0026#34; } ], \u0026#34;worker\u0026#34;:[ { \u0026#34;resources\u0026#34;:{ \u0026#34;limits\u0026#34;:{ \u0026#34;cpu\u0026#34;:\u0026#34;4\u0026#34;, \u0026#34;memory\u0026#34;:\u0026#34;4Gi\u0026#34; }, \u0026#34;requests\u0026#34;:{ \u0026#34;cpu\u0026#34;:\u0026#34;250m\u0026#34;, \u0026#34;memory\u0026#34;:\u0026#34;100Mi\u0026#34; } }, \u0026#34;name\u0026#34;:\u0026#34;worker1-taoli-test\u0026#34; } ], \u0026#34;externalDomain\u0026#34;:\u0026#34;139.198.112.218.nip.io\u0026#34;, \u0026#34;externalPort\u0026#34;:50443 }, \u0026#34;status\u0026#34;:{ \u0026#34;controlPlane\u0026#34;:{ }, \u0026#34;worker\u0026#34;:{ } } } ##删除cluster\npkg/cluster/handler/cluster.go DeleteCluster\nurl:http://139.198.112.218:31880/api/v1alpha1/cluster/default/c-1m5e231k/delete\nmethod:get\n##获取cluster列表\n指定cluster：pkg/cluster/handler/cluster.go GetCluster\ncluster列表：pkg/cluster/handler/cluster.go ListClusterForUser\nurl：http://139.198.112.218:31880/api/v1alpha1/clusters?page=1\nmethod：get\nresp:\n{ \u0026#34;metadata\u0026#34;:{ \u0026#34;resourceVersion\u0026#34;:\u0026#34;15320407\u0026#34; }, \u0026#34;items\u0026#34;:[ { \u0026#34;kind\u0026#34;:\u0026#34;DolphinCluster\u0026#34;, \u0026#34;apiVersion\u0026#34;:\u0026#34;kubeocean.kubesphere.io/v1alpha1\u0026#34;, \u0026#34;metadata\u0026#34;:{ \u0026#34;name\u0026#34;:\u0026#34;c-evp8lez6\u0026#34;, \u0026#34;namespace\u0026#34;:\u0026#34;default\u0026#34;, \u0026#34;uid\u0026#34;:\u0026#34;af9a6961-ebcf-488f-97d1-bf9c6ad1f88e\u0026#34;, \u0026#34;resourceVersion\u0026#34;:\u0026#34;13479085\u0026#34;, \u0026#34;generation\u0026#34;:1, \u0026#34;creationTimestamp\u0026#34;:\u0026#34;2022-01-12T00:52:48Z\u0026#34;, \u0026#34;managedFields\u0026#34;:[ { \u0026#34;manager\u0026#34;:\u0026#34;ko-apiserver\u0026#34;, \u0026#34;operation\u0026#34;:\u0026#34;Update\u0026#34;, \u0026#34;apiVersion\u0026#34;:\u0026#34;kubeocean.kubesphere.io/v1alpha1\u0026#34;, \u0026#34;time\u0026#34;:\u0026#34;2022-01-12T00:52:48Z\u0026#34;, \u0026#34;fieldsType\u0026#34;:\u0026#34;FieldsV1\u0026#34;, \u0026#34;fieldsV1\u0026#34;:{ \u0026#34;f:spec\u0026#34;:{ \u0026#34;.\u0026#34;:{ }, \u0026#34;f:controlPlane\u0026#34;:{ }, \u0026#34;f:externalDomain\u0026#34;:{ }, \u0026#34;f:externalPort\u0026#34;:{ }, \u0026#34;f:worker\u0026#34;:{ } } } }, { \u0026#34;manager\u0026#34;:\u0026#34;manager\u0026#34;, \u0026#34;operation\u0026#34;:\u0026#34;Update\u0026#34;, \u0026#34;apiVersion\u0026#34;:\u0026#34;kubeocean.kubesphere.io/v1alpha1\u0026#34;, \u0026#34;time\u0026#34;:\u0026#34;2022-01-12T00:52:48Z\u0026#34;, \u0026#34;fieldsType\u0026#34;:\u0026#34;FieldsV1\u0026#34;, \u0026#34;fieldsV1\u0026#34;:{ \u0026#34;f:status\u0026#34;:{ \u0026#34;.\u0026#34;:{ }, \u0026#34;f:controlPlane\u0026#34;:{ \u0026#34;.\u0026#34;:{ }, \u0026#34;f:nodes\u0026#34;:{ }, \u0026#34;f:size\u0026#34;:{ } }, \u0026#34;f:phase\u0026#34;:{ }, \u0026#34;f:worker\u0026#34;:{ \u0026#34;.\u0026#34;:{ }, \u0026#34;f:nodes\u0026#34;:{ } } } } } ] }, \u0026#34;spec\u0026#34;:{ \u0026#34;controlPlane\u0026#34;:[ { \u0026#34;resources\u0026#34;:{ \u0026#34;limits\u0026#34;:{ \u0026#34;cpu\u0026#34;:\u0026#34;2\u0026#34;, \u0026#34;memory\u0026#34;:\u0026#34;2Gi\u0026#34; }, \u0026#34;requests\u0026#34;:{ \u0026#34;cpu\u0026#34;:\u0026#34;250m\u0026#34;, \u0026#34;memory\u0026#34;:\u0026#34;100Mi\u0026#34; } }, \u0026#34;name\u0026#34;:\u0026#34;master1-c-evp8lez6\u0026#34; } ], \u0026#34;worker\u0026#34;:[ { \u0026#34;resources\u0026#34;:{ \u0026#34;limits\u0026#34;:{ \u0026#34;cpu\u0026#34;:\u0026#34;4\u0026#34;, \u0026#34;memory\u0026#34;:\u0026#34;4Gi\u0026#34; }, \u0026#34;requests\u0026#34;:{ \u0026#34;cpu\u0026#34;:\u0026#34;250m\u0026#34;, \u0026#34;memory\u0026#34;:\u0026#34;100Mi\u0026#34; } }, \u0026#34;name\u0026#34;:\u0026#34;worker1-c-evp8lez6\u0026#34; } ], \u0026#34;externalDomain\u0026#34;:\u0026#34;139.198.112.218.nip.io\u0026#34;, \u0026#34;externalPort\u0026#34;:50443 }, \u0026#34;status\u0026#34;:{ \u0026#34;controlPlane\u0026#34;:{ \u0026#34;size\u0026#34;:1, \u0026#34;nodes\u0026#34;:[ { \u0026#34;name\u0026#34;:\u0026#34;master1-c-evp8lez6\u0026#34;, \u0026#34;address\u0026#34;:\u0026#34;10.233.96.70\u0026#34;, \u0026#34;phase\u0026#34;:\u0026#34;Running\u0026#34;, \u0026#34;startTime\u0026#34;:\u0026#34;2022-01-12T00:52:52Z\u0026#34; } ] }, \u0026#34;worker\u0026#34;:{ \u0026#34;nodes\u0026#34;:[ { \u0026#34;name\u0026#34;:\u0026#34;worker1-c-evp8lez6\u0026#34;, \u0026#34;address\u0026#34;:\u0026#34;10.233.90.131\u0026#34;, \u0026#34;phase\u0026#34;:\u0026#34;Running\u0026#34;, \u0026#34;startTime\u0026#34;:\u0026#34;2022-01-12T00:52:53Z\u0026#34; } ] }, \u0026#34;phase\u0026#34;:\u0026#34;Running\u0026#34; } }, { \u0026#34;kind\u0026#34;:\u0026#34;DolphinCluster\u0026#34;, \u0026#34;apiVersion\u0026#34;:\u0026#34;kubeocean.kubesphere.io/v1alpha1\u0026#34;, \u0026#34;metadata\u0026#34;:{ \u0026#34;name\u0026#34;:\u0026#34;test\u0026#34;, \u0026#34;namespace\u0026#34;:\u0026#34;default\u0026#34;, \u0026#34;uid\u0026#34;:\u0026#34;0a7b26c8-0fb8-4b7a-92d9-1185f8ec4dc6\u0026#34;, \u0026#34;resourceVersion\u0026#34;:\u0026#34;13819565\u0026#34;, \u0026#34;generation\u0026#34;:1, \u0026#34;creationTimestamp\u0026#34;:\u0026#34;2022-01-13T08:13:38Z\u0026#34;, \u0026#34;managedFields\u0026#34;:[ { \u0026#34;manager\u0026#34;:\u0026#34;ko-apiserver\u0026#34;, \u0026#34;operation\u0026#34;:\u0026#34;Update\u0026#34;, \u0026#34;apiVersion\u0026#34;:\u0026#34;kubeocean.kubesphere.io/v1alpha1\u0026#34;, \u0026#34;time\u0026#34;:\u0026#34;2022-01-13T08:13:38Z\u0026#34;, \u0026#34;fieldsType\u0026#34;:\u0026#34;FieldsV1\u0026#34;, \u0026#34;fieldsV1\u0026#34;:{ \u0026#34;f:spec\u0026#34;:{ \u0026#34;.\u0026#34;:{ }, \u0026#34;f:controlPlane\u0026#34;:{ }, \u0026#34;f:externalDomain\u0026#34;:{ }, \u0026#34;f:externalPort\u0026#34;:{ }, \u0026#34;f:worker\u0026#34;:{ } } } }, { \u0026#34;manager\u0026#34;:\u0026#34;manager\u0026#34;, \u0026#34;operation\u0026#34;:\u0026#34;Update\u0026#34;, \u0026#34;apiVersion\u0026#34;:\u0026#34;kubeocean.kubesphere.io/v1alpha1\u0026#34;, \u0026#34;time\u0026#34;:\u0026#34;2022-01-13T08:13:38Z\u0026#34;, \u0026#34;fieldsType\u0026#34;:\u0026#34;FieldsV1\u0026#34;, \u0026#34;fieldsV1\u0026#34;:{ \u0026#34;f:status\u0026#34;:{ \u0026#34;.\u0026#34;:{ }, \u0026#34;f:controlPlane\u0026#34;:{ \u0026#34;.\u0026#34;:{ }, \u0026#34;f:nodes\u0026#34;:{ }, \u0026#34;f:size\u0026#34;:{ } }, \u0026#34;f:phase\u0026#34;:{ }, \u0026#34;f:worker\u0026#34;:{ \u0026#34;.\u0026#34;:{ }, \u0026#34;f:nodes\u0026#34;:{ } } } } } ] }, \u0026#34;spec\u0026#34;:{ \u0026#34;controlPlane\u0026#34;:[ { \u0026#34;resources\u0026#34;:{ \u0026#34;limits\u0026#34;:{ \u0026#34;cpu\u0026#34;:\u0026#34;2\u0026#34;, \u0026#34;memory\u0026#34;:\u0026#34;2Gi\u0026#34; }, \u0026#34;requests\u0026#34;:{ \u0026#34;cpu\u0026#34;:\u0026#34;250m\u0026#34;, \u0026#34;memory\u0026#34;:\u0026#34;100Mi\u0026#34; } }, \u0026#34;name\u0026#34;:\u0026#34;master1-test\u0026#34; } ], \u0026#34;worker\u0026#34;:[ { \u0026#34;resources\u0026#34;:{ \u0026#34;limits\u0026#34;:{ \u0026#34;cpu\u0026#34;:\u0026#34;4\u0026#34;, \u0026#34;memory\u0026#34;:\u0026#34;4Gi\u0026#34; }, \u0026#34;requests\u0026#34;:{ \u0026#34;cpu\u0026#34;:\u0026#34;250m\u0026#34;, \u0026#34;memory\u0026#34;:\u0026#34;100Mi\u0026#34; } }, \u0026#34;name\u0026#34;:\u0026#34;worker1-test\u0026#34; } ], \u0026#34;externalDomain\u0026#34;:\u0026#34;139.198.112.218.nip.io\u0026#34;, \u0026#34;externalPort\u0026#34;:50443 }, \u0026#34;status\u0026#34;:{ \u0026#34;controlPlane\u0026#34;:{ \u0026#34;size\u0026#34;:1, \u0026#34;nodes\u0026#34;:[ { \u0026#34;name\u0026#34;:\u0026#34;master1-test\u0026#34;, \u0026#34;address\u0026#34;:\u0026#34;10.233.96.78\u0026#34;, \u0026#34;phase\u0026#34;:\u0026#34;Running\u0026#34;, \u0026#34;startTime\u0026#34;:\u0026#34;2022-01-13T08:13:42Z\u0026#34; } ] }, \u0026#34;worker\u0026#34;:{ \u0026#34;nodes\u0026#34;:[ { \u0026#34;name\u0026#34;:\u0026#34;worker1-test\u0026#34;, \u0026#34;address\u0026#34;:\u0026#34;10.233.90.133\u0026#34;, \u0026#34;phase\u0026#34;:\u0026#34;Running\u0026#34;, \u0026#34;startTime\u0026#34;:\u0026#34;2022-01-13T08:13:43Z\u0026#34; } ] }, \u0026#34;phase\u0026#34;:\u0026#34;Running\u0026#34; } } ] } 获取cluster中所有的service 使用/users/{user_id}/clusters/{cluster_id}/services\t或者\t/users/{user_id}/clusterservices/{cluster_id}\nurl:http://139.198.112.218:31880/api/v1alpha1/cluster/default/test/services\nmethod:get resp:\n{ \u0026#34;metadata\u0026#34;:{ \u0026#34;resourceVersion\u0026#34;:\u0026#34;1385819\u0026#34; }, \u0026#34;items\u0026#34;:[ { \u0026#34;metadata\u0026#34;:{ \u0026#34;name\u0026#34;:\u0026#34;kubernetes\u0026#34;, \u0026#34;namespace\u0026#34;:\u0026#34;default\u0026#34;, \u0026#34;uid\u0026#34;:\u0026#34;85d2a8f2-b888-43d2-bd38-82d6b04199df\u0026#34;, \u0026#34;resourceVersion\u0026#34;:\u0026#34;198\u0026#34;, \u0026#34;creationTimestamp\u0026#34;:\u0026#34;2022-01-13T08:13:52Z\u0026#34;, \u0026#34;labels\u0026#34;:{ \u0026#34;component\u0026#34;:\u0026#34;apiserver\u0026#34;, \u0026#34;provider\u0026#34;:\u0026#34;kubernetes\u0026#34; }, \u0026#34;managedFields\u0026#34;:[ { \u0026#34;manager\u0026#34;:\u0026#34;k3s\u0026#34;, \u0026#34;operation\u0026#34;:\u0026#34;Update\u0026#34;, \u0026#34;apiVersion\u0026#34;:\u0026#34;v1\u0026#34;, \u0026#34;time\u0026#34;:\u0026#34;2022-01-13T08:13:52Z\u0026#34;, \u0026#34;fieldsType\u0026#34;:\u0026#34;FieldsV1\u0026#34;, \u0026#34;fieldsV1\u0026#34;:{ \u0026#34;f:metadata\u0026#34;:{ \u0026#34;f:labels\u0026#34;:{ \u0026#34;.\u0026#34;:{ }, \u0026#34;f:component\u0026#34;:{ }, \u0026#34;f:provider\u0026#34;:{ } } }, \u0026#34;f:spec\u0026#34;:{ \u0026#34;f:clusterIP\u0026#34;:{ }, \u0026#34;f:ipFamilyPolicy\u0026#34;:{ }, \u0026#34;f:ports\u0026#34;:{ \u0026#34;.\u0026#34;:{ }, \u0026#34;k:{\\\u0026#34;port\\\u0026#34;:443,\\\u0026#34;protocol\\\u0026#34;:\\\u0026#34;TCP\\\u0026#34;}\u0026#34;:{ \u0026#34;.\u0026#34;:{ }, \u0026#34;f:name\u0026#34;:{ }, \u0026#34;f:port\u0026#34;:{ }, \u0026#34;f:protocol\u0026#34;:{ }, \u0026#34;f:targetPort\u0026#34;:{ } } }, \u0026#34;f:sessionAffinity\u0026#34;:{ }, \u0026#34;f:type\u0026#34;:{ } } } } ] }, \u0026#34;spec\u0026#34;:{ \u0026#34;ports\u0026#34;:[ { \u0026#34;name\u0026#34;:\u0026#34;https\u0026#34;, \u0026#34;protocol\u0026#34;:\u0026#34;TCP\u0026#34;, \u0026#34;port\u0026#34;:443, \u0026#34;targetPort\u0026#34;:6443 } ], \u0026#34;clusterIP\u0026#34;:\u0026#34;10.43.0.1\u0026#34;, \u0026#34;clusterIPs\u0026#34;:[ \u0026#34;10.43.0.1\u0026#34; ], \u0026#34;type\u0026#34;:\u0026#34;ClusterIP\u0026#34;, \u0026#34;sessionAffinity\u0026#34;:\u0026#34;None\u0026#34;, \u0026#34;ipFamilies\u0026#34;:[ \u0026#34;IPv4\u0026#34; ], \u0026#34;ipFamilyPolicy\u0026#34;:\u0026#34;SingleStack\u0026#34; }, \u0026#34;status\u0026#34;:{ \u0026#34;loadBalancer\u0026#34;:{ } } }, { \u0026#34;metadata\u0026#34;:{ \u0026#34;name\u0026#34;:\u0026#34;nginx2\u0026#34;, \u0026#34;namespace\u0026#34;:\u0026#34;default\u0026#34;, \u0026#34;uid\u0026#34;:\u0026#34;78c9d726-b903-4892-a2b9-460a4761c0e2\u0026#34;, \u0026#34;resourceVersion\u0026#34;:\u0026#34;740\u0026#34;, \u0026#34;creationTimestamp\u0026#34;:\u0026#34;2022-01-13T08:15:33Z\u0026#34;, \u0026#34;annotations\u0026#34;:{ \u0026#34;kubectl.kubernetes.io/last-applied-configuration\u0026#34;:\u0026#34;{\\\u0026#34;apiVersion\\\u0026#34;:\\\u0026#34;v1\\\u0026#34;,\\\u0026#34;kind\\\u0026#34;:\\\u0026#34;Service\\\u0026#34;,\\\u0026#34;metadata\\\u0026#34;:{\\\u0026#34;annotations\\\u0026#34;:{},\\\u0026#34;name\\\u0026#34;:\\\u0026#34;nginx2\\\u0026#34;,\\\u0026#34;namespace\\\u0026#34;:\\\u0026#34;default\\\u0026#34;},\\\u0026#34;spec\\\u0026#34;:{\\\u0026#34;ports\\\u0026#34;:[{\\\u0026#34;nodePort\\\u0026#34;:30030,\\\u0026#34;port\\\u0026#34;:80,\\\u0026#34;protocol\\\u0026#34;:\\\u0026#34;TCP\\\u0026#34;,\\\u0026#34;targetPort\\\u0026#34;:80}],\\\u0026#34;selector\\\u0026#34;:{\\\u0026#34;app\\\u0026#34;:\\\u0026#34;nginx2\\\u0026#34;},\\\u0026#34;type\\\u0026#34;:\\\u0026#34;NodePort\\\u0026#34;}}\\n\u0026#34; }, \u0026#34;managedFields\u0026#34;:[ { \u0026#34;manager\u0026#34;:\u0026#34;kubectl-client-side-apply\u0026#34;, \u0026#34;operation\u0026#34;:\u0026#34;Update\u0026#34;, \u0026#34;apiVersion\u0026#34;:\u0026#34;v1\u0026#34;, \u0026#34;time\u0026#34;:\u0026#34;2022-01-13T08:15:33Z\u0026#34;, \u0026#34;fieldsType\u0026#34;:\u0026#34;FieldsV1\u0026#34;, \u0026#34;fieldsV1\u0026#34;:{ \u0026#34;f:metadata\u0026#34;:{ \u0026#34;f:annotations\u0026#34;:{ \u0026#34;.\u0026#34;:{ }, \u0026#34;f:kubectl.kubernetes.io/last-applied-configuration\u0026#34;:{ } } }, \u0026#34;f:spec\u0026#34;:{ \u0026#34;f:externalTrafficPolicy\u0026#34;:{ }, \u0026#34;f:ports\u0026#34;:{ \u0026#34;.\u0026#34;:{ }, \u0026#34;k:{\\\u0026#34;port\\\u0026#34;:80,\\\u0026#34;protocol\\\u0026#34;:\\\u0026#34;TCP\\\u0026#34;}\u0026#34;:{ \u0026#34;.\u0026#34;:{ }, \u0026#34;f:nodePort\u0026#34;:{ }, \u0026#34;f:port\u0026#34;:{ }, \u0026#34;f:protocol\u0026#34;:{ }, \u0026#34;f:targetPort\u0026#34;:{ } } }, \u0026#34;f:selector\u0026#34;:{ \u0026#34;.\u0026#34;:{ }, \u0026#34;f:app\u0026#34;:{ } }, \u0026#34;f:sessionAffinity\u0026#34;:{ }, \u0026#34;f:type\u0026#34;:{ } } } } ] }, \u0026#34;spec\u0026#34;:{ \u0026#34;ports\u0026#34;:[ { \u0026#34;protocol\u0026#34;:\u0026#34;TCP\u0026#34;, \u0026#34;port\u0026#34;:80, \u0026#34;targetPort\u0026#34;:80, \u0026#34;nodePort\u0026#34;:30030 } ], \u0026#34;selector\u0026#34;:{ \u0026#34;app\u0026#34;:\u0026#34;nginx2\u0026#34; }, \u0026#34;clusterIP\u0026#34;:\u0026#34;10.43.252.33\u0026#34;, \u0026#34;clusterIPs\u0026#34;:[ \u0026#34;10.43.252.33\u0026#34; ], \u0026#34;type\u0026#34;:\u0026#34;NodePort\u0026#34;, \u0026#34;sessionAffinity\u0026#34;:\u0026#34;None\u0026#34;, \u0026#34;externalTrafficPolicy\u0026#34;:\u0026#34;Cluster\u0026#34;, \u0026#34;ipFamilies\u0026#34;:[ \u0026#34;IPv4\u0026#34; ], \u0026#34;ipFamilyPolicy\u0026#34;:\u0026#34;SingleStack\u0026#34; }, \u0026#34;status\u0026#34;:{ \u0026#34;loadBalancer\u0026#34;:{ } } }, { \u0026#34;metadata\u0026#34;:{ \u0026#34;name\u0026#34;:\u0026#34;kube-dns\u0026#34;, \u0026#34;namespace\u0026#34;:\u0026#34;kube-system\u0026#34;, \u0026#34;uid\u0026#34;:\u0026#34;9a67e8e8-9f8d-422a-8dd2-8ac15ee57e6a\u0026#34;, \u0026#34;resourceVersion\u0026#34;:\u0026#34;287\u0026#34;, \u0026#34;creationTimestamp\u0026#34;:\u0026#34;2022-01-13T08:13:56Z\u0026#34;, \u0026#34;labels\u0026#34;:{ \u0026#34;k8s-app\u0026#34;:\u0026#34;kube-dns\u0026#34;, \u0026#34;kubernetes.io/cluster-service\u0026#34;:\u0026#34;true\u0026#34;, \u0026#34;kubernetes.io/name\u0026#34;:\u0026#34;CoreDNS\u0026#34;, \u0026#34;objectset.rio.cattle.io/hash\u0026#34;:\u0026#34;bce283298811743a0386ab510f2f67ef74240c57\u0026#34; }, \u0026#34;annotations\u0026#34;:{ \u0026#34;objectset.rio.cattle.io/applied\u0026#34;:\u0026#34;{\\\u0026#34;apiVersion\\\u0026#34;:\\\u0026#34;v1\\\u0026#34;,\\\u0026#34;kind\\\u0026#34;:\\\u0026#34;Service\\\u0026#34;,\\\u0026#34;metadata\\\u0026#34;:{\\\u0026#34;annotations\\\u0026#34;:{\\\u0026#34;objectset.rio.cattle.io/id\\\u0026#34;:\\\u0026#34;\\\u0026#34;,\\\u0026#34;objectset.rio.cattle.io/owner-gvk\\\u0026#34;:\\\u0026#34;k3s.cattle.io/v1, Kind=Addon\\\u0026#34;,\\\u0026#34;objectset.rio.cattle.io/owner-name\\\u0026#34;:\\\u0026#34;coredns\\\u0026#34;,\\\u0026#34;objectset.rio.cattle.io/owner-namespace\\\u0026#34;:\\\u0026#34;kube-system\\\u0026#34;,\\\u0026#34;prometheus.io/port\\\u0026#34;:\\\u0026#34;9153\\\u0026#34;,\\\u0026#34;prometheus.io/scrape\\\u0026#34;:\\\u0026#34;true\\\u0026#34;},\\\u0026#34;labels\\\u0026#34;:{\\\u0026#34;k8s-app\\\u0026#34;:\\\u0026#34;kube-dns\\\u0026#34;,\\\u0026#34;kubernetes.io/cluster-service\\\u0026#34;:\\\u0026#34;true\\\u0026#34;,\\\u0026#34;kubernetes.io/name\\\u0026#34;:\\\u0026#34;CoreDNS\\\u0026#34;,\\\u0026#34;objectset.rio.cattle.io/hash\\\u0026#34;:\\\u0026#34;bce283298811743a0386ab510f2f67ef74240c57\\\u0026#34;},\\\u0026#34;name\\\u0026#34;:\\\u0026#34;kube-dns\\\u0026#34;,\\\u0026#34;namespace\\\u0026#34;:\\\u0026#34;kube-system\\\u0026#34;},\\\u0026#34;spec\\\u0026#34;:{\\\u0026#34;clusterIP\\\u0026#34;:\\\u0026#34;10.43.0.10\\\u0026#34;,\\\u0026#34;ports\\\u0026#34;:[{\\\u0026#34;name\\\u0026#34;:\\\u0026#34;dns\\\u0026#34;,\\\u0026#34;port\\\u0026#34;:53,\\\u0026#34;protocol\\\u0026#34;:\\\u0026#34;UDP\\\u0026#34;},{\\\u0026#34;name\\\u0026#34;:\\\u0026#34;dns-tcp\\\u0026#34;,\\\u0026#34;port\\\u0026#34;:53,\\\u0026#34;protocol\\\u0026#34;:\\\u0026#34;TCP\\\u0026#34;},{\\\u0026#34;name\\\u0026#34;:\\\u0026#34;metrics\\\u0026#34;,\\\u0026#34;port\\\u0026#34;:9153,\\\u0026#34;protocol\\\u0026#34;:\\\u0026#34;TCP\\\u0026#34;}],\\\u0026#34;selector\\\u0026#34;:{\\\u0026#34;k8s-app\\\u0026#34;:\\\u0026#34;kube-dns\\\u0026#34;}}}\u0026#34;, \u0026#34;objectset.rio.cattle.io/id\u0026#34;:\u0026#34;\u0026#34;, \u0026#34;objectset.rio.cattle.io/owner-gvk\u0026#34;:\u0026#34;k3s.cattle.io/v1, Kind=Addon\u0026#34;, \u0026#34;objectset.rio.cattle.io/owner-name\u0026#34;:\u0026#34;coredns\u0026#34;, \u0026#34;objectset.rio.cattle.io/owner-namespace\u0026#34;:\u0026#34;kube-system\u0026#34;, \u0026#34;prometheus.io/port\u0026#34;:\u0026#34;9153\u0026#34;, \u0026#34;prometheus.io/scrape\u0026#34;:\u0026#34;true\u0026#34; }, \u0026#34;managedFields\u0026#34;:[ { \u0026#34;manager\u0026#34;:\u0026#34;k3s\u0026#34;, \u0026#34;operation\u0026#34;:\u0026#34;Update\u0026#34;, \u0026#34;apiVersion\u0026#34;:\u0026#34;v1\u0026#34;, \u0026#34;time\u0026#34;:\u0026#34;2022-01-13T08:13:56Z\u0026#34;, \u0026#34;fieldsType\u0026#34;:\u0026#34;FieldsV1\u0026#34;, \u0026#34;fieldsV1\u0026#34;:{ \u0026#34;f:metadata\u0026#34;:{ \u0026#34;f:annotations\u0026#34;:{ \u0026#34;.\u0026#34;:{ }, \u0026#34;f:objectset.rio.cattle.io/applied\u0026#34;:{ }, \u0026#34;f:objectset.rio.cattle.io/id\u0026#34;:{ }, \u0026#34;f:objectset.rio.cattle.io/owner-gvk\u0026#34;:{ }, \u0026#34;f:objectset.rio.cattle.io/owner-name\u0026#34;:{ }, \u0026#34;f:objectset.rio.cattle.io/owner-namespace\u0026#34;:{ }, \u0026#34;f:prometheus.io/port\u0026#34;:{ }, \u0026#34;f:prometheus.io/scrape\u0026#34;:{ } }, \u0026#34;f:labels\u0026#34;:{ \u0026#34;.\u0026#34;:{ }, \u0026#34;f:k8s-app\u0026#34;:{ }, \u0026#34;f:kubernetes.io/cluster-service\u0026#34;:{ }, \u0026#34;f:kubernetes.io/name\u0026#34;:{ }, \u0026#34;f:objectset.rio.cattle.io/hash\u0026#34;:{ } } }, \u0026#34;f:spec\u0026#34;:{ \u0026#34;f:clusterIP\u0026#34;:{ }, \u0026#34;f:ports\u0026#34;:{ \u0026#34;.\u0026#34;:{ }, \u0026#34;k:{\\\u0026#34;port\\\u0026#34;:53,\\\u0026#34;protocol\\\u0026#34;:\\\u0026#34;TCP\\\u0026#34;}\u0026#34;:{ \u0026#34;.\u0026#34;:{ }, \u0026#34;f:name\u0026#34;:{ }, \u0026#34;f:port\u0026#34;:{ }, \u0026#34;f:protocol\u0026#34;:{ }, \u0026#34;f:targetPort\u0026#34;:{ } }, \u0026#34;k:{\\\u0026#34;port\\\u0026#34;:53,\\\u0026#34;protocol\\\u0026#34;:\\\u0026#34;UDP\\\u0026#34;}\u0026#34;:{ \u0026#34;.\u0026#34;:{ }, \u0026#34;f:name\u0026#34;:{ }, \u0026#34;f:port\u0026#34;:{ }, \u0026#34;f:protocol\u0026#34;:{ }, \u0026#34;f:targetPort\u0026#34;:{ } }, \u0026#34;k:{\\\u0026#34;port\\\u0026#34;:9153,\\\u0026#34;protocol\\\u0026#34;:\\\u0026#34;TCP\\\u0026#34;}\u0026#34;:{ \u0026#34;.\u0026#34;:{ }, \u0026#34;f:name\u0026#34;:{ }, \u0026#34;f:port\u0026#34;:{ }, \u0026#34;f:protocol\u0026#34;:{ }, \u0026#34;f:targetPort\u0026#34;:{ } } }, \u0026#34;f:selector\u0026#34;:{ \u0026#34;.\u0026#34;:{ }, \u0026#34;f:k8s-app\u0026#34;:{ } }, \u0026#34;f:sessionAffinity\u0026#34;:{ }, \u0026#34;f:type\u0026#34;:{ } } } } ] }, \u0026#34;spec\u0026#34;:{ \u0026#34;ports\u0026#34;:[ { \u0026#34;name\u0026#34;:\u0026#34;dns\u0026#34;, \u0026#34;protocol\u0026#34;:\u0026#34;UDP\u0026#34;, \u0026#34;port\u0026#34;:53, \u0026#34;targetPort\u0026#34;:53 }, { \u0026#34;name\u0026#34;:\u0026#34;dns-tcp\u0026#34;, \u0026#34;protocol\u0026#34;:\u0026#34;TCP\u0026#34;, \u0026#34;port\u0026#34;:53, \u0026#34;targetPort\u0026#34;:53 }, { \u0026#34;name\u0026#34;:\u0026#34;metrics\u0026#34;, \u0026#34;protocol\u0026#34;:\u0026#34;TCP\u0026#34;, \u0026#34;port\u0026#34;:9153, \u0026#34;targetPort\u0026#34;:9153 } ], \u0026#34;selector\u0026#34;:{ \u0026#34;k8s-app\u0026#34;:\u0026#34;kube-dns\u0026#34; }, \u0026#34;clusterIP\u0026#34;:\u0026#34;10.43.0.10\u0026#34;, \u0026#34;clusterIPs\u0026#34;:[ \u0026#34;10.43.0.10\u0026#34; ], \u0026#34;type\u0026#34;:\u0026#34;ClusterIP\u0026#34;, \u0026#34;sessionAffinity\u0026#34;:\u0026#34;None\u0026#34;, \u0026#34;ipFamilies\u0026#34;:[ \u0026#34;IPv4\u0026#34; ], \u0026#34;ipFamilyPolicy\u0026#34;:\u0026#34;SingleStack\u0026#34; }, \u0026#34;status\u0026#34;:{ \u0026#34;loadBalancer\u0026#34;:{ } } } ] } 获取宿主集群的dolphinservices 使用/users/{user_id}/dolphinservices\nurl:http://139.198.112.218:31880/api/v1alpha1/dolphinservices\nmethod:get resp:\n{ \u0026#34;metadata\u0026#34;:{ \u0026#34;resourceVersion\u0026#34;:\u0026#34;15322249\u0026#34; }, \u0026#34;items\u0026#34;:[ { \u0026#34;kind\u0026#34;:\u0026#34;DolphinService\u0026#34;, \u0026#34;apiVersion\u0026#34;:\u0026#34;kubeocean.kubesphere.io/v1alpha1\u0026#34;, \u0026#34;metadata\u0026#34;:{ \u0026#34;name\u0026#34;:\u0026#34;nginx-30030-default\u0026#34;, \u0026#34;namespace\u0026#34;:\u0026#34;default\u0026#34;, \u0026#34;uid\u0026#34;:\u0026#34;342ae991-286c-4711-8a47-013105ad1f0c\u0026#34;, \u0026#34;resourceVersion\u0026#34;:\u0026#34;13479334\u0026#34;, \u0026#34;generation\u0026#34;:1, \u0026#34;creationTimestamp\u0026#34;:\u0026#34;2022-01-12T00:54:16Z\u0026#34;, \u0026#34;managedFields\u0026#34;:[ { \u0026#34;manager\u0026#34;:\u0026#34;ko-apiserver\u0026#34;, \u0026#34;operation\u0026#34;:\u0026#34;Update\u0026#34;, \u0026#34;apiVersion\u0026#34;:\u0026#34;kubeocean.kubesphere.io/v1alpha1\u0026#34;, \u0026#34;time\u0026#34;:\u0026#34;2022-01-12T00:54:16Z\u0026#34;, \u0026#34;fieldsType\u0026#34;:\u0026#34;FieldsV1\u0026#34;, \u0026#34;fieldsV1\u0026#34;:{ \u0026#34;f:spec\u0026#34;:{ \u0026#34;.\u0026#34;:{ }, \u0026#34;f:cluster\u0026#34;:{ }, \u0026#34;f:externalDomain\u0026#34;:{ }, \u0026#34;f:externalPort\u0026#34;:{ }, \u0026#34;f:ingressClassName\u0026#34;:{ }, \u0026#34;f:service\u0026#34;:{ \u0026#34;.\u0026#34;:{ }, \u0026#34;f:name\u0026#34;:{ }, \u0026#34;f:port\u0026#34;:{ \u0026#34;.\u0026#34;:{ }, \u0026#34;f:nodePort\u0026#34;:{ }, \u0026#34;f:protocol\u0026#34;:{ } } } } } }, { \u0026#34;manager\u0026#34;:\u0026#34;manager\u0026#34;, \u0026#34;operation\u0026#34;:\u0026#34;Update\u0026#34;, \u0026#34;apiVersion\u0026#34;:\u0026#34;kubeocean.kubesphere.io/v1alpha1\u0026#34;, \u0026#34;time\u0026#34;:\u0026#34;2022-01-12T00:54:16Z\u0026#34;, \u0026#34;fieldsType\u0026#34;:\u0026#34;FieldsV1\u0026#34;, \u0026#34;fieldsV1\u0026#34;:{ \u0026#34;f:status\u0026#34;:{ \u0026#34;.\u0026#34;:{ }, \u0026#34;f:host\u0026#34;:{ }, \u0026#34;f:ingress\u0026#34;:{ } } } } ] }, \u0026#34;spec\u0026#34;:{ \u0026#34;cluster\u0026#34;:\u0026#34;c-evp8lez6\u0026#34;, \u0026#34;service\u0026#34;:{ \u0026#34;name\u0026#34;:\u0026#34;nginx\u0026#34;, \u0026#34;port\u0026#34;:{ \u0026#34;protocol\u0026#34;:\u0026#34;TCP\u0026#34;, \u0026#34;nodePort\u0026#34;:30030 } }, \u0026#34;ingressClassName\u0026#34;:\u0026#34;nginx\u0026#34;, \u0026#34;externalDomain\u0026#34;:\u0026#34;139.198.112.218.nip.io\u0026#34;, \u0026#34;externalPort\u0026#34;:50080 }, \u0026#34;status\u0026#34;:{ \u0026#34;host\u0026#34;:\u0026#34;nginx-30030-c-evp8lez6.139.198.112.218.nip.io\u0026#34;, \u0026#34;ingress\u0026#34;:\u0026#34;nginx-30030-c-evp8lez6\u0026#34; } }, { \u0026#34;kind\u0026#34;:\u0026#34;DolphinService\u0026#34;, \u0026#34;apiVersion\u0026#34;:\u0026#34;kubeocean.kubesphere.io/v1alpha1\u0026#34;, \u0026#34;metadata\u0026#34;:{ \u0026#34;name\u0026#34;:\u0026#34;nginx2-30030-default\u0026#34;, \u0026#34;namespace\u0026#34;:\u0026#34;default\u0026#34;, \u0026#34;uid\u0026#34;:\u0026#34;79b0a561-7a59-4cd2-9043-89f44b4fde5e\u0026#34;, \u0026#34;resourceVersion\u0026#34;:\u0026#34;13820007\u0026#34;, \u0026#34;generation\u0026#34;:1, \u0026#34;creationTimestamp\u0026#34;:\u0026#34;2022-01-13T08:16:09Z\u0026#34;, \u0026#34;managedFields\u0026#34;:[ { \u0026#34;manager\u0026#34;:\u0026#34;ko-apiserver\u0026#34;, \u0026#34;operation\u0026#34;:\u0026#34;Update\u0026#34;, \u0026#34;apiVersion\u0026#34;:\u0026#34;kubeocean.kubesphere.io/v1alpha1\u0026#34;, \u0026#34;time\u0026#34;:\u0026#34;2022-01-13T08:16:09Z\u0026#34;, \u0026#34;fieldsType\u0026#34;:\u0026#34;FieldsV1\u0026#34;, \u0026#34;fieldsV1\u0026#34;:{ \u0026#34;f:spec\u0026#34;:{ \u0026#34;.\u0026#34;:{ }, \u0026#34;f:cluster\u0026#34;:{ }, \u0026#34;f:externalDomain\u0026#34;:{ }, \u0026#34;f:externalPort\u0026#34;:{ }, \u0026#34;f:ingressClassName\u0026#34;:{ }, \u0026#34;f:service\u0026#34;:{ \u0026#34;.\u0026#34;:{ }, \u0026#34;f:name\u0026#34;:{ }, \u0026#34;f:port\u0026#34;:{ \u0026#34;.\u0026#34;:{ }, \u0026#34;f:nodePort\u0026#34;:{ }, \u0026#34;f:protocol\u0026#34;:{ } } } } } }, { \u0026#34;manager\u0026#34;:\u0026#34;manager\u0026#34;, \u0026#34;operation\u0026#34;:\u0026#34;Update\u0026#34;, \u0026#34;apiVersion\u0026#34;:\u0026#34;kubeocean.kubesphere.io/v1alpha1\u0026#34;, \u0026#34;time\u0026#34;:\u0026#34;2022-01-13T08:16:09Z\u0026#34;, \u0026#34;fieldsType\u0026#34;:\u0026#34;FieldsV1\u0026#34;, \u0026#34;fieldsV1\u0026#34;:{ \u0026#34;f:status\u0026#34;:{ \u0026#34;.\u0026#34;:{ }, \u0026#34;f:host\u0026#34;:{ }, \u0026#34;f:ingress\u0026#34;:{ } } } } ] }, \u0026#34;spec\u0026#34;:{ \u0026#34;cluster\u0026#34;:\u0026#34;test\u0026#34;, \u0026#34;service\u0026#34;:{ \u0026#34;name\u0026#34;:\u0026#34;nginx2\u0026#34;, \u0026#34;port\u0026#34;:{ \u0026#34;protocol\u0026#34;:\u0026#34;TCP\u0026#34;, \u0026#34;nodePort\u0026#34;:30030 } }, \u0026#34;ingressClassName\u0026#34;:\u0026#34;nginx\u0026#34;, \u0026#34;externalDomain\u0026#34;:\u0026#34;139.198.112.218.nip.io\u0026#34;, \u0026#34;externalPort\u0026#34;:50080 }, \u0026#34;status\u0026#34;:{ \u0026#34;host\u0026#34;:\u0026#34;nginx2-30030-test.139.198.112.218.nip.io\u0026#34;, \u0026#34;ingress\u0026#34;:\u0026#34;nginx2-30030-test\u0026#34; } }, { \u0026#34;kind\u0026#34;:\u0026#34;DolphinService\u0026#34;, \u0026#34;apiVersion\u0026#34;:\u0026#34;kubeocean.kubesphere.io/v1alpha1\u0026#34;, \u0026#34;metadata\u0026#34;:{ \u0026#34;name\u0026#34;:\u0026#34;tomcat-30080-default\u0026#34;, \u0026#34;namespace\u0026#34;:\u0026#34;default\u0026#34;, \u0026#34;uid\u0026#34;:\u0026#34;9d128631-a000-440c-9278-0757af993835\u0026#34;, \u0026#34;resourceVersion\u0026#34;:\u0026#34;13480120\u0026#34;, \u0026#34;generation\u0026#34;:1, \u0026#34;creationTimestamp\u0026#34;:\u0026#34;2022-01-12T00:57:50Z\u0026#34;, \u0026#34;managedFields\u0026#34;:[ { \u0026#34;manager\u0026#34;:\u0026#34;ko-apiserver\u0026#34;, \u0026#34;operation\u0026#34;:\u0026#34;Update\u0026#34;, \u0026#34;apiVersion\u0026#34;:\u0026#34;kubeocean.kubesphere.io/v1alpha1\u0026#34;, \u0026#34;time\u0026#34;:\u0026#34;2022-01-12T00:57:50Z\u0026#34;, \u0026#34;fieldsType\u0026#34;:\u0026#34;FieldsV1\u0026#34;, \u0026#34;fieldsV1\u0026#34;:{ \u0026#34;f:spec\u0026#34;:{ \u0026#34;.\u0026#34;:{ }, \u0026#34;f:cluster\u0026#34;:{ }, \u0026#34;f:externalDomain\u0026#34;:{ }, \u0026#34;f:externalPort\u0026#34;:{ }, \u0026#34;f:ingressClassName\u0026#34;:{ }, \u0026#34;f:service\u0026#34;:{ \u0026#34;.\u0026#34;:{ }, \u0026#34;f:name\u0026#34;:{ }, \u0026#34;f:port\u0026#34;:{ \u0026#34;.\u0026#34;:{ }, \u0026#34;f:nodePort\u0026#34;:{ }, \u0026#34;f:protocol\u0026#34;:{ } } } } } }, { \u0026#34;manager\u0026#34;:\u0026#34;manager\u0026#34;, \u0026#34;operation\u0026#34;:\u0026#34;Update\u0026#34;, \u0026#34;apiVersion\u0026#34;:\u0026#34;kubeocean.kubesphere.io/v1alpha1\u0026#34;, \u0026#34;time\u0026#34;:\u0026#34;2022-01-12T00:57:50Z\u0026#34;, \u0026#34;fieldsType\u0026#34;:\u0026#34;FieldsV1\u0026#34;, \u0026#34;fieldsV1\u0026#34;:{ \u0026#34;f:status\u0026#34;:{ \u0026#34;.\u0026#34;:{ }, \u0026#34;f:host\u0026#34;:{ }, \u0026#34;f:ingress\u0026#34;:{ } } } } ] }, \u0026#34;spec\u0026#34;:{ \u0026#34;cluster\u0026#34;:\u0026#34;c-1m5e231k\u0026#34;, \u0026#34;service\u0026#34;:{ \u0026#34;name\u0026#34;:\u0026#34;tomcat\u0026#34;, \u0026#34;port\u0026#34;:{ \u0026#34;protocol\u0026#34;:\u0026#34;TCP\u0026#34;, \u0026#34;nodePort\u0026#34;:30080 } }, \u0026#34;ingressClassName\u0026#34;:\u0026#34;nginx\u0026#34;, \u0026#34;externalDomain\u0026#34;:\u0026#34;139.198.112.218.nip.io\u0026#34;, \u0026#34;externalPort\u0026#34;:50080 }, \u0026#34;status\u0026#34;:{ \u0026#34;host\u0026#34;:\u0026#34;tomcat-30080-c-1m5e231k.139.198.112.218.nip.io\u0026#34;, \u0026#34;ingress\u0026#34;:\u0026#34;tomcat-30080-c-1m5e231k\u0026#34; } }, { \u0026#34;kind\u0026#34;:\u0026#34;DolphinService\u0026#34;, \u0026#34;apiVersion\u0026#34;:\u0026#34;kubeocean.kubesphere.io/v1alpha1\u0026#34;, \u0026#34;metadata\u0026#34;:{ \u0026#34;name\u0026#34;:\u0026#34;demo-30256-kube-node-lease\u0026#34;, \u0026#34;namespace\u0026#34;:\u0026#34;kube-node-lease\u0026#34;, \u0026#34;uid\u0026#34;:\u0026#34;123fe18c-63a9-40c8-855f-351bec102f7c\u0026#34;, \u0026#34;resourceVersion\u0026#34;:\u0026#34;679110\u0026#34;, \u0026#34;generation\u0026#34;:1, \u0026#34;creationTimestamp\u0026#34;:\u0026#34;2021-10-10T10:01:10Z\u0026#34;, \u0026#34;managedFields\u0026#34;:[ { \u0026#34;manager\u0026#34;:\u0026#34;apiserver\u0026#34;, \u0026#34;operation\u0026#34;:\u0026#34;Update\u0026#34;, \u0026#34;apiVersion\u0026#34;:\u0026#34;kubeocean.kubesphere.io/v1alpha1\u0026#34;, \u0026#34;time\u0026#34;:\u0026#34;2021-10-10T10:01:10Z\u0026#34;, \u0026#34;fieldsType\u0026#34;:\u0026#34;FieldsV1\u0026#34;, \u0026#34;fieldsV1\u0026#34;:{ \u0026#34;f:spec\u0026#34;:{ \u0026#34;.\u0026#34;:{ }, \u0026#34;f:cluster\u0026#34;:{ }, \u0026#34;f:externalDomain\u0026#34;:{ }, \u0026#34;f:externalPort\u0026#34;:{ }, \u0026#34;f:ingressClassName\u0026#34;:{ }, \u0026#34;f:service\u0026#34;:{ \u0026#34;.\u0026#34;:{ }, \u0026#34;f:name\u0026#34;:{ }, \u0026#34;f:port\u0026#34;:{ \u0026#34;.\u0026#34;:{ }, \u0026#34;f:nodePort\u0026#34;:{ }, \u0026#34;f:protocol\u0026#34;:{ } } } } } }, { \u0026#34;manager\u0026#34;:\u0026#34;manager\u0026#34;, \u0026#34;operation\u0026#34;:\u0026#34;Update\u0026#34;, \u0026#34;apiVersion\u0026#34;:\u0026#34;kubeocean.kubesphere.io/v1alpha1\u0026#34;, \u0026#34;time\u0026#34;:\u0026#34;2021-10-10T10:01:10Z\u0026#34;, \u0026#34;fieldsType\u0026#34;:\u0026#34;FieldsV1\u0026#34;, \u0026#34;fieldsV1\u0026#34;:{ \u0026#34;f:status\u0026#34;:{ \u0026#34;.\u0026#34;:{ }, \u0026#34;f:host\u0026#34;:{ }, \u0026#34;f:ingress\u0026#34;:{ } } } } ] }, \u0026#34;spec\u0026#34;:{ \u0026#34;cluster\u0026#34;:\u0026#34;c-5f1htip0\u0026#34;, \u0026#34;service\u0026#34;:{ \u0026#34;name\u0026#34;:\u0026#34;demo\u0026#34;, \u0026#34;port\u0026#34;:{ \u0026#34;protocol\u0026#34;:\u0026#34;TCP\u0026#34;, \u0026#34;nodePort\u0026#34;:30256 } }, \u0026#34;ingressClassName\u0026#34;:\u0026#34;nginx\u0026#34;, \u0026#34;externalDomain\u0026#34;:\u0026#34;139.198.112.218.nip.io\u0026#34;, \u0026#34;externalPort\u0026#34;:50080 }, \u0026#34;status\u0026#34;:{ \u0026#34;host\u0026#34;:\u0026#34;demo-30256-c-5f1htip0.139.198.112.218.nip.io\u0026#34;, \u0026#34;ingress\u0026#34;:\u0026#34;demo-30256-c-5f1htip0\u0026#34; } }, { \u0026#34;kind\u0026#34;:\u0026#34;DolphinService\u0026#34;, \u0026#34;apiVersion\u0026#34;:\u0026#34;kubeocean.kubesphere.io/v1alpha1\u0026#34;, \u0026#34;metadata\u0026#34;:{ \u0026#34;name\u0026#34;:\u0026#34;demo-32752-default\u0026#34;, \u0026#34;namespace\u0026#34;:\u0026#34;kube-node-lease\u0026#34;, \u0026#34;uid\u0026#34;:\u0026#34;ccf1f362-831f-4299-8a39-8071d450779d\u0026#34;, \u0026#34;resourceVersion\u0026#34;:\u0026#34;687364\u0026#34;, \u0026#34;generation\u0026#34;:1, \u0026#34;creationTimestamp\u0026#34;:\u0026#34;2021-10-10T10:46:42Z\u0026#34;, \u0026#34;managedFields\u0026#34;:[ { \u0026#34;manager\u0026#34;:\u0026#34;apiserver\u0026#34;, \u0026#34;operation\u0026#34;:\u0026#34;Update\u0026#34;, \u0026#34;apiVersion\u0026#34;:\u0026#34;kubeocean.kubesphere.io/v1alpha1\u0026#34;, \u0026#34;time\u0026#34;:\u0026#34;2021-10-10T10:46:42Z\u0026#34;, \u0026#34;fieldsType\u0026#34;:\u0026#34;FieldsV1\u0026#34;, \u0026#34;fieldsV1\u0026#34;:{ \u0026#34;f:spec\u0026#34;:{ \u0026#34;.\u0026#34;:{ }, \u0026#34;f:cluster\u0026#34;:{ }, \u0026#34;f:externalDomain\u0026#34;:{ }, \u0026#34;f:externalPort\u0026#34;:{ }, \u0026#34;f:ingressClassName\u0026#34;:{ }, \u0026#34;f:service\u0026#34;:{ \u0026#34;.\u0026#34;:{ }, \u0026#34;f:name\u0026#34;:{ }, \u0026#34;f:port\u0026#34;:{ \u0026#34;.\u0026#34;:{ }, \u0026#34;f:nodePort\u0026#34;:{ }, \u0026#34;f:protocol\u0026#34;:{ } } } } } }, { \u0026#34;manager\u0026#34;:\u0026#34;manager\u0026#34;, \u0026#34;operation\u0026#34;:\u0026#34;Update\u0026#34;, \u0026#34;apiVersion\u0026#34;:\u0026#34;kubeocean.kubesphere.io/v1alpha1\u0026#34;, \u0026#34;time\u0026#34;:\u0026#34;2021-10-10T10:46:42Z\u0026#34;, \u0026#34;fieldsType\u0026#34;:\u0026#34;FieldsV1\u0026#34;, \u0026#34;fieldsV1\u0026#34;:{ \u0026#34;f:status\u0026#34;:{ \u0026#34;.\u0026#34;:{ }, \u0026#34;f:host\u0026#34;:{ }, \u0026#34;f:ingress\u0026#34;:{ } } } } ] }, \u0026#34;spec\u0026#34;:{ \u0026#34;cluster\u0026#34;:\u0026#34;c-5f1htip0\u0026#34;, \u0026#34;service\u0026#34;:{ \u0026#34;name\u0026#34;:\u0026#34;demo\u0026#34;, \u0026#34;port\u0026#34;:{ \u0026#34;protocol\u0026#34;:\u0026#34;TCP\u0026#34;, \u0026#34;nodePort\u0026#34;:32752 } }, \u0026#34;ingressClassName\u0026#34;:\u0026#34;nginx\u0026#34;, \u0026#34;externalDomain\u0026#34;:\u0026#34;139.198.112.218.nip.io\u0026#34;, \u0026#34;externalPort\u0026#34;:50080 }, \u0026#34;status\u0026#34;:{ \u0026#34;host\u0026#34;:\u0026#34;demo-32752-c-5f1htip0.139.198.112.218.nip.io\u0026#34;, \u0026#34;ingress\u0026#34;:\u0026#34;demo-32752-c-5f1htip0\u0026#34; } }, { \u0026#34;kind\u0026#34;:\u0026#34;DolphinService\u0026#34;, \u0026#34;apiVersion\u0026#34;:\u0026#34;kubeocean.kubesphere.io/v1alpha1\u0026#34;, \u0026#34;metadata\u0026#34;:{ \u0026#34;name\u0026#34;:\u0026#34;nginx-31834-kube-node-lease\u0026#34;, \u0026#34;namespace\u0026#34;:\u0026#34;kube-node-lease\u0026#34;, \u0026#34;uid\u0026#34;:\u0026#34;8fe933d2-5833-48fc-84ce-405c6c5ad11a\u0026#34;, \u0026#34;resourceVersion\u0026#34;:\u0026#34;673082\u0026#34;, \u0026#34;generation\u0026#34;:1, \u0026#34;creationTimestamp\u0026#34;:\u0026#34;2021-10-10T09:27:58Z\u0026#34;, \u0026#34;managedFields\u0026#34;:[ { \u0026#34;manager\u0026#34;:\u0026#34;apiserver\u0026#34;, \u0026#34;operation\u0026#34;:\u0026#34;Update\u0026#34;, \u0026#34;apiVersion\u0026#34;:\u0026#34;kubeocean.kubesphere.io/v1alpha1\u0026#34;, \u0026#34;time\u0026#34;:\u0026#34;2021-10-10T09:27:58Z\u0026#34;, \u0026#34;fieldsType\u0026#34;:\u0026#34;FieldsV1\u0026#34;, \u0026#34;fieldsV1\u0026#34;:{ \u0026#34;f:spec\u0026#34;:{ \u0026#34;.\u0026#34;:{ }, \u0026#34;f:cluster\u0026#34;:{ }, \u0026#34;f:externalDomain\u0026#34;:{ }, \u0026#34;f:externalPort\u0026#34;:{ }, \u0026#34;f:ingressClassName\u0026#34;:{ }, \u0026#34;f:service\u0026#34;:{ \u0026#34;.\u0026#34;:{ }, \u0026#34;f:name\u0026#34;:{ }, \u0026#34;f:port\u0026#34;:{ \u0026#34;.\u0026#34;:{ }, \u0026#34;f:nodePort\u0026#34;:{ }, \u0026#34;f:protocol\u0026#34;:{ } } } } } }, { \u0026#34;manager\u0026#34;:\u0026#34;manager\u0026#34;, \u0026#34;operation\u0026#34;:\u0026#34;Update\u0026#34;, \u0026#34;apiVersion\u0026#34;:\u0026#34;kubeocean.kubesphere.io/v1alpha1\u0026#34;, \u0026#34;time\u0026#34;:\u0026#34;2021-10-10T09:27:58Z\u0026#34;, \u0026#34;fieldsType\u0026#34;:\u0026#34;FieldsV1\u0026#34;, \u0026#34;fieldsV1\u0026#34;:{ \u0026#34;f:status\u0026#34;:{ \u0026#34;.\u0026#34;:{ }, \u0026#34;f:host\u0026#34;:{ }, \u0026#34;f:ingress\u0026#34;:{ } } } } ] }, \u0026#34;spec\u0026#34;:{ \u0026#34;cluster\u0026#34;:\u0026#34;c-5f1htip0\u0026#34;, \u0026#34;service\u0026#34;:{ \u0026#34;name\u0026#34;:\u0026#34;nginx\u0026#34;, \u0026#34;port\u0026#34;:{ \u0026#34;protocol\u0026#34;:\u0026#34;TCP\u0026#34;, \u0026#34;nodePort\u0026#34;:31834 } }, \u0026#34;ingressClassName\u0026#34;:\u0026#34;nginx\u0026#34;, \u0026#34;externalDomain\u0026#34;:\u0026#34;139.198.112.218.nip.io\u0026#34;, \u0026#34;externalPort\u0026#34;:50080 }, \u0026#34;status\u0026#34;:{ \u0026#34;host\u0026#34;:\u0026#34;nginx-31834-c-5f1htip0.139.198.112.218.nip.io\u0026#34;, \u0026#34;ingress\u0026#34;:\u0026#34;nginx-31834-c-5f1htip0\u0026#34; } }, { \u0026#34;kind\u0026#34;:\u0026#34;DolphinService\u0026#34;, \u0026#34;apiVersion\u0026#34;:\u0026#34;kubeocean.kubesphere.io/v1alpha1\u0026#34;, \u0026#34;metadata\u0026#34;:{ \u0026#34;name\u0026#34;:\u0026#34;test-30815-kube-node-lease\u0026#34;, \u0026#34;namespace\u0026#34;:\u0026#34;kube-node-lease\u0026#34;, \u0026#34;uid\u0026#34;:\u0026#34;83040bea-c9e2-4d6b-9294-bbd70b9201e7\u0026#34;, \u0026#34;resourceVersion\u0026#34;:\u0026#34;674565\u0026#34;, \u0026#34;generation\u0026#34;:1, \u0026#34;creationTimestamp\u0026#34;:\u0026#34;2021-10-10T09:36:07Z\u0026#34;, \u0026#34;managedFields\u0026#34;:[ { \u0026#34;manager\u0026#34;:\u0026#34;apiserver\u0026#34;, \u0026#34;operation\u0026#34;:\u0026#34;Update\u0026#34;, \u0026#34;apiVersion\u0026#34;:\u0026#34;kubeocean.kubesphere.io/v1alpha1\u0026#34;, \u0026#34;time\u0026#34;:\u0026#34;2021-10-10T09:36:07Z\u0026#34;, \u0026#34;fieldsType\u0026#34;:\u0026#34;FieldsV1\u0026#34;, \u0026#34;fieldsV1\u0026#34;:{ \u0026#34;f:spec\u0026#34;:{ \u0026#34;.\u0026#34;:{ }, \u0026#34;f:cluster\u0026#34;:{ }, \u0026#34;f:externalDomain\u0026#34;:{ }, \u0026#34;f:externalPort\u0026#34;:{ }, \u0026#34;f:ingressClassName\u0026#34;:{ }, \u0026#34;f:service\u0026#34;:{ \u0026#34;.\u0026#34;:{ }, \u0026#34;f:name\u0026#34;:{ }, \u0026#34;f:port\u0026#34;:{ \u0026#34;.\u0026#34;:{ }, \u0026#34;f:nodePort\u0026#34;:{ }, \u0026#34;f:protocol\u0026#34;:{ } } } } } }, { \u0026#34;manager\u0026#34;:\u0026#34;manager\u0026#34;, \u0026#34;operation\u0026#34;:\u0026#34;Update\u0026#34;, \u0026#34;apiVersion\u0026#34;:\u0026#34;kubeocean.kubesphere.io/v1alpha1\u0026#34;, \u0026#34;time\u0026#34;:\u0026#34;2021-10-10T09:36:07Z\u0026#34;, \u0026#34;fieldsType\u0026#34;:\u0026#34;FieldsV1\u0026#34;, \u0026#34;fieldsV1\u0026#34;:{ \u0026#34;f:status\u0026#34;:{ \u0026#34;.\u0026#34;:{ }, \u0026#34;f:host\u0026#34;:{ }, \u0026#34;f:ingress\u0026#34;:{ } } } } ] }, \u0026#34;spec\u0026#34;:{ \u0026#34;cluster\u0026#34;:\u0026#34;c-5f1htip0\u0026#34;, \u0026#34;service\u0026#34;:{ \u0026#34;name\u0026#34;:\u0026#34;test\u0026#34;, \u0026#34;port\u0026#34;:{ \u0026#34;protocol\u0026#34;:\u0026#34;TCP\u0026#34;, \u0026#34;nodePort\u0026#34;:30815 } }, \u0026#34;ingressClassName\u0026#34;:\u0026#34;nginx\u0026#34;, \u0026#34;externalDomain\u0026#34;:\u0026#34;139.198.112.218.nip.io\u0026#34;, \u0026#34;externalPort\u0026#34;:50080 }, \u0026#34;status\u0026#34;:{ \u0026#34;host\u0026#34;:\u0026#34;test-30815-c-5f1htip0.139.198.112.218.nip.io\u0026#34;, \u0026#34;ingress\u0026#34;:\u0026#34;test-30815-c-5f1htip0\u0026#34; } } ] } 创建宿主集群dolphinservices url：http://139.198.112.218:31880/api/v1alpha1/cluster/default/taoli-test/dolphinservices\nmethod：post\nparam:\n{ \u0026#34;apiVersion\u0026#34;:\u0026#34;kubeocean.kubesphere.io/v1alpha1\u0026#34;, \u0026#34;kind\u0026#34;:\u0026#34;DolphinService\u0026#34;, \u0026#34;metadata\u0026#34;:{ \u0026#34;name\u0026#34;:\u0026#34;k3d-nginx-service-lb-32589-default\u0026#34;, \u0026#34;namespace\u0026#34;:\u0026#34;default\u0026#34; }, \u0026#34;spec\u0026#34;:{ \u0026#34;cluster\u0026#34;:\u0026#34;taoli-test\u0026#34;, \u0026#34;service\u0026#34;:{ \u0026#34;name\u0026#34;:\u0026#34;k3d-nginx-service-lb\u0026#34;, \u0026#34;port\u0026#34;:{ \u0026#34;protocol\u0026#34;:\u0026#34;TCP\u0026#34;, \u0026#34;nodePort\u0026#34;:32589, \u0026#34;enableTLS\u0026#34;:false } }, \u0026#34;ingressClassName\u0026#34;:\u0026#34;nginx\u0026#34;, \u0026#34;externalDomain\u0026#34;:\u0026#34;139.198.112.218.nip.io\u0026#34;, \u0026#34;externalPort\u0026#34;:50080 } } resp:\n{ \u0026#34;metadata\u0026#34;:{ \u0026#34;name\u0026#34;:\u0026#34;k3d-nginx-service-lb-32589-default\u0026#34;, \u0026#34;namespace\u0026#34;:\u0026#34;default\u0026#34;, \u0026#34;uid\u0026#34;:\u0026#34;7cca489e-a3d9-44ca-8383-14a157e413f9\u0026#34;, \u0026#34;resourceVersion\u0026#34;:\u0026#34;15358572\u0026#34;, \u0026#34;generation\u0026#34;:1, \u0026#34;creationTimestamp\u0026#34;:\u0026#34;2022-01-19T06:00:24Z\u0026#34;, \u0026#34;managedFields\u0026#34;:[ { \u0026#34;manager\u0026#34;:\u0026#34;ko-apiserver\u0026#34;, \u0026#34;operation\u0026#34;:\u0026#34;Update\u0026#34;, \u0026#34;apiVersion\u0026#34;:\u0026#34;kubeocean.kubesphere.io/v1alpha1\u0026#34;, \u0026#34;time\u0026#34;:\u0026#34;2022-01-19T06:00:24Z\u0026#34;, \u0026#34;fieldsType\u0026#34;:\u0026#34;FieldsV1\u0026#34;, \u0026#34;fieldsV1\u0026#34;:{ \u0026#34;f:spec\u0026#34;:{ \u0026#34;.\u0026#34;:{ }, \u0026#34;f:cluster\u0026#34;:{ }, \u0026#34;f:externalDomain\u0026#34;:{ }, \u0026#34;f:externalPort\u0026#34;:{ }, \u0026#34;f:ingressClassName\u0026#34;:{ }, \u0026#34;f:service\u0026#34;:{ \u0026#34;.\u0026#34;:{ }, \u0026#34;f:name\u0026#34;:{ }, \u0026#34;f:port\u0026#34;:{ \u0026#34;.\u0026#34;:{ }, \u0026#34;f:nodePort\u0026#34;:{ }, \u0026#34;f:protocol\u0026#34;:{ } } } } } } ] }, \u0026#34;spec\u0026#34;:{ \u0026#34;cluster\u0026#34;:\u0026#34;taoli-test\u0026#34;, \u0026#34;service\u0026#34;:{ \u0026#34;name\u0026#34;:\u0026#34;k3d-nginx-service-lb\u0026#34;, \u0026#34;port\u0026#34;:{ \u0026#34;protocol\u0026#34;:\u0026#34;TCP\u0026#34;, \u0026#34;nodePort\u0026#34;:32589 } }, \u0026#34;ingressClassName\u0026#34;:\u0026#34;nginx\u0026#34;, \u0026#34;externalDomain\u0026#34;:\u0026#34;139.198.112.218.nip.io\u0026#34;, \u0026#34;externalPort\u0026#34;:50080 }, \u0026#34;status\u0026#34;:{ } } 获取kubeconfig url:http://139.198.112.218:31880/api/v1alpha1/cluster/default/taoli-test/kubeconfig\nmethod: get\nresp:\n{ \u0026#34;stdout\u0026#34;:\u0026#34;apiVersion: v1\\nclusters:\\n- cluster:\\n certificate-authority-data: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUJkekNDQVIyZ0F3SUJBZ0lCQURBS0JnZ3Foa2pPUFFRREFqQWpNU0V3SHdZRFZRUUREQmhyTTNNdGMyVnkKZG1WeUxXTmhRREUyTkRJMU5qQTJPRE13SGhjTk1qSXdNVEU1TURJMU1USXpXaGNOTXpJd01URTNNREkxTVRJegpXakFqTVNFd0h3WURWUVFEREJock0zTXRjMlZ5ZG1WeUxXTmhRREUyTkRJMU5qQTJPRE13V1RBVEJnY3Foa2pPClBRSUJCZ2dxaGtqT1BRTUJCd05DQUFST28xcnJ5RE91eC9DTFNzdW5rUXBsbCtOaWNhZm9BMHlVNHV2cWtrQzEKazlqYzZLTml2dWVsRTFodWRDTU4vMDZDVWZ6ZUF4K1l6QnhXSVNsV0xDSWdvMEl3UURBT0JnTlZIUThCQWY4RQpCQU1DQXFRd0R3WURWUjBUQVFIL0JBVXdBd0VCL3pBZEJnTlZIUTRFRmdRVThLdkNnYm9ycitsRHlqVHJvdGc1CitmeVpxdUl3Q2dZSUtvWkl6ajBFQXdJRFNBQXdSUUlnTXF3NXVJd1lGQ05PcFcrczlzbjhJL0xseVRlOWEwRU0KUFNQbUt2RzdhV1lDSVFEM2NPQURxSkw4czBFNSsrMW4rdG4vclYzZTZrZytVaTdaQjl2Y2JRTlZKUT09Ci0tLS0tRU5EIENFUlRJRklDQVRFLS0tLS0K\\n server: https://apiserver-taoli-test-default.139.198.112.218.nip.io:50443\\n name: default\\ncontexts:\\n- context:\\n cluster: default\\n user: default\\n name: default\\ncurrent-context: default\\nkind: Config\\npreferences: {}\\nusers:\\n- name: default\\n user:\\n client-certificate-data: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUJrVENDQVRlZ0F3SUJBZ0lJWmJQTzBUaHcxcmN3Q2dZSUtvWkl6ajBFQXdJd0l6RWhNQjhHQTFVRUF3d1kKYXpOekxXTnNhV1Z1ZEMxallVQXhOalF5TlRZd05qZ3pNQjRYRFRJeU1ERXhPVEF5TlRFeU0xb1hEVEl6TURFeApPVEF5TlRFeU0xb3dNREVYTUJVR0ExVUVDaE1PYzNsemRHVnRPbTFoYzNSbGNuTXhGVEFUQmdOVkJBTVRESE41CmMzUmxiVHBoWkcxcGJqQlpNQk1HQnlxR1NNNDlBZ0VHQ0NxR1NNNDlBd0VIQTBJQUJDOE9kZlJjMWdhVzNDbXEKQ2pqZkRCTnk4RjNWenhPbmpBUFJPUXdoQ28wa0o2S2IwMFE0N0xTeWk4S2lscTdhaDQ1TCtvWGx0bUJSejNsQQo2REE5cDlXalNEQkdNQTRHQTFVZER3RUIvd1FFQXdJRm9EQVRCZ05WSFNVRUREQUtCZ2dyQmdFRkJRY0RBakFmCkJnTlZIU01FR0RBV2dCUWdwanQ2Vlc1ZVBneHNvbTRKMDFmQWNLNERuekFLQmdncWhrak9QUVFEQWdOSUFEQkYKQWlFQThKWGtqeE5NT1ROeUQrMkhiY3BNc041OGtpdUFHYVFrQUYvaVppOXRwN01DSUhCWndYZmlIbURNMFVUQwpkZ3lmSjIrMVZsdUhRSFlnZVFlcHZrbmlBaVFLCi0tLS0tRU5EIENFUlRJRklDQVRFLS0tLS0KLS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUJlRENDQVIyZ0F3SUJBZ0lCQURBS0JnZ3Foa2pPUFFRREFqQWpNU0V3SHdZRFZRUUREQmhyTTNNdFkyeHAKWlc1MExXTmhRREUyTkRJMU5qQTJPRE13SGhjTk1qSXdNVEU1TURJMU1USXpXaGNOTXpJd01URTNNREkxTVRJegpXakFqTVNFd0h3WURWUVFEREJock0zTXRZMnhwWlc1MExXTmhRREUyTkRJMU5qQTJPRE13V1RBVEJnY3Foa2pPClBRSUJCZ2dxaGtqT1BRTUJCd05DQUFTZ0FPRWRSVDhoU2dqQk0vQWt2KzFmMXNuczI5alVhT0dFbXg1VFdDbXIKVDhXSHlvQUNxSjZ5Z2I3d3N0R0kxak8zZE1Ea2FoV1l2UnM0L1Q4SU1IVUlvMEl3UURBT0JnTlZIUThCQWY4RQpCQU1DQXFRd0R3WURWUjBUQVFIL0JBVXdBd0VCL3pBZEJnTlZIUTRFRmdRVUlLWTdlbFZ1WGo0TWJLSnVDZE5YCndIQ3VBNTh3Q2dZSUtvWkl6ajBFQXdJRFNRQXdSZ0loQU5XUkRsdTVLbWp3QnNnazJJdnRjdCtDQ3dhejJ3Qm0KVkJkYzlpcHdYV0kvQWlFQTJHYjlSSmZqZmRYSFhNSDhzd0Q1WDArcTY3VU5TMVllall0UHM1V1pqSDg9Ci0tLS0tRU5EIENFUlRJRklDQVRFLS0tLS0K\\n client-key-data: LS0tLS1CRUdJTiBFQyBQUklWQVRFIEtFWS0tLS0tCk1IY0NBUUVFSUNYR0ZIOEZ2ZHdKU1VzUnVyZHhYSXBMN2lSUEMrRXlzQnFGemk2YUkrTHZvQW9HQ0NxR1NNNDkKQXdFSG9VUURRZ0FFTHc1MTlGeldCcGJjS2FvS09OOE1FM0x3WGRYUEU2ZU1BOUU1RENFS2pTUW5vcHZUUkRqcwp0TEtMd3FLV3J0cUhqa3Y2aGVXMllGSFBlVURvTUQybjFRPT0KLS0tLS1FTkQgRUMgUFJJVkFURSBLRVktLS0tLQo=\\n\u0026#34; } ","permalink":"https://moyuduo.github.io/posts/ko_api/","summary":"获取namespace: url:http://139.198.112.218:31880/api/v1alpha1/namespaces method:get\nresp:\n{ \u0026#34;metadata\u0026#34;:{ \u0026#34;resourceVersion\u0026#34;:\u0026#34;15319237\u0026#34; }, \u0026#34;items\u0026#34;:[ { \u0026#34;metadata\u0026#34;:{ \u0026#34;name\u0026#34;:\u0026#34;default\u0026#34;, \u0026#34;uid\u0026#34;:\u0026#34;e3c6a8af-9d8a-412e-bca9-893635d545a6\u0026#34;, \u0026#34;resourceVersion\u0026#34;:\u0026#34;205\u0026#34;, \u0026#34;creationTimestamp\u0026#34;:\u0026#34;2021-10-07T04:16:49Z\u0026#34;, \u0026#34;labels\u0026#34;:{ \u0026#34;kubernetes.io/metadata.name\u0026#34;:\u0026#34;default\u0026#34; }, \u0026#34;managedFields\u0026#34;:[ { \u0026#34;manager\u0026#34;:\u0026#34;kube-apiserver\u0026#34;, \u0026#34;operation\u0026#34;:\u0026#34;Update\u0026#34;, \u0026#34;apiVersion\u0026#34;:\u0026#34;v1\u0026#34;, \u0026#34;time\u0026#34;:\u0026#34;2021-10-07T04:16:49Z\u0026#34;, \u0026#34;fieldsType\u0026#34;:\u0026#34;FieldsV1\u0026#34;, \u0026#34;fieldsV1\u0026#34;:{ \u0026#34;f:metadata\u0026#34;:{ \u0026#34;f:labels\u0026#34;:{ \u0026#34;.\u0026#34;:{ }, \u0026#34;f:kubernetes.io/metadata.name\u0026#34;:{ } } } } } ] }, \u0026#34;spec\u0026#34;:{ \u0026#34;finalizers\u0026#34;:[ \u0026#34;kubernetes\u0026#34; ] }, \u0026#34;status\u0026#34;:{ \u0026#34;phase\u0026#34;:\u0026#34;Active\u0026#34; } }, { \u0026#34;metadata\u0026#34;:{ \u0026#34;name\u0026#34;:\u0026#34;ingress-nginx\u0026#34;, \u0026#34;uid\u0026#34;:\u0026#34;db2263b3-992c-4aeb-99c8-3de1b66a91d9\u0026#34;, \u0026#34;resourceVersion\u0026#34;:\u0026#34;5156\u0026#34;, \u0026#34;creationTimestamp\u0026#34;:\u0026#34;2021-10-07T04:48:20Z\u0026#34;, \u0026#34;labels\u0026#34;:{ \u0026#34;app.kubernetes.io/instance\u0026#34;:\u0026#34;ingress-nginx\u0026#34;, \u0026#34;app.kubernetes.io/name\u0026#34;:\u0026#34;ingress-nginx\u0026#34;, \u0026#34;kubernetes.io/metadata.name\u0026#34;:\u0026#34;ingress-nginx\u0026#34; }, \u0026#34;annotations\u0026#34;:{ \u0026#34;kubectl.kubernetes.io/last-applied-configuration\u0026#34;:\u0026#34;{\\\u0026#34;apiVersion\\\u0026#34;:\\\u0026#34;v1\\\u0026#34;,\\\u0026#34;kind\\\u0026#34;:\\\u0026#34;Namespace\\\u0026#34;,\\\u0026#34;metadata\\\u0026#34;:{\\\u0026#34;annotations\\\u0026#34;:{},\\\u0026#34;labels\\\u0026#34;:{\\\u0026#34;app.kubernetes.io/instance\\\u0026#34;:\\\u0026#34;ingress-nginx\\\u0026#34;,\\\u0026#34;app.kubernetes.io/name\\\u0026#34;:\\\u0026#34;ingress-nginx\\\u0026#34;},\\\u0026#34;name\\\u0026#34;:\\\u0026#34;ingress-nginx\\\u0026#34;}}\\n\u0026#34; }, \u0026#34;managedFields\u0026#34;:[ { \u0026#34;manager\u0026#34;:\u0026#34;kubectl-client-side-apply\u0026#34;, \u0026#34;operation\u0026#34;:\u0026#34;Update\u0026#34;, \u0026#34;apiVersion\u0026#34;:\u0026#34;v1\u0026#34;, \u0026#34;time\u0026#34;:\u0026#34;2021-10-07T04:48:20Z\u0026#34;, \u0026#34;fieldsType\u0026#34;:\u0026#34;FieldsV1\u0026#34;, \u0026#34;fieldsV1\u0026#34;:{ \u0026#34;f:metadata\u0026#34;:{ \u0026#34;f:annotations\u0026#34;:{ \u0026#34;.","title":"ko_api"},{"content":"kubebuilder kubebuilder 是用于使用自定义资源(CRD)构建 kubernetes api 的框架，可以大大的提高开发人员的开发速度降低复杂性，以便快速的在 Go 中构建和发布 kubernetes api。kubebuilder 通过 Operator模式来定义自定义资源和发布 kubernetes api。\nResource + Controller = Operator\n架构： 安装：\n安装 curl -L -o kubebuilder https://go.kubebuilder.io/dl/latest/$(go env GOOS)/$(go env GOARCH) chmod +x kubebuilder \u0026amp;\u0026amp; mv kubebuilder /usr/local/bin/ 创建项目 mkdir operator-project cd operator-project go mod init operator-project kubebuilder init --domain qingcloud.com 创建 api kubebuilder edit --multigroup=true kubebuilder create api --group webapp --version v1 --kind GuestBook 目录结构 [root@centos72 guestbook1]# tree . ├── apis │ └── webapp │ └── v1 │ ├── groupversion_info.go │ ├── guestbook_types.go │ └── zz_generated.deepcopy.go ├── bin │ └── controller-gen ├── config │ ├── crd │ │ ├── kustomization.yaml │ │ ├── kustomizeconfig.yaml │ │ └── patches │ │ ├── cainjection_in_guestbooks.yaml │ │ └── webhook_in_guestbooks.yaml │ ├── default │ │ ├── kustomization.yaml │ │ ├── manager_auth_proxy_patch.yaml │ │ └── manager_config_patch.yaml │ ├── manager │ │ ├── controller_manager_config.yaml │ │ ├── kustomization.yaml │ │ └── manager.yaml │ ├── prometheus │ │ ├── kustomization.yaml │ │ └── monitor.yaml │ ├── rbac │ │ ├── auth_proxy_client_clusterrole.yaml │ │ ├── auth_proxy_role_binding.yaml │ │ ├── auth_proxy_role.yaml │ │ ├── auth_proxy_service.yaml │ │ ├── guestbook_editor_role.yaml │ │ ├── guestbook_viewer_role.yaml │ │ ├── kustomization.yaml │ │ ├── leader_election_role_binding.yaml │ │ ├── leader_election_role.yaml │ │ ├── role_binding.yaml │ │ └── service_account.yaml │ └── samples │ └── webapp_v1_guestbook.yaml ├── controllers │ └── webapp │ ├── guestbook_controller.go │ └── suite_test.go ├── Dockerfile ├── go.mod ├── go.sum ├── hack │ └── boilerplate.go.txt ├── main.go ├── Makefile └── PROJECT 按需求修改自定义资源结构和Reconcile逻辑 # 修改 apis/webapp/v1/xxx_types.go 和 controller/xxx_controller.go 实现监听自定义资源变化的业务逻辑 # 通过 make manifest 生成 CRDs 和 CRs # 生成的 CRDs 保存在 config/crd/bases 下 CRs 保存在 config/sample 下 # 通过修改 apis/webapp/v1/groupversion_info.go apis/webapp/v1/xxx_types.go 的标签 apis/webapp/v1/groupversion_info.go: // Package v1 contains API Schema definitions for the webapp v1 API group // 告诉 object 代码生成器会使用该包下的内容 //+kubebuilder:object:generate=true // 控制代码生成生成 crd 时的 group //+groupName=webapp.qingcloud.com package v1 import ( \u0026#34;k8s.io/apimachinery/pkg/runtime/schema\u0026#34; \u0026#34;sigs.k8s.io/controller-runtime/pkg/scheme\u0026#34; ) var ( // GroupVersion is group version used to register these objects GroupVersion = schema.GroupVersion{Group: \u0026#34;webapp.qingcloud.com\u0026#34;, Version: \u0026#34;v1\u0026#34;} // SchemeBuilder is used to add go types to the GroupVersionKind scheme SchemeBuilder = \u0026amp;scheme.Builder{GroupVersion: GroupVersion} // AddToScheme adds the types in this group-version to the given scheme. AddToScheme = SchemeBuilder.AddToScheme ) apis/webapp/v1/xxx_types.go: package v1 import ( metav1 \u0026#34;k8s.io/apimachinery/pkg/apis/meta/v1\u0026#34; ) // EDIT THIS FILE! THIS IS SCAFFOLDING FOR YOU TO OWN! // NOTE: json tags are required. Any new fields you add must have json tags for the fields to be serialized. // GuestBookSpec defines the desired state of GuestBook type GuestBookSpec struct { // INSERT ADDITIONAL SPEC FIELDS - desired state of cluster // Important: Run \u0026#34;make\u0026#34; to regenerate code after modifying this file Name string `json:\u0026#34;name\u0026#34;` } // GuestBookStatus defines the observed state of GuestBook type GuestBookStatus struct { // INSERT ADDITIONAL STATUS FIELD - define observed state of cluster // Important: Run \u0026#34;make\u0026#34; to regenerate code after modifying this file Number int64 `json:\u0026#34;number\u0026#34;` } // 告诉 object 这是一种 root type Kind。 object 生成器根据该标签生成相关所有kind都要实现的runtime.Object接口 //+kubebuilder:object:root=true // 在当前 CRD 上启用 \u0026#34;/status\u0026#34; 子资源 //+kubebuilder:subresource:status // 控制生成的 CRD 的 scope/singular/shortName //+kubebuilder:resource:scope=Namespaced,singular=guestbook,shortName=gb;ggbb // GuestBook is the Schema for the guestbooks API type GuestBook struct { metav1.TypeMeta `json:\u0026#34;,inline\u0026#34;` metav1.ObjectMeta `json:\u0026#34;metadata,omitempty\u0026#34;` Spec GuestBookSpec `json:\u0026#34;spec,omitempty\u0026#34;` Status GuestBookStatus `json:\u0026#34;status,omitempty\u0026#34;` } //+kubebuilder:object:root=true // GuestBookList contains a list of GuestBook type GuestBookList struct { metav1.TypeMeta `json:\u0026#34;,inline\u0026#34;` metav1.ListMeta `json:\u0026#34;metadata,omitempty\u0026#34;` Items []GuestBook `json:\u0026#34;items\u0026#34;` } func init() { SchemeBuilder.Register(\u0026amp;GuestBook{}, \u0026amp;GuestBookList{}) } kubebuilder使用marker控制代码生成器\n通过make命令管理 # 生成 yaml 文件 make manifests # 生成 DeepCopy, DeepCopyInto, and DeepCopyObject method make generate # 生成二进制可执行文件，生成的文件保存在 bin/ 下 make build # 打包 docker image make docker-build IMG=guestbook1:v0.01 # 推送 docker image 到仓库，在执行这条命令之前要执行 make docker-build make docker-push IMG=guestbook1:v0.01 # 通过 kubectl 把 crd 部署到集群 make install # 通过 kubectl 卸载 crd make uninstall # 通过 kubectl 把 crd 和 operator 部署到集群，在执行这条命令之前需要执行 make docker-build 和 make docker-push make deploy # 通过 kubectl 卸载 crd 和 operator make undeploy ","permalink":"https://moyuduo.github.io/posts/kubebuilder/","summary":"kubebuilder kubebuilder 是用于使用自定义资源(CRD)构建 kubernetes api 的框架，可以大大的提高开发人员的开发速度降低复杂性，以便快速的在 Go 中构建和发布 kubernetes api。kubebuilder 通过 Operator模式来定义自定义资源和发布 kubernetes api。\nResource + Controller = Operator\n架构： 安装：\n安装 curl -L -o kubebuilder https://go.kubebuilder.io/dl/latest/$(go env GOOS)/$(go env GOARCH) chmod +x kubebuilder \u0026amp;\u0026amp; mv kubebuilder /usr/local/bin/ 创建项目 mkdir operator-project cd operator-project go mod init operator-project kubebuilder init --domain qingcloud.com 创建 api kubebuilder edit --multigroup=true kubebuilder create api --group webapp --version v1 --kind GuestBook 目录结构 [root@centos72 guestbook1]# tree . ├── apis │ └── webapp │ └── v1 │ ├── groupversion_info.","title":"kubebuilder"},{"content":"是什么 kustomize 使用 k8s 原生概念帮助创建并复用资源配置(YAML)，允许用户以一个应用描述文件 （YAML 文件）为基础（Base YAML），然后通过 Overlay 的方式生成最终部署应用所需的描述文件。\n可以把kustomize理解为轻量级的helm。\n解决什么问题 一般应用都会存在多套部署环境：开发环境、测试环境、生产环境，多套环境意味着存在多套 K8S 应用资源 YAML。而这么多套 YAML 之间只存在微小配置差异，比如镜像版本不同、Label 不同等，而这些不同环境下的YAML 经常会因为人为疏忽导致配置错误。再者，多套环境的 YAML 维护通常是通过把一个环境下的 YAML 拷贝出来然后对差异的地方进行修改。\n概念 kustomization：指的是 kustomization.yaml 文件，或者指的是包含kustomization.yaml 文件的目录以及它里面引用的所有相关文件路径 base：base 指的是一个 kustomization , 任何的 kustomization 包括 overlay，都可以作为另一个 kustomization 的 base (简单理解为基础目录)。base中描述了共享的内容，如资源和常见的资源配置。base 是需要通过 overlay 修订的基础配置 overlay：overlay 是一个 kustomization, 它修改(并因此依赖于)另外一个 kustomization variant：variant 是在集群中将 overlay 应用于 base 的结果。例如开发和生产环境都修改了一些共同 base以创建不同的 variant。这些 variant 使用相同的总体资源，并与简单的方式变化，例如 deployment的副本数、ConfigMap使用的数据源等。简而言之，variant 是含有同一组 base 的不同 resource：resource 是描述 k8s API 对象的 YAML 或 JSON文件的相对路径。即是指向一个声明了 kubernetes API 对象的 YAML 文件 patch：修改文件的一般说明。文件路径，指向一个声明了 kubernetes API patch 的 YAML 文件 安装 go get github.com/kubernetes-sigs/kustomize 使用 创建一个目录 mkdir kustomize_test 在这个目录下创建base文件夹，并在该文件夹下创建资源 cd kustomize_test mkdir base cd base cat \u0026lt;\u0026lt; EOF \u0026gt; configmap.yaml apiVersion: v1 kind: ConfigMap metadata: name: the-map data: altGreeting: \u0026#34;Good Morning!\u0026#34; enableRisky: \u0026#34;false\u0026#34; EOF cat \u0026lt;\u0026lt; EOF \u0026gt; service.yaml kind: Service apiVersion: v1 metadata: name: the-service spec: selector: deployment: hello type: LoadBalancer ports: - protocol: TCP port: 8666 targetPort: 8080 EOF cat \u0026lt;\u0026lt; EOF \u0026gt; deploy.yaml apiVersion: apps/v1 kind: Deployment metadata: name: the-deployment spec: replicas: 3 selector: matchLabels: deployment: hello template: metadata: labels: deployment: hello spec: containers: - name: the-container image: monopole/hello:1 command: [\u0026#34;/hello\u0026#34;, \u0026#34;--port=8080\u0026#34;, \u0026#34;--enableRiskyFeature=$(ENABLE_RISKY)\u0026#34;] ports: - containerPort: 8080 env: - name: ALT_GREETING valueFrom: configMapKeyRef: name: the-map key: altGreeting - name: ENABLE_RISKY valueFrom: configMapKeyRef: name: the-map key: enableRisky EOF 在base文件夹下创建kustomization文件 cat \u0026lt;\u0026lt; EOF \u0026gt; kustomization.yaml apiVersion: kustomize.config.k8s.io/v1beta1 kind: Kustomization metadata: name: arbitrary # Example configuration for the webserver # at https://github.com/monopole/hello commonLabels: app: hello resources: - configmap.yaml - service.yaml - deploy.yaml EOF 在base文件夹下执行kustomize build .,输出的所有资源都被加上了label kustomize build . apiVersion: v1 data: altGreeting: Good Morning! enableRisky: \u0026#34;false\u0026#34; kind: ConfigMap metadata: labels: app: hello name: the-map --- apiVersion: v1 kind: Service metadata: labels: app: hello name: the-service spec: ports: - port: 8666 protocol: TCP targetPort: 8080 selector: app: hello deployment: hello type: LoadBalancer --- apiVersion: apps/v1 kind: Deployment metadata: labels: app: hello name: the-deployment spec: replicas: 3 selector: matchLabels: app: hello deployment: hello template: metadata: labels: app: hello deployment: hello spec: containers: - command: - /hello - --port=8080 - --enableRiskyFeature=$(ENABLE_RISKY) env: - name: ALT_GREETING valueFrom: configMapKeyRef: key: altGreeting name: the-map - name: ENABLE_RISKY valueFrom: configMapKeyRef: key: enableRisky name: the-map image: monopole/hello:1 name: the-container ports: - containerPort: 8080 在kustomize_test目录下创建overlay目录 mkdir overlay cd overlay 在overlay目录下创建staging目录，并在目录下创建kustomization文件 mkdir staging cd staging cat \u0026lt;\u0026lt; EOF \u0026gt; kustomization.yaml namePrefix: staging- commonLabels: variant: staging org: acmeCorporation commonAnnotations: note: Hello, I am staging! resources: - ../../base patchesStrategicMerge: - map.yaml EOF 在staging目录下创建map.yaml文件 cat \u0026lt;\u0026lt; EOF \u0026gt; map.yaml apiVersion: v1 kind: ConfigMap metadata: name: the-map data: altGreeting: \u0026#34;Have a pineapple!\u0026#34; enableRisky: \u0026#34;true\u0026#34; EOF 在staging环境下执行kustomize build .,输出的配置文件中configmap已经在base目录下执行kustomize build .的基础上加上了staging环境的label、annotation和更新data kustomize build . apiVersion: v1 data: altGreeting: Have a pineapple! enableRisky: \u0026#34;true\u0026#34; kind: ConfigMap metadata: annotations: note: Hello, I am staging! labels: app: hello org: acmeCorporation variant: staging name: staging-the-map --- apiVersion: v1 kind: Service metadata: annotations: note: Hello, I am staging! labels: app: hello org: acmeCorporation variant: staging name: staging-the-service spec: ports: - port: 8666 protocol: TCP targetPort: 8080 selector: app: hello deployment: hello org: acmeCorporation variant: staging type: LoadBalancer --- apiVersion: apps/v1 kind: Deployment metadata: annotations: note: Hello, I am staging! labels: app: hello org: acmeCorporation variant: staging name: staging-the-deployment spec: replicas: 3 selector: matchLabels: app: hello deployment: hello org: acmeCorporation variant: staging template: metadata: annotations: note: Hello, I am staging! labels: app: hello deployment: hello org: acmeCorporation variant: staging spec: containers: - command: - /hello - --port=8080 - --enableRiskyFeature=$(ENABLE_RISKY) env: - name: ALT_GREETING valueFrom: configMapKeyRef: key: altGreeting name: staging-the-map - name: ENABLE_RISKY valueFrom: configMapKeyRef: key: enableRisky name: staging-the-map image: monopole/hello:1 name: the-container ports: - containerPort: 8080 在staging目录下新建prod目录，并在目录下创建kustomization文件 mkdir prod cd prod cat \u0026lt;\u0026lt; EOF \u0026gt; kustomization.yaml namePrefix: production- commonLabels: variant: production org: acmeCorporation commonAnnotations: note: Hello, I am production! resources: - ../../base patchesStrategicMerge: - deploy.yaml EOF 在prod目录下创建deploy文件 cat \u0026lt;\u0026lt; EOF \u0026gt; deploy.yaml apiVersion: apps/v1 kind: Deployment metadata: name: the-deployment spec: replicas: 10 EOF 在prod目录下执行kustomize build .,输入的配置文件中相较于在base文件夹下执行kustomize build .加上了label、annotation、replicas也改为了10 kustomize build . apiVersion: v1 data: altGreeting: Good Morning! enableRisky: \u0026#34;false\u0026#34; kind: ConfigMap metadata: annotations: note: Hello, I am production! labels: app: hello org: acmeCorporation variant: production name: production-the-map --- apiVersion: v1 kind: Service metadata: annotations: note: Hello, I am production! labels: app: hello org: acmeCorporation variant: production name: production-the-service spec: ports: - port: 8666 protocol: TCP targetPort: 8080 selector: app: hello deployment: hello org: acmeCorporation variant: production type: LoadBalancer --- apiVersion: apps/v1 kind: Deployment metadata: annotations: note: Hello, I am production! labels: app: hello org: acmeCorporation variant: production name: production-the-deployment spec: replicas: 10 selector: matchLabels: app: hello deployment: hello org: acmeCorporation variant: production template: metadata: annotations: note: Hello, I am production! labels: app: hello deployment: hello org: acmeCorporation variant: production spec: containers: - command: - /hello - --port=8080 - --enableRiskyFeature=$(ENABLE_RISKY) env: - name: ALT_GREETING valueFrom: configMapKeyRef: key: altGreeting name: production-the-map - name: ENABLE_RISKY valueFrom: configMapKeyRef: key: enableRisky name: production-the-map image: monopole/hello:1 name: the-container ports: - containerPort: 8080 generatorOptions Kustomize 提供了修改 ConfigMapGenerator 和 SecretGenerator 行为的选项\n这些选项的功能包括：\n不再将基于内容生成的哈希后缀添加到资源名称后 为生成的资源添加 labels 为生成的资源添加 annotations kustomization配置文件：\nnamePrefix: production- nameSuffix: -v1 commonLabels: variant: production org: acmeCorporation commonAnnotations: note: Hello, I am production! generatorOptions: disableNameSuffixHash: true #关闭哈希后缀 labels: kustomize.generated.resource: somevalue annotations: annotations.only.for.generated: othervalue configMapGenerator: - name: my-configmap literals:\t- foo=bar - baz=qux 变量 变量的查找和替换并不适用于任意字段，默认仅适用于容器的 env， args和 command\n修改base目录下的deploy.yaml文件 command: [\u0026#34;/hello\u0026#34;, \u0026#34;--port=8080\u0026#34;, \u0026#34;--enableRiskyFeature=$(ENABLE_RISKY)\u0026#34;] =\u0026gt; command: [\u0026#34;/hello\u0026#34;, \u0026#34;--port=$(HELLO_PORT)\u0026#34;, \u0026#34;--enableRiskyFeature=$(ENABLE_RISKY)\u0026#34;] 修改staging目录下的kustomization.yaml cat \u0026lt;\u0026lt; EOF \u0026gt;\u0026gt; kustomization.yaml vars: - name: HELLO_PORT objref: apiVersion: v1 kind: Service name: the-service fieldref: fieldpath: spec.ports[0].port EOF 在staging目录下执行kustomize build .,HELLO_PORT变量已经被替换 kustomize build . ... - command: - /hello - --port=8666 - --enableRiskyFeature=$(ENABLE_RISKY) ... 替换镜像 进入prod目录执行kustomize edit set image monopole/hello:1=alpine:3.6 #kustomization.yaml文件追加了一下内容 apiVersion: kustomize.config.k8s.io/v1beta1 kind: Kustomization images: - name: monopole/hello:1 newName: alpine newTag: \u0026#34;3.6\u0026#34; 在该目录下执行kustomize build .,会发现该镜像都被替换成了指定的镜像 image: alpine:3.6 name: the-container patches 格式：\npatches: - path: \u0026lt;PatchFile\u0026gt; target: group: \u0026lt;Group\u0026gt; version: \u0026lt;Version\u0026gt; kind: \u0026lt;Kind\u0026gt; name: \u0026lt;Name\u0026gt; namespace: \u0026lt;Namespace\u0026gt; labelSelector: \u0026lt;LabelSelector\u0026gt; annotationSelector: \u0026lt;AnnotationSelector\u0026gt; 示例:\napiVersion: kustomize.config.k8s.io/v1beta1 kind: Kustomization patches: - path: patch.yaml target: group: apps version: v1 kind: Deployment name: deploy.* labelSelector: \u0026#34;env=dev\u0026#34; annotationSelector: \u0026#34;zone=west\u0026#34; - patch: |- - op: replace path: /some/existing/path value: new value target: kind: MyKind labelSelector: \u0026#34;env=dev\u0026#34; 修改staging目录下的kustomiztion.yaml文件 cat \u0026lt;\u0026lt; EOF \u0026gt; patch.yaml apiVersion: apps/v1 kind: Deployment metadata: name: the-deployment spec: template: spec: containers: - name: the-container image: prod/hello:1 EOF cat \u0026lt;\u0026lt; EOF \u0026gt;\u0026gt; kustomization.yaml patches: - path: patch.yaml target: group: apps version: v1 kind: Deployment name: the-deployment - patch: |- - op: replace path: /spec/template/spec/containers/0/ports/0/containerPort value: 9090 target: kind: Deployment name: the-deployment EOF 在staging目录下执行kustomize build .,可以看到image和containerPort都已经被替换了 ... spec: containers: - command: - /hello - --port=8666 - --enableRiskyFeature=$(ENABLE_RISKY) env: - name: ALT_GREETING valueFrom: configMapKeyRef: key: altGreeting name: staging-the-map - name: ENABLE_RISKY valueFrom: configMapKeyRef: key: enableRisky name: staging-the-map image: prod/hello:1 name: the-container ports: - containerPort: 9090 ... namespace 为所有资源添加namespace\n修改staging目录下的kustomization.yaml cat \u0026lt;\u0026lt; EOF \u0026gt;\u0026gt; kustomization.yaml namesapce: staging EOF 在staging目录下执行kustomize build .,可以看到所有资源的namespace都被改为了staging kustomize build . ... name: staging-the-service namespace: staging ... 修改prod目录下的kustomization.yaml cat \u0026lt;\u0026lt; EOF \u0026gt;\u0026gt; kustomization.yaml namespace: prod EOF 在prod目录下执行kustomize build .,可以发现所有资源的namespace都被改为了prod kustomize build . ... name: production-the-service-v1 namespace: prod ... replicas 修改所有资源的副本\n在prod目录下修改kustomization.yaml文件 cat \u0026lt;\u0026lt; EOF \u0026gt;\u0026gt; kustomization.yaml replicas: - name: the-deployment count: 50 EOF 在prod目录下执行kustomize build .,可以看到deployment的replicas已经被改为50 kustomize build . ... spec: replicas: 50 selector: matchLabels: ... ","permalink":"https://moyuduo.github.io/posts/kustomize/","summary":"是什么 kustomize 使用 k8s 原生概念帮助创建并复用资源配置(YAML)，允许用户以一个应用描述文件 （YAML 文件）为基础（Base YAML），然后通过 Overlay 的方式生成最终部署应用所需的描述文件。\n可以把kustomize理解为轻量级的helm。\n解决什么问题 一般应用都会存在多套部署环境：开发环境、测试环境、生产环境，多套环境意味着存在多套 K8S 应用资源 YAML。而这么多套 YAML 之间只存在微小配置差异，比如镜像版本不同、Label 不同等，而这些不同环境下的YAML 经常会因为人为疏忽导致配置错误。再者，多套环境的 YAML 维护通常是通过把一个环境下的 YAML 拷贝出来然后对差异的地方进行修改。\n概念 kustomization：指的是 kustomization.yaml 文件，或者指的是包含kustomization.yaml 文件的目录以及它里面引用的所有相关文件路径 base：base 指的是一个 kustomization , 任何的 kustomization 包括 overlay，都可以作为另一个 kustomization 的 base (简单理解为基础目录)。base中描述了共享的内容，如资源和常见的资源配置。base 是需要通过 overlay 修订的基础配置 overlay：overlay 是一个 kustomization, 它修改(并因此依赖于)另外一个 kustomization variant：variant 是在集群中将 overlay 应用于 base 的结果。例如开发和生产环境都修改了一些共同 base以创建不同的 variant。这些 variant 使用相同的总体资源，并与简单的方式变化，例如 deployment的副本数、ConfigMap使用的数据源等。简而言之，variant 是含有同一组 base 的不同 resource：resource 是描述 k8s API 对象的 YAML 或 JSON文件的相对路径。即是指向一个声明了 kubernetes API 对象的 YAML 文件 patch：修改文件的一般说明。文件路径，指向一个声明了 kubernetes API patch 的 YAML 文件 安装 go get github.","title":"kustomize"},{"content":"LinkedHashMap源码分析 为什么要有LinkedHashMap？ 在分析HashMap的时候提到了HashMap是无序的，即添加节点的顺序和遍历的顺序不一致 @Test public void test1() { HashMap\u0026lt;String,String\u0026gt; hashMap=new HashMap\u0026lt;String, String\u0026gt;(); hashMap.put(\u0026#34;tom\u0026#34;, \u0026#34;american\u0026#34;); hashMap.put(\u0026#34;jack\u0026#34;, \u0026#34;chainese\u0026#34;); hashMap.put(\u0026#34;mary\u0026#34;, \u0026#34;japanese\u0026#34;); Set\u0026lt;Entry\u0026lt;String, String\u0026gt;\u0026gt; entrySet = hashMap.entrySet(); Iterator\u0026lt;Entry\u0026lt;String, String\u0026gt;\u0026gt; iterator = entrySet.iterator(); while(iterator.hasNext()) { Entry\u0026lt;String, String\u0026gt; entry = iterator.next(); String key = entry.getKey(); String value = entry.getValue(); System.out.println(key+\u0026#34;:\u0026#34;+value); } } 输出： tom:american mary:japanese jack:chainese LinkedHashMap保证节点的顺序，这也是LinkedHashMap和HashMap的主要区别 @Test public void test2() { LinkedHashMap\u0026lt;String,String\u0026gt; linkedHashMap=new LinkedHashMap(); linkedHashMap.put(\u0026#34;tom\u0026#34;, \u0026#34;american\u0026#34;); linkedHashMap.put(\u0026#34;jack\u0026#34;, \u0026#34;chainese\u0026#34;); linkedHashMap.put(\u0026#34;mary\u0026#34;, \u0026#34;japanese\u0026#34;); Set\u0026lt;Entry\u0026lt;String, String\u0026gt;\u0026gt; entrySet = linkedHashMap.entrySet(); Iterator\u0026lt;Entry\u0026lt;String, String\u0026gt;\u0026gt; iterator = entrySet.iterator(); while(iterator.hasNext()) { Entry\u0026lt;String, String\u0026gt; entry = iterator.next(); String key = entry.getKey(); String value = entry.getValue(); System.out.println(key+\u0026#34;:\u0026#34;+value); } } 输出： tom:american jack:chainese mary:japanese 存储示意图 类结构 public class LinkedHashMap\u0026lt;K,V\u0026gt; extends HashMap\u0026lt;K,V\u0026gt; implements Map\u0026lt;K,V\u0026gt; LinkedHashMap是HashMap的子类，它对HashMap做了一些增强\n节点 static class Entry\u0026lt;K,V\u0026gt; extends HashMap.Node\u0026lt;K,V\u0026gt; {//LinkedHashMap的Entry节点是HashMap的Node节点的子类 Entry\u0026lt;K,V\u0026gt; before, after;//新增了before、after分别指向前驱和后继 Entry(int hash, K key, V value, Node\u0026lt;K,V\u0026gt; next) { //直接使用HashMap的Node节点构造方法 super(hash, key, value, next); } } 属性 //头指针指向第一个添加节点 transient LinkedHashMap.Entry\u0026lt;K,V\u0026gt; head; //尾指针指向最后一个添加节点 transient LinkedHashMap.Entry\u0026lt;K,V\u0026gt; tail; //排序规则，true的话按照访问顺序排序，最近访问的放到最后，false也是默认按照插入顺序排序 final boolean accessOrder; 构造方法 //指定初始化容量和加载因子 public LinkedHashMap(int initialCapacity, float loadFactor) { super(initialCapacity, loadFactor); accessOrder = false; } //指定初始化容量 public LinkedHashMap(int initialCapacity) { super(initialCapacity); accessOrder = false; } //无参构造方法 public LinkedHashMap() { super(); accessOrder = false; } //使用Map初始化 public LinkedHashMap(Map\u0026lt;? extends K, ? extends V\u0026gt; m) { super(); accessOrder = false; putMapEntries(m, false); } //指定初始化容量、加载因子、排序规则 public LinkedHashMap(int initialCapacity, float loadFactor, boolean accessOrder) { super(initialCapacity, loadFactor); this.accessOrder = accessOrder; } 方法 LinkedHashMap中并没有put方法，所以使用的是父类HashMap的put方法\npublic V put(K key, V value) { return putVal(hash(key), key, value, false, true); } final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) { Node\u0026lt;K,V\u0026gt;[] tab; Node\u0026lt;K,V\u0026gt; p; int n, i; if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; if ((p = tab[i = (n - 1) \u0026amp; hash]) == null) //当根据hash计算的下标位置没放节点，调用LinkedHashMap的newNode方法 tab[i] = newNode(hash, key, value, null); else { Node\u0026lt;K,V\u0026gt; e; K k; if (p.hash == hash \u0026amp;\u0026amp; ((k = p.key) == key || (key != null \u0026amp;\u0026amp; key.equals(k)))) e = p; else if (p instanceof TreeNode) e = ((TreeNode\u0026lt;K,V\u0026gt;)p).putTreeVal(this, tab, hash, key, value); else { for (int binCount = 0; ; ++binCount) { if ((e = p.next) == null) { p.next = newNode(hash, key, value, null); if (binCount \u0026gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; } if (e.hash == hash \u0026amp;\u0026amp; ((k = e.key) == key || (key != null \u0026amp;\u0026amp; key.equals(k)))) break; p = e; } } if (e != null) { // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; //如果是指定访问顺序排序，那么替换后，把节点移动到最后 afterNodeAccess(e); return oldValue; } } ++modCount; if (++size \u0026gt; threshold) resize(); afterNodeInsertion(evict); return null; } Node\u0026lt;K,V\u0026gt; newNode(int hash, K key, V value, Node\u0026lt;K,V\u0026gt; e) { LinkedHashMap.Entry\u0026lt;K,V\u0026gt; p = new LinkedHashMap.Entry\u0026lt;K,V\u0026gt;(hash, key, value, e); linkNodeLast(p); return p; } private void linkNodeLast(LinkedHashMap.Entry\u0026lt;K,V\u0026gt; p) { //保存LinkedHashMap的为指针 LinkedHashMap.Entry\u0026lt;K,V\u0026gt; last = tail; tail = p; if (last == null)//尾指针为null说明LinkedHashMap中没元素 head = p; else {//有元素 //新节点的前驱指向添加之前的尾指针 p.before = last; //添加之前的尾指针节点的后继指向新节点 last.after = p; } } void afterNodeAccess(Node\u0026lt;K,V\u0026gt; e) { // move node to last LinkedHashMap.Entry\u0026lt;K,V\u0026gt; last; if (accessOrder \u0026amp;\u0026amp; (last = tail) != e) {//如果指定了按访问顺序排序且替换的节点不是最末尾的节点 LinkedHashMap.Entry\u0026lt;K,V\u0026gt; p = (LinkedHashMap.Entry\u0026lt;K,V\u0026gt;)e, b = p.before, a = p.after; p.after = null; if (b == null) head = a; else b.after = a; if (a != null) a.before = b; else last = b; if (last == null) head = p; else { p.before = last; last.after = p; } tail = p; ++modCount; } void afterNodeInsertion(boolean evict) { // possibly remove eldest LinkedHashMap.Entry\u0026lt;K,V\u0026gt; first; if (evict \u0026amp;\u0026amp; (first = head) != null \u0026amp;\u0026amp; removeEldestEntry(first)) {//removeEldestEntry方法返回false所以不会进入if K key = first.key; removeNode(hash(key), key, null, false, true); } } get(Object）根据key获取值\npublic V get(Object key) { Node\u0026lt;K,V\u0026gt; e; if ((e = getNode(hash(key), key)) == null)//调用HashMap的方法拿到值 return null; if (accessOrder)//如果是按照访问顺序排序的话 //访问过后要修改顺序 afterNodeAccess(e); return e.value; } //把访问的节点移动到链表的最末端 void afterNodeAccess(Node\u0026lt;K,V\u0026gt; e) { LinkedHashMap.Entry\u0026lt;K,V\u0026gt; last; if (accessOrder \u0026amp;\u0026amp; (last = tail) != e) {//按访问顺序排序并且访问节点不是最后一个节点 LinkedHashMap.Entry\u0026lt;K,V\u0026gt; p = (LinkedHashMap.Entry\u0026lt;K,V\u0026gt;)e, b = p.before, a = p.after; p.after = null; if (b == null) head = a; else b.after = a; if (a != null) a.before = b; else last = b; if (last == null) head = p; else { p.before = last; last.after = p; } tail = p; ++modCount; } } remove(Object)方法是调用父类HashMap的方法\npublic V remove(Object key) { Node\u0026lt;K,V\u0026gt; e; return (e = removeNode(hash(key), key, null, false, true)) == null ? null : e.value; } final Node\u0026lt;K,V\u0026gt; removeNode(int hash, Object key, Object value, boolean matchValue, boolean movable) { Node\u0026lt;K,V\u0026gt;[] tab; Node\u0026lt;K,V\u0026gt; p; int n, index; if ((tab = table) != null \u0026amp;\u0026amp; (n = tab.length) \u0026gt; 0 \u0026amp;\u0026amp; (p = tab[index = (n - 1) \u0026amp; hash]) != null) { Node\u0026lt;K,V\u0026gt; node = null, e; K k; V v; if (p.hash == hash \u0026amp;\u0026amp; ((k = p.key) == key || (key != null \u0026amp;\u0026amp; key.equals(k)))) node = p; else if ((e = p.next) != null) { if (p instanceof TreeNode) node = ((TreeNode\u0026lt;K,V\u0026gt;)p).getTreeNode(hash, key); else { do { if (e.hash == hash \u0026amp;\u0026amp; ((k = e.key) == key || (key != null \u0026amp;\u0026amp; key.equals(k)))) { node = e; break; } p = e; } while ((e = e.next) != null); } } if (node != null \u0026amp;\u0026amp; (!matchValue || (v = node.value) == value || (value != null \u0026amp;\u0026amp; value.equals(v)))) { if (node instanceof TreeNode) ((TreeNode\u0026lt;K,V\u0026gt;)node).removeTreeNode(this, tab, movable); else if (node == p) tab[index] = node.next; else p.next = node.next; ++modCount; --size; //调用LinkedHashMap·的方法来实现双链的删除 afterNodeRemoval(node); return node; } } return null; } void afterNodeRemoval(Node\u0026lt;K,V\u0026gt; e) { // unlink LinkedHashMap.Entry\u0026lt;K,V\u0026gt; p = (LinkedHashMap.Entry\u0026lt;K,V\u0026gt;)e, b = p.before, a = p.after; //把要移除节点的前驱后继置为null p.before = p.after = null; if (b == null)//b为null即移除的就是第一个元素 //头指针指向移除元素的后继 head = a; else b.after = a; if (a == null)//a为null即移除的元素是最后一个元素 //尾指针指向移除元素的前驱 tail = b; else a.before = b; } ","permalink":"https://moyuduo.github.io/posts/linkedhashmap%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/","summary":"LinkedHashMap源码分析 为什么要有LinkedHashMap？ 在分析HashMap的时候提到了HashMap是无序的，即添加节点的顺序和遍历的顺序不一致 @Test public void test1() { HashMap\u0026lt;String,String\u0026gt; hashMap=new HashMap\u0026lt;String, String\u0026gt;(); hashMap.put(\u0026#34;tom\u0026#34;, \u0026#34;american\u0026#34;); hashMap.put(\u0026#34;jack\u0026#34;, \u0026#34;chainese\u0026#34;); hashMap.put(\u0026#34;mary\u0026#34;, \u0026#34;japanese\u0026#34;); Set\u0026lt;Entry\u0026lt;String, String\u0026gt;\u0026gt; entrySet = hashMap.entrySet(); Iterator\u0026lt;Entry\u0026lt;String, String\u0026gt;\u0026gt; iterator = entrySet.iterator(); while(iterator.hasNext()) { Entry\u0026lt;String, String\u0026gt; entry = iterator.next(); String key = entry.getKey(); String value = entry.getValue(); System.out.println(key+\u0026#34;:\u0026#34;+value); } } 输出： tom:american mary:japanese jack:chainese LinkedHashMap保证节点的顺序，这也是LinkedHashMap和HashMap的主要区别 @Test public void test2() { LinkedHashMap\u0026lt;String,String\u0026gt; linkedHashMap=new LinkedHashMap(); linkedHashMap.put(\u0026#34;tom\u0026#34;, \u0026#34;american\u0026#34;); linkedHashMap.put(\u0026#34;jack\u0026#34;, \u0026#34;chainese\u0026#34;); linkedHashMap.put(\u0026#34;mary\u0026#34;, \u0026#34;japanese\u0026#34;); Set\u0026lt;Entry\u0026lt;String, String\u0026gt;\u0026gt; entrySet = linkedHashMap.entrySet(); Iterator\u0026lt;Entry\u0026lt;String, String\u0026gt;\u0026gt; iterator = entrySet.","title":"LinkedHashMap源码分析"},{"content":"linux vxlan和tun网络 vlan和tun都属于overlay网络，即建立在一个屋里网络(Underlay网络)之上的虚拟网络，Underlay网络是真正存在的实体，承载Overlay网络的通信。如两个设备通过udp/tcp进行通信这就是Underlay网络。但是在udp/tcp之上承载的应用层数据中如果包含了IP协议的数据，那么这就是Overlay三层网络，如果应用层数据包含了数据链路层的数据，那么这就是Overlay二层网络。\nlinux tun:在四层网络之上构建三层网络。\noverlay网络通信协议位于Ip层及以上。\noverlay网络不支持arp协议。(arp协议位于数据链路层)\nlinux vxlan:在四层网络之上构建二层网络。\noverlay网络通信协议位于Ip层及以上。\noverlay网络支持arp协议。\nvxlan实验 在host1上配置:\nip link add name vxlan100 type vxlan id 100 dstport 4789 local 192.168.37.131 remote 192.168.37.134 ip link set vxlan100 up ip addr add 172.17.0.4/32 dev vxlan100 ip route add 172.17.0.0/24 dev vxlan100 在host2上配置:\nip link add name vxlan100 type vxlan id 100 dstport 4789 local 192.168.37.134 remote 192.168.37.131 ip link set vxlan100 up ip addr add 172.17.0.3/32 dev vxlan100 ip route add 172.17.0.0/24 dev vxlan100 注意：host1、host2上配置vxlan时的id、dstport必须相同\ntun实验 参考：https://blog.csdn.net/u014044624/article/details/104823596\n","permalink":"https://moyuduo.github.io/posts/linux-vxlan%E5%92%8Ctun%E7%BD%91%E7%BB%9C/","summary":"linux vxlan和tun网络 vlan和tun都属于overlay网络，即建立在一个屋里网络(Underlay网络)之上的虚拟网络，Underlay网络是真正存在的实体，承载Overlay网络的通信。如两个设备通过udp/tcp进行通信这就是Underlay网络。但是在udp/tcp之上承载的应用层数据中如果包含了IP协议的数据，那么这就是Overlay三层网络，如果应用层数据包含了数据链路层的数据，那么这就是Overlay二层网络。\nlinux tun:在四层网络之上构建三层网络。\noverlay网络通信协议位于Ip层及以上。\noverlay网络不支持arp协议。(arp协议位于数据链路层)\nlinux vxlan:在四层网络之上构建二层网络。\noverlay网络通信协议位于Ip层及以上。\noverlay网络支持arp协议。\nvxlan实验 在host1上配置:\nip link add name vxlan100 type vxlan id 100 dstport 4789 local 192.168.37.131 remote 192.168.37.134 ip link set vxlan100 up ip addr add 172.17.0.4/32 dev vxlan100 ip route add 172.17.0.0/24 dev vxlan100 在host2上配置:\nip link add name vxlan100 type vxlan id 100 dstport 4789 local 192.168.37.134 remote 192.168.37.131 ip link set vxlan100 up ip addr add 172.17.0.3/32 dev vxlan100 ip route add 172.","title":"linux vxlan和tun网络"},{"content":"linux命令自查 查看cpu和内存 cpu个数 cat /proc/cpuinfo | grep \u0026#34;physical id\u0026#34; | uniq | wc -l cpu核数 cat /proc/cpuinfo | grep \u0026#34;cpu cores\u0026#34; | uniq cpu型号 cat /proc/cpuinfo | grep \u0026#39;model name\u0026#39; |uniq 内存大小 cat /proc/meminfo | grep MemTotal 设置linux开机自启动 linux文件/etc/rc.local文件中的内容会linux启动完成后执行，所以可以用来做开机自启动，/etc/rc.local默认是lrwxrwxrwx权限，但是由于它是/etc/rc.d/rc.local的一个软连接，所以/etc/rc.d/rc.local这个文件必须要有执行权限才能开机自启动，而这个人间默认是-rw-rw-rw-权限，所以必须要修改添加执行权限,注意在这个文件中添加开机执行死循环脚本时必须使用\u0026amp;后台执行。\n秒级检测脚本 #!/bin/bash while true do count=`ps -ef|grep etcd|grep -v grep|wc -l` if [ $count -eq 0 ]; then cd /opt/etcd-v3.5.0-linux-amd64 ./etcd -listen-client-urls=\u0026#34;http://0.0.0.0:2379\u0026#34; --advertise-client-urls=\u0026#34;http://0.0.0.0:2379\u0026#34; echo \u0026#34;restart etcd at $(date)\u0026#34; \u0026gt;\u0026gt; /opt/etcd-v3.5.0-linux-amd64/record fi sleep 1 done 原理是通过ps -ef|grep按照条件过滤执行的进程，再通过wc -l转换为进程个数，最后通过shell进行判断。\n这种方式本质上是通过循环来进行判断，相比于crontab而言，时间可以精确到秒，而crontab的最小单位是分钟\n单行命令直接增加cpu占有率到100% for i in `seq 1 $(cat /proc/cpuinfo |grep \u0026#34;physical id\u0026#34; |wc -l)`; do dd if=/dev/zero of=/dev/null \u0026amp; done 说明: cat /proc/cpuinfo |grep \u0026#34;physical id\u0026#34; | wc -l 可以获得CPU的个数,　我们将其表示为N。 seq 1 N 用来生成１到Ｎ之间的数字 for i in `seq 1 N`; 就是循环执行命令,从１到Ｎ dd if=/dev/zero of=/dev/null 执行dd命令,　输出到/dev/null, 实际上只占用CPU,　没有IO操作. 由于连续执行Ｎ个(Ｎ是ＣＰＵ个数)的dd 命令, 且使用率为100%,　这时调度器会调度每个dd命令在不同的CPU上处理. 最终就实现所有ＣＰＵ占用率100% 测试完毕后，必须使用top命令查看cpu使用率，并kill掉脚本的进程\nfind find path -option name option常用的有 name 按照名字查找文件，支持通配符 type 按照类型查找，d为目录、c为字节型文件、f一般文件、s为socket size ssh远程免密登录 #生成rsa秘钥 ssh-keygen #把id_rsa.pub文件拷贝打要远程登录的目标机器,并改名为authorized_keys #在拷贝前一定要保证有/root/.ssh这个目录，可以是用ssh-keygen生成秘钥对来创建该目录，也可以手动创建该目录 scp id_rsa.pub root@192.168.37.152:/root/authorized_keys #配置完成后测试 ssh root@192.168.37.152 \u0026#34;ls -l /root\u0026#34; #或 ssh 192.168.37.152 \u0026#34;ls -l /root\u0026#34; 配置hosts本地DNS vim /etc/hosts #添加 ip\t域名 防火墙操作 #开放端口 firewall-cmd --add-port=9092/tcp --permanent #重新加载防火墙配置 firewall-cmd --reload #查询端口释放开放 firewall-cmd --query-port=9092/tcp #关闭端口 firewall-cmd --remove-port=9092/tcp --permanent shell脚本中使用其他用户执行脚本 #切换用户执行命令 su - user -c command #切换用户执行一个shell脚本 su - user -s /bin/bash xxx.sh #参考：https://www.cnblogs.com/bigben0123/archive/2013/05/07/3064843.html 配置yum源 cd /etc/yum.repos.d/ curl -O http://mirrors.aliyun.com/repo/Centos-7.repo #备份原来的yum源 mv CentOS-Base.repo CentOS-Base.repo.bak #修改yum源为下载的yum源 mv Centos-7.repo CentOS-Base.repo yum clean all yum makecache yum update wsl下ubuntu设置密码找回密码 cmd打开powershell 输入ubuntu按tab选择要重置的虚拟机 ubuntu.exe conifg \u0026ndash;default-user root 打开ubuntu,会切换指定用户登录且不需要密码，passwd修改密码 ubuntu更新apt源 在https://opsx.alibaba.com/mirror找到对应的ubuntu版本 sudo mv /etc/apt/sources.list /etc/apt/sources.list_backup 将 sources.list 文件备份 sudo vim /etc/apt/sources.list写入配置 sudo apt-get update 更新apt软件源 vim vim模式：\n普通默认：使用vim进来默认就是 view模式：按v进入，可以使用HJKL来移动光标选择文本 view line模式：按V进入，使用JK可上下移动光标来按行选择文本 插入默认：按i、a、o都可进入，可以插入文本 在vim的普通模式中可以使用HJKL四个键来控制光标的上下左右移动，H是光标左移、J是光标下移、K是光标上移、L是光标右移\n在普通模式下，按b键会跳转到单词的开头或上一个单词开头(当前以及处于单词开头),按w键会跳转到下一个单词的开头\n在普通模式下可以使用f+字符来对当前行光标之后进行查找包含当前查找字符的下一处，查找到会把光标移动到下一处对应的查找字符，并且可以使用；键来继续在当前行向后查找，使用，键来在当前行向前查找\n在普通模式下使用F+字符来对当前行光标之前查找包含当前查找字符的上一处\n可以使用:set nu来设置vim显示行号，但是这种方式退出后再次进入就失效了，可以在当前用户的家目录下建立.vimrc文件来设置当前用户的个人vim设置，也可建立/etc/vimrc来配置系统级别的vim设置\n使用:set nonu来取消vim行号显示\n在view模式下，按iw可以选中当前单词，按aw可以选中当前单词及后面的所有空格\n在普通模式下按d、c、y、v都可以进入对应的待决模式\nd是删除模式，例如要删除一个单词就可以使用diw或者daw\nc是修改模式，也是用于删除，例如：ciw或caw就可删除一个单词，它与删除模式不同的是，删除模式删除之后还是在普通模式，而修改模式删除之后就进入插入模式\ny是复制模式，可以使用yiw或yaw来复制一个单词，然后使用p来粘贴\n使用m + 符号来设置一个标记，然后可以使用` + 符号 来快速跳转到标记的位置\n普通模式下按V进入view line模式使用，JK来选择一个范围的内容，按y进行赋值，然后可以p进行粘贴\n在普通模式下可以使用ctl + b向上翻页，ctl + f向下翻页，ctl + u向上翻半页，ctl + d向下翻半页\n在普通模式下输入:/pattern 来进行查找，查找到的单词会高亮显示，可以按n来进行跳转，可以使用:/xxx来搜索一个不存在的关键词或：noh来取消高亮显示\n在普通模式下输入:%s/pattern/string/g 来进行全局的替换，其中pattern是待替换的词，string是替换后的词\n在普通模式下可以使用gg来跳转到首行第一个字符，使用G可以跳转到最后一行最后一个字符，使用：n可以跳转到指定行，n为行号\n在普通模式下按0可以跳转当前行的行首，按$即ctl + 4可以跳转到行末\n使用:e! 来退出文档编辑并重新打开文档\n使用ngg或nG或:n 来跳转到指定的行，n为行号\n用户管理 #添加用户 useradd [options] \u0026lt;user_name\u0026gt; options: -d 指定家目录，默认会在/home目录下创建和用户名同名的家目录，如果给用户指定的家目录不存在可以使用-m参数指定不存在就创建 -g 指定用户所属的组，如果指定的组不存在则创建失败，一个用户只能所属与一个组 #删除用户 userdel [options] \u0026lt;user_name\u0026gt; options: -r 会把用户的家目录一并删除 #修改用户，主要是修改用户相关组合家目录，并不是修改名字 usermod [options] \u0026lt;user_name\u0026gt; 参数options和useradd的类似,但是可以使用-l参数来修改用户名,ex：usermod -l new_name old_name #添加组 groupadd [options] \u0026lt;group_name\u0026gt; options: -g 指定组编号 #删除分组 groupdel \u0026lt;group_name\u0026gt; #修改组 groupmod [options] \u0026lt;group_name\u0026gt; options:和groupadd类似但是可以使用-n参数来修改组名,ex：groupmod -n new_group_name old_group_name #用户密码管理 passwd [options] \u0026lt;user_name\u0026gt; 如果不指定参数的话那么可以给用户设置密码，如果指定参数的话则用户下次登录就要相关限制 options: -d 删除密码，以后该用户登录就没有密码了 -l 锁定账户 -u 解锁账户 -f 强制执行 tail 查看文件末内容\n#默认显示文件的最后10行 tail /filename #-f参数可使循环读取，在读取日志文件时可以实时查看日志 tail -f xxx.log #-n参数可以指定显示文件末的行数，默认为10 tail -n 20 -f xxx.log linux链接 硬连接：多个文件的副本，会随任意文件的修改而修改，但是删除其中的文件，并不会影响其他文件\n软连接：软连接相当于创建了一个快捷方式，删除软连接不影响源文件\necho \u0026#34;init\u0026#34; \u0026gt; f1.txt #对f1.txt创建名为f2.txt的硬连接 ln f1.txt f2.txt # -s参数指定创建软连接 ln -s [链接指向的目标] [软链接名称] ln -s f1.txt f3.txt ls -li 1094956 -rw-rw-r-- 2 aiiqh aiiqh 5 Oct 13 12:01 f1.txt 1094956 -rw-rw-r-- 2 aiiqh aiiqh 5 Oct 13 12:01 f2.txt #inode号相同 1094958 lrwxrwxrwx 1 aiiqh aiiqh 6 Oct 13 12:01 f3.txt -\u0026gt; f1.txt rm -f f1.txt cat f2.txt #init cat f3.txt #cat: f3.txt: No such file or directory 查看文件夹内文件大小 cd / du -h --max-depth=1 nc 用于快速启动一个tcp或udp服务器\n#安装 yum install -y nc #使用-l xxx参数用于启动一个在指定端口上的tcp(默认)服务 nc -l 5000 #使用-w xxx参数指定建立连接的超时时间 nc -l 5000 -w 5 #使用nc ip 端口号 来与外部tcp服务建立连接 nc 127.0.0.1 22 #使用-k参数来指定允许多个连接，不指定该参数默认只允许建立一个链接 nc -l 5000 -k #使用-v参数来显示详细信息 nc -l 5000 -v #使用-u参数来指定使用udp，不使用该参数默认使用tcp nc -l 5000 -uv nc -u 127.0.0.1 5000 #使用-p参数来指定使用的源端口 nc -u -p 8888 127.0.0.1 5000 lsns lsns用于查看linux下的namespace\nlsns -t {namespace} lsns -t pid lsns -t net brctl [root@centos72 ~]# brctl -bash: brctl: command not found yum install -y bridge-utils #创建虚拟网桥 brctl addbr br0 #查看 ip a 11: br0: \u0026lt;BROADCAST,MULTICAST\u0026gt; mtu 1500 qdisc noop state DOWN group default qlen 1000 link/ether 92:47:2a:9f:bf:3f brd ff:ff:ff:ff:ff:ff #关闭STP(生成树协议)因为我们只有一个路由器，是绝对不可能形成一个环的 brctl stp br0 off #添加以太物理接口 brctl addif br0 ens33 #删除网桥物理接口 brctl delif br0 ens33 #给网桥分配一个ip地址 ifconfig br0 172.18.0.1 #启用网桥 ifconfig br0 up #关闭网桥 ifconfig br0 down #删除网桥 brctl delbr b grep grep用于过滤字符，适用于进行日志查询，grep不会一次把所有内容加载到内存，而是一次加载一部分进行匹配后继续向下匹配，相较于cat、vim、more更适用于大量日志分析。\n-C 参数用于指定显示匹配内容上下文的行数，即匹配内容的上下n行都会输出 grep -C 5 \u0026#39;aaa\u0026#39; text -B参数指定显示匹配内容及前n行 -A参数指定显示匹配内容及后n行 -I 忽略大小写 -o 只显示匹配的内容 -c 统计过滤到的内容的行数 -n 显示行号 -v 剔除匹配到的内容 - w 精确 #基础正则，直接用grep就可以使用 . 表示任意字符 grep \u0026#39;A.C\u0026#39; text #可匹配ABC A1C A+C ... ^ 匹配行开头 $ 匹配行结尾 ^$ 匹配空行 * 表示前一个字符出现0次或0次以上 .* 表示匹配任意字符，包括空行 0* 会匹配到任意字符，因为*表示0个或0个以上字符，所以可以匹配到空字符，而每个行都有空字符 [] 中括号表示匹配中括号的内的任一字符，中括号内如果有特殊字符，那么这些字符都被去除特殊含义 grep \u0026#39;[abc]123\u0026#39; #可以匹配 a123 b123 c123 grep \u0026#39;[a-c]123\u0026#39; #同上 grep \u0026#39;[abc|.,]123\u0026#39; #中括号内的 | . , 都被去除特殊含义，可以匹配到 |123 .123 ,123 #扩展正则，使用grep -E 或 egrep + 前一个字符出现了0次以上 | 表示或者 grep -E \u0026#39;abc|123\u0026#39; #匹配abc 或 123 () 作为一个整体，可看做一个字符 grep -E \u0026#39;a(b|c)d\u0026#39; #匹配 abd 或 acd {m,n} 表示前一次字符出现几次 grep -E \u0026#39;abc{1,3}\u0026#39; #c出现1次以上3次即一下 匹配 abc abcc abccc grep -E \u0026#39;abc{1,}\u0026#39; #只指定最少出现几次，而不指定上界 grep -E \u0026#39;abc{,3}\u0026#39; #只指定上界，而不指定下界 grep -E \u0026#39;abc{1}\u0026#39; #恰好出现几次 ，匹配abc grep -E \u0026#39;(a{1,}b{1,}c{1,}){1,}\u0026#39; #匹配 abc aabbcc aabbccc ? 指定前一个字符出现0次或一次 grep -E \u0026#39;abc?\u0026#39; #匹配ab 或 abc EOF 向文件test.sh里输入内容\n[root@slave-server opt]# cat \u0026lt;\u0026lt; EOF \u0026gt;test.sh 123123123 3452354345 asdfasdfs EOF cat \u0026lt;\u0026lt; EOF \u0026gt; test.go package main import ( \u0026#34;fmt\u0026#34; \u0026#34;runtime\u0026#34; ) func main() { fmt.Println(\u0026#34;cpu:\u0026#34;, runtime.NumCPU()) } EOF alias 设置别名:\nalias k=\u0026#39;kubectl\u0026#39; 查看已经设置的别名：\nalias -p 删除别名：\nunalias k 设置别名每次登陆可用：\n默认使用 alias 设置的别名仅本次登陆有效，如果想每次登陆都能使用别名，可以把alias设置别名的命令放在~/.bashrc文件中。\n清空文件内容 使用vi/vim打开文件，输入%d即清空,:wq保存即可 使用cat /dev/null \u0026gt; file 使用echo \u0026quot;\u0026quot; \u0026gt; file shell脚本中路径问题 在shell中如果通过$PWD获取路径，那么获取到的值是指向shell脚本时的路径,如test.sh脚本在/etc路径下，但是执行的时候是在/root路径下执行./etc/test.sh那么$PWD获取到的值就是/root\nbase64 base64加密 base64 \u0026lt;file_name\u0026gt; echo \u0026#34;abc\u0026#34; | base64 base64解码 base64 -d \u0026lt;file_name\u0026gt; echo \u0026#34;YWJjCg==\u0026#34; | base64 -d 环境变量 KUBECONFIG=config.yaml k get ns #暴露的环境变量仅改行命令有效 export KUBECONFIG=config.yaml #暴露的环境变量当前终端有效，新开的终端对该环境变量不可见 k get ns 常用快捷键 #清屏 ctrl + l #跳转到上一条历史命令,相当于 ↑键 ctrl + p #跳转到下一条命令,相当于 ↓键 ctrl + n #删除光标指向字符 ctrl + d #命令行中向前移动一个字符 ctrl + b #命令行中向后移动一个字符 ctrl + f #命令行中向前移动一个单词 alt + b #命令行中向后移动一个单词 alt + f #移动到命令行最前端 ctrl + a #移动到命令行最后端 ctrl + e #停止记录命令行输入 ctrl + s #回复记录命令行输入 ctrl + q #根据关键字搜索历史命令，如果有多条命令被匹配到可以ctrl + r 进行切换选择，然后按tab可以把该命令显示到命令行，或者直接enter直接执行该命令 ctrl + r 查看端口占用 # -a 参数列出所有状态的端口占用，监听的端口、已建立连接的端口 # -n 参数不进行name解析显示ip地址 # -p 参数显示端口相关程序的pid # -t 参数显示tcp相关的端口占用 # -u 参数显示udp相关的端口占用 netstat -anp 脚本后台运行 使用\u0026amp;在终端断连之后继续执行:sh test.sh \u0026gt; test.log \u0026amp; 使用nohup加\u0026amp;可以在终端断连之后继续执行：nohup sh test.sh \u0026gt; test.log \u0026amp; linux运行级别 # 0 关机 # 1 单用户 # 2 多用户，无网络模式 # 3 完全多用户模式 # 4 用户自定义级别 # 5 图形化界面多用户 # 6 重启 runlevel N 3 init 命令加对应的级别可以切换到不同的级别 init 6 正则 标准正则 匹配开头\n[root@centos72 shell_t]# cat /etc/passwd |grep ^a adm:x:3:4:adm:/var/adm:/sbin/nologin 匹配结尾\n[root@centos72 shell_t]# cat /etc/passwd |grep n$ bin:x:1:1:bin:/bin:/sbin/nologin daemon:x:2:2:daemon:/sbin:/sbin/nologin adm:x:3:4:adm:/var/adm:/sbin/nologin . 号,匹配任意一个字符\n[root@centos72 shell_t]# cat /etc/passwd |grep r..t root:x:0:0:root:/root:/bin/bash operator:x:11:0:operator:/root:/sbin/nologin ftp:x:14:50:FTP User:/var/ftp:/sbin/nologin dockerroot:x:991:988:Docker User:/var/lib/docker:/sbin/nologin * 号，不单独使用，表示匹配*号之前的字符0次或多次\n#ro*t 匹配 rot root roooot [root@centos72 shell_t]# cat /etc/passwd |grep ro*t root:x:0:0:root:/root:/bin/bash operator:x:11:0:operator:/root:/sbin/nologin dockerroot:x:991:988:Docker User:/var/lib/docker:/sbin/nologin .* 匹配任意一个字符任意次，即匹配任意字符串\n[root@centos72 shell_t]# cat /etc/passwd |grep r.*t root:x:0:0:root:/root:/bin/bash operator:x:11:0:operator:/root:/sbin/nologin ftp:x:14:50:FTP User:/var/ftp:/sbin/nologin [] 匹配字符区间\n[6,8] 匹配6或者8 [0-9] 匹配0-9的任意数字 [^0-9] 匹配任意非数字字符 [0-9]* 匹配任意数字串 [a-z] 匹配a-z的字符 [a-Z] 匹配a-Z的任意字符 [root@centos72 shell_t]# cat /etc/passwd |grep r[a-z]*t root:x:0:0:root:/root:/bin/bash operator:x:11:0:operator:/root:/sbin/nologin sshd:x:74:74:Privilege-separated SSH:/var/empty/sshd:/sbin/nologin rabbitmq:x:997:995:RabbitMQ messaging server:/var/lib/rabbitmq:/bin/bash gitlab-prometheus:x:992:989::/var/opt/gitlab/prometheus:/bin/sh dockerroot:x:991:988:Docker User:/var/lib/docker:/sbin/nologin \\转义\n#匹配$ grep \\$ test.sh 扩展正则 {}指定前一个字符出现几次\n{n}这种写法是扩展正则，grep使用扩展正则需要加 -E 参数 [root@centos72 shell_t]# grep -E ro{2}t /etc/passwd root:x:0:0:root:/root:/bin/bash operator:x:11:0:operator:/root:/sbin/nologin dockerroot:x:991:988:Docker User:/var/lib/docker:/sbin/nologin #{n,}匹配前一个字符至少n次 [root@centos72 shell_t]# grep -E \u0026#34;ro{0,}t\u0026#34; /etc/passwd root:x:0:0:root:/root:/bin/bash operator:x:11:0:operator:/root:/sbin/nologin dockerroot:x:991:988:Docker User:/var/lib/docker:/sbin/nologin #{,n}匹配前一个字符至多n次 [root@centos72 shell_t]# grep -E \u0026#34;ro{,2}t\u0026#34; /etc/passwd root:x:0:0:root:/root:/bin/bash operator:x:11:0:operator:/root:/sbin/nologin dockerroot:x:991:988:Docker User:/var/lib/docker:/sbin/nologin {n,m}匹配前一个字符n到m次 [root@centos72 shell_t]# grep -E \u0026#34;ro{1,2}t\u0026#34; /etc/passwd root:x:0:0:root:/root:/bin/bash operator:x:11:0:operator:/root:/sbin/nologin dockerroot:x:991:988:Docker User:/var/lib/docker:/sbin/nologin +号匹配前一个字符一次及以上\ncat \u0026lt;\u0026lt; EOF | grep -E \u0026#34;go+\u0026#34; g go goo goole EOF go goo goole ?号匹配前一个字符0次或一次\ncat \u0026lt;\u0026lt; EOF | grep -E \u0026#34;go?\u0026#34; g go goo goole EOF g #匹配到g go #匹配到go goo #匹配到go goole #匹配到go 匹配13开头的手机号码\ngrep -E \u0026#34;13[0-9]{9}\u0026#34; phone.txt cat cat命令用来查看一个文件的内容\ncat test.sh cat命令配合EOF加输出重定向可以向文件中写入内容\ncat \u0026lt;\u0026lt;EOF \u0026gt; test.sh name=\u0026#34;tom\u0026#34; echo \u0026#34;hello,\\${name}!\u0026#34; #在EOF中使用$需要加\\转移 EOF cat test.sh name=\u0026#34;tom\u0026#34; echo \u0026#34;hello, ${name}!\u0026#34; cut cut命令用于获取文件指定的列，并输出到标准输出\n#-d指定分隔符 -f指定列 cat \u0026lt;\u0026lt;EOF | cut -d \u0026#34; \u0026#34; -f 1 tom man 20 jerry female 18 jack man 25 EOF tom jerry jack cat \u0026lt;\u0026lt;EOF | cut -d \u0026#34; \u0026#34; -f 1,2 tom man 20 jerry female 18 jack man 25 EOF tom man jerry female jack man cat \u0026lt;\u0026lt;EOF | cut -d \u0026#34; \u0026#34; -f 1-2 tom man 20 jerry female 18 jack man 25 EOF tom man jerry female jack man cat \u0026lt;\u0026lt;EOF | cut -d \u0026#34; \u0026#34; -f -2 tom man 20 jerry female 18 jack man 25 EOF tom man jerry female jack man cat \u0026lt;\u0026lt;EOF | cut -d \u0026#34; \u0026#34; -f 2- tom man 20 jerry female 18 jack man 25 EOF man 20 female 18 man 25 获取ip地址\nifconfig ens33 |grep netmask |cut -d \u0026#34; \u0026#34; -f 10 192.168.37.131 grep grep用于配合正则按行过滤数据\ncat \u0026lt;\u0026lt;EOF | grep \u0026#39;go\u0026#39; g go goole EOF go goole # -E 指定使用扩展正则 cat \u0026lt;\u0026lt;EOF | grep -E \u0026#39;go+\u0026#39; g go goole EOF go #匹配到go goole #匹配到goo # -m 参数指定输出的最大行数 cat \u0026lt;\u0026lt;EOF | grep -m 1 -E \u0026#39;go+\u0026#39; g go goole EOF go # -c 参数指定输出匹配到的行数 cat \u0026lt;\u0026lt;EOF | grep -c -E \u0026#39;go+\u0026#39; g go goole EOF 2 # -i 参数指定忽略匹配正则的大小写 cat \u0026lt;\u0026lt;EOF | grep -i -E \u0026#39;go+\u0026#39; g go Go goole EOF go Go goole # -v 参数指定输出匹配到的行以外的行 cat \u0026lt;\u0026lt;EOF | grep -v -E \u0026#39;go+\u0026#39; g go Go goole EOF g Go # -w 参数指定正则要匹配整个单词 cat \u0026lt;\u0026lt;EOF | grep -w -E \u0026#39;go+\u0026#39; g go Go goole EOF go # -x 参数指定正则要匹配一整行的内容 cat \u0026lt;\u0026lt;EOF | grep -x -E \u0026#39;go+\u0026#39; g go go is good goole EOF go # -o 参数指定只显示匹配到的内容，对于同一行有多个匹配到的内容会隔行显示 cat \u0026lt;\u0026lt;EOF | grep -o -E \u0026#39;go+\u0026#39; g go go is good goole EOF go go goo goo sed sed针对文件的每一行进行处理，把一行读入放入模式空间，然后对模式空间的数据进行处理(增加/修改/删除)后输出到屏幕，直到处理完文件的每一行,处理完毕后并不会改变源文件，只会把处理后的结果输出到屏幕，改变源文件需要配合输出重定向\n-e 参数指定多次编辑(可以写多个规则) cat \u0026lt;\u0026lt;EOF \u0026gt; test.txt line1 name tom line2 age 20 line3 gender man EOF sed -e \u0026#34;1p\u0026#34; -n test.txt # p参数指定打印行为 -n参数取消默认打印，只输出匹配到的行 line1 name tom sed -e \u0026#34;/name/p\u0026#34; -n test.txt # 模糊匹配存在name的行 line1 name tom sed -e \u0026#34;/^line2/p\u0026#34; -n test.txt line2 age 20 sed -e \u0026#34;1,2p\u0026#34; -n test.txt # 1,2 指定第一行和第二行 line1 name tom line2 age 20 sed -e \u0026#34;2~1p\u0026#34; -n test.txt # 2~1 指定从第二行开始，已1步长匹配行 line2 age 20 line3 gender man sed -e \u0026#34;2~2p\u0026#34; -n test.txt line2 age 20 sed -e \u0026#34;2,+3p\u0026#34; -n test.txt # 2,+3 表示从第二行开始匹配向下三行(包括本行) line2 age 20 line3 gender man sed -e \u0026#34;2,\\$p\u0026#34; -n test.txt # 2,\\$ 表示匹配从第二行开始一直到结尾的行 line2 age 20 line3 gender man sed -e \u0026#34;1d\u0026#34; test.txt # d参数指定删除的行 line2 age 20 line3 gender man sed -e \u0026#34;1d\u0026#34; -e \u0026#34;s/age 20/age 30/g\u0026#34; test.txt # s参数指定进行替换，g是全局 line2 age 30 line3 gender man cat test.txt #源文件内容没有变 line1 name tom line2 age 20 line3 gender man sed -e \u0026#34;1a hight 170cm\u0026#34; test.txt # a参数指定在指定的行后添加一行/多行 line1 name tom hight 170cm line2 age 20 line3 gender man sed -e \u0026#34;1i weight 55kg\u0026#34; test.txt # i参数指定在指定的行前插入一行/多行 weight 55kg line1 name tom line2 age 20 line3 gender man #输出结果重定向 sed -e \u0026#34;1a hight 170cm\u0026#34; test.txt \u0026gt; test.txt -n 参数指定只输出匹配到的被处理的内容 sed -e \u0026#34;1p\u0026#34; -n test.txt # p参数指定打印行为 -n参数取消默认打印，只输出匹配到的行 line1 name tom -i 参数指定修改应用到源文件 cat test.txt line1 name tom line2 age 20 line3 gender man sed -i -e \u0026#34;s/age 20/age 30/g\u0026#34; test.txt cat test.txt line1 name tom line2 age 30 line3 gender man -r 参数指定开启扩展正则 cat \u0026lt;\u0026lt;EOF \u0026gt; test.txt go goo goole EOF sed -e \u0026#34;s/go+/x/g\u0026#34; test.txt # 不加-r参数由于+是扩展正则，所以不能匹配到任何的内容 go goo goole sed -r -e \u0026#34;s/go+/x/g\u0026#34; test.txt x x xle sed取ip地址 ifconfig ens33 | sed \u0026#39;2p\u0026#39; -n | sed \u0026#34;s/^.*inet//g\u0026#34; | sed \u0026#34;s/netmask.*$//g\u0026#34; 192.168.37.131 #前后有空格 ifconfig ens33 | sed -e \u0026#34;2s/^.*inet//\u0026#34; -n -e \u0026#34;s/netmask.*$//p\u0026#34; -n 192.168.37.131 awk awk通过正则过滤到匹配的行，然后对行进行切片(默认以空格)，然后对每个切片进行处理\n# -F 参数指定行分隔符 cat /etc/passwd | awk -F \u0026#34;:\u0026#34; \u0026#39;/^root/ {print $7}\u0026#39; /bin/bash cat /etc/passwd | awk -F \u0026#34;:\u0026#34; \u0026#39;/^root/ {print $1 \u0026#34;,\u0026#34; $7}\u0026#39; root,/bin/bash # BEGIN代码块在过滤之前执行 END代码块在过滤结束之后执行 cat /etc/passwd | awk -F \u0026#34;:\u0026#34; \u0026#39;BEGIN{print \u0026#34;start\u0026#34;}{print $1\u0026#34;=\u0026#34;$7}END{print \u0026#34;stop\u0026#34;}\u0026#39; start root=/bin/bash bin=/sbin/nologin daemon=/sbin/nologin stop cat /etc/passwd | awk -F \u0026#34;:\u0026#34; \u0026#39;{print $3+1}\u0026#39; 1 2 3 4 5 # 使用-v参数可以像awk中的变量赋值 cat /etc/passwd | awk -F \u0026#34;:\u0026#34; -v num=1 \u0026#39;{print $3+num}\u0026#39; # 内置变量 # FILENAME 文件名 # NR 行号 # NF 列号 cat /etc/passwd | awk -F \u0026#34;:\u0026#34; \u0026#39;{print \u0026#34;filename=\u0026#34;FILENAME, \u0026#34;row_number=\u0026#34;NR, \u0026#34;col_number\u0026#34;NF}\u0026#39; [root@centos72 shell_t]# cat /etc/passwd | awk -F \u0026#34;:\u0026#34; \u0026#39;{print \u0026#34;filename=\u0026#34;FILENAME, \u0026#34;row_number=\u0026#34;NR, \u0026#34;col_number\u0026#34;NF}\u0026#39; filename=- row_number=1 col_number7 filename=- row_number=2 col_number7 filename=- row_number=3 col_number7 awk截取ip\nifconfig | awk \u0026#39;/netmask/ {print $2}\u0026#39; 172.17.0.1 192.168.37.131 127.0.0.1 sort cat \u0026lt;\u0026lt;EOF \u0026gt; sort.txt aa:1:tom bb:0:jack dd:5:jarry cc:4:lucy ee:3:mike EOF sort sort.txt #按照字母序排序 aa:1:tom bb:0:jack cc:4:lucy dd:5:jarry ee:3:mike sort -r sort.txt #-r指定降序排序 ee:3:mike dd:5:jarry cc:4:lucy bb:0:jack aa:1:tom sort -t : -k 2 sort.txt #-t指定分隔符 -k指定对哪一列排序 bb:0:jack aa:1:tom ee:3:mike cc:4:lucy dd:5:jarry nohup nohup命令将程序以忽略挂起信号的方式后台运行，输出的结果不打印到终端而是保存在当前目录的nohup.out文件中，如果当前目录下的nohup.out文件无法写入会保存到$HOME/nohup.out文件中\nnohup ping baidu.com nohup: ignoring input and appending output to ‘nohup.out’ #进程会hang在这儿，不能执行其他命令，如果ctrl+c结束程序，那么执行的程序也会停止 nohup ping bilibili.com \u0026amp; nohup: ignoring input and appending output to ‘nohup.out’ #进程会hang在这儿,但是ctrl+c结束结束程序后，执行的程序不会停止 nohup ping baidu.com \u0026gt; ping.log \u0026amp; # 把程序的标准输出重定向到指定文件 nohup ping baidu.com \u0026gt;ping.log \u0026amp; # 标准输出 1 # 标准错误输出 2 nohup ping baidu.com \u0026gt; ping.log 2\u0026gt;\u0026amp;1 \u0026amp; # 把程序的标准输出及出错信息都写入到指定文件 nohup ping baidu.com \u0026gt; /dev/null 2\u0026gt;\u0026amp;1 \u0026amp; # 把程序的输出写入到linux的黑洞文件立即销毁 把程序的标准输出和标准错误输出写入文件\n# 把标准输出写入app.log,标准错误输出写入err.log nohup ping baidu.com \u0026gt; ping-app.log 2\u0026gt;ping-err.log \u0026amp; nohup ping baidu.com 1\u0026gt;ping-app.log 2\u0026gt;ping-err.log \u0026amp; # 把标准输出标准错误输出都写入app.log文件 nohup ping baidu.com \u0026gt; app.log 2\u0026gt;\u0026amp;1 \u0026amp; nohup ping baidu.com \u0026amp;\u0026gt;app.log \u0026amp; nohup 执行的命令后如果要结束程序就需要取查进程号kill\nps -ef|grep stdout UID PID PPID C STIME TTY TIME CMD aiiqh 798370 798026 0 09:26 pts/0 00:00:00 python3 stdout_stderr.py aiiqh 799200 798026 0 09:59 pts/0 00:00:00 grep --color=auto stdout kill 798370 定时任务 at at命令可用于执行定时任务，但是只执行一次，at定时任务的执行依赖atd后台服务，所以需要确保atd在后台运行\nat定时任务也只能精确到分钟\n[root@centos72 shell_t]# at 09:40 at\u0026gt; echo \u0026#34;$(date +%H:%M:%S)\u0026#34; \u0026gt; at.log at\u0026gt; \u0026lt;EOT\u0026gt; job 9 at Thu Oct 6 09:40:00 2022 batch batch命令用于在指定时间，当系统不繁忙时执行任务，用法与at相似\nbatch at\u0026gt; echo \u0026#34;$(date +%H:%M:%S)\u0026#34; \u0026gt; batch.log crontab crontab依赖crond后台进程每分钟检查一次定时任务进行执行 crond检查/var/spool/cron文件夹下的文件进行解析执行里面的定时任务，除此之外还会检查 /etc/cron.d目录以及 /etc/anaccrontab里面存放的是每小时、每天、每周、每月需要执行的定时任务\ncrontab -e * * * * * sh test.sh #第一个*是分钟 #第二个*是小时 #第三个*是天 #第四个*是月 #第五个*是星期几 # Example of job definition: # .---------------- minute (0 - 59) # | .------------- hour (0 - 23) # | | .---------- day of month (1 - 31) # | | | .------- month (1 - 12) OR jan,feb,mar,apr ... # | | | | .---- day of week (0 - 6) (Sunday=0 or 7) OR sun,mon,tue,wed,thu,fri,sat # | | | | | # * * * * * user-name command to be executed #特殊符号 # * 代表每的意思 * * * * * 代表每分钟执行一次 # - 代表范围的意思 1-10 * * * * 代表每小时的0到10分钟之内都执行意思 # , 代表分割 1,3,5 * * * * 代表每小时的第一、三、五分钟执行 # /n 每隔n执行 */5 * * * * 每五分钟执行一次 0 7-11/2 * * * 每天7点到11点每隔2小时执行一次 30 10/2 * * * 从10点30分开始每2小时执行一次 或者直接编辑 /var/spool/cron/root 要删除定时任务也可以 crontab -e 或者编辑 /var/spool/cron/root 删除 定时任务执行后会发送一个邮件给linux用户，使用(postfix服务),会提示you have mail in /var/spool/mail/root\nsu myd [myd@centos72 root]$ mailx -s \u0026#34;test\u0026#34; root hello, i am myd! . EOT exit [root@centos72 ~]# mail Heirloom Mail version 12.5 7/5/10. Type ? for help. \u0026#34;/var/spool/mail/root\u0026#34;: 1363 messages 1 new 1338 unread U1361 (Cron Daemon) Sun Oct 2 18:15 29/1053 \u0026#34;Cron \u0026lt;root@centos72\u0026gt; sh /root/shell_t/test.sh /root/shell_t /root/backup2\u0026#34; U1362 (Cron Daemon) Sun Oct 2 18:16 29/1053 \u0026#34;Cron \u0026lt;root@centos72\u0026gt; sh /root/shell_t/test.sh /root/shell_t /root/backup2\u0026#34; \u0026gt;N1363 myd@centos72.localdo Thu Oct 6 09:23 18/601 \u0026#34;test\u0026#34; \u0026amp; 1363 Message 1363: From myd@centos72.localdomain Thu Oct 6 09:23:49 2022 Return-Path: \u0026lt;myd@centos72.localdomain\u0026gt; X-Original-To: root Delivered-To: root@centos72.localdomain Date: Thu, 06 Oct 2022 09:23:49 +0800 To: root@centos72.localdomain Subject: test User-Agent: Heirloom mailx 12.5 7/5/10 Content-Type: text/plain; charset=us-ascii From: myd@centos72.localdomain Status: R hello, i am myd! \u0026amp; #发送文件夹中的内容 mailx -s \u0026#34;test\u0026#34; root \u0026lt; test.mail exit [root@centos72 ~]# mail Heirloom Mail version 12.5 7/5/10. Type ? for help. \u0026#34;/var/spool/mail/root\u0026#34;: 1366 messages 3 new 1340 unread U1361 (Cron Daemon) Sun Oct 2 18:15 29/1053 \u0026#34;Cron \u0026lt;root@centos72\u0026gt; sh /root/shell_t/test.sh /root/shell_t /root/backup2\u0026#34; U1362 (Cron Daemon) Sun Oct 2 18:16 29/1053 \u0026#34;Cron \u0026lt;root@centos72\u0026gt; sh /root/shell_t/test.sh /root/shell_t /root/backup2\u0026#34; 1363 myd@centos72.localdo Thu Oct 6 09:23 19/612 \u0026#34;test\u0026#34; \u0026gt;N1364 myd@centos72.localdo Thu Oct 6 09:26 16/637 \u0026#34;*** SECURITY information for centos72 ***\u0026#34; N1365 myd@centos72.localdo Thu Oct 6 09:27 16/637 \u0026#34;*** SECURITY information for centos72 ***\u0026#34; N1366 myd@centos72.localdo Thu Oct 6 09:28 18/606 \u0026#34;test\u0026#34; \u0026amp; 1366 Message 1366: From myd@centos72.localdomain Thu Oct 6 09:28:46 2022 Return-Path: \u0026lt;myd@centos72.localdomain\u0026gt; X-Original-To: root Delivered-To: root@centos72.localdomain Date: Thu, 06 Oct 2022 09:28:46 +0800 To: root@centos72.localdomain Subject: test User-Agent: Heirloom mailx 12.5 7/5/10 Content-Type: text/plain; charset=us-ascii From: myd@centos72.localdomain Status: R content from txt file \u0026amp; 向指定登陆的终端发送信息 ps -ef|grep ssh aiiqh 798025 797922 0 09:07 ? 00:00:00 sshd: aiiqh@pts/0 echo \u0026#34;msg\u0026#34; \u0026gt;\u0026gt; /dev/pts/0 获取后台执行程序的输出 参考链接：https://juejin.cn/post/7089818727524335630\n在linux的/proc/{pid}/fd目录下存在三个文件\n标准输入，描述符为 0，默认就是键盘输入 标准输出，描述符为 1，默认就是输出到屏幕 标准输出，描述符为 2，默认还是输出到屏幕 使用测试程序进行测试 stdout_stderr.py:\nimport time import sys while True: ts = int(time.time()) if ts % 2 == 0: print(f\u0026#34;stdout now time is {ts}\u0026#34;, file=sys.stdout) sys.stdout.flush() #不缓存 else: print(f\u0026#34;stderr now time is {ts}\u0026#34;, file=sys.stderr) sys.stderr.flush() #不缓存 time.sleep(1) 后台运行\n#使用nohup命令后台运行程序，程序运行输出会被nohup进行接管 nohup python3 stdout_stderr.py \u0026amp; #或者 #必须要指定日志输出文件才行，/dev/null 这种都不会生效 python3 stdout_stderr.py \u0026amp;\u0026gt;stdout_stderr.log \u0026amp; ps -ef|grep stdout aiiqh 798370 798026 0 09:26 pts/0 00:00:00 python3 stdout_stderr.py aiiqh 799007 798026 0 09:49 pts/0 00:00:00 grep --color=auto std pid 798370 是nohup程序 pid 798026 是python3程序 #由于python3的输出被nohup接管了，所以取nohup里查看 cd /proc/798370/fd ls -la total 0 dr-x------ 2 aiiqh aiiqh 0 Oct 22 09:44 . dr-xr-xr-x 9 aiiqh aiiqh 0 Oct 22 09:26 .. l-wx------ 1 aiiqh aiiqh 64 Oct 22 09:44 0 -\u0026gt; /dev/null l-wx------ 1 aiiqh aiiqh 64 Oct 22 09:44 1 -\u0026gt; /home/aiiqh/python_proj/script/nohup.out l-wx------ 1 aiiqh aiiqh 64 Oct 22 09:44 2 -\u0026gt; /home/aiiqh/python_proj/script/nohup.out #查看标准输出 tail -f 1 #查看标准错误输出 tail -f 2 head head 命令用于查看文件的头部信息\ncat \u0026lt;\u0026lt;EOF \u0026gt; test-head.txt this is line 1 this is line 2 this is line 3 this is line 4 this is line 5 this is line 6 this is line 7 this is line 8 this is line 9 this is line 10 this is line 11 this is line 12 EOF #默认显示十行 head test-head.txt this is line 1 this is line 2 ... this is line 9 this is line 10 #-n参数指定显示几行 head -n 5 test-head.txt this is line 1 this is line 2 this is line 3 this is line 4 this is line 5 #-c参数指定显示几字节 head -c 50 test-head.txt this is line 1 this is line 2 this is line 3 this tail tail 命令用于查看文件的末端内容\n#默认显示文件的最后10行 tail test-head.txt this is line 3 this is line 4 this is line 5 this is line 6 this is line 7 this is line 8 this is line 9 this is line 10 this is line 11 this is line 12 #-n参数用于指定查看文件的最后几行 tail -n 5 test-head.txt this is line 8 this is line 9 this is line 10 this is line 11 this is line 12 #-c参数用于指定查看文件的最后几字节 tail -c 50 test-head.txt 9 this is line 10 this is line 11 this is line 12 #-f参数用于指定循环读取，文件有新内容追加会进行打印 tail -f test-head.txt this is line 3 this is line 4 this is line 5 this is line 6 this is line 7 this is line 8 this is line 9 this is line 10 this is line 11 this is line 12 more more 与 cat命令类似，以分页的形式查看文件\n#-{num}参数指定一页显示几行 #+{num}参数指定从第几行开始 #enter 用于显示下一行 #space 用于显示下一页 #b 用于回到上一页 #q 用于退出 #v 用于调期vi指令并指向当前行,退出后还是more命令 more -3 +2 test-head.txt this is line 2 this is line 3 this is line 4 --More--(32%) netstat netstat 用于显示linux网络状态\n#-a 参数用于所有socket #-n或--numeric 直接使用IP地址，而不显示域名 #-p或--programs 显示正在使用Socket的程序识别码和程序名称 #-t或--tcp 显示TCP传输协议的连线状况 #-u或--udp 显示UDP传输协议的连线状况 netstat -anp (Not all processes could be identified, non-owned process info will not be shown, you would have to be root to see it all.) Active Internet connections (servers and established) Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp 0 0 127.0.0.1:33491 0.0.0.0:* LISTEN - tcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN - tcp 0 0 127.0.0.1:45227 0.0.0.0:* LISTEN 3761/node tcp 0 0 127.0.0.53:53 0.0.0.0:* LISTEN - tcp 0 0 127.0.0.1:45227 127.0.0.1:46626 ESTABLISHED 4224/node tcp 0 0 127.0.0.1:50826 127.0.0.1:45227 ESTABLISHED - tcp 0 0 127.0.0.1:45227 127.0.0.1:58744 ESTABLISHED 5070/node ... udp 0 0 127.0.0.53:53 0.0.0.0:* - udp 0 0 192.168.52.128:68 0.0.0.0:* - raw6 0 0 :::58 :::* 7 - Active UNIX domain sockets (servers and established) Proto RefCnt Flags Type State I-Node PID/Program name Path unix 2 [ ACC ] STREAM LISTENING 32724 - /run/dbus/system_bus_socket unix 2 [ ACC ] STREAM LISTENING 32726 - /run/docker.sock unix 2 [ ACC ] STREAM LISTENING 14730 - /run/snapd.socket unix 2 [ ACC ] STREAM LISTENING 14732 - /run/snapd-snap.socket unix 2 [ ACC ] STREAM LISTENING 14734 - /run/uuidd/request ","permalink":"https://moyuduo.github.io/posts/linux%E5%91%BD%E4%BB%A4%E8%87%AA%E6%9F%A5/","summary":"linux命令自查 查看cpu和内存 cpu个数 cat /proc/cpuinfo | grep \u0026#34;physical id\u0026#34; | uniq | wc -l cpu核数 cat /proc/cpuinfo | grep \u0026#34;cpu cores\u0026#34; | uniq cpu型号 cat /proc/cpuinfo | grep \u0026#39;model name\u0026#39; |uniq 内存大小 cat /proc/meminfo | grep MemTotal 设置linux开机自启动 linux文件/etc/rc.local文件中的内容会linux启动完成后执行，所以可以用来做开机自启动，/etc/rc.local默认是lrwxrwxrwx权限，但是由于它是/etc/rc.d/rc.local的一个软连接，所以/etc/rc.d/rc.local这个文件必须要有执行权限才能开机自启动，而这个人间默认是-rw-rw-rw-权限，所以必须要修改添加执行权限,注意在这个文件中添加开机执行死循环脚本时必须使用\u0026amp;后台执行。\n秒级检测脚本 #!/bin/bash while true do count=`ps -ef|grep etcd|grep -v grep|wc -l` if [ $count -eq 0 ]; then cd /opt/etcd-v3.5.0-linux-amd64 ./etcd -listen-client-urls=\u0026#34;http://0.0.0.0:2379\u0026#34; --advertise-client-urls=\u0026#34;http://0.0.0.0:2379\u0026#34; echo \u0026#34;restart etcd at $(date)\u0026#34; \u0026gt;\u0026gt; /opt/etcd-v3.5.0-linux-amd64/record fi sleep 1 done 原理是通过ps -ef|grep按照条件过滤执行的进程，再通过wc -l转换为进程个数，最后通过shell进行判断。","title":"linux命令自查"},{"content":"makefile 核心 makefile的主要有三个核心：目标、依赖、命令\n目标：一般指要编译的文件对象\n依赖：一般指要生成的可执行文件\n命令：指生成目标要执行的命令\n规则 所有命令都必须用tab缩进，不能使用空格也不行 如果有多个依赖可以用tab、空格分隔，如果一个目标有多个依赖，那么会依次执行依赖的命令，最后执行该目标本身的命令 $^代表所有依赖 $\u0026lt;代表第一个依赖 $@代表目标 使用echo xxx命令会把该命令输出再输出xxx,可以使用@echo xxx来只输出xxx 如果使用空格缩进，那么会报错Makefile:2: *** missing separator. Stop. 一条makefile规则的依赖可以是该makefile中其他规则的目标，那么再执行该规则时，会去执行依赖的规则 使用make命令生成目标时会检测依赖和目标的时间戳，如果目标已经存在且目标的时间戳大于所有依赖，那么意味着依赖并没有改动，那么无需重新生成目标，会提示make: clean\u0026rsquo; is up to date.` 如果一条makefile规则没有依赖且该目标文件存在，那么始终不会执行该规则的命令，而有些时候我会想执行一些清除操作，如rm如果这条规则的目标叫clean，如果恰巧该文件夹下有一个文件叫clean，那么就不能执行清除，此时可以使用.PHONY:clean标记clean目标不需要检查目标文件是否存在，目标文件的时间戳是否大于所有依赖 变量 ###自定义变量\nmakefile中可以将经常使用的命令、依赖定义成变量\nmakefile中变量区分大小写\nmakefile中对变量的引用使用$(xxx)\nmakefile中对变量的定义形式为A=xxx等号两边可以有空格，不需要加引号，因为makefile中变量中油字符串类型\n系统变量 CC：编译器名字，默认CC等于gcc CC = arm-linux-gcc\nRM：删除文件，相当于rm -f\n可以使用$(ENV_NAME)来获取系统定义好的环境变量，如：$(GOPATH) $(JAVA_HOME)\n自动化变量 $^代表所有依赖文件\n$\u0026lt;代表第一个依赖文件\n$@代表目标文件\n伪命令 如果一条makefile规则没有依赖且该目标文件存在，那么始终不会执行该规则的命令，而有些时候我会想执行一些清除操作，如rm如果这条规则的目标叫clean，如果恰巧该文件夹下有一个文件叫clean，那么就不能执行清除，此时可以使用.PHONY:clean标记clean目标不需要检查目标文件是否存在，目标文件的时间戳是否大于所有依赖\n实践 GO= CGO_ENABLED=0 GO111MODULE=on go GOCGO = CGO_ENABLED=1 GO111MODULE=on go #在申明变量时，如果要执行shell中的命令获取值需要使用$(shell xxx)，这是因为如果只使用$(xxx)的话回去取xxx变量的值，而xxx变量不存在，所以要在定义变量时使用shell命令必须使用shell关键字 GP = $(shell go env GOPATH) VERSION = v2.0.0 #commit id GIT_COMMIT=$(shell git rev-parse HEAD) #branch name GIT_BRANCH=$(shell git name-rev --name-only HEAD) #构建时间 BUILD_DATE=$(shell date \u0026#39;+%Y-%m-%d-%H:%M:%S\u0026#39;) #使用go build的-ldflags 参数可以在编译的时候对变量进行赋值，常用在编译时添加版本、架构、编译日期等信息 #使用-X参数进行替换，makef为项目名称，为go mod init makef, version是该项目下的一个包， Version为包中的一个变量 LDFLAGS = -ldflags \u0026#34;-X makef/version.Version=$(VERSION)\u0026#34; add:cmd/add/main.go $(GO) build $(LDFLAGS) -o $@ $^ sub:cmd/sub/main.go $(GOCGO) build $(LDFLAGS) -o $@ $^ # -gcflags指定all=-N可以指定禁止优化， -l禁止内联, 禁止优化和内联可以让运行时(runtime)中的函数变得更容易调试 GOBUILD = $(GOCMD) build -gcflags \u0026#34;all=-N -l\u0026#34; -ldflags \u0026#34;$(LDFLAGS)\u0026#34; #这种写法不行会报错： #CGO_ENABLED=0 GO111MODULE=on go build -ldflags \u0026#34;-X makef/version.Version=v2.0.0\u0026#34; -o add cmd/add #package cmd/add is not in GOROOT (/storehouse/go/src/cmd/add) #make: *** [add] Error 1 add:./cmd/add $(GO) build $(LDFLAGS) -o $@ $^ #这种写法没问题 add: $(GO) build $(LDFLAGS) -o $@ ./cmd/add 当执行make命令时会执行当前目录下的makefile/Makefile中的第一条命令\n","permalink":"https://moyuduo.github.io/posts/makefile/","summary":"makefile 核心 makefile的主要有三个核心：目标、依赖、命令\n目标：一般指要编译的文件对象\n依赖：一般指要生成的可执行文件\n命令：指生成目标要执行的命令\n规则 所有命令都必须用tab缩进，不能使用空格也不行 如果有多个依赖可以用tab、空格分隔，如果一个目标有多个依赖，那么会依次执行依赖的命令，最后执行该目标本身的命令 $^代表所有依赖 $\u0026lt;代表第一个依赖 $@代表目标 使用echo xxx命令会把该命令输出再输出xxx,可以使用@echo xxx来只输出xxx 如果使用空格缩进，那么会报错Makefile:2: *** missing separator. Stop. 一条makefile规则的依赖可以是该makefile中其他规则的目标，那么再执行该规则时，会去执行依赖的规则 使用make命令生成目标时会检测依赖和目标的时间戳，如果目标已经存在且目标的时间戳大于所有依赖，那么意味着依赖并没有改动，那么无需重新生成目标，会提示make: clean\u0026rsquo; is up to date.` 如果一条makefile规则没有依赖且该目标文件存在，那么始终不会执行该规则的命令，而有些时候我会想执行一些清除操作，如rm如果这条规则的目标叫clean，如果恰巧该文件夹下有一个文件叫clean，那么就不能执行清除，此时可以使用.PHONY:clean标记clean目标不需要检查目标文件是否存在，目标文件的时间戳是否大于所有依赖 变量 ###自定义变量\nmakefile中可以将经常使用的命令、依赖定义成变量\nmakefile中变量区分大小写\nmakefile中对变量的引用使用$(xxx)\nmakefile中对变量的定义形式为A=xxx等号两边可以有空格，不需要加引号，因为makefile中变量中油字符串类型\n系统变量 CC：编译器名字，默认CC等于gcc CC = arm-linux-gcc\nRM：删除文件，相当于rm -f\n可以使用$(ENV_NAME)来获取系统定义好的环境变量，如：$(GOPATH) $(JAVA_HOME)\n自动化变量 $^代表所有依赖文件\n$\u0026lt;代表第一个依赖文件\n$@代表目标文件\n伪命令 如果一条makefile规则没有依赖且该目标文件存在，那么始终不会执行该规则的命令，而有些时候我会想执行一些清除操作，如rm如果这条规则的目标叫clean，如果恰巧该文件夹下有一个文件叫clean，那么就不能执行清除，此时可以使用.PHONY:clean标记clean目标不需要检查目标文件是否存在，目标文件的时间戳是否大于所有依赖\n实践 GO= CGO_ENABLED=0 GO111MODULE=on go GOCGO = CGO_ENABLED=1 GO111MODULE=on go #在申明变量时，如果要执行shell中的命令获取值需要使用$(shell xxx)，这是因为如果只使用$(xxx)的话回去取xxx变量的值，而xxx变量不存在，所以要在定义变量时使用shell命令必须使用shell关键字 GP = $(shell go env GOPATH) VERSION = v2.0.0 #commit id GIT_COMMIT=$(shell git rev-parse HEAD) #branch name GIT_BRANCH=$(shell git name-rev --name-only HEAD) #构建时间 BUILD_DATE=$(shell date \u0026#39;+%Y-%m-%d-%H:%M:%S\u0026#39;) #使用go build的-ldflags 参数可以在编译的时候对变量进行赋值，常用在编译时添加版本、架构、编译日期等信息 #使用-X参数进行替换，makef为项目名称，为go mod init makef, version是该项目下的一个包， Version为包中的一个变量 LDFLAGS = -ldflags \u0026#34;-X makef/version.","title":"makefile"},{"content":"MQTT vs AMQP 参考：\nhttp://jiagoushi.pro/technology-selection-amqp-vs-mqtt ","permalink":"https://moyuduo.github.io/posts/mqtt-vs-amqp/","summary":"MQTT vs AMQP 参考：\nhttp://jiagoushi.pro/technology-selection-amqp-vs-mqtt ","title":"MQTT vs AMQP"},{"content":"Mysql centos7下安装mysql 下载MySQL安装包\nwget https://dev.mysql.com/get/Downloads/MySQL-5.7/mysql-5.7.24-linux-glibc2.12-x86_64.tar.gz 把安装包解压\n#如果不知道安装包下载的位置可以使用 find / -name mysql-5.7.24-linux-glibc2.12-x86_64.tar.gz 查看 tar -zxvf mysql-5.7.24-linux-glibc2.12-x86_64.tar.gz 在/usr/local/下新建/usr/local/mysql\nmkdir -p /usr/local/mysql 把解压的安装包移动到/usr/local/mysql/mysql57目录下，并授权\nmv mysql-5.7.24-linux-glibc2.12-x86_64 //usr/local/mysql/mysql57 chown -R mysql.mysql /usr/local/mysql/mysql57 在/usr/local/mysql/mysql57下新建data目录用于存放数据库数据\nmkdir data 初始化mysql,初始化成功后会显示默认密码\ncd /usr/local/mysql/mysql57/bin ./mysqld --initialize --user=mysql --datadir=/usr/local/mysql/mysql57/data --basedir=/usr/local/mysql/mysql57 检查my.cnf文件\nvim /etc/my/cnf [mysqld] basedir=/usr/local/mysql/mysql57 #datadir=/usr/local/mysql/mysql57/data datadir=/data/mysql2 port = 3306 sql_mode=NO_ENGINE_SUBSTITUTION,STRICT_TRANS_TABLES symbolic-links=0 max_connections=400 innodb_file_per_table=1 server_id=1 log_bin=mysql-bin binlog_format=row 添加软连接，启动mysql\nln -s /usr/local/mysql//mysql57/support-files/mysql.server /etc/init.d/mysqld ln -s /usr/local/mysql//mysql57/bin/mysql /usr/bin/mysql 启动mysql\nservice mysql start 登录mysql\nmysql -uroot -p 修改默认密码\nmysql -uroot -p mysql\u0026gt; alter user \u0026#39;root\u0026#39;@\u0026#39;localhost\u0026#39; identified by \u0026#39;lpt316\u0026#39;; Query OK, 0 rows affected (0.00 sec) 添加一个远程连接账号，默认root账号只能本地连接\ngrant all privileges on *.* to \u0026#39;root\u0026#39;@\u0026#39;%\u0026#39; identified by \u0026#39;lpt316\u0026#39; with grant option; #刷新权限表 flush privileges; firewalld添加开发端口供远程连接使用\nfirewall-cmd --zone=public --add-port=3306/tcp --permanent firewall-cmd --reload 设置开机自启动\ncp /usr/local/mysql/mysql57/support-files/mysql.server /etc/init.d/mysql chmod +x /etc/init.d/mysql chkconfig --add mysql chkconfig --list DDL 建库 create database stu charset utf8 collate utf8_bin; CREATE DATABASE test3 CHARSET=utf8; #collate指定排序规则\tutf8_bin为区分大小写\tutf8_general_ci不区分大小写 #查看数据库字符集 show charset database stu; 修改数据库 alter database stu charset utf8; 删除库 drop database stu; 建表 CREATE TABLE test3.t1(num INT)ENGINE INNODB CHARSET utf8; create table student( id int not null primary key auto_increment comment \u0026#39;学号\u0026#39;, sname varchar(255) not null comment \u0026#39;姓名\u0026#39;, sage tinyint unsigned not null default 0 comment \u0026#39;年龄\u0026#39;, sgender enum(\u0026#39;m\u0026#39;,\u0026#39;f\u0026#39;,\u0026#39;n\u0026#39;) not null default \u0026#39;n\u0026#39; comment \u0026#39;性别\u0026#39;, id_card char(18) not null unique comment \u0026#39;身份证\u0026#39;, enter_time timestamp not null default now() comment \u0026#39;入学时间\u0026#39; ) engine=innodb charset=utf8 comment \u0026#39;学生表\u0026#39;; 建库和建表语句指定字符、引擎等可以使用=也可以隔一个空格\n修改表 #添加qq列 alter table student add qq varchar(20) not null unique comment \u0026#39;QQ号码\u0026#39;; #在sname后添加微信号列 alter table student add wechat varchar(64) not null unique comment \u0026#39;微信号码\u0026#39; after sname; #在id列前添加phone列(第一列) alter table student add phone varchar(15) not null unique comment \u0026#39;电话号码\u0026#39; first; #修改列 alter table user modify column birth varchar(20); #删除数据列(需要进行数据迁移，效率极差) alter table drop phone; 查看表信息 #查看数据库中所有表 show tables; desc student; #查看建表语句 show create table student; 删表 drop table student; DCL grant #identified by \u0026#39;123\u0026#39;表示创建并授权\tgrant option表示可以把自己有的权限授予其他用户 grant all on *.* to root@\u0026#39;%\u0026#39; identified by \u0026#39;123\u0026#39; with grant option; revoke revoke delete on *.* from root@\u0026#39;%\u0026#39;; 修改密码 #set password for 用户@地址=password(新密码); set password for root@localhost=password(\u0026#39;123\u0026#39;); #mysqladmin -P端口号 -u用户 -p原密码 password 新密码\t-P参数如果端口号默认3306也可以不指定 mysqladmin -P3307 -uroot -p123 password 456 DML 插入数据 #在插入数据之前通常使用 desc student；查看表定义 # 录入一条数据 insert into student(sname,id_card,qq,wechat,phone) values (\u0026#39;张三\u0026#39;,\u0026#39;1234567891012345678\u0026#39;,\u0026#39;12345678910\u0026#39;,\u0026#39;12345678910\u0026#39;,\u0026#39;12345678910\u0026#39;); #插入多行 insert into student(sname,id_card,qq,wechat,phone) values (\u0026#39;张三\u0026#39;,\u0026#39;1234567891012345678\u0026#39;,\u0026#39;12345678910\u0026#39;,\u0026#39;12345678910\u0026#39;,\u0026#39;12345678910\u0026#39;)， (\u0026#39;李四\u0026#39;,\u0026#39;1234567891012345678\u0026#39;,\u0026#39;12345678910\u0026#39;,\u0026#39;12345678910\u0026#39;,\u0026#39;12345678910\u0026#39;)； 更新数据 #在更新数据之前通常使用 desc student；查看表定义 #更新数据一定要带条件，否则会改全表 update student set sname=\u0026#39;zhangsan\u0026#39; where id=1; 删除数据 delete from student; truncate table student; #区别 #delete是逻辑性删除，逐行进行删除，速度慢 #truncate是对表段中数据页进行清空,速度快 #数据的伪删除，使用一个字段来标识数据行是否被删除 alter table student add is_deleted tinyint not null default 0; DQL 单独使用 # 使用select @@xxx 查看系统参数 select @@port; select @@basedir; select @@datadir; SELECT @@socket; SELECT @@server_id; #使用函数 select now(); select database(); select user(); select concat(user,\u0026#39;@\u0026#39;,host) from mysql.user; 查询所有数据 #查询所有数据，大表谨慎使用 select * from student; 比较操作符 select * from student where id\u0026gt;10; #不等于可以使用\u0026lt;\u0026gt; 或 != select * from student where id\u0026lt;\u0026gt;10; 逻辑运算符 select * from student where id=1 and sname=\u0026#39;张三\u0026#39;; select * from student where id=1 or id=13; 模糊查询 #查询姓张的 select * from student where sname like \u0026#39;张%\u0026#39;; #查询姓名是两个子，且结尾为三 select * from student where sname like \u0026#39;_三\u0026#39;; #模糊查询中%和_区别是\t%表示可以是多个字符\t_只表示一个字符 #注意%不能放在模糊查询的最前面，因为不走索引 in #查询张三或李四的信息 select * from student where sname in(\u0026#39;张三\u0026#39;,\u0026#39;李四\u0026#39;); between #查询id在11-12之间的 #between包括前后边界 select * from student where id between 11 and 12; group by + 聚合函数 #在sql中where语句必须放在group by之前 #按年龄统计人数 select sage,count(1) from student group by sage; #统计所有男性女性的年龄总和 select sgender,sum(sage) from student group by sgender; #查询男性和女性的平均年龄 select sgender,avg(sage) from student group by sgender; #查询男性女性年龄的最大值 select sgender,max(sage) from student group by sgender; #查询男性女性年龄的最小值 select sgender,min(sage) from student group by sgender; #按年龄统计名字 select sage,group_concat(sname) from student group by sage; #统计年龄\u0026gt;=20岁男性女性人数 select sgender,count(1) from student where sage\u0026gt;=20 group by sgender; #统计年龄\u0026gt;=20岁男性女性人数 #这两个相同的问题可以使用不同的思路解决，可以选选择在分组\t或者 先分组再选择\thaving语句只能用于分组列的条件比较 # having语句的条件不走索引 select sgender,count(1) from student group sage having sage\u0026gt;=20; order by #按年龄升序排序,默认升序 select * from student order by sage; #按年龄降序排序 select * from student order by sage desc; #把女性按年龄进行分组并按各个年龄人数降序排序 select sage,count(1) from student where sgender=\u0026#39;f\u0026#39; group by sage order by count(1) desc; limit #查询年龄最大的三个人 select * from student order by sage desc limit 3; #查询年龄第2-3大的两人 select * from student order by sage desc limit 1,2; --limit 1,2 表示跳过一个，取两个 select * from student order by sage desc limit 2 offset 1;\t--limit 2 offset 1表示去两个跳过一个 distinct select sage from student;--有重复的 select distinct sage from student;--去重 #distinct会验证所有字段，只有当所有字段相同才判定为相同的，去重 union #查询年龄为18或性别为女性的人 select * from student where sage=18 union select * from student where sgender=\u0026#39;f\u0026#39;; #union 前后查询语句的字段必须相同 # union和union all的区别是union会进行去重，而union all不进行去重 #一般情况下我们把in或or改写为union all语句提高效率 连接查询 笛卡尔积 把两张表联系起来，列为两表之和，行为两表之积\n表A：\na b 1 2 3 4 表B：\nc d 5 6 7 8 select * from a,b; #等值连接不写条件也是笛卡尔积 select * from a join b; a b c d 1 2 5 6 3 4 5 6 1 2 7 8 3 4 7 8 内连接 等值连接 两表连接的条件是\t=\nselect * from student join sc on student.sno=sc.sno; 自然连接 在等值连接中，相同的两个字段没有必要重复出现,等值连接会自动去比较字段名相同数据类型相同的列，如果有多列字段名相同字段类型相同的列，对应列必须相等才会连接\nselect * from student natural join sc; sno字段只出现一次\n不等值连接 两表连接的条件是 \u0026gt;\t\u0026gt;=\t\u0026lt;\t\u0026lt;=\t\u0026lt;\u0026gt;或！= 表A：\na b 1 1 2 6 表B：\nc d 3 7 4 8 select * from a join b on a.b\u0026gt;b.c; a b c d 2 6 3 7 2 6 4 8 外连接 左外连接 左外连接会从左表返回所有行，即使右表没有匹配，如果有表没有匹配，那么字段值为null\nselect * from student left join sc on student.sno=sc.sno; 右外连接 右外连接会从右表返回所有行，即使左表没有匹配，如果没有匹配，那么做表字段全为null\nselect * from student right join sc on student.sno=sc.sno; 全连接 左外连接和右外连接的并集，即左表没有比配，那么左表字段值全为null，如果右表没有匹配，那么右表字段值全为null\nmysql中没有全连接，但是可以通过左外连接union右外连接实现\nselect * from student left join sc on student.sno=sc.sno union select * from student right join sc on student.sno=sc.sno; show #查看数据库 show databases; #查看数据库下的表 show tables; #查看表的创建语句 show create table student; #查看可用字符集 show charset; #查看排序规则 show collation; #查看数据库存储引擎 show engines; #查看数据库连接情况 show processlist; #查看索引 show index from student; #查看授权 show grant for root@\u0026#39;localhost\u0026#39;; #查看数据库状态 show status; #查看配置信息 show variables; 三范式 第一范式 数据的每一列都需要保持原子性不可拆分 如在某些场景下地址可再拆分为省、市、县，即不满足第一范式\n第二范式 非主属性比如完全依赖主键\n如表：\n学号 姓名 性别 院系 课程 成绩 1 tom 男 计算机系 程序设计 90 1 tom 男 计算机系 数据库 80 该表的主键为\u0026lt;学号,课程\u0026gt;，非主属性为姓名、性别、院系、成绩，其中非主属性姓名、性别、院系部分依赖于主属性\u0026lt;学号\u0026gt;，所以这一张表还应该进行拆分\n第三范式 所有的非主属性不依赖于其他非主属性\n如表：\n学号 姓名 性别 院系 院系主任 1 tom 男 计算机系 张三 在该表中主键为学号，其他列都是非主属性，而非主属性列院系主任依赖于非主属性列院系，所以不符合第三范式，应该进行拆分\n索引 种类 B树索引 Hash索引 R树索引 Fulltext Gis BTree B树属于多路查找树，由根、枝、叶节点组成。\nB+Tree 在范围查询时提供更好的性能（\u0026gt; \u0026gt;= \u0026lt; \u0026lt;= like）\nB+树是在B树的基础上，在叶子节点上加上了访问下一个叶子节点的指针，使得遍历时不需要再从根节点进行遍历。\nB*Tree B*树是在B+树的基础上，在枝节点加上了访问下一个枝节点的指针，使得遍历时不需要再从根节点进行遍历。\n聚集索引 数据表创建了聚集索引，那么数据行就会按照聚集索引顺序存放。\n在建表时，建议创建一个数值类型的主键，这时就会创建聚集索引。\n一个表只能创建一个聚集索引，创建了聚集索引后行的插入是按照聚集索引列值的顺序进行存储的，索引表中的数据行都是按照聚集索引列值的递增顺序存放的。\n由于索引表中的数据行都是按照聚集索引列值的递增顺序存放的，所以聚集索引B+树的叶子节点是直接存放的数据页。\n创建聚集索引过程 创建数据行 根据主键在磁盘页中顺序存储数据行 根据数据页创建B+树的枝节点 根据枝节点创建根节点 辅助索引 创建辅助索引过程 取出索引列值，进行排序 创建B+树叶子节点，并将索引列值和对应数据页存入叶子节点 根据叶子节点创建枝节点 根据枝节点创建根节点 如果创建辅助索引的表已经创建了聚集索引，那么叶子节点存储的就是索引列值和对应的聚集索引列值，当查询时，根据辅助索引拿到聚集索引列值，在去聚集索引中查找，由于聚集索引的叶子节点直接存储数据页，不同于辅助索引存储页码，减少了回表操作\n当列需要作为条件频繁的进行查询时，可以考虑建立索引，但是还需要考虑是否列要频繁进行更新，因为更新操作需要更新所有树，导致锁定索引树，这种情况是否需要建立索引还需要进行一定的权衡\n单列索引 为需要进行查询的一列建立的所有\nALTER TABLE student ADD INDEX idx_sname(sname); ALTER TABLE student DROP INDEX idx_sname; 前缀索引 只去列的前几个字符建立索引，列数据类型必须是字符串\nALTER TABLE student ADD INDEX idx_sname(sname(5)); 联合索引 当需要进行多条件查询时\nALTER TABLE student ADD INDEX idx_n_a_g(name,age,gender); select * from student where name=\u0026#39;xxx\u0026#39; and age=20 and gender=\u0026#39;m\u0026#39;; 唯一索引 ALTER TABLE student ADD unique INDEX idx_telphone(telphone); 聚集索引和辅助索引的区别 聚集索引一个表只能有一个，辅助索引可以有多个，一般配合聚集索引使用 聚集索引的叶子节点就是磁盘数据行存储的数据页 Mysql是根据聚集索引组织存储数据，数据行存储时就是按照聚集索引列值的顺序进行存储 创建索引时，聚集索引列值本身就是有序的，而辅助索引需要对列值进行排序 执行计划分析 在查询语句前加desc可以查看查询语句的执行相关信息\nDESC SELECT * FROM t_100w WHERE k2=\u0026#39;STOP\u0026#39;; 相关查询结果列：\ntable\t查询语句使用的数据库\ntype\t查询的类型\nALL全表扫描\nindex全索引扫描\nrange索引范围扫描 聚集索引：\u0026lt;\u0026gt; not in 辅助索引：\u0026gt; \u0026lt; \u0026gt;= \u0026lt;= like in or\nref非唯一性等值索引\neq_ref在多表连接时，连接条件使用了唯一索引（unique,pk）\nconst唯一索引的等值查询\npossible_keys 可能会用到的索引\nkey\t使用的索引\nextra\t额外信息\n当查询语句使用了条件并且有排序或分组时，可以使用联合索引来优化\n不走索引的情况 查询条件没有建立索引 查询结果集是原表中的大部分数据，25%以上 索引失效，统计数据不真实，索引具有自我维护的功能，对于频繁更新的列建立的所有，频繁的更新可能导致所有失效，这个时候一般是删除索引，频繁更新的列不适合建立索引 在索引类的条件查询，条件使用了函数或者对所有列进行计算 select * from student where id-1=9; 隐式转换 #telphone列数据类型是char(11) select * from student where telphone=12345678910; 对于辅助索引，\u0026lt;\u0026gt;、in、not in不走索引，这种情况可以把in改写成union all like “%xx”like语句%在最前面不走索引 存储引擎 可以通过\nselect @@default_storage_engine; 查看数据库引擎\n功能 数据读写 数据安全和一致性 提高性能 热备份 自动故障恢复 高可用 在Mysql5.5版本以后，数据库默认引擎为InnoDB，提供高可靠性和高性能。\nInnoDB引擎 特点： 支持事务 InnoDB锁粒度为行级锁 聚集索引组织表 支持外键，保证多表数据一致性 支持CSR（故障自动恢复） 支持数据热备份 事务的ACID特性 Atomic（原子性）：所有语句作为一个单元，全部成功或全部失败 Consistent（一致性）：如果数据库事务开始处于一致状态，则在执行事务期间保留一致状态 Isolated（隔离性）：事务之间不相互影响 Durable（持久性）：事务成功后，所有的更改将记录到数据库中。 四种隔离级别 Read Uncommited：在该隔离级别下，所有事务都可以看到其他未提交事务的执行结果，称之为脏读。 Read Commited：该隔离级别为大多数数据库默认的隔离级别(mysql中不是)，该隔离级别下一个事务能够读取到其他事务已经提交了的数据。但是这种隔离级别会造成不可重复读现象， 即：在个事务中先查询了某一部分记录，然后其他的事务修改了这一部分数据，并且提交了，那么这些修改对当前事务都是可见的，当再次查询这部分记录是，和之前的查询不一样了，即在同一个事务内 两次相同的查询得到不一样的数据。 Repeatable Read:该隔离级别是mysql默认的隔离级别，即在同一个事务内读取数据并不会受到其他事务的影响，都会读取到一致的记录。但是该隔离级别会导致幻读：事务A根据条件修改了数据，此时事务B刚好插入了该范围内的数据，当事务A再次查询修改的数据时，发现同样的条件任然有一部分数据没有被修改。 Serializable：通过强制事务排序，使之不可能相互冲突，从而解决幻读问题。简言之，它是在每个读的数据行上加上共享锁。在这个级别，可能导致大量的超时现象和锁竞争。 Mysql默认采用REPEATABLE_READ隔离级别\n事务的开启结束 begin --开启事务，Mysql5.5以后默认自动开启事务，可以不写 commit --提交事务 rollback --回滚事务，把执行了的操作都撤销，恢复到开始事务状态 自动提交策略 Mysql中默认开启了自动提交策略\n#可以通过以下语句查看Mysql是否开启了事务自动提交，0表示关闭自动提交，1表示开启了自动提交 SELECT @@autocommit; #可以通过以下语句设置当前连接不开启事务自动提交 set autocommit=0; #可以通过以下语句设置数据库全局关闭事务自动提交 set global autocommit=0; 事务的实现原理 事务是基于重做日志(redo log)和回滚日志(undo log)来实现的，每提交一个事务前必须将所有的操作记录到重做日志中再进行持久话，当发生故障时可以基于重做日志来进行回复保证事务的原子性和持久性 当修改事务是会产生回滚日志，如果需要回滚则根据回滚日志的反向语句进行逻辑操作，重做日志主要是保证数据的一致性\nredolog regolog不是随事务的提交才写入的，而是在事务的执行过程中，便开始写入redolog，具体的落盘策略可以进行配置，用来防止在发生故障的时候任然有脏页未写入磁盘，在重启mysql的时候会根据redolog进行重做，从而达到恢复未落盘数据的特性，保证数据的持久性\nundolog undolog用来回滚事务到记录的某个版本，在事务未提交之前，undolog保存了未提交之前的版本的数据，undolog中的数据可以作为旧版本数据的快照供其他并发事务进行快照读，undolog是为了实现事务的原子性的产物，在innodb存储引擎中用来实现多版本并发控制。\nbinlog Mysql的binlog是用来记录数据库表结构变更和表数据修改的二进制日志。binlog不会记录show、select这类操作，因为这类操作对表结构和表数据本身没有修改，但是可以通过查询通用日志来查看Mysql执行的所有语句。\nMysql的binlog以事件形式记录，包含语句执行的时间，Mysql的binlog是事务安全型的，binlog的主要目的是为了用于复制和恢复。\nbinlog有三种形式：\nstatement:基于sql语句的模式，某些语句如包含函数UUID的语句在复制和恢复的过程中会导致数据的不一致 row:基于行的模式，记录的是行的变化，很安全。在大表中清除大量数据时会在binlog中产生大量语句，导致在复制时从库的延迟变大 mixed:混合模式，根据语句来选择statement模式还是row模式 可以在事务中混用存储引擎吗？ 尽量不要在事务中使用多种存储引擎，Mysql的服务器层不管理事务，事务是由底层的存储引擎管理的，如果在一个事务中混用了存储引擎，如一个事务中包含堆事务型表的操作(innodb)和非事务型表的操作(myisam)，在正常的提交下没有问题，但是如果事务需要回滚，非事务型的表的变更无法撤销，会导致数据库处于不一致的状态\nMysql中是如何实现事务隔离的 Read Uncommited 和 Serialable 是基本不考虑的隔离级别，前者不加任何锁的限制，后者相当于单线程执行效率差，Mysql在 Read Commited 隔离级别通过行锁和间歇锁的组合(Next-Key)解决了幻读问题，\n间歇锁：使用间隙锁锁住的是一个区间，而不仅仅是这个区间中的每一条数据。 举例来说，假如emp表中只有101条记录，其empid的值分别是1,2,\u0026hellip;,100,101，下面的SQL\nSELECT * FROM emp WHERE empid \u0026gt; 100 FOR UPDATE 当我们用条件检索数据，并请求共享或排他锁时，InnoDB不仅会对符合条件的empid值为101的记录加锁，也会对empid大于101（这些记录并不存在）的“间隙”加锁。\n这个时候如果你插入empid等于102的数据的，如果那边事物还没有提交，那你就会处于等待状态，无法插入数据。\nMVCC MVCC即多版本并发控制，MVCC的实现是通过保存数据在某一个时间点的快照来实现的，根据事务开始的时间点不同，每个事务对同一表看到的数据可能是不相同的\n对于Innodb存储引擎聚簇索引记录包含三个隐藏的列：\nROW ID:隐藏的自增ID，如果表没有主键，Innodb会按照ROW ID产生一个聚集索引树。 事务ID，记录最后一次修改该记录的事务ID 回滚指针：指向这条记录的上一个版本 如图：首先 insert 语句向表 t1 中插入了一条数据，a 字段为 1，b 字段为 1， ROW ID 也为 1 ，事务 ID 假设为 1，回滚指针假设为 null。当执行 update t1 set b=666 where a=1 时，大致步骤如下：\n数据库会先对满足a=1的行加排他锁 复制原记录到undolog中 修改匹配到的行记录b的值为666，修改事务ID为当前事务的ID 修改隐藏回滚指针使其指向undolog中的上一条记录 提交事务，释放之前对满足a=1的行加的排他锁 Innodb的每一行都有一个隐藏的列回滚指针用于指向该行修改前的一个版本的数据，这个数据存储在undolog中，如果要执行更新操作哪个会把该行的记录复制到undolog中，修改完该行的数据之后会把回滚指针指向undolog中保存的该行的上一个版本记录，当其他事务需要查询时，通过回滚指针查询undolog中保存的上个版本的数据\nMVCC的最大好处是读不加锁，读写不冲突，极大地增加了Mysql的并发性，通过MVCC保证了事务ACID中的I隔离性\nMyISAM引擎 特点： 不支持事务 只能支持表锁 不支持外键 每个表用三个文件存储，.frm文件存储表定义，.MYD文件存储数据，.MYI文件存储索引 查询数据库的表的引擎 SELECT table_schema,table_name,ENGINE FROM information_schema.TABLES WHERE table_schema=\u0026#39;xxx\u0026#39;; 修改表的存储引擎 alter table xxx engine innodb; 缓冲区池 #查看缓冲区池大小 select @@innodb_buffer_pool_size; 日志 错误日志 记录一些error和warn信息\n默认是开启的\n#查看错误日志目录 SELECT @@log_error; #这个参数不可以使用 set global log_error=xxx这样的方式修改，只能修改配置文件然后重启mysql #配置文件在basedir对应的路径下，可以使用select @@basedir查看 #windows下的配置文件是my.ini文件，linux下配置文件是my.cnf #添加 log_error=xxx\\mysql.log 二进制日志 备份恢复需要依赖二进制日志 主从环境依赖二进制日志 默认没有开启\n#标志,0表示没开启，1表示开启 select @@log_bin; #日志路径及名字 select @@log_bin_basename; #服务id号 select @@server_id; #二进制格式 select @@binlog_format; #这几个参数也是必须要在配置文件中配置，不能再命令行修改 binlog记录的是什么？记录的是变更的sql语句，不记录查询日志。会记录DDL、DCL、DML，对于DDL和DCL是全部记录，但是对于DML只记录提交了的事务。\nbinlog_format指定二进制日志的格式，有row、statement、mixed三种，row是记录数据行的变化、statement原封不动的记录所有DML，这种模式不够严谨，可能出现数据不一致，因为他是记录sql，在恢复时相当于重新执行一遍sql，如果sql中有与时间相关的就可能出现数据不一致、mixed是row和statement的混合\n#查看所有二进制日志 show binary logs; show master logs; #刷新日志 flush logs; #查看正在使用的日志 show master status; #查看日志事件 show binlog events in \u0026#39;mysql-bin.000003\u0026#39;; 从日志中恢复数据 在测试之前，应该确认二进制日志文件是否开启\n#0为关闭，1为开启 select @@log_bin; 如果没有开启要在mysql的配置文件中配置，windows下为my.ini，linux下为/etc/my.cnf，\n需要添加\tlog_bin=/xxxx\t配置二进制文件放置的位置,这个目录必须是datadir下的，不然会报错\nmysqlbinlog参数 --start-position\t截取的起始position --stop-position\t截取的终止position -d\t指定数据库的日志 mysqlbinlog --start-position=316 --stop-position=1018 /mysql-bin.0000xx \u0026gt; /backup/ttt.sql 恢复 #创建表 CREATE TABLE `ttt` ( `sno` int(11) NOT NULL AUTO_INCREMENT, `sname` varchar(20) DEFAULT NULL, PRIMARY KEY (`sno`) )； #在新建的表中插入数据 insert into ttt values(\u0026#39;aaa\u0026#39;),(\u0026#39;bbb\u0026#39;),(\u0026#39;ccc\u0026#39;); #删除数据库 drop table ttt; #查看正在使用的二进制日志 show master status; #查看日志判断误操作的位置 show binlog events in \u0026#39;mysql-bin.0000xx\u0026#39;; #使用mysqlbinlog来生成sql mysqlbinlog --start-position=316 --stop-position=1018 /mysql-bin.0000xx \u0026gt; /backup/ttt.sql #登录mysql使用source命令执行sql use xxx; set sql_log_bin=0;--关闭记录日志，恢复操作不需要记录日志 source /backup/ttt.sql; set sql_log_bin=1; #这样就把数据恢复了，从二进制日志中导出的sql是某一状态下操作的sql，所以要恢复必须要把数据恢复到某一时刻，然后执行二进制日志导出的sql，相当于在某一状态下，又把这些语句执行了一遍 #所以二进制文件通常配合备份一起使用 GTID gtid是在5.6添加的，主要是解决二进制日志文件中截取片段查找起点和终点position不方便的问题。\n在mysql5.7版本中gtid即使不开启也会自动生成\n#查看gtid SELECT @@gtid_next; ANONYMOUS gtid由两部分组成source_id ：transaction_id\tsource_id 为一个机器的唯一id，transaction_id是一个自增事务id 7E11FA47-31CA-19E1-9E56-C43AA21293967:29\n可以在mysql的配置文件,windows下为my.ini，linux下为my.cnf中显式添加配置\ngtid-mode=on\t开启gtid enforce-gtid-consistency=true\t强制gtid的一致性\nMaster [(none)]\u0026gt;create database gtid charset utf8; Query OK, 1 row affected (0.01 sec) Master [(none)]\u0026gt;show master status ; +------------------+----------+--------------+------------------+----------------------------------------+ | File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set | +------------------+----------+--------------+------------------+----------------------------------------+ | mysql-bin.000004 | 326 | | | dff98809-55c3-11e9-a58b-000c2928f5dd:1 | +------------------+----------+--------------+------------------+----------------------------------------+ 1 row in set (0.00 sec) Master [(none)]\u0026gt;use gtid Database changed Master [gtid]\u0026gt;create table t1 (id int); Query OK, 0 rows affected (0.01 sec) Master [gtid]\u0026gt;show master status ; +------------------+----------+--------------+------------------+------------------------------------------+ | File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set | +------------------+----------+--------------+------------------+------------------------------------------+ | mysql-bin.000004 | 489 | | | dff98809-55c3-11e9-a58b-000c2928f5dd:1-2 | +------------------+----------+--------------+------------------+------------------------------------------+ 1 row in set (0.00 sec) Master [gtid]\u0026gt;begin; Query OK, 0 rows affected (0.00 sec) Master [gtid]\u0026gt;insert into t1 values(1); Query OK, 1 row affected (0.00 sec) Master [gtid]\u0026gt;commit; Query OK, 0 rows affected (0.00 sec) Master [gtid]\u0026gt;show master status ; +------------------+----------+--------------+------------------+------------------------------------------+ | File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set | +------------------+----------+--------------+------------------+------------------------------------------+ | mysql-bin.000004 | 1068 | | | dff98809-55c3-11e9-a58b-000c2928f5dd:1-3 | +------------------+----------+--------------+------------------+------------------------------------------+ 1 row in set (0.00 sec) 可以看到每执行一条DDL、DCL就是一个事务，而执行DML时，只有事务提交了，那么事务号才增加\ngtid模式下是由mysqlbinlog来截取日志\n#--include-gtids是指定要截取的事务号范围，包括前界和后界，这里是截取1-6号事务日志 #--exclude-gtids是指定截取的事务号返回内需要跳过的事务号，多个需要跳过的使用，分割 #--skip-gtids是指定截取日志是跳过gtid，因为开启gtid后，如果是相同的gtid那么就不会再执行，如果不跳过，那么在恢复的时候会跳过这些事务 mysqlbinlog --skip-gtids --include-gtids=\u0026#39;dff98809-55c3-11e9-a58b-000c2928f5dd:1-6\u0026#39; --exclude-gtids=\u0026#39;dff98809-55c3-11e9-a58b-000c2928f5dd:4\u0026#39; /data/binlog/mysql-bin.000004 使用截取的日志sql来恢复\nset sql_log_bin=0; source /tmp/binlog.sql set sql_log_bin=1; slowlog 作用：记录慢SQL，定位低效SQL语句\n#查询slowlog是否开启，默认没开启 select @@slow_query_log; #查询慢语句日志目录 select @@slow_query_log_file; #查看慢查询语句时间阈值，超过这个阈值就是慢sql,默认为10秒 select @@long_query_time; #查询是否开启不走索引语句记录慢日志，0为关闭，1为开启 select @@log_queries_not_using_indexes; 需要在配置文件中添加相关配置\nslow_query_log=1 slow_query_log_file=C:\\Program Files (x86)\\MySQL\\MySQL Server 5.5\\slow.log long_query_time=0.2 log_queries_not_using_indexes=1 重启数据库\n执行一些耗时的sql后查看慢日志\nC:\\Program Files (x86)\\MySQL\\MySQL Server 5.5\\bin\\mysqld, Version: 5.5.28-log (MySQL Community Server (GPL)). started with: TCP Port: 3306, Named Pipe: (null) Time Id Command Argument C:\\Program Files (x86)\\MySQL\\MySQL Server 5.5\\bin\\mysqld, Version: 5.5.28-log (MySQL Community Server (GPL)). started with: TCP Port: 3306, Named Pipe: (null) Time Id Command Argument # Time: 200529 21:37:48 # User@Host: root[root] @ localhost [127.0.0.1] # Query_time: 1.233220 Lock_time: 0.013930 Rows_sent: 636438 Rows_examined: 636438 use oldboy; SET timestamp=1590759468; select * from t_100w; # Time: 200529 21:39:39 # User@Host: root[root] @ localhost [127.0.0.1] # Query_time: 0.338753 Lock_time: 0.000000 Rows_sent: 1 Rows_examined: 636438 SET timestamp=1590759579; select count(*) from t_100w; # Time: 200529 21:40:18 # User@Host: root[root] @ localhost [127.0.0.1] # Query_time: 0.449270 Lock_time: 0.000000 Rows_sent: 1 Rows_examined: 636438 SET timestamp=1590759618; select * from t_100w where id=10000; # Time: 200529 21:41:34 # User@Host: root[root] @ localhost [127.0.0.1] # Query_time: 0.503289 Lock_time: 0.000000 Rows_sent: 10 Rows_examined: 636448 SET timestamp=1590759694; select * from t_100w where id\u0026lt;10000 order by k1 limit 10; 使用mysqldumpslow工具来分析慢日志\n#-s是指定排序规则\tc：按访问次数降序排序\tl：按锁定时间降序排序\tr：按返回记录降序排序\tal：平均锁定时间降序排序\tar：平均访问次数降序排序\tat：平均查询时间降序排序 #-t是指定显示条数 mysqldumpslow -s c -t 3 slow.log 备份 备份类型 热备份\n在数据库正常业务时，进行备份，并且能够保证数据一致性\n温备份\n锁表备份，只能查询不能增删改\n冷备份\n关闭数据库业务，在数据库没有任何变更的情况下进行备份\n备份方式 逻辑备份 基于sql进行备份\nmysqldump mysqlbinlog 物理备份 基于磁盘数据进行备份\nxtrabackup：percona第三方 逻辑备份和物理备份比较 mysqldump\n优点：\n​\t1不需要下载安装\n​\t2备份出来的是sql，可读性高\n​\t3压缩比高，节省磁盘空间\n缺点：\n​\t1依赖于数据库引擎，需要从磁盘把数据读出，然后转换成sql，耗费资源\n​\t2对于大量数据（100G以上）效率很差\nxtrabackup\n优点：\n​\t1类似于直接拷贝物理文件，不需要管逻辑结构，效率高\n​\t2由于是直接拷贝的物理文件，可读性差\n​\t3压缩比低，耗费更多的磁盘空间\nmysqldump 备份方式 -u -p -S -h -p #本地备份 mysqlsump -uroot -pxxx -S /temp/mysql.sock #远程备份\t在进行远程备份时，远程数据库版本必须和本地mysqldump命令数据库版本一致 mysqldump -uroot -pxxx -h 10.0.0.51 -P3306 全备份（全库） #\t-A参数全部数据库备份 mysqldump -uroot -pxxx -A \u0026gt; dir/full.sql 单（多）库备份 #\t-B参数备份多个数据库 mysqldump -uroot -pxxx -B hello world \u0026gt; dir/hellowordld.sql 单（多）表备份 #\t备份数据库下的单个或多个表 #\t备份stumanage下的student，course，sc三张表 #这种方式进行恢复的时候，数据库必须存在，且必须use才能source mysqldump -uroot -pxxx stumanage student course sc \u0026gt; dir/tb.sql 按各个库的每张表生产一个备份语句 SELECT CONCAT(\u0026#39;mysqldump -uroot -pxxx \u0026#39;,table_schema,\u0026#39; \u0026#39;,table_name,\u0026#39;\u0026gt;/backup/\u0026#39;,table_schema,\u0026#39;_\u0026#39;,table_name,\u0026#39;.sql\u0026#39;) FROM information_schema.tables WHERE table_schema NOT IN (\u0026#39;sys\u0026#39;,\u0026#39;information_schema\u0026#39;,\u0026#39;performance_schema\u0026#39;) INTO OUTFILE \u0026#39;/backup/tb_back.sh\u0026#39;; mysqldump高级参数 -R\t备份存储过程及函数 --triggers\t备份触发器 -E\t备份事件 -F\t在备份的时候，刷新一个新的binlog日志 --master-date=2\t以注释的形式保存备份开启事件的binlog的position，方便恢复 --single-transaction\tinnodb存储引擎开启热备 mysqldump+binlog恢复数据库 先全备数据库stumanage\nmysqldump -uroot -pxxx -B stumanage --trigger -R -E --master-data=2 --single-transaction \u0026gt; D:/backup/bak.sql 然后向表中插入一些数据\ninsert into stumanage.student values(11,\u0026#39;test11\u0026#39;,\u0026#39;男\u0026#39;,11,\u0026#39;挖掘机工程\u0026#39;)， (22,\u0026#39;test22\u0026#39;,\u0026#39;男\u0026#39;,22,\u0026#39;水利工程\u0026#39;)； #向另一些数据库的表中插入数据 insert into test.t1 values(1),(2),(3); #删除另一个数据库的表 drop table test.t2; 模拟误操作删除数据库stumanage\ndrop database stumanage; 分析日志\nmysql -uroot -pxxx -e \u0026#34;show binlog events in \u0026#39;mysql-bin.000010\u0026#39;\u0026#34; |tail -100 |grep -i \u0026#39;drop\u0026#39; 找到drop语句的开始position #在全备中找到备份时开始的position -- CHANGE MASTER TO MASTER_LOG_FILE=\u0026#39;mysql-bin.000010\u0026#39;, MASTER_LOG_POS=18166; 截取日志\n#\t-d stumanage指定只截取stumanage数据库的日志 mysqlbinlog -d stumanage --start-position=13732 --stop-position=19215 ../mysql-bin.000010 \u0026gt; D:/backup/logbin.sql 恢复日志\n#登录mysql mysql -uroot -pxxx #关闭记录日志，恢复操作不需要记录日志 set sql_log_bin=0; #恢复全备 source D:/backup/bak.sql; #恢复日志备份 source D:/backup/logbin.sql; #开启日志记录 set sql_log_bin=1; XBK备份 安装 安装依赖包\nwget -O /etc/yum.repos.d/epel.repo http://mirrors.aliyun.com/repo/epel-7.repo yum -y install perl perl-devel libaio libaio-devel perl-Time-HiRes perl-DBD-MySQL libev 下载rpm包\nwget https://www.percona.com/downloads/XtraBackup/Percona-XtraBackup-2.4.12/binary/redhat/7/x86_64/percona-xtrabackup-24-2.4.12-1.el7.x86_64.rpm 安装xbk\nyum -y install percona-xtrabackup-24-2.4.4-1.el7.x86_64.rpm 检查是否安装好\ninnobackupex --version 全备 #默认在备份目录下生成一个按时间戳命名的文件夹 innobackupex --user=root --password=xxx /data/backup [root@localhost etc]# cd /data/backup/ [root@localhost backup]# ll 总用量 0 drwxr-x---. 6 root root 210 6月 4 17:16 2020-06-04_17-16-31 #不使用时间戳命名备份文件夹，自定义备份文件 innobackupex --user=root --password=lpt316 --no-timestamp /data/backup/full [root@localhost backup]# cd /data/backup/ [root@localhost backup]# ll 总用量 0 drwxr-x---. 6 root root 210 6月 4 17:16 2020-06-04_17-16-31 drwxr-x---. 6 root root 210 6月 4 17:20 full 使用全备恢复 模拟误操作删除数据库\nrm -rf /usr/local/mysql/mysql57/data/stumanage 将redo进行重做，已提交的写到数据文件，未提交的使用undo回滚掉\ninnobackupex --apply-log /data/backup/full/ 准备一个目录，因为进行恢复的时候要求目录必须是空的\nmkdir /data/mysql 把恢复的数据拷贝到该目录下\ncp -a /data/backup/full/ /data/mysql1/ 授权(必须在拷贝之后授权)\nchown -R mysql.mysql /data/mysql1 修改mysql的配置文件数据目录\nvim /etc/my.cnf 修改 datadir=/data/mysql 重启mysql\nservice mysqld start 增量备份 首先进行全备\ninnobackupex --user=root --password=lpt316 --socket=/tmp/mysql.sock --no-timestamp /data/backup/full 模拟第一天数据改变\nCREATE TABLE test.t1(num INT)ENGINE=INNODB CHARSET=utf8; INSERT INTO test.t1 VALUES(1),(2),(3); 进行第一天的增量备份\ninnobackupex --user=root --password=lpt316 --socket=/tmp/mysql.sock --no-timestamp --incremental --incremental-basedir=/data/backup/full/ /data/backup/inc1 模拟第二天数据变化\nCREATE TABLE test.t2(num INT)ENGINE=INNODB CHARSET=utf8; INSERT INTO test.t2 VALUES(1),(2),(3); 进行第二天的全备\ninnobackupex --user=root --password=lpt316 --socket=/tmp/mysql.sock --no-timestamp --incremental --incremental-basedir=/data/backup/inc1/ /data/backup/inc2 模拟第三天数据变化\nCREATE TABLE test.t3(num INT)ENGINE=INNODB CHARSET=utf8; INSERT INTO test.t3 VALUES(1),(2),(3); 进行第三天的增量备份\ninnobackupex --user=root --password=lpt316 --socket=/tmp/mysql.sock --no-timestamp --incremental --incremental-basedir=/data/backup/inc2/ /data/backup/inc3 模拟故障之前一些操作\nINSERT INTO test.t3 VALUES(5),(6),(7); 模拟误错误删除了库\nrm -rf /data/mysql/test/ 恢复\n#整理全备 innobackupex --apply-log --redo-only /data/backup/full/ #把inc1合并到full innobackupex --apply-log --redo-only --incremental-dir=/data/backup/inc1 /data/backup/full/ #把inc2合并到full innobackupex --apply-log --redo-only --incremental-dir=/data/backup/inc2 /data/backup/full/ #把inc3合并到full innobackupex --apply-log --incremental-dir=/data/backup/inc3 /data/backup/full/ #最后进行一次全备整理 innobackupex --apply-log /data/backup/full 新建目录，把恢复的文件拷贝过去，并授权\n[root@localhost backup]# mkdir /data/mysql2 [root@localhost backup]# cp -a full/* /data/mysql2/ [root@localhost backup]# chown -R mysql.mysql /data/mysql2 截取故障当天的二进制日志\n#判断起点 cat /data/backup/inc3/xtrabackup_binlog_info #找到终点 mysql -uroot -plpt316 -e \u0026#34;show binlog events in \u0026#39;mysql-bin.000002\u0026#39;\u0026#34; |grep drop #导出二进制日志 ./mysqlbinlog --start-position=2681 --stop-position=3006 /data/mysql/mysql-bin.000002 \u0026gt; /data/backup/binlog.sql 关闭数据库\nservice mysqld stop 修改mysql的配置文件\nvim /etc/my.cnf datadir=/data/mysql2 启动mysql\nservice mysqld start 此时已恢复到故障前一天的状态\n恢复二进制日志\nsource /data/backup/binlog.sql; 成功恢复到误删除前\n单表恢复 进行全备\ninnobackupex --user=root --password=lpt316 --socket=/tmp/mysql.sock --no-timestamp /data/backup/all 只删除一个表\nDROP TABLE test2.ttt; 恢复\ninnobackupex --apply-log /data/backup/all 创建一个和删除表相同结构的表\nCREATE TABLE test2.ttt(num INT)ENGINE=INNODB CHARSET=utf8; 卸载表空间\n#卸载表空间 ALTER TABLE test2.ttt DISCARD TABLESPACE; 把恢复的全备里的相关表文件拷贝到数据库数据文件下，并授权\ncp /data/backup/all/test2/ttt.ibd /data/mysql2/test2/ chown -R mysql.mysql /data/mysql2/test2/ttt.ibd 添加表空间\nALTER TABLE test2.ttt IMPORT TABLESPACE; 至此，数据就恢复回来了\n主从复制 主从复制前提：\n两个数据库实例，并配置server_id 主库需要开启二进制日志 主库需要建立专用的赋值用户（replication slave） 主库全备，从库使用备份恢复，保证主库从库一致 change master to 主库ip 端口 用户名 密码 二进制文件 日志position start slave 主从备份实施 确保两数据库配置了server_id，并开启了二进制日志 主库： server_id=1 log_bin=mysql-bin binlog_format=row 从库： server_id=2 log_bin=mysql-bin binlog_format=row 主机全备发送到从机执行，确保主从复制前主从库数据一致 主库： ./mysqldump -uroot -plpt316 -A --triggers -R -E -F --master-data=2 --single-transaction \u0026gt; /data/backup/20200609full.sql 发送全备到从库： scp /data/backup/20200609full.sql root@192.168.37.131:/data/backup 从库： #登录 mysql -uroot -p #设置恢复全备不记录日志 set sql_log_bin=0; #同步主库数据 source /data/backup/20200609full.sql; #恢复记录sql二进制日志 set sql_log_bin=1; 主库建立一个主从复制专用用户 grant replication slave on *.* to rep@\u0026#39;192.168.37.*\u0026#39; identified by \u0026#39;lpt316\u0026#39;; flush privileges; change master to #首先查看全备里的position位置 CHANGE MASTER TO MASTER_LOG_FILE=\u0026#39;mysql-bin.000007\u0026#39;, MASTER_LOG_POS=154; CHANGE MASTER TO MASTER_HOST=\u0026#39;192.168.37.130\u0026#39;, MASTER_USER=\u0026#39;rep\u0026#39;, MASTER_PASSWORD=\u0026#39;lpt316\u0026#39;, MASTER_PORT=3306, MASTER_LOG_FILE=\u0026#39;mysql-bin.000008\u0026#39;, MASTER_LOG_POS=154, MASTER_CONNECT_RETRY=10, MASTER_RETRY_COUNT=0; start slave; 在主库中添加数据看看从库同步了没有 从库： mysql\u0026gt; select * from test3.t1; Empty set (0.01 sec) 主库： mysql\u0026gt; insert into test3.t1 values(1),(2),(3); Query OK, 3 rows affected (0.00 sec) Records: 3 Duplicates: 0 Warnings: 0 从库查看是否同步： mysql\u0026gt; select * from test3.t1; 主从复制原理 涉及的文件 主库：\nmysql-bin.00000x：二进制文件 从库：\nlocalhost-relay-bin.00000x：中继日志文件 master.info：主库信息 relay-log.info：中继日志信息 涉及的线程 主库：\nBinlog_Dump_Thread:监控主库，如果有新操作，和Slave_IO_Thread交互，通知从库 从库：\nSlave_IO_Thread：负责和主库建立TCP/IP连接，和Binlog_Thread交互，当主库通知该线程时，拷贝二进制文件回来 Slave_SQL_Thread：负责把拷贝回来的二进制文件转换成SQL语句，并在从库中执行，保证主从一致 主从异常 主从故障 连接问题：\nSlave_IO_Running: Connecting 可能的错误有： ip错误 端口错误 user，password错误或不允许在该ip登录 主库未启动 防火墙未开放端口 连接已达到上限 解决：\n首先ping从库ip看是否网络有问题 ping xxx.xxx.xxx.xxx 如何能ping通，可能是端口，用户名，密码等其他问题,在从库使用主从账号远程连接 mysql -u repl -p xxx -h 192.168.37.111 二进制文件问题：\n如：\n二进制文件删除 二进制文件不全 主库reset master 解决：\n停止主从 stop slave; 重置从库信息 reset slave all; 主库重启导出一个全备，在从库中恢复，重启搭建主从 SQL线程故障：\nrelay-log.info文件不存在，或不全 SQL无法执行 原因：\n版本差异，参数设定不一样 主从环境不一致，要创建的数据库已经存在，要删除的对象不存在 解决：\n可以在配置文件中设置 read_only=1 但是这种方式只能针对普通账户，管理员任然能够修改数据 主从延迟 主库做的操作，从库很久才能追加上\n外在原因 网络 主从硬件差异 版本差异 参数差异 主库原因 二进制日志写入不及时：sync_binlog；在mysql5.7默认为1，即立即写入二进制日志 主库发生了大事务，由于是串行传递，会阻塞后续事务 解决：\n5.6开始，开启GTID实现Group Commit，可以并行传输日志给从库IO线程\n5.7开始，不开启GTID，会自动维护匿名GTID，也能实现Group Commit\n从库原因 主库并发了大量事务，从库只能串行回放 主库发生了大事务，会阻塞后续的所有事务 解决：\n5.6版本开启GTID之后，加入了SQL多线程特性，但是只能针对不同的数据库下的事务进行并行回放\n5.7版本开启GTID之后，在SQL方面，提供了基于逻辑时钟seq_no机制，真正实现了事务级别的并发回放MTS技术\n延时从库 使用原因：预防人为原因导致数据库误删除\n思想：延时从库和普通从库一样，只是延时从库拿到数据写入relaylog中，SQL线程必须延时指定的时间才去运行\n配置 stop slave; CHANGE MASTER TO MASTER_DELAY = 300; start slave; show slave status \\G #从库延时时间 SQL_Delay: 300\t#从库将要执行语句的最近时间 SQL_Remaining_Delay: NULL 恢复 发现错误，及时停止延时从库的SQL线程 截取relaylog日志，起点为stop sql线程时的relaylog位置，终点为drop之间的位置 把截取的日志恢复到从库 从库代替主库工作 恢复案例 #配置延时从库 stop slave; CHANGE MASTER TO MASTER_DELAY = 300; start slave; #在主库中创建一个delay库，并创建一个测试表，插入几条测试数据 create database delay charset=utf8; create table delay.test(num int)engine=innodb charset=utf8; insert into delay.test values(1),(2),(3); #删除主库delay数据库 drop database delay; #发现错误，立即停止从库SQL线程 stop slave sql_thread; #查看relaylog日志的起点 Relay_Log_File: localhost-relay-bin.000002 Relay_Log_Pos: 320 #查看relaylog找到drop误操作前的位置 show relaylog events in \u0026#34;localhost-relay-bin.000002\u0026#34;; localhost-relay-bin.000002 | 1016 | Query | 1 | 945 | drop database delay #截取日志 [root@localhost bin]# ./mysqlbinlog --start-position=320 --stop-position=1016 /usr/local/mysql/mysql57/data/localhost-relay-bin.000002 \u0026gt; /tmp/relay.sql #恢复日志数据 source /tmp/relay.sql; #把主库设置为从库或延时从库恢复好的数据导出在主库中恢复 过滤复制 相关参数 主库：\nBinlog_Do_DB：\nBinlog_Ignore_DB：\n这两个是主库空配置要进行复制的白名单和黑名单，不过一般不在主库配置，因为主库配置这两个参数，涉及的库并不会记录二进制日志，不利于使用二进制进行备份\n从库： Replicate_Do_DB: 复制库白名单 Replicate_Ignore_DB: 复制库黑名单\nReplicate_Do_Table: 复制表白名单 Replicate_Ignore_Table: 复制表黑名单\nReplicate_Wild_Do_Table: 复制表模糊白名单 Replicate_Wild_Ignore_Table:复制表模糊黑名单\n案例 #修改从库配置文件，设置从库只不复制filter1和filter2数据库数据 vim /etc/my.cnf 添加 replicate_ignore_db=filter1 replicate_ignore_db=filter2 注意配置文件里不能大写 #重启mysql service mysqld start #在主库中创建一个filter1数据库 create database filter1 charset=utf8; #在从库中查询 mysql\u0026gt; show databases; +--------------------+ | Database | +--------------------+ | information_schema | | mysql | | performance_schema | | sys | | test2 | | test3 | +--------------------+ 6 rows in set (0.00 sec) 并没有filter1数据库 GTID主从复制 GTID(Global Transaction ID)是对于一个已提交事务的唯一编号，并且是一个全局(主从复制)唯一的编号。 它的官方定义如下： GTID = source_id ：transaction_id 7E11FA47-31CA-19E1-9E56-C43AA21293967:29\n配置文件核心参数 gtid-mode=on --启用gtid类型，否则就是普通的复制架构 enforce-gtid-consistency=true --强制GTID的一致性 log-slave-updates=1 --slave更新是否记入日志 从库操作 change master to master_host=\u0026#39;10.0.0.51\u0026#39;, master_user=\u0026#39;repl\u0026#39;, master_password=\u0026#39;123\u0026#39; , MASTER_AUTO_POSITION=1; 和传统主从的复制的区别：在启动复制时，不需要指定binlog文件名和position号，直接auto即可自动读取最后一个relay，获取到上次已经复制GTID号，从此号码开始向后复制即可，在MHA高可用环境下，主库无法SSH时，从库进行数据补偿，更加便捷。\n","permalink":"https://moyuduo.github.io/posts/mysql/","summary":"Mysql centos7下安装mysql 下载MySQL安装包\nwget https://dev.mysql.com/get/Downloads/MySQL-5.7/mysql-5.7.24-linux-glibc2.12-x86_64.tar.gz 把安装包解压\n#如果不知道安装包下载的位置可以使用 find / -name mysql-5.7.24-linux-glibc2.12-x86_64.tar.gz 查看 tar -zxvf mysql-5.7.24-linux-glibc2.12-x86_64.tar.gz 在/usr/local/下新建/usr/local/mysql\nmkdir -p /usr/local/mysql 把解压的安装包移动到/usr/local/mysql/mysql57目录下，并授权\nmv mysql-5.7.24-linux-glibc2.12-x86_64 //usr/local/mysql/mysql57 chown -R mysql.mysql /usr/local/mysql/mysql57 在/usr/local/mysql/mysql57下新建data目录用于存放数据库数据\nmkdir data 初始化mysql,初始化成功后会显示默认密码\ncd /usr/local/mysql/mysql57/bin ./mysqld --initialize --user=mysql --datadir=/usr/local/mysql/mysql57/data --basedir=/usr/local/mysql/mysql57 检查my.cnf文件\nvim /etc/my/cnf [mysqld] basedir=/usr/local/mysql/mysql57 #datadir=/usr/local/mysql/mysql57/data datadir=/data/mysql2 port = 3306 sql_mode=NO_ENGINE_SUBSTITUTION,STRICT_TRANS_TABLES symbolic-links=0 max_connections=400 innodb_file_per_table=1 server_id=1 log_bin=mysql-bin binlog_format=row 添加软连接，启动mysql\nln -s /usr/local/mysql//mysql57/support-files/mysql.server /etc/init.d/mysqld ln -s /usr/local/mysql//mysql57/bin/mysql /usr/bin/mysql 启动mysql\nservice mysql start 登录mysql\nmysql -uroot -p 修改默认密码","title":"Mysql"},{"content":"Postgresql相关 安装 安装不要使用yum安装，因为版本很老\n#centos7 x84 arch 安装 postgresql13 # Install the repository RPM: sudo yum install -y https://download.postgresql.org/pub/repos/yum/reporpms/EL-7-x86_64/pgdg-redhat-repo-latest.noarch.rpm # Install PostgreSQL: sudo yum install -y postgresql13-server # Optionally initialize the database and enable automatic start: sudo /usr/pgsql-13/bin/postgresql-13-setup initdb sudo systemctl enable postgresql-13 sudo systemctl start postgresql-13 #其他版本参考 https://www.postgresql.org/download/linux/ 修改配置文件支持远程连接 #使用ps查看postgresql是否启动，并获取数据保存路径\t/var/lib/pgsql/13/data/ [root@i-u8fxb68q data]# ps -ef|grep postgre root 9821 7321 0 10:40 pts/0 00:00:00 su postgres postgres 9822 9821 0 10:40 pts/0 00:00:00 bash root 10896 9990 0 10:58 pts/0 00:00:00 su postgres postgres 10897 10896 0 10:58 pts/0 00:00:00 bash postgres 13020 1 0 11:27 ? 00:00:00 /usr/pgsql-13/bin/postmaster -D /var/lib/pgsql/13/data/ postgres 13022 13020 0 11:27 ? 00:00:00 postgres: logger postgres 13024 13020 0 11:27 ? 00:00:00 postgres: checkpointer postgres 13025 13020 0 11:27 ? 00:00:00 postgres: background writer postgres 13026 13020 0 11:27 ? 00:00:00 postgres: walwriter postgres 13027 13020 0 11:27 ? 00:00:00 postgres: autovacuum launcher postgres 13028 13020 0 11:27 ? 00:00:00 postgres: stats collector postgres 13029 13020 0 11:27 ? 00:00:00 postgres: logical replication launcher root 13183 11285 0 11:30 pts/0 00:00:00 su postgres postgres 13184 13183 0 11:30 pts/0 00:00:00 bash postgres 13235 13020 0 11:31 ? 00:00:02 postgres: postgres postgres 110.191.179.192(24432) idle root 13642 13586 0 11:35 pts/0 00:00:00 grep --color=auto postgre 进入数据目录修改pg_hba.conf、postgresql.conf两个文件。\n修改pg_hba.conf可访问的ip地址\n修改postgresql.conf监听的范围,原本为注释的，修改并改为*\n修改密码 #切换用户 su postgres #进入客户端 psql #修改密码，出现ALTER ROLE即成功 alter user postgres with password \u0026#39;995072337@Lt\u0026#39;; ALTER ROLE 练习 #查看数据库 \\l #进入数据库 \\c dbname #查看当前数据库的表 \\d #查看表格信息 \\d tablename create database ttt; alter database ttt rename to t1; drop database ttt; drop database if exist ttt; create table stu2 ( id int, name varchar(30), birth date, score numeric(5,2) ); alter table stu2 rename id to bh; alter table stu2 alter column name type varchar(20); alter table stu2 drop column birth; alter table stu2 add column addr varchar(200); drop table stu2; drop table if exists stu2; insert into temp values(2, 3, 3.14, 9.99); #插入时最后一个字段的定义为numeric(5,2) 但是插入时其实我超范围了但是不会报错，值会被四舍五入 insert into temp values(2, 3, 3.14, 9.999); create table temp1( t time, d date, tm timestamp ); insert into temp1 values(\u0026#39;10:10:10\u0026#39;, \u0026#39;2021-08-20\u0026#39;, \u0026#39;2021-08-20 10:10:10\u0026#39;); create table temp2( ch char(10), vch varchar(30), t text ); insert into temp2 values(\u0026#39;litao\u0026#39;, \u0026#39;litao\u0026#39;, \u0026#39;litao\u0026#39;); select concat(\u0026#39;#\u0026#39;, ch, \u0026#39;#\u0026#39;), concat(\u0026#39;#\u0026#39;, vch, \u0026#39;#\u0026#39;), concat(\u0026#39;#\u0026#39;, t, \u0026#39;#\u0026#39;) from temp2; #算数运算符 select 1+2, 1-2, 1*2, 1/2, 1%2; #比较运算符 #字符串和数字比较会把字符串转换成数字，null和任何类型比较都是null select 1\u0026gt;2, 1\u0026lt;2, 1\u0026gt;=1, 1\u0026lt;=2, 1=2, 1!=2, \u0026#39;2\u0026#39;=2, null=null, null=1; select 2 between 1 and 3; select 2 in (1, 2, 3); select \u0026#39;abc\u0026#39; like \u0026#39;a%\u0026#39;, \u0026#39;abc\u0026#39; like \u0026#39;_b_\u0026#39;, \u0026#39;abc\u0026#39; not like \u0026#39;%c\u0026#39;; # 1,y被当做真\t0，n被当做假 select not \u0026#39;1\u0026#39;, not \u0026#39;y\u0026#39;, not \u0026#39;0\u0026#39;, not \u0026#39;n\u0026#39;; select \u0026#39;1\u0026#39; and \u0026#39;y\u0026#39;, \u0026#39;1\u0026#39; and \u0026#39;n\u0026#39;, \u0026#39;0\u0026#39; and \u0026#39;n\u0026#39;; select \u0026#39;1\u0026#39; or \u0026#39;y\u0026#39;, \u0026#39;1\u0026#39; or \u0026#39;n\u0026#39;, \u0026#39;0\u0026#39; or \u0026#39;n\u0026#39;; #索引 create index id_idx on stu(id); drop index id_idx; #视图 create view stu_view as select * from stu where age \u0026lt; 20; select * from stu_view; select id, name from stu_view; drop view stu_view; #插入 insert into stu values(1, \u0026#39;tom\u0026#39;, 20, \u0026#39;m\u0026#39;); insert into stu values(2, \u0026#39;jack\u0026#39;, 18, \u0026#39;m\u0026#39;),(3, \u0026#39;marry\u0026#39;, 20, \u0026#39;f\u0026#39;); insert into stu(id, name) values(5, \u0026#39;moyuduo\u0026#39;); insert into stu(name, id) values(\u0026#39;qqq\u0026#39;, 6); insert into stu2 select * from stu where id = 1; #更新 update stu set age = 30 where id = 4; #删除 delete from stu where id = 1; delete from stu where age \u0026lt; 20; delete from stu; #truncate不记录删除日志，不可恢复，但是速度快 truncate table stu; #约束 create table score2( id bigint primary key, #主键约束 course_name varchar(20), score decimal(2,2), sid bigint, constraint score2_fk foreign key(sid) references stu(id)\t#外键约束 ); alter table score add constraint score_pk primary key(id); alter table score add constraint score_fk foreign key(sid) references stu(id); alter table score3 alter column score set default(0.00); alter table score3 alter column score drop default; alter table score3 alter column course_name set not null; alter table score3 alter column course_name drop not null; #自增主键 create table test_pk1( id serial primary key, #serial自增 范围1 到 2147483647 name varchar(20) ); 数据类型 smallint:范围：-32768-32767,2字节 int：-2147483648-2147483647,4字节 real：表示6位十进制数进度 numeric：numeric(m,n)表示整数部分m位，小数部分n位 time:一日之内的时间，格式为'10:10:10' date:日期类型，格式为：\u0026lsquo;2021-08-20\u0026rsquo; timestamp:时间戳类型，格式为'2021-08-20 10:10:10\u0026rsquo;不能直接使用时间戳 char(n):定长字符串，如果插入的字符不足指定位数时，使用空白字符填充，检索效率比varchar高 varchar(n):边长字符串，如果插入的字符不足指定位数时，只存储值，不做其他操作 text:和varchar类似 管理工具 官网下载pgAdmin，免费\n下载好后在pgAdmin是有postgresql客户端的，在安装路径，如：F:\\v5\\runtime\\psql.exe，可以把这个文件配置到环境变量，就可以在cmd终端直接使用psql命名\n数据导入 导入命令：psql -h 139.198.11.13 -p5431 -d iot -U postgres -f F:\\sql脚本\\iot_device.sql\n-h指定ip地址，默认本地\n-p指定端口，默认5432\n-d指定数据库\n-U指定登录的用户\n执行命令后如果不是本地会要求输入密码\n从一个postgresql导出的数据如果在本地windows进行导入会出现编码转换错误：\n这是由于windows本地文件使用GBK进行编码，但是进行导入的postgresql数据库是UTF8编码，在windows上使用postgresql客户端进行文件传输并不会进行编码转换，直接使用的windows的GBK编码\ngo-pg type ( User struct { Id int64 Name string Emails []string tableName struct{} `sql:\u0026#34;user\u0026#34;` } Story struct { Id int64 Title string AuthorId int64 Author *User tableName struct{} `sql:\u0026#34;story\u0026#34;` } ) func (u User) String() string { return fmt.Sprintf(\u0026#34;User\u0026lt;%d %s %v\u0026gt;\u0026#34;, u.Id, u.Name, u.Emails) } func (s Story) String() string { return fmt.Sprintf(\u0026#34;Story\u0026lt;%d %s %#v\u0026gt;\u0026#34;, s.Id, s.Title, s.Author) } func connect() *pg.DB { db := pg.Connect(\u0026amp;pg.Options{ Addr: \u0026#34;139.198.11.13:5432\u0026#34;, User: \u0026#34;postgres\u0026#34;, Password: \u0026#34;995072337@Lt\u0026#34;, Database: \u0026#34;test\u0026#34;, }) var n int _, err := db.QueryOne(pg.Scan(\u0026amp;n), \u0026#34;select 1\u0026#34;) if err != nil { panic(err) } return db } func createTables(db *pg.DB, tabs []interface{}) { for _, model := range tabs { err := db.CreateTable(model, \u0026amp;orm.CreateTableOptions{ IfNotExists: true, FKConstraints: true, }) if err != nil { panic(err) } } } func delTables(db *pg.DB, tabs []interface{}) { for _, model := range tabs { err := db.DropTable(model, \u0026amp;orm.DropTableOptions{ IfExists: true, Cascade: true, }) if err != nil { panic(err) } } } func insert(db *pg.DB) { u1 := \u0026amp;User{ Name: \u0026#34;u1\u0026#34;, Emails: []string{\u0026#34;u1@163.com\u0026#34;, \u0026#34;u1@qq.com\u0026#34;}, } u2 := \u0026amp;User{ Name: \u0026#34;u2\u0026#34;, Emails: []string{\u0026#34;u2@163.com\u0026#34;}, } err := db.Insert(u1, u2) if err != nil { panic(err) } u3 := \u0026amp;User{ Name: \u0026#34;u3\u0026#34;, Emails: []string{\u0026#34;u3@163.com\u0026#34;}, } u4 := \u0026amp;User{ Name: \u0026#34;u4\u0026#34;, Emails: []string{\u0026#34;u4@163.com\u0026#34;}, } res, err := db.Model(u3, u4).Insert() if err != nil { panic(err) } fmt.Printf(\u0026#34;%#v \\n\u0026#34;, res) u5 := \u0026amp;User{ Name: \u0026#34;u5\u0026#34;, Emails: []string{\u0026#34;u5@163.com\u0026#34;}, } u6 := \u0026amp;User{ Name: \u0026#34;u6\u0026#34;, Emails: []string{\u0026#34;u6@163.com\u0026#34;}, } users := make([]*User, 0) users = append(users, u5) users = append(users, u6) res, err = db.Model(\u0026amp;users).Insert() if err != nil { panic(err) } fmt.Printf(\u0026#34;%#v \\n\u0026#34;, res) } func delUserRecord(db *pg.DB) { //按主键删除 err := db.Delete(\u0026amp;User{ Id: 2, Name: \u0026#34;u2\u0026#34;, Emails: []string{\u0026#34;u2@163.com\u0026#34;}, }) if err != nil { panic(err) } res, err := db.Model(\u0026amp;User{}).Where(\u0026#34;id in (?)\u0026#34;, pg.In([]int64{3, 4})).Delete() if err != nil { panic(err) } fmt.Printf(\u0026#34;%#v \\n\u0026#34;, res) } func delUserRecord2(db *pg.DB) { err := db.Delete(\u0026amp;User{ Id: 1, }) if err != nil { panic(err) } } func updateUserRecord(db *pg.DB) { user := User{ Id: 5, Name: \u0026#34;u555\u0026#34;, } err := db.Update(\u0026amp;user) if err != nil { panic(err) } } func updateUserRecord2(db *pg.DB) { user := User{ Id: 6, Name: \u0026#34;u666\u0026#34;, } res, err := db.Model(\u0026amp;user).Set(\u0026#34;name=?\u0026#34;, user.Name).WherePK().Update() if err != nil { panic(err) } fmt.Printf(\u0026#34;%#v \\n\u0026#34;, res) } func updateUserRecord3(db *pg.DB) { user := User{ Id: 7, Name: \u0026#34;u777\u0026#34;, } res, err := db.Model(\u0026amp;user).Column(\u0026#34;name\u0026#34;).WherePK().Update() if err != nil { panic(err) } fmt.Printf(\u0026#34;%#v \\n\u0026#34;, res) } func updateUserRecord4(db *pg.DB) { user := User{ Id: 8, Name: \u0026#34;u888\u0026#34;, } res, err := db.Model(\u0026amp;user).Set(\u0026#34;name=?name\u0026#34;).WherePK().Update() if err != nil { panic(err) } fmt.Printf(\u0026#34;%#v \\n\u0026#34;, res) } func query1(db *pg.DB) { var user User res, err := db.Query(\u0026amp;user, \u0026#34;select * from users where id = ?\u0026#34;, 6) if err != nil { panic(err) } fmt.Printf(\u0026#34;%#v %#v \\n\u0026#34;, user, res) } func query2(db *pg.DB) { var user User //如果记过有多行 panic: pg: multiple rows in result set res, err := db.QueryOne(\u0026amp;user, \u0026#34;select * from users where id \u0026lt; ?\u0026#34;, 10) if err != nil { panic(err) } fmt.Printf(\u0026#34;%#v %#v \\n\u0026#34;, user, res) } func query3(db *pg.DB) { user := User{ Id: 6, } err := db.Model(\u0026amp;user).Where(\u0026#34;id = ?id\u0026#34;).Select() if err != nil { panic(err) } fmt.Println(user) } func query4(db *pg.DB) { user := User{ Id: 6, } err := db.Model(\u0026amp;user).Column(\u0026#34;id\u0026#34;, \u0026#34;name\u0026#34;).Where(\u0026#34;id = ?id\u0026#34;).Select() if err != nil { panic(err) } fmt.Println(user) } func query5(db *pg.DB) { var id int64 var name string err := db.Model((*User)(nil)).Column(\u0026#34;id\u0026#34;, \u0026#34;name\u0026#34;).Where(\u0026#34;id = ?\u0026#34;, 6).Select(\u0026amp;id, \u0026amp;name) if err != nil { panic(err) } fmt.Println(id, name) } func query6(db *pg.DB) { user := User{} err := db.Model(\u0026amp;user).Where(\u0026#34;id = ? and name = ?\u0026#34;, 6, \u0026#34;u666\u0026#34;).Select() // err := db.Model(\u0026amp;user).Where(\u0026#34;id = ?\u0026#34;, 6).Where(\u0026#34;name = ?\u0026#34;, \u0026#34;u666\u0026#34;).Select() if err != nil { panic(err) } fmt.Println(user) } func query7(db *pg.DB) { user := User{ Id: 6, Name: \u0026#34;u777\u0026#34;, } err := db.Model(\u0026amp;user).Where(\u0026#34;id = ?id\u0026#34;).WhereOr(\u0026#34;name = ?name\u0026#34;).Limit(1).Select() if err != nil { panic(err) } fmt.Println(user) } func query8(db *pg.DB) { var users []User err := db.Model((*User)(nil)).Where(\u0026#34;id = ?\u0026#34;, 6).WhereOr(\u0026#34;name = ?\u0026#34;, \u0026#34;u777\u0026#34;).Select(\u0026amp;users) if err != nil { panic(err) } fmt.Println(users) } func query9(db *pg.DB) { var users []User err := db.Model((*User)(nil)).Where(\u0026#34;id \u0026lt; ?\u0026#34;, 10). WhereGroup(func(q *orm.Query) (*orm.Query, error) { q = q.Where(\u0026#34;name = ?\u0026#34;, \u0026#34;u666\u0026#34;). WhereOr(\u0026#34;name = ?\u0026#34;, \u0026#34;u777\u0026#34;) return q, nil }).Select(\u0026amp;users) if err != nil { panic(err) } fmt.Println(users) } func query10(db *pg.DB) { var user []User err := db.Model((*User)(nil)).Where(\u0026#34;id in (?)\u0026#34;, pg.In([]int64{6, 7})).Select(\u0026amp;user) if err != nil { panic(err) } fmt.Println(user) } func query11(db *pg.DB) { n, err := db.Model((*User)(nil)).Where(\u0026#34;id \u0026lt; ?\u0026#34;, 10).Count() if err != nil { panic(err) } fmt.Println(n) } func query12(db *pg.DB) { var users []User err := db.Model((*User)(nil)).Where(\u0026#34;id \u0026lt; ?\u0026#34;, 10).Order(\u0026#34;id desc\u0026#34;).Select(\u0026amp;users) if err != nil { panic(err) } fmt.Println(users) } func query13(db *pg.DB) { var ids []int64 err := db.Model((*User)(nil)).ColumnExpr(\u0026#34;array_agg(id)\u0026#34;).Select(pg.Array(\u0026amp;ids)) if err != nil { panic(err) } fmt.Println(ids) } func query14(db *pg.DB) { s := Story{} // err := db.Model(\u0026amp;s).Relation(\u0026#34;Author\u0026#34;).Where(\u0026#34;story.id = ?\u0026#34;, 1).Select() err := db.Model(\u0026amp;s).Relation(\u0026#34;Author\u0026#34;, func(q *orm.Query) (*orm.Query, error) { return q.Where(\u0026#34;story.id = ?\u0026#34;, 1), nil }).Select() if err != nil { panic(err) } fmt.Println(s) } func query15(db *pg.DB) { var ss []Story err := db.Model(\u0026amp;ss).Column(\u0026#34;story.*\u0026#34;).Relation(\u0026#34;Author\u0026#34;).Select() if err != nil { panic(err) } fmt.Println(ss) } func query16(db *pg.DB) { exist, err := db.Model((*User)(nil)).Where(\u0026#34;id = ?\u0026#34;, 1).Exists() if err != nil { panic(err) } fmt.Println(exist) } func query17(db *pg.DB) { db.Model((*User)(nil)).Order(\u0026#34;id desc\u0026#34;).ForEach(func(u *User) error { fmt.Println(u) return nil }) } ","permalink":"https://moyuduo.github.io/posts/postgresql%E7%9B%B8%E5%85%B3/","summary":"Postgresql相关 安装 安装不要使用yum安装，因为版本很老\n#centos7 x84 arch 安装 postgresql13 # Install the repository RPM: sudo yum install -y https://download.postgresql.org/pub/repos/yum/reporpms/EL-7-x86_64/pgdg-redhat-repo-latest.noarch.rpm # Install PostgreSQL: sudo yum install -y postgresql13-server # Optionally initialize the database and enable automatic start: sudo /usr/pgsql-13/bin/postgresql-13-setup initdb sudo systemctl enable postgresql-13 sudo systemctl start postgresql-13 #其他版本参考 https://www.postgresql.org/download/linux/ 修改配置文件支持远程连接 #使用ps查看postgresql是否启动，并获取数据保存路径\t/var/lib/pgsql/13/data/ [root@i-u8fxb68q data]# ps -ef|grep postgre root 9821 7321 0 10:40 pts/0 00:00:00 su postgres postgres 9822 9821 0 10:40 pts/0 00:00:00 bash root 10896 9990 0 10:58 pts/0 00:00:00 su postgres postgres 10897 10896 0 10:58 pts/0 00:00:00 bash postgres 13020 1 0 11:27 ?","title":"Postgresql相关"},{"content":"RabbitMQ安装 安装erlang wget http://www.rabbitmq.com/releases/erlang/erlang-18.3-1.el7.centos.x86_64.rpm rpm -ivh erlang-18.3-1.el7.centos.x86_64.rpm 安装socat wget http://repo.iotti.biz/CentOS/7/x86_64/socat-1.7.3.2-5.el7.lux.x86_64.rpm rpm -ivh socat-1.7.3.2-5.el7.lux.x86_64.rpm 安装rabbitmq wget http://www.rabbitmq.com/releases/rabbitmq-server/v3.6.5/rabbitmq-server-3.6.5-1.noarch.rpm rpm -ivh rabbitmq-server-3.6.5-1.noarch.rpm 如果没提示错误，就安装成功\n启用后台管理插件 rabbitmq-plugins enable rabbitmq_management 提示： The following plugins have been enabled: mochiweb webmachine rabbitmq_web_dispatch amqp_client rabbitmq_management_agent rabbitmq_management Applying plugin configuration to rabbit@localhost... started 6 plugins. 则安装成功 配置防火墙开启端口 firewall-cmd --zone=public --add-port=15672/tcp --permanent firewall-cmd --zone=public --add-port=5672/tcp --permanent firewall-cmd --reload 开启远程访问 由于rabbitmq默认用户guest只允许本机访问，为了能够支持远程访问，需要在/etc/rabbitmq目录下新建rabbitmq.config文件，内容为[{rabbit, [{loopback_users, []}]}].然后重启service rabbitmq-server restart即可\n远程访问 在浏览器地址栏输入http://192.168.37.131:15672即可访问登录页面，使用user：guest、password：guest登录成功说明安装配置成功\n队列 简单队列 package com.moyuduo.rabbitmq.utils; /** *@author litao,School of computer and software engineering,Xihua University *@date 2020/06/10 */ import java.io.IOException; import java.util.concurrent.TimeoutException; import com.rabbitmq.client.Connection; import com.rabbitmq.client.ConnectionFactory; public class RabbitmqUtils { public static Connection getConnection() throws IOException, TimeoutException { //定义一个工厂 ConnectionFactory factory=new ConnectionFactory(); //设置服务器地址 factory.setHost(\u0026#34;192.168.37.131\u0026#34;); //设置端口 factory.setPort(5672); //vhost factory.setVirtualHost(\u0026#34;/vhost_myd\u0026#34;); //设置用户名 factory.setUsername(\u0026#34;moyuduo\u0026#34;); //设置密码 factory.setPassword(\u0026#34;lpt316\u0026#34;); return factory.newConnection(); } } //发送 package com.moyuduo.rabbitmq.simple; import java.io.IOException; import java.util.concurrent.TimeoutException; import com.moyuduo.rabbitmq.utils.RabbitmqUtils; import com.rabbitmq.client.Channel; import com.rabbitmq.client.Connection; /** *@author litao,School of computer and software engineering,Xihua University *@date 2020/06/10 */ public class Send { public static final String QUEUE_NAME=\u0026#34;test-simple-queue\u0026#34;; public static void main(String[] args) throws IOException, TimeoutException { //获取连接 Connection connection = RabbitmqUtils.getConnection(); //从连接中获取通道 Channel channel = connection.createChannel(); //创建队列申明 channel.queueDeclare(QUEUE_NAME, false, false, false, null); String message=\u0026#34;hello\u0026#34;; channel.basicPublish(\u0026#34;\u0026#34;, QUEUE_NAME, null, message.getBytes()); System.out.println(\u0026#34;发送消息：\u0026#34;+message+\u0026#34; 成功！\u0026#34;); //关闭通道 channel.close(); //关闭连接 connection.close(); } } //接收 package com.moyuduo.rabbitmq.simple; import java.io.IOException; import java.util.concurrent.TimeoutException; import com.moyuduo.rabbitmq.utils.RabbitmqUtils; import com.rabbitmq.client.AMQP.BasicProperties; import com.rabbitmq.client.Channel; import com.rabbitmq.client.Connection; import com.rabbitmq.client.ConsumerCancelledException; import com.rabbitmq.client.DefaultConsumer; import com.rabbitmq.client.Envelope; import com.rabbitmq.client.QueueingConsumer; import com.rabbitmq.client.QueueingConsumer.Delivery; import com.rabbitmq.client.ShutdownSignalException; /** *@author litao,School of computer and software engineering,Xihua University *@date 2020/06/10 */ public class Receive { public static final String QUEUE_NAME=\u0026#34;test-simple-queue\u0026#34;; @SuppressWarnings(\u0026#34;deprecation\u0026#34;) public static void main(String[] args) throws IOException, TimeoutException, ShutdownSignalException, ConsumerCancelledException, InterruptedException { //oldApi(); newApi(); } public static void oldApi() throws IOException, TimeoutException, ShutdownSignalException, ConsumerCancelledException, InterruptedException { //获取连接 Connection connection = RabbitmqUtils.getConnection(); //创建通道 Channel channel = connection.createChannel(); //定义队列消费者 QueueingConsumer consumer = new QueueingConsumer(channel); //监听队列 channel.basicConsume(QUEUE_NAME, true, consumer); while(true) { Delivery delivery = consumer.nextDelivery(); String message=new String(delivery.getBody()); System.out.println(\u0026#34;收到消息：\u0026#34;+message); } } public static void newApi() throws IOException, TimeoutException { //获取连接 Connection connection = RabbitmqUtils.getConnection(); //创建通道 Channel channel = connection.createChannel(); //队列申明 channel.queueDeclare(QUEUE_NAME, false, false, false, null); DefaultConsumer consumer = new DefaultConsumer(channel) { @Override public void handleDelivery(String consumerTag, Envelope envelope, BasicProperties properties, byte[] body) throws IOException { String message=new String(body,\u0026#34;utf-8\u0026#34;); System.out.println(\u0026#34;收到消息：\u0026#34;+message); } }; //监听队列 channel.basicConsume(QUEUE_NAME, consumer); } } 简单队列的不足 耦合度高，一个消费者对应一个消费者 队名变更，生产者和消费者都必须变更 工作队列 为什么会出现工作队列？\n简单队列是一一对应的，在实际开发中，生成者发送消息是毫不费力的，消费者要跟业务相结合，需要花费更多的时间，这样就会积压很多的消息\n轮询分发 //发送 package com.moyuduo.rabbitmq.work; import java.io.IOException; import java.util.concurrent.TimeoutException; import com.moyuduo.rabbitmq.utils.RabbitmqUtils; import com.rabbitmq.client.Channel; import com.rabbitmq.client.Connection; /** *@author litao,School of computer and software engineering,Xihua University *@date 2020/06/11 */ public class Send { private static final String QUEUE_NAME=\u0026#34;test-work-queue\u0026#34;; public static void main(String[] args) throws IOException, TimeoutException, InterruptedException { Connection connection = RabbitmqUtils.getConnection(); Channel channel = connection.createChannel(); channel.queueDeclare(QUEUE_NAME, false, false, false, null); for(int i=0;i\u0026lt;50;i++) { String message=i+\u0026#34;\u0026#34;; channel.basicPublish(\u0026#34;\u0026#34;, QUEUE_NAME, null, message.getBytes()); System.out.println(\u0026#34;发送消息：\u0026#34;+message); Thread.sleep(100); } channel.close(); connection.close(); } } //开启两个线程模拟接收 package com.moyuduo.rabbitmq.work; import java.io.IOException; import java.util.concurrent.TimeoutException; import com.moyuduo.rabbitmq.utils.RabbitmqUtils; import com.rabbitmq.client.AMQP.BasicProperties; import com.rabbitmq.client.Channel; import com.rabbitmq.client.Connection; import com.rabbitmq.client.DefaultConsumer; import com.rabbitmq.client.Envelope; /** *@author litao,School of computer and software engineering,Xihua University *@date 2020/06/11 */ public class Recevie { private static final String QUEUE_NAME=\u0026#34;test-work-queue\u0026#34;; public static void main(String[] args) throws IOException, TimeoutException { new Thread(new Runnable() { public void run() { Connection connection; try { connection = RabbitmqUtils.getConnection(); Channel channel = connection.createChannel(); channel.queueDeclare(QUEUE_NAME, false, false, false, null); DefaultConsumer consumer1= new DefaultConsumer(channel) { @Override public void handleDelivery(String consumerTag, Envelope envelope, BasicProperties properties, byte[] body) throws IOException { String message=new String(body,\u0026#34;utf-8\u0026#34;); System.out.println(\u0026#34;接收线程1：\u0026#34;+message); try { Thread.sleep(20); } catch (InterruptedException e) { e.printStackTrace(); } } }; channel.basicConsume(QUEUE_NAME, true, consumer1); } catch (IOException e) { e.printStackTrace(); } catch (TimeoutException e) { e.printStackTrace(); } } }).start(); new Thread(new Runnable() { public void run() { Connection connection; try { connection = RabbitmqUtils.getConnection(); Channel channel = connection.createChannel(); channel.queueDeclare(QUEUE_NAME, false, false, false, null); DefaultConsumer consumer1 = new DefaultConsumer(channel) { @Override public void handleDelivery(String consumerTag, Envelope envelope, BasicProperties properties, byte[] body) throws IOException { String message = new String(body, \u0026#34;utf-8\u0026#34;); System.out.println(\u0026#34;接收线程2：\u0026#34; + message); try { Thread.sleep(50); } catch (InterruptedException e) { e.printStackTrace(); } } }; channel.basicConsume(QUEUE_NAME, true, consumer1); } catch (IOException e) { e.printStackTrace(); } catch (TimeoutException e) { e.printStackTrace(); } } }).start(); } } 轮询的机制是mq发送一个消息给A后，然后发送消息给B，假如B的效率更高，反而比A提前完成了任务，此时也必须等到A完毕后，先给A发送，再给B发送，即AB依次发送消息\n轮询分发的缺点 轮询分发的缺点是有些提前消费了消息的客户端反而需要等待还没完成消息消费的客户端，那么效率更高的客户端没法发挥它的最大效率\n公平分发 //发送 package com.moyuduo.rabbitmq.workfair; import java.io.IOException; import java.util.concurrent.TimeoutException; import com.moyuduo.rabbitmq.utils.RabbitmqUtils; import com.rabbitmq.client.Channel; import com.rabbitmq.client.Connection; /** *@author litao,School of computer and software engineering,Xihua University *@date 2020/06/11 */ public class Send { private static final String QUEUE_NAME=\u0026#34;test-work-queue\u0026#34;; public static void main(String[] args) throws IOException, TimeoutException, InterruptedException { Connection connection = RabbitmqUtils.getConnection(); Channel channel = connection.createChannel(); channel.queueDeclare(QUEUE_NAME, false, false, false, null); for(int i=0;i\u0026lt;50;i++) { String message=i+\u0026#34;\u0026#34;; channel.basicPublish(\u0026#34;\u0026#34;, QUEUE_NAME, null, message.getBytes()); System.out.println(\u0026#34;发送消息：\u0026#34;+message); Thread.sleep(100); } channel.close(); connection.close(); } } //使用两个线程模拟消费消息 package com.moyuduo.rabbitmq.workfair; import java.io.IOException; import java.util.concurrent.TimeoutException; import com.moyuduo.rabbitmq.utils.RabbitmqUtils; import com.rabbitmq.client.AMQP.BasicProperties; import com.rabbitmq.client.Channel; import com.rabbitmq.client.Connection; import com.rabbitmq.client.DefaultConsumer; import com.rabbitmq.client.Envelope; /** *@author litao,School of computer and software engineering,Xihua University *@date 2020/06/11 */ public class Recevie { private static final String QUEUE_NAME=\u0026#34;test-work-queue\u0026#34;; public static void main(String[] args) throws IOException, TimeoutException { new Thread(new Runnable() { public void run() { Connection connection; try { connection = RabbitmqUtils.getConnection(); final Channel channel = connection.createChannel(); channel.queueDeclare(QUEUE_NAME, false, false, false, null); //设置未手动回复前发送消息数 channel.basicQos(1); DefaultConsumer consumer1= new DefaultConsumer(channel) { @Override public void handleDelivery(String consumerTag, Envelope envelope, BasicProperties properties, byte[] body) throws IOException { String message=new String(body,\u0026#34;utf-8\u0026#34;); System.out.println(\u0026#34;接收线程1：\u0026#34;+message); try { Thread.sleep(200); } catch (InterruptedException e) { e.printStackTrace(); }finally { //手动回复 channel.basicAck(envelope.getDeliveryTag(), false); } } }; channel.basicConsume(QUEUE_NAME, false, consumer1); } catch (IOException e) { e.printStackTrace(); } catch (TimeoutException e) { e.printStackTrace(); } } }).start(); new Thread(new Runnable() { public void run() { Connection connection; try { connection = RabbitmqUtils.getConnection(); final Channel channel = connection.createChannel(); channel.queueDeclare(QUEUE_NAME, false, false, false, null); //设置未手动回复前发送消息数 channel.basicQos(1); DefaultConsumer consumer1 = new DefaultConsumer(channel) { @Override public void handleDelivery(String consumerTag, Envelope envelope, BasicProperties properties, byte[] body) throws IOException { String message = new String(body, \u0026#34;utf-8\u0026#34;); System.out.println(\u0026#34;接收线程2：\u0026#34; + message); try { Thread.sleep(400); } catch (InterruptedException e) { e.printStackTrace(); }finally { //手动回复 channel.basicAck(envelope.getDeliveryTag(), false); } } }; channel.basicConsume(QUEUE_NAME, false, consumer1); } catch (IOException e) { e.printStackTrace(); } catch (TimeoutException e) { e.printStackTrace(); } } }).start(); } } 在公平分发模式下，延迟小的客户端（即效率更高的客户端）能消费更多的消息，而不必像轮询模式下那样，效率高的客户端去等待效率低的客户端完成对消息的消费，更能发挥效率高客户端的性能\n消息应答和消息持久化 消息应答 boolean autoAck=true; channel.basicConsume(QUEUE_NAME, autoAck, consumer1); autoAck=true即自动确认模式，一旦rabbitmq将消息发送给了消费者，rabbitmq就会把消息从内存中删除，这种情况下可能出现的问题有如果消费者线程挂了，由于消息已经在内存中被删除了，那么这个消息就丢失了。\nautoAck=false即手动确认模式，也是默认的。在这种模式下，rabbitmq将消息发送给消费者后并不会立即将消息从内存中删除，而是等待收到消费者的一个应答消息，才将消息从内存中删除。\n消息持久化 boolean durable=false; channel.queueDeclare(QUEUE_NAME, durable, false, false, null); boolean durable这个参数就是定义消息是否持久化的，false不进行持久化，true进行持久化。\ndurable这个参数对于已经定义的不进行持久化的队列，修改该参数为true会报错。\n交换机的几种模式 在声明交换机时需要指定一个类型\nchannel.exchangeDeclare(EXCHANGE_NAME, \u0026#34;fanout\u0026#34;); 这个类型：\nfanout不处理路由键 direct处理路由键 topic主题模式 订阅模式 在订阅模式下，一个消息的生产者对于多个消费者，而且这些消费者都能收到生产者发布的消息。具体的操作是生产者把消息发送到一个交换机，交换机上绑定多个队列，生产者发送消息时，消息会经由交换机发送到每一个交换机上绑定的队列，就可以实现多个消费者消费同一个消息。\n例如一个注册功能：\n​\t|\u0026mdash;\u0026mdash;\u0026mdash;-发送邮件\n​\t注册\u0026mdash;\u0026mdash;\u0026ndash;|\n​\t|\u0026mdash;\u0026mdash;\u0026mdash;-发送短信\n//发送 package com.moyuduo.rabbitmq.subscribe; import java.io.IOException; import java.util.concurrent.TimeoutException; import com.moyuduo.rabbitmq.utils.RabbitmqUtils; import com.rabbitmq.client.Channel; import com.rabbitmq.client.Connection; /** *@author litao,School of computer and software engineering,Xihua University *@date 2020/06/11 */ public class Send { private static final String EXCHANGE_NAME=\u0026#34;test-exchange-fanout\u0026#34;; public static void main(String[] args) throws IOException, TimeoutException, InterruptedException { Connection connection = RabbitmqUtils.getConnection(); Channel channel = connection.createChannel(); //申明交换机 channel.exchangeDeclare(EXCHANGE_NAME, \u0026#34;fanout\u0026#34;); String message=\u0026#34;subscribe message\u0026#34;; //发送消息 channel.basicPublish(EXCHANGE_NAME, \u0026#34;\u0026#34;, null, message.getBytes()); channel.close(); connection.close(); } } //开启两个线程模拟消费者 package com.moyuduo.rabbitmq.subscribe; import java.io.IOException; import java.util.concurrent.TimeoutException; import com.moyuduo.rabbitmq.utils.RabbitmqUtils; import com.rabbitmq.client.AMQP.BasicProperties; import com.rabbitmq.client.Channel; import com.rabbitmq.client.Connection; import com.rabbitmq.client.DefaultConsumer; import com.rabbitmq.client.Envelope; /** *@author litao,School of computer and software engineering,Xihua University *@date 2020/06/11 */ public class Recevie { private static final String EXCHANGE_NAME=\u0026#34;test-exchange-fanout\u0026#34;; public static void main(String[] args) throws IOException, TimeoutException { new Thread(new Runnable() { public void run() { final String QUEUE_NAME=\u0026#34;test-queue-email\u0026#34;; Connection connection; try { connection = RabbitmqUtils.getConnection(); final Channel channel = connection.createChannel(); //申明队列 channel.queueDeclare(QUEUE_NAME, false, false, false, null); //绑定队列到交换机 channel.queueBind(QUEUE_NAME, EXCHANGE_NAME, \u0026#34;\u0026#34;); //设置未手动回复前发送消息数 channel.basicQos(1); DefaultConsumer consumer1= new DefaultConsumer(channel) { @Override public void handleDelivery(String consumerTag, Envelope envelope, BasicProperties properties, byte[] body) throws IOException { String message=new String(body,\u0026#34;utf-8\u0026#34;); System.out.println(\u0026#34;接收线程1：\u0026#34;+message); try { Thread.sleep(200); } catch (InterruptedException e) { e.printStackTrace(); }finally { //手动回复 channel.basicAck(envelope.getDeliveryTag(), false); } } }; channel.basicConsume(QUEUE_NAME, false, consumer1); } catch (IOException e) { e.printStackTrace(); } catch (TimeoutException e) { e.printStackTrace(); } } }).start(); new Thread(new Runnable() { public void run() { final String QUEUE_NAME=\u0026#34;test-queue-cms\u0026#34;; Connection connection; try { connection = RabbitmqUtils.getConnection(); final Channel channel = connection.createChannel(); //申明队列 channel.queueDeclare(QUEUE_NAME, false, false, false, null); //绑定队列到交换机 channel.queueBind(QUEUE_NAME, EXCHANGE_NAME, \u0026#34;\u0026#34;); //设置未手动回复前发送消息数 channel.basicQos(1); DefaultConsumer consumer1 = new DefaultConsumer(channel) { @Override public void handleDelivery(String consumerTag, Envelope envelope, BasicProperties properties, byte[] body) throws IOException { String message = new String(body, \u0026#34;utf-8\u0026#34;); System.out.println(\u0026#34;接收线程2：\u0026#34; + message); try { Thread.sleep(400); } catch (InterruptedException e) { e.printStackTrace(); }finally { //手动回复 channel.basicAck(envelope.getDeliveryTag(), false); } } }; channel.basicConsume(QUEUE_NAME, false, consumer1); } catch (IOException e) { e.printStackTrace(); } catch (TimeoutException e) { e.printStackTrace(); } } }).start(); } } 在订阅模式下，交换机绑定的所有队列都会收到消息\n路由模式 //发送 package com.moyuduo.rabbitmq.routing; import java.io.IOException; import java.util.concurrent.TimeoutException; import com.moyuduo.rabbitmq.utils.RabbitmqUtils; import com.rabbitmq.client.Channel; import com.rabbitmq.client.Connection; /** *@author litao,School of computer and software engineering,Xihua University *@date 2020/06/11 */ public class Send { private static final String EXCHANGE_NAME=\u0026#34;test-exchange-direct\u0026#34;; public static void main(String[] args) throws IOException, TimeoutException, InterruptedException { Connection connection = RabbitmqUtils.getConnection(); Channel channel = connection.createChannel(); //申明交换机 channel.exchangeDeclare(EXCHANGE_NAME, \u0026#34;direct\u0026#34;); String message=\u0026#34;routing message\u0026#34;; //发送消息 channel.basicPublish(EXCHANGE_NAME, \u0026#34;warning\u0026#34;, null, message.getBytes()); channel.close(); connection.close(); } } //使用两个线程模拟消费者 package com.moyuduo.rabbitmq.routing; import java.io.IOException; import java.util.concurrent.TimeoutException; import com.moyuduo.rabbitmq.utils.RabbitmqUtils; import com.rabbitmq.client.AMQP.BasicProperties; import com.rabbitmq.client.Channel; import com.rabbitmq.client.Connection; import com.rabbitmq.client.DefaultConsumer; import com.rabbitmq.client.Envelope; /** *@author litao,School of computer and software engineering,Xihua University *@date 2020/06/11 */ public class Receive { private static final String EXCHANGE_NAME=\u0026#34;test-exchange-direct\u0026#34;; public static void main(String[] args) { new Thread(new Runnable() { public void run() { try { final String QUEUE_NAME=\u0026#34;test-queue-a\u0026#34;; Connection connection = RabbitmqUtils.getConnection(); final Channel channel = connection.createChannel(); //申明队列 channel.queueDeclare(QUEUE_NAME, false, false, false, null); //队列绑定到交换机 channel.queueBind(QUEUE_NAME, EXCHANGE_NAME, \u0026#34;error\u0026#34;); channel.basicQos(1); DefaultConsumer consumer = new DefaultConsumer(channel) { @Override public void handleDelivery(String consumerTag, Envelope envelope, BasicProperties properties, byte[] body) throws IOException { String message=new String(body,\u0026#34;utf-8\u0026#34;); System.out.println(\u0026#34;消费线程1：\u0026#34;+message); channel.basicAck(envelope.getDeliveryTag(), false); } }; channel.basicConsume(QUEUE_NAME,false, consumer); } catch (IOException e) { e.printStackTrace(); } catch (TimeoutException e) { e.printStackTrace(); } } }).start(); new Thread(new Runnable() { public void run() { try { final String QUEUE_NAME=\u0026#34;test-queue-b\u0026#34;; Connection connection = RabbitmqUtils.getConnection(); final Channel channel = connection.createChannel(); //申明队列 channel.queueDeclare(QUEUE_NAME, false, false, false, null); //队列绑定交换机 channel.queueBind(QUEUE_NAME, EXCHANGE_NAME, \u0026#34;info\u0026#34;); channel.queueBind(QUEUE_NAME, EXCHANGE_NAME, \u0026#34;error\u0026#34;); channel.queueBind(QUEUE_NAME, EXCHANGE_NAME, \u0026#34;warning\u0026#34;); channel.basicQos(1); DefaultConsumer consumer = new DefaultConsumer(channel) { @Override public void handleDelivery(String consumerTag, Envelope envelope, BasicProperties properties, byte[] body) throws IOException { String message=new String(body,\u0026#34;utf-8\u0026#34;); System.out.println(\u0026#34;消费线程2：\u0026#34;+message); channel.basicAck(envelope.getDeliveryTag(), false); } }; channel.basicConsume(QUEUE_NAME,false, consumer); } catch (IOException e) { e.printStackTrace(); } catch (TimeoutException e) { e.printStackTrace(); } } }).start(); } } 主题模式 //发送 package com.moyuduo.rabbitmq.toppic; import java.io.IOException; import java.util.concurrent.TimeoutException; import com.moyuduo.rabbitmq.utils.RabbitmqUtils; import com.rabbitmq.client.Channel; import com.rabbitmq.client.Connection; /** *@author litao,School of computer and software engineering,Xihua University *@date 2020/06/11 */ public class Send { private static final String EXCHANGE_NAME=\u0026#34;test-exchange-topic\u0026#34;; public static void main(String[] args) throws IOException, TimeoutException, InterruptedException { Connection connection = RabbitmqUtils.getConnection(); Channel channel = connection.createChannel(); //申明交换机 channel.exchangeDeclare(EXCHANGE_NAME, \u0026#34;topic\u0026#34;); String message=\u0026#34;china weather\u0026#34;; //发送消息 channel.basicPublish(EXCHANGE_NAME, \u0026#34;china.weather\u0026#34;, null, message.getBytes()); message=\u0026#34;japan weather\u0026#34;; //发送消息 channel.basicPublish(EXCHANGE_NAME, \u0026#34;japan.weather\u0026#34;, null, message.getBytes()); channel.close(); connection.close(); } } //使用三个线程模拟消费者 package com.moyuduo.rabbitmq.toppic; import java.io.IOException; import java.util.concurrent.TimeoutException; import com.moyuduo.rabbitmq.utils.RabbitmqUtils; import com.rabbitmq.client.AMQP.BasicProperties; import com.rabbitmq.client.Channel; import com.rabbitmq.client.Connection; import com.rabbitmq.client.DefaultConsumer; import com.rabbitmq.client.Envelope; /** * @author litao,School of computer and software engineering,Xihua University * @date 2020/06/11 */ public class Receive { private static final String EXCHANGE_NAME = \u0026#34;test-exchange-topic\u0026#34;; public static void main(String[] args) { new Thread(new Runnable() { public void run() { try { final String QUEUE_NAME = \u0026#34;test-queue-topic-1\u0026#34;; Connection connection = RabbitmqUtils.getConnection(); final Channel channel = connection.createChannel(); // 申明队列 channel.queueDeclare(QUEUE_NAME, false, false, false, null); // 队列绑定到交换机 channel.queueBind(QUEUE_NAME, EXCHANGE_NAME, \u0026#34;china.#\u0026#34;); channel.basicQos(1); DefaultConsumer consumer = new DefaultConsumer(channel) { @Override public void handleDelivery(String consumerTag, Envelope envelope, BasicProperties properties, byte[] body) throws IOException { String message = new String(body, \u0026#34;utf-8\u0026#34;); System.out.println(\u0026#34;消费线程1：\u0026#34; + message); channel.basicAck(envelope.getDeliveryTag(), false); } }; channel.basicConsume(QUEUE_NAME, false, consumer); } catch (IOException e) { e.printStackTrace(); } catch (TimeoutException e) { e.printStackTrace(); } } }).start(); new Thread(new Runnable() { public void run() { try { final String QUEUE_NAME = \u0026#34;test-queue-topic-2\u0026#34;; Connection connection = RabbitmqUtils.getConnection(); final Channel channel = connection.createChannel(); // 申明队列 channel.queueDeclare(QUEUE_NAME, false, false, false, null); // 队列绑定交换机 channel.queueBind(QUEUE_NAME, EXCHANGE_NAME, \u0026#34;japan.#\u0026#34;); channel.basicQos(1); DefaultConsumer consumer = new DefaultConsumer(channel) { @Override public void handleDelivery(String consumerTag, Envelope envelope, BasicProperties properties, byte[] body) throws IOException { String message = new String(body, \u0026#34;utf-8\u0026#34;); System.out.println(\u0026#34;消费线程2：\u0026#34; + message); channel.basicAck(envelope.getDeliveryTag(), false); } }; channel.basicConsume(QUEUE_NAME, false, consumer); } catch (IOException e) { e.printStackTrace(); } catch (TimeoutException e) { e.printStackTrace(); } } }).start(); new Thread(new Runnable() { public void run() { try { final String QUEUE_NAME = \u0026#34;test-queue-topic-3\u0026#34;; Connection connection = RabbitmqUtils.getConnection(); final Channel channel = connection.createChannel(); // 申明队列 channel.queueDeclare(QUEUE_NAME, false, false, false, null); // 队列绑定交换机 channel.queueBind(QUEUE_NAME, EXCHANGE_NAME, \u0026#34;#.weather\u0026#34;); channel.basicQos(1); DefaultConsumer consumer = new DefaultConsumer(channel) { @Override public void handleDelivery(String consumerTag, Envelope envelope, BasicProperties properties, byte[] body) throws IOException { String message = new String(body, \u0026#34;utf-8\u0026#34;); System.out.println(\u0026#34;消费线程3：\u0026#34; + message); channel.basicAck(envelope.getDeliveryTag(), false); } }; channel.basicConsume(QUEUE_NAME, false, consumer); } catch (IOException e) { e.printStackTrace(); } catch (TimeoutException e) { e.printStackTrace(); } } }).start(); } } Rabbitmq的消息确认机制（事务+confirm） 问题：生产者将消息发送出去之后，消息到底有没有到达rabbitmq服务器默认情况下是不知道啊\n两种方式：\n​\tAMQP实现了事务机制\n​\tConfirm模式\n事务机制确认消息 //发送 package com.moyuduo.rabbitmq.tx; import java.io.IOException; import java.util.concurrent.TimeoutException; import com.moyuduo.rabbitmq.utils.RabbitmqUtils; import com.rabbitmq.client.Channel; import com.rabbitmq.client.Connection; /** *@author litao,School of computer and software engineering,Xihua University *@date 2020/06/10 */ public class Send { public static final String QUEUE_NAME=\u0026#34;test-queue-tx\u0026#34;; public static void main(String[] args) throws IOException, TimeoutException { //获取连接 Connection connection = RabbitmqUtils.getConnection(); //从连接中获取通道 Channel channel = connection.createChannel(); //创建队列申明 channel.queueDeclare(QUEUE_NAME, false, false, false, null); String message=\u0026#34;hello\u0026#34;; try { channel.txSelect(); channel.basicPublish(\u0026#34;\u0026#34;, QUEUE_NAME, null, message.getBytes()); int i=10/0; System.out.println(\u0026#34;发送消息：\u0026#34;+message+\u0026#34; 成功！\u0026#34;); channel.txCommit(); }catch(Exception e) { channel.txRollback(); System.out.println(\u0026#34;发送消息：\u0026#34;+message+\u0026#34; 失败！\u0026#34;); } //关闭通道 channel.close(); //关闭连接 connection.close(); } } //接收 package com.moyuduo.rabbitmq.tx; import java.io.IOException; import java.util.concurrent.TimeoutException; import com.moyuduo.rabbitmq.utils.RabbitmqUtils; import com.rabbitmq.client.AMQP.BasicProperties; import com.rabbitmq.client.Channel; import com.rabbitmq.client.Connection; import com.rabbitmq.client.ConsumerCancelledException; import com.rabbitmq.client.DefaultConsumer; import com.rabbitmq.client.Envelope; import com.rabbitmq.client.QueueingConsumer; import com.rabbitmq.client.QueueingConsumer.Delivery; import com.rabbitmq.client.ShutdownSignalException; /** *@author litao,School of computer and software engineering,Xihua University *@date 2020/06/10 */ public class Receive { public static final String QUEUE_NAME=\u0026#34;test-queue-tx\u0026#34;; public static void main(String[] args) throws IOException, TimeoutException, ShutdownSignalException, ConsumerCancelledException, InterruptedException { //获取连接 Connection connection = RabbitmqUtils.getConnection(); //创建通道 Channel channel = connection.createChannel(); //队列申明 channel.queueDeclare(QUEUE_NAME, false, false, false, null); DefaultConsumer consumer = new DefaultConsumer(channel) { @Override public void handleDelivery(String consumerTag, Envelope envelope, BasicProperties properties, byte[] body) throws IOException { String message=new String(body,\u0026#34;utf-8\u0026#34;); System.out.println(\u0026#34;收到消息：\u0026#34;+message); } }; //监听队列 channel.basicConsume(QUEUE_NAME, consumer); } } confirm机制确认消息 串行 //发送 package com.moyuduo.rabbitmq.confirm; import java.io.IOException; import java.util.concurrent.TimeoutException; import com.moyuduo.rabbitmq.utils.RabbitmqUtils; import com.rabbitmq.client.Channel; import com.rabbitmq.client.Connection; /** * @author litao,School of computer and software engineering,Xihua University * @date 2020/06/10 */ public class Send { public static final String QUEUE_NAME = \u0026#34;test-queue-confirm\u0026#34;; public static void main(String[] args) throws IOException, TimeoutException, InterruptedException { // 获取连接 Connection connection = RabbitmqUtils.getConnection(); // 从连接中获取通道 Channel channel = connection.createChannel(); // 创建队列申明 channel.queueDeclare(QUEUE_NAME, false, false, false, null); channel.confirmSelect(); String message = \u0026#34;hello\u0026#34;; channel.basicPublish(\u0026#34;\u0026#34;, QUEUE_NAME, null, message.getBytes()); //阻塞判断消息是否被接收 boolean confirms = channel.waitForConfirms(); if(confirms) { System.out.println(\u0026#34;发送消息：\u0026#34; + message + \u0026#34; 成功！\u0026#34;); }else { System.out.println(\u0026#34;发送消息：\u0026#34; + message + \u0026#34; 失败！\u0026#34;); } // 关闭通道 channel.close(); // 关闭连接 connection.close(); } } //接收 package com.moyuduo.rabbitmq.confirm; import java.io.IOException; import java.util.concurrent.TimeoutException; import com.moyuduo.rabbitmq.utils.RabbitmqUtils; import com.rabbitmq.client.AMQP.BasicProperties; import com.rabbitmq.client.Channel; import com.rabbitmq.client.Connection; import com.rabbitmq.client.ConsumerCancelledException; import com.rabbitmq.client.DefaultConsumer; import com.rabbitmq.client.Envelope; import com.rabbitmq.client.QueueingConsumer; import com.rabbitmq.client.QueueingConsumer.Delivery; import com.rabbitmq.client.ShutdownSignalException; /** * @author litao,School of computer and software engineering,Xihua University * @date 2020/06/10 */ public class Receive { public static final String QUEUE_NAME = \u0026#34;test-queue-confirm\u0026#34;; public static void main(String[] args) throws IOException, TimeoutException, ShutdownSignalException, ConsumerCancelledException, InterruptedException { // 获取连接 Connection connection = RabbitmqUtils.getConnection(); // 创建通道 Channel channel = connection.createChannel(); // 队列申明 channel.queueDeclare(QUEUE_NAME, false, false, false, null); DefaultConsumer consumer = new DefaultConsumer(channel) { @Override public void handleDelivery(String consumerTag, Envelope envelope, BasicProperties properties, byte[] body) throws IOException { String message = new String(body, \u0026#34;utf-8\u0026#34;); System.out.println(\u0026#34;收到消息：\u0026#34; + message); } }; // 监听队列 channel.basicConsume(QUEUE_NAME, consumer); } } 异步 //发送 package com.moyuduo.rabbitmq.confirm; import java.io.IOException; import java.util.concurrent.TimeoutException; import com.moyuduo.rabbitmq.utils.RabbitmqUtils; import com.rabbitmq.client.Channel; import com.rabbitmq.client.ConfirmListener; import com.rabbitmq.client.Connection; /** * @author litao,School of computer and software engineering,Xihua University * @date 2020/06/10 */ public class Send2 { public static final String QUEUE_NAME = \u0026#34;test-queue-confirm\u0026#34;; public static void main(String[] args) throws IOException, TimeoutException, InterruptedException { // 获取连接 Connection connection = RabbitmqUtils.getConnection(); // 从连接中获取通道 Channel channel = connection.createChannel(); // 创建队列申明 channel.queueDeclare(QUEUE_NAME, false, false, false, null); channel.confirmSelect(); //confirm监听器 channel.addConfirmListener(new ConfirmListener() { //处理消息发送失败 public void handleNack(long deliveryTag, boolean multiple) throws IOException { } //处理消息发送成功 public void handleAck(long deliveryTag, boolean multiple) throws IOException { } }); String message = \u0026#34;hello\u0026#34;; channel.basicPublish(\u0026#34;\u0026#34;, QUEUE_NAME, null, message.getBytes()); // 关闭通道 channel.close(); // 关闭连接 connection.close(); } } ","permalink":"https://moyuduo.github.io/posts/rabbitmq/","summary":"RabbitMQ安装 安装erlang wget http://www.rabbitmq.com/releases/erlang/erlang-18.3-1.el7.centos.x86_64.rpm rpm -ivh erlang-18.3-1.el7.centos.x86_64.rpm 安装socat wget http://repo.iotti.biz/CentOS/7/x86_64/socat-1.7.3.2-5.el7.lux.x86_64.rpm rpm -ivh socat-1.7.3.2-5.el7.lux.x86_64.rpm 安装rabbitmq wget http://www.rabbitmq.com/releases/rabbitmq-server/v3.6.5/rabbitmq-server-3.6.5-1.noarch.rpm rpm -ivh rabbitmq-server-3.6.5-1.noarch.rpm 如果没提示错误，就安装成功\n启用后台管理插件 rabbitmq-plugins enable rabbitmq_management 提示： The following plugins have been enabled: mochiweb webmachine rabbitmq_web_dispatch amqp_client rabbitmq_management_agent rabbitmq_management Applying plugin configuration to rabbit@localhost... started 6 plugins. 则安装成功 配置防火墙开启端口 firewall-cmd --zone=public --add-port=15672/tcp --permanent firewall-cmd --zone=public --add-port=5672/tcp --permanent firewall-cmd --reload 开启远程访问 由于rabbitmq默认用户guest只允许本机访问，为了能够支持远程访问，需要在/etc/rabbitmq目录下新建rabbitmq.config文件，内容为[{rabbit, [{loopback_users, []}]}].然后重启service rabbitmq-server restart即可\n远程访问 在浏览器地址栏输入http://192.168.37.131:15672即可访问登录页面，使用user：guest、password：guest登录成功说明安装配置成功\n队列 简单队列 package com.moyuduo.rabbitmq.utils; /** *@author litao,School of computer and software engineering,Xihua University *@date 2020/06/10 */ import java.","title":"RabbitMQ"},{"content":"redis主从、哨兵、分片集群 概念：\nredis主从及哨兵\nredis分片集群\n单机 在redis安装目录下执行./src/redis-server redis.conf会在6379端口启动单机版redis 使用 python3:\n安装依赖库:pip3 install redis\nimport redis conn = redis.StrictRedis(connection_pool=redis.ConnectionPool( host=\u0026#34;127.0.0.1\u0026#34;, port=\u0026#34;6381\u0026#34;, password=\u0026#34;\u0026#34; )) # string类型的写入读取 ret = conn.set(\u0026#34;py-k1\u0026#34;, \u0026#34;py-v1\u0026#34;) print(ret) val = conn.get(\u0026#34;py-k1\u0026#34;) print(val) 执行：\npython3 single-redis.py True b\u0026#39;py-v1\u0026#39; 主从搭建 参考：\nredis主从模式搭建\n下载redis 去http://download.redis.io/releases/上下载对应版本的redis(本次使用redis-6.0.0) curl -O http://download.redis.io/releases/redis-6.0.0.tar.gz 解压tar -zxvf redis-6.0.0.tar.gz 进入文件夹cd redis-6.0.0 编译redis文件make 规划 Name Role IP Port master1 master 127.0.0.1 6379 slave1 slave 127.0.0.1 6380 slave2 slave 127.0.0.1 6381 准备配置文件 修改redis安装目录下的redis.conf文件daemonize为yes后台启动 拷贝redis.conf为master.conf 拷贝redis.conf为slave1.conf并修改port为6380,添加replicaof 127.0.0.1 6379 拷贝redis.conf为slave2.conf并修改port为6381,添加replicaof 127.0.0.1 6379 启动主从节点 进入到redis安装目录下的src目录\n启动master节点:./redis-server master.conf 启动slave1节点:./redis-server slave1.conf 启动slave2节点:./redis-server slave2.conf 查看redis启动状态: ps -ef|grep redis root 7219 1 0 09:51 ? 00:00:00 ./redis-server 127.0.0.1:6379 root 7309 1 0 09:53 ? 00:00:00 ./redis-server 127.0.0.1:6380 root 7432 1 0 09:55 ? 00:00:00 ./redis-server 127.0.0.1:6381 root 7442 2409 0 09:55 pts/0 00:00:00 grep --color=auto redis 验证主从 主节点上执行:\n127.0.0.1:6379\u0026gt; info replication # Replication role:master connected_slaves:2 slave0:ip=127.0.0.1,port=6381,state=online,offset=9446,lag=1 slave1:ip=127.0.0.1,port=6380,state=online,offset=9446,lag=1 master_replid:05521584a197dc89d0c9117ab8dae0e2b7c80e6b master_replid2:0000000000000000000000000000000000000000 master_repl_offset:9446 master_repl_meaningful_offset:80 second_repl_offset:-1 repl_backlog_active:1 repl_backlog_size:1048576 repl_backlog_first_byte_offset:1 repl_backlog_histlen:9446 验证主从同步 进入到redis安装目录下的src文件夹\n执行./redis-cli -p 6379进入主节点 执行set k1 v1在主节点上设置值 执行./redis-cli -p 6380进入slave1节点 127.0.0.1:6380\u0026gt; keys * 1) \u0026#34;k1\u0026#34; #k1已经同步到了slave1节点 127.0.0.1:6380\u0026gt; get k1 \u0026#34;v1\u0026#34; 127.0.0.1:6380\u0026gt; 执行./redis-cli -p 6381进入slave2节点 127.0.0.1:6381\u0026gt; keys * 1) \u0026#34;k1\u0026#34; 127.0.0.1:6381\u0026gt; get k1 \u0026#34;v1\u0026#34; 127.0.0.1:6381\u0026gt; 验证从节点故障下线恢复后能否从主节点同步数据 手动停掉slave2节点kill xxx 验证节点状态 root 7219 1 0 09:51 ? 00:00:11 ./redis-server 127.0.0.1:6379 root 7309 1 0 09:53 ? 00:00:10 ./redis-server 127.0.0.1:6380 在master上设置值 127.0.0.1:6379\u0026gt; set k2 v2 OK 127.0.0.1:6379\u0026gt; set k3 v3 OK 127.0.0.1:6379\u0026gt; 验证slave1有没有同步数据 127.0.0.1:6380\u0026gt; keys * 1) \u0026#34;k3\u0026#34; 2) \u0026#34;k2\u0026#34; 3) \u0026#34;k1\u0026#34; 127.0.0.1:6380\u0026gt; get k2 \u0026#34;v2\u0026#34; 127.0.0.1:6380\u0026gt; get k3 \u0026#34;v3\u0026#34; 127.0.0.1:6380\u0026gt; slave2上线./redis-server slave2.conf 执行./redis-cli -p 6381登录slave2 127.0.0.1:6381\u0026gt; keys * 1) \u0026#34;k1\u0026#34; #上线后成功从master同步数据 2) \u0026#34;k2\u0026#34; 3) \u0026#34;k3\u0026#34; 127.0.0.1:6381\u0026gt; get k2 \u0026#34;v2\u0026#34; 127.0.0.1:6381\u0026gt; get k3 \u0026#34;v3\u0026#34; 127.0.0.1:6381\u0026gt; 验证slave节点能否写数据 在slave2上执行set s2 s2 #从节点不可写数据 127.0.0.1:6381\u0026gt; set s2 s2 (error) READONLY You can\u0026#39;t write against a read only replica. 验证master节点挂后能否从slave读数据 下线master节点kill xxx 验证在slave1上查数据 127.0.0.1:6380\u0026gt; keys * 1) \u0026#34;k3\u0026#34; 2) \u0026#34;k2\u0026#34; 3) \u0026#34;k1\u0026#34; 127.0.0.1:6380\u0026gt; 127.0.0.1:6380\u0026gt; 127.0.0.1:6380\u0026gt; get k2 \u0026#34;v2\u0026#34; 127.0.0.1:6380\u0026gt; 验证在slave2上查数据 127.0.0.1:6381\u0026gt; keys * 1) \u0026#34;k1\u0026#34; 2) \u0026#34;k2\u0026#34; 3) \u0026#34;k3\u0026#34; 127.0.0.1:6381\u0026gt; get k2 \u0026#34;v2\u0026#34; 验证master故障下线恢复后写入数据slave能否同步 下线master节点kill xxx 上线master节点./redis-server master.conf 在master节点上执行set k4 v4 在slave1节点上验证数据 127.0.0.1:6380\u0026gt; keys * 1) \u0026#34;k3\u0026#34; 2) \u0026#34;k4\u0026#34; 3) \u0026#34;k2\u0026#34; 4) \u0026#34;k1\u0026#34; 127.0.0.1:6380\u0026gt; get k4 \u0026#34;v4\u0026#34; 127.0.0.1:6380\u0026gt; 在slave1节点上验证数据 127.0.0.1:6381\u0026gt; keys * 1) \u0026#34;k1\u0026#34; 2) \u0026#34;k2\u0026#34; 3) \u0026#34;k4\u0026#34; 4) \u0026#34;k3\u0026#34; 127.0.0.1:6381\u0026gt; get v4 (nil) 127.0.0.1:6381\u0026gt; get k4 \u0026#34;v4\u0026#34; 127.0.0.1:6381\u0026gt; 使用 python3:\n哨兵模式 参考：\nredis哨兵模式搭建\n哨兵模式相较于主从模式主要是增加了master下线选举新的slave节点为master\n规划 Name Role IP Port master1 master 127.0.0.1 6379 slave1 slave 127.0.0.1 6380 slave2 slave 127.0.0.1 6381 sentinel1 - 127.0.0.1 26379 sentinel2 - 127.0.0.1 26380 sentinel3 - 127.0.0.1 26381 搭建主从 参考前面主从搭建\n搭建哨兵 一个哨兵节点也是一个redis节点，哨兵节点不负责数据的读写，只负责监控主从节点，当主节点下线后，所有的哨兵节点(一般为基数)会进行投票选出一个新的主节点\n准备配置文件 redis安装目录下有sentinel.conf示例哨兵配置简介\n准备哨兵配置文件，按需修改 port 26379 daemonize yes pidfile /var/run/redis-sentinel.pid logfile \u0026#34;\u0026#34; dir /tmp #定义哨兵监视的主节点，并且需要至少2个哨兵节点连接不到主节点才判定为下线 sentinel monitor mymaster 127.0.0.1 6379 2 #主节点3秒内无响应则认为下线 sentinel down-after-milliseconds mymaster 3000 #当从节点当选为主节点后，同时只能有一个从节点从主节点同步数据 sentinel parallel-syncs mymaster 1 sentinel failover-timeout mymaster 180000 sentinel deny-scripts-reconfig yes 复制上述配置文件到sentinel1.conf 复制上述配置文件到sentinel2.conf，并修改port为26380 复制上述配置文件到sentinel3.conf，并修改port为26381 启动哨兵1、2、3 ./redis-server sentinelX.conf 查看状态 ps -ef|grep redis root 7309 1 0 09:53 ? 00:00:30 ./redis-server 127.0.0.1:6380 root 12413 1 0 11:11 ? 00:00:20 ./redis-server 127.0.0.1:6381 root 12968 1 0 11:21 ? 00:00:21 ./redis-server 127.0.0.1:6379 root 17727 1 0 13:25 ? 00:00:00 ./redis-server *:26379 [sentinel] root 17745 1 2 13:25 ? 00:00:00 ./redis-server *:26380 [sentinel] root 17753 1 4 13:25 ? 00:00:00 ./redis-server *:26381 [sentinel] root 17761 2409 0 13:25 pts/0 00:00:00 grep --color=auto redis 验证 验证主节点下线后从节点是否会被选为主节点 下线主节点 kill xxx 查看slave1状态 127.0.0.1:6380\u0026gt; info replication # Replication role:slave master_host:127.0.0.1 master_port:6381 master_link_status:up master_last_io_seconds_ago:1 master_sync_in_progress:0 slave_repl_offset:64986 slave_priority:100 slave_read_only:1 connected_slaves:0 master_replid:2e365fdeb24324c2e16f68e1ec945a4cd1ac9a78 master_replid2:05521584a197dc89d0c9117ab8dae0e2b7c80e6b master_repl_offset:64986 master_repl_meaningful_offset:64986 second_repl_offset:58804 repl_backlog_active:1 repl_backlog_size:1048576 repl_backlog_first_byte_offset:1 repl_backlog_histlen:64986 查看slave2状态 127.0.0.1:6381\u0026gt; info replication # Replication role:master #slave2已经被选为主节点 connected_slaves:1 slave0:ip=127.0.0.1,port=6380,state=online,offset=66715,lag=0 master_replid:2e365fdeb24324c2e16f68e1ec945a4cd1ac9a78 master_replid2:05521584a197dc89d0c9117ab8dae0e2b7c80e6b master_repl_offset:66715 master_repl_meaningful_offset:66715 second_repl_offset:58804 repl_backlog_active:1 repl_backlog_size:1048576 repl_backlog_first_byte_offset:1 repl_backlog_histlen:66715 验证原主节点下线后重新上线后角色类型 下线主节点重新选主(参考上面) 上线原主节点 ./redis-server master.conf 验证原主节点类型 127.0.0.1:6379\u0026gt; info replication # Replication role:slave #重新上线后原master节点类型为从节点 master_host:127.0.0.1 master_port:6381 master_link_status:up master_last_io_seconds_ago:1 master_sync_in_progress:0 slave_repl_offset:115766 slave_priority:100 slave_read_only:1 connected_slaves:0 master_replid:2e365fdeb24324c2e16f68e1ec945a4cd1ac9a78 master_replid2:0000000000000000000000000000000000000000 master_repl_offset:115766 master_repl_meaningful_offset:115766 second_repl_offset:-1 repl_backlog_active:1 repl_backlog_size:1048576 repl_backlog_first_byte_offset:111593 repl_backlog_histlen:4174 使用 python3:\nfrom redis.sentinel import Sentinel if __name__ == \u0026#34;__main__\u0026#34;: sentinel_list = [ (\u0026#34;127.0.0.1\u0026#34;, \u0026#34;26379\u0026#34;), (\u0026#34;127.0.0.1\u0026#34;, \u0026#34;26380\u0026#34;), (\u0026#34;127.0.0.1\u0026#34;, \u0026#34;26381\u0026#34;), ] sentinel = Sentinel(sentinel_list) master = sentinel.master_for(\u0026#39;mymaster\u0026#39;, socket_timeout=0.1) ret = master.set(\u0026#39;py-sentinel-k1\u0026#39;, \u0026#39;py-sentinel-v1\u0026#39;) print(ret) slave = sentinel.slave_for(\u0026#39;mymaster\u0026#39;, socket_timeout=0.1) ret = slave.get(\u0026#39;py-sentinel-k1\u0026#39;) print(ret) 执行：\npython3 conn-sentinel-redis.py True b\u0026#39;py-sentinel-v1\u0026#39; 分片集群 参考：\nredis分片集群搭建\nredis分片集群搭建\n分片集群相较于哨兵模式的优点在于哨兵模式虽然保证了高可用，但是不管是master还是slave节点，每个节点都保存了全量的数据，这样对于大数据的场景就不太友好，分片集群的优点在于集群中的每个节点只保存一部分数据，整个集群作为一个整体对外提供服务，并且集群中的每个分片也有备份，分片可以看成是一个哨兵模式的集群，当分片的master节点挂了，那么分片的slave节点会成为master节点继续提供服务\n规划 Name Role IP Port node1 - 127.0.0.1 6379 node2 - 127.0.0.1 6380 node3 - 127.0.0.1 6381 node4 - 127.0.0.1 6382 node5 - 127.0.0.1 6383 node6 - 127.0.0.1 6384 准备配置文件 daemonize yes port 6379 # 本地数据库存储目录，需要修改 dir /storehouse/redis_t/cluster/redis_6379 # 是否以集群模式启动 cluster-enabled yes # 集群节点回应最长时间，超过该时间被认为下线 cluster-node-timeout 15000 # 生成的集群节点配置文件名，文件名需要修改 cluster-config-file nodes_6379.conf 准备redis-cluster-xxx.conf修改port、dir和cluster-config-file\nll total 24 -rw-r--r--. 1 root root 268 Nov 27 15:09 redis-cluster-6379.conf -rw-r--r--. 1 root root 268 Nov 27 15:10 redis-cluster-6380.conf -rw-r--r--. 1 root root 268 Nov 27 15:10 redis-cluster-6381.conf -rw-r--r--. 1 root root 268 Nov 27 15:11 redis-cluster-6382.conf -rw-r--r--. 1 root root 268 Nov 27 15:11 redis-cluster-6383.conf -rw-r--r--. 1 root root 268 Nov 27 15:12 redis-cluster-6384.conf 启动节点： ./redis-server /storehouse/redis_t/cluster/redis-cluster-6379.conf ./redis-server /storehouse/redis_t/cluster/redis-cluster-6380.conf ... 查看状态\nps -ef|grep redis root 22656 1 0 15:15 ? 00:00:00 ./redis-server *:6379 [cluster] root 22669 1 0 15:15 ? 00:00:00 ./redis-server *:6380 [cluster] root 22683 1 0 15:15 ? 00:00:00 ./redis-server *:6381 [cluster] root 22691 1 0 15:15 ? 00:00:00 ./redis-server *:6382 [cluster] root 22697 1 0 15:15 ? 00:00:00 ./redis-server *:6383 [cluster] root 22707 1 1 15:15 ? 00:00:00 ./redis-server *:6384 [cluster] root 22715 2409 0 15:15 pts/0 00:00:00 grep --color=auto redis 创建集群 master节点数量=节点总数/(replicas+1),所以这里总共6个节点，replicas为1，那么master数量为3即由三个分片，每个分片有一个slave节点\n./redis-cli --cluster create 127.0.0.1:6379 127.0.0.1:6380 127.0.0.1:6381 127.0.0.1:6382 127.0.0.1:6383 127.0.0.1:6384 --cluster-replicas 1 \u0026gt;\u0026gt;\u0026gt; Performing hash slots allocation on 6 nodes... Master[0] -\u0026gt; Slots 0 - 5460 Master[1] -\u0026gt; Slots 5461 - 10922 Master[2] -\u0026gt; Slots 10923 - 16383 Adding replica 127.0.0.1:6383 to 127.0.0.1:6379 Adding replica 127.0.0.1:6384 to 127.0.0.1:6380 Adding replica 127.0.0.1:6382 to 127.0.0.1:6381 \u0026gt;\u0026gt;\u0026gt; Trying to optimize slaves allocation for anti-affinity [WARNING] Some slaves are in the same host as their master M: eb896ce4ed050f7135d298c7c09b5efc34233539 127.0.0.1:6379 slots:[0-5460] (5461 slots) master M: 8fec6b575bf196aa0648cfee4d1169c33ea88db1 127.0.0.1:6380 slots:[5461-10922] (5462 slots) master M: 851d9155d0acc04d278dcbadd0e7c0642c40974a 127.0.0.1:6381 slots:[10923-16383] (5461 slots) master S: 7fffe89ccf2247acd1612f1692c6972dc37af78a 127.0.0.1:6382 replicates 851d9155d0acc04d278dcbadd0e7c0642c40974a #127.0.0.1:6382这个节点是127.0.0.1:6381这个节点的副本 S: 136fd46e678c22319b1db4d34efe1a7bc44c988c 127.0.0.1:6383 replicates eb896ce4ed050f7135d298c7c09b5efc34233539 S: c599010190b588c4f47ecae2b838e7e113e00683 127.0.0.1:6384 replicates 8fec6b575bf196aa0648cfee4d1169c33ea88db1 Can I set the above configuration? (type \u0026#39;yes\u0026#39; to accept): yes \u0026gt;\u0026gt;\u0026gt; Nodes configuration updated \u0026gt;\u0026gt;\u0026gt; Assign a different config epoch to each node \u0026gt;\u0026gt;\u0026gt; Sending CLUSTER MEET messages to join the cluster Waiting for the cluster to join ..... \u0026gt;\u0026gt;\u0026gt; Performing Cluster Check (using node 127.0.0.1:6379) M: eb896ce4ed050f7135d298c7c09b5efc34233539 127.0.0.1:6379 slots:[0-5460] (5461 slots) master 1 additional replica(s) M: 851d9155d0acc04d278dcbadd0e7c0642c40974a 127.0.0.1:6381 slots:[10923-16383] (5461 slots) master 1 additional replica(s) S: 136fd46e678c22319b1db4d34efe1a7bc44c988c 127.0.0.1:6383 slots: (0 slots) slave replicates eb896ce4ed050f7135d298c7c09b5efc34233539 S: 7fffe89ccf2247acd1612f1692c6972dc37af78a 127.0.0.1:6382 slots: (0 slots) slave replicates 851d9155d0acc04d278dcbadd0e7c0642c40974a S: c599010190b588c4f47ecae2b838e7e113e00683 127.0.0.1:6384 slots: (0 slots) slave replicates 8fec6b575bf196aa0648cfee4d1169c33ea88db1 M: 8fec6b575bf196aa0648cfee4d1169c33ea88db1 127.0.0.1:6380 slots:[5461-10922] (5462 slots) master 1 additional replica(s) [OK] All nodes agree about slots configuration. \u0026gt;\u0026gt;\u0026gt; Check for open slots... \u0026gt;\u0026gt;\u0026gt; Check slots coverage... [OK] All 16384 slots covered. 登录节点查看集群信息\n# -c 参数指定以集群模式连接redis ./redis-cli -c -p 6379 127.0.0.1:6379\u0026gt; cluster info cluster_state:ok cluster_slots_assigned:16384 cluster_slots_ok:16384 cluster_slots_pfail:0 cluster_slots_fail:0 cluster_known_nodes:6 cluster_size:3 cluster_current_epoch:6 cluster_my_epoch:1 cluster_stats_messages_ping_sent:349 cluster_stats_messages_pong_sent:343 cluster_stats_messages_sent:692 cluster_stats_messages_ping_received:338 cluster_stats_messages_pong_received:349 cluster_stats_messages_meet_received:5 cluster_stats_messages_received:692 127.0.0.1:6379\u0026gt; cluster node (error) ERR Unknown subcommand or wrong number of arguments for \u0026#39;node\u0026#39;. Try CLUSTER HELP. 127.0.0.1:6379\u0026gt; cluster nodes 851d9155d0acc04d278dcbadd0e7c0642c40974a 127.0.0.1:6381@16381 master - 0 1669534510801 3 connected 10923-16383 eb896ce4ed050f7135d298c7c09b5efc34233539 127.0.0.1:6379@16379 myself,master - 0 1669534511000 1 connected 0-5460 136fd46e678c22319b1db4d34efe1a7bc44c988c 127.0.0.1:6383@16383 slave eb896ce4ed050f7135d298c7c09b5efc34233539 0 1669534511830 5 connected 7fffe89ccf2247acd1612f1692c6972dc37af78a 127.0.0.1:6382@16382 slave 851d9155d0acc04d278dcbadd0e7c0642c40974a 0 1669534511000 4 connected c599010190b588c4f47ecae2b838e7e113e00683 127.0.0.1:6384@16384 slave 8fec6b575bf196aa0648cfee4d1169c33ea88db1 0 1669534511000 6 connected 8fec6b575bf196aa0648cfee4d1169c33ea88db1 127.0.0.1:6380@16380 master - 0 1669534512855 2 connected 5461-10922 验证 验证设置/获取值 在127.0.0.1:6379节点上执行./redis-cli -c -p 6379\n./redis-cli -c -p 6379 set k1 v1 #在redis分片集群模式下设置值会对key计算hash以确定会被存储到哪个分片上 -\u0026gt; Redirected to slot [12706] located at 127.0.0.1:6381 OK 127.0.0.1:6379\u0026gt; get k1 #获取值时也会对key去hash计算数据存储在那个节点上，如果不在当前节点会redirect到相应的节点 -\u0026gt; Redirected to slot [12706] located at 127.0.0.1:6381 \u0026#34;v1\u0026#34; 直连127.0.0.1:6379节点查看keys *\n./redis-cli -p 6379 127.0.0.1:6379\u0026gt; keys * (empty array) #说明k1不是存在该节点上 直连127.0.0.1:6381节点查看keys *(分片master节点)\n./redis-cli -p 6381 127.0.0.1:6381\u0026gt; keys * 1) \u0026#34;k1\u0026#34; #说明k1是存在该节点上 直连127.0.0.1:6382节点查看keys *(分片slave节点 验证分片数据是否保存到了分片副本上)\n./redis-cli -p 6382 127.0.0.1:6382\u0026gt; keys * 1) \u0026#34;k1\u0026#34; #说明分片上的数据会全部同步到分片副本上 验证分片的master节点下线后集群状态 由于通过cluster nodes命令知道127.0.0.1:6382这个节点是127.0.0.1:6381master的副本，那么kill 127.0.0.1:6381 这个节点即可验证127.0.0.1:6382这个节点会不会成为master\nps -ef|grep redis root 23270 1 0 15:27 ? 00:00:03 ./redis-server *:6379 [cluster] root 23297 1 0 15:28 ? 00:00:03 ./redis-server *:6380 [cluster] root 23305 1 0 15:28 ? 00:00:03 ./redis-server *:6381 [cluster] root 23315 1 0 15:28 ? 00:00:03 ./redis-server *:6382 [cluster] root 23321 1 0 15:28 ? 00:00:03 ./redis-server *:6383 [cluster] root 23329 1 0 15:28 ? 00:00:03 ./redis-server *:6384 [cluster] root 24215 7340 0 15:49 pts/2 00:00:00 ./redis-cli -p 6381 root 24261 2409 0 15:51 pts/0 00:00:00 grep --color=auto redis kill 23305 ./redis-cli -c -p 6379 127.0.0.1:6379\u0026gt; 127.0.0.1:6379\u0026gt; cluster nodes 851d9155d0acc04d278dcbadd0e7c0642c40974a 127.0.0.1:6381@16381 master,fail - 1669535502496 1669535497392 3 disconnected #节点下线了 eb896ce4ed050f7135d298c7c09b5efc34233539 127.0.0.1:6379@16379 myself,master - 0 1669535551000 1 connected 0-5460 136fd46e678c22319b1db4d34efe1a7bc44c988c 127.0.0.1:6383@16383 slave eb896ce4ed050f7135d298c7c09b5efc34233539 0 1669535551055 5 connected 7fffe89ccf2247acd1612f1692c6972dc37af78a 127.0.0.1:6382@16382 master - 0 1669535550035 7 connected 10923-16383 #节点成为分片的master c599010190b588c4f47ecae2b838e7e113e00683 127.0.0.1:6384@16384 slave 8fec6b575bf196aa0648cfee4d1169c33ea88db1 0 1669535549014 6 connected 8fec6b575bf196aa0648cfee4d1169c33ea88db1 127.0.0.1:6380@16380 master - 0 1669535552077 2 connected 5461-10922 127.0.0.1:6379\u0026gt; get k1 -\u0026gt; Redirected to slot [12706] located at 127.0.0.1:6382 \u0026#34;v1\u0026#34; 验证分片的master节点下线后重新上线集群状态 ./redis-server /storehouse/redis_t/cluster/redis-cluster-6381.conf 24436:C 27 Nov 2022 15:55:52.538 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo 24436:C 27 Nov 2022 15:55:52.538 # Redis version=6.0.0, bits=64, commit=00000000, modified=0, pid=24436, just started 24436:C 27 Nov 2022 15:55:52.538 # Configuration loaded ./redis-cli -c -p 6379 127.0.0.1:6379\u0026gt; cluster nodes 851d9155d0acc04d278dcbadd0e7c0642c40974a 127.0.0.1:6381@16381 slave 7fffe89ccf2247acd1612f1692c6972dc37af78a 0 1669535779000 7 connected #原master节点上线后成为分片slave节点 eb896ce4ed050f7135d298c7c09b5efc34233539 127.0.0.1:6379@16379 myself,master - 0 1669535777000 1 connected 0-5460 136fd46e678c22319b1db4d34efe1a7bc44c988c 127.0.0.1:6383@16383 slave eb896ce4ed050f7135d298c7c09b5efc34233539 0 1669535779717 5 connected 7fffe89ccf2247acd1612f1692c6972dc37af78a 127.0.0.1:6382@16382 master - 0 1669535778000 7 connected 10923-16383 c599010190b588c4f47ecae2b838e7e113e00683 127.0.0.1:6384@16384 slave 8fec6b575bf196aa0648cfee4d1169c33ea88db1 0 1669535778692 6 connected 8fec6b575bf196aa0648cfee4d1169c33ea88db1 127.0.0.1:6380@16380 master - 0 1669535777671 2 connected 5461-10922 使用 python3 安装依赖：pip3 install rediscluster\nfrom rediscluster import RedisCluster if __name__ == \u0026#34;__main__\u0026#34;: startup_nodes = [ {\u0026#34;host\u0026#34;:\u0026#34;127.0.0.1\u0026#34;, \u0026#34;port\u0026#34;:6379}, {\u0026#34;host\u0026#34;:\u0026#34;127.0.0.1\u0026#34;, \u0026#34;port\u0026#34;:6380}, {\u0026#34;host\u0026#34;:\u0026#34;127.0.0.1\u0026#34;, \u0026#34;port\u0026#34;:6381}, {\u0026#34;host\u0026#34;:\u0026#34;127.0.0.1\u0026#34;, \u0026#34;port\u0026#34;:6382}, {\u0026#34;host\u0026#34;:\u0026#34;127.0.0.1\u0026#34;, \u0026#34;port\u0026#34;:6383}, {\u0026#34;host\u0026#34;:\u0026#34;127.0.0.1\u0026#34;, \u0026#34;port\u0026#34;:6384}, ] # 连接集群 conn = RedisCluster(startup_nodes=startup_nodes, decode_responses=True) ret = conn.set(\u0026#34;py-cluster-k1\u0026#34;, \u0026#34;py-cluster-v1\u0026#34;) print(ret) ret = conn.get(\u0026#34;py-cluster-k1\u0026#34;) print(ret) 执行：\npython3 conn-cluster-redis.py True py-cluster-v1 ","permalink":"https://moyuduo.github.io/posts/redis-%E4%B8%BB%E4%BB%8E-%E5%93%A8%E5%85%B5-%E5%88%86%E7%89%87%E9%9B%86%E7%BE%A4/","summary":"redis主从、哨兵、分片集群 概念：\nredis主从及哨兵\nredis分片集群\n单机 在redis安装目录下执行./src/redis-server redis.conf会在6379端口启动单机版redis 使用 python3:\n安装依赖库:pip3 install redis\nimport redis conn = redis.StrictRedis(connection_pool=redis.ConnectionPool( host=\u0026#34;127.0.0.1\u0026#34;, port=\u0026#34;6381\u0026#34;, password=\u0026#34;\u0026#34; )) # string类型的写入读取 ret = conn.set(\u0026#34;py-k1\u0026#34;, \u0026#34;py-v1\u0026#34;) print(ret) val = conn.get(\u0026#34;py-k1\u0026#34;) print(val) 执行：\npython3 single-redis.py True b\u0026#39;py-v1\u0026#39; 主从搭建 参考：\nredis主从模式搭建\n下载redis 去http://download.redis.io/releases/上下载对应版本的redis(本次使用redis-6.0.0) curl -O http://download.redis.io/releases/redis-6.0.0.tar.gz 解压tar -zxvf redis-6.0.0.tar.gz 进入文件夹cd redis-6.0.0 编译redis文件make 规划 Name Role IP Port master1 master 127.0.0.1 6379 slave1 slave 127.0.0.1 6380 slave2 slave 127.0.0.1 6381 准备配置文件 修改redis安装目录下的redis.conf文件daemonize为yes后台启动 拷贝redis.","title":"redis-主从-哨兵-分片集群"},{"content":"申明 在shell脚本中，第一行写#!/bin/bash申请使用bash执行该脚本，当使用./执行脚本文件时就会使用第一行申明的执行器执行，如果使用sh/bash/source/.执行脚本，那么文件申不申明#!/bin/bash都无所谓\n执行方式 加可执行权限执行：会解析到文件第一行申明的执行器，使用该执行器开启子shell执行脚本 sh/bash执行：会使用指定的shell执行器开启子shell执行脚本 source/.执行：会使用当前的shell(终端登录的shell)执行脚本，可以避免父子shell变量作用域问题 环境变量 全局环境变量：在当前shell以及子shell中都能够访问的环境变量 局部环境变量：仅在当前shell中可以访问的环境变量，子shell不可访问 env\\printenv查看所有全局环境变量\n[root@centos72 shell_t]# env XDG_SESSION_ID=1 HOSTNAME=centos72 SELINUX_ROLE_REQUESTED= [root@centos72 shell_t]# printenv XDG_SESSION_ID=1 HOSTNAME=centos72 SELINUX_ROLE_REQUESTED= printenv HOME /root 常用全局环境变量：$HOME $PWD $SHELL $USER\nset查看当前shell的所有环境变量(全局环境变量和局部环境变量)\n定义变量 定义局部变量 a=1 #等号前后不能有空格 b=\u0026#34;hello world\u0026#34; #变量的值不能用空格，如果用空格用引号 定义全局变量 a=1 export a #导出局部变量为全局环境变量 export b=\u0026#34;hello world\u0026#34; #直接申明为全局环境变量 在子shell中定义全局变量/修改父shell中的全局环境变量对父shell来说都是不可见的\n由于source/.执行脚本时都是在当前shell中执行，所以在脚本中导出的全局环境变量对当前终端是可见的，所以我们经常使用source /etc/profile导出全局环境变量，而不是sh /etc/profile\n一般局部环境变量用小写，全局环境变量用大写\n定义只读变量 # readonly定义只读变量,只读变量不可撤销 readonly pi=3.14 unset pi -bash: unset: pi: cannot unset: readonly variable 撤销变量 a=1 echo $a unset a echo $a 变量使用 使用$号取值: echo $a 使用${变量名}取值: echo ${a}_${b}_${c} a=1 b=2 c=3 echo $a_$b_$c #输出 3 3 echo ${a}_${b}_${c} #输出 1_2_3 1_2_3 特殊变量 特殊变量用于向脚本中传入参数\ncat \u0026lt;\u0026lt;EOF \u0026gt; arg.sh #!/bin/bash echo $0 #脚本名称 echo $1 #执行脚本传递的第一个参数 echo $2 echo $3 echo \u0026#34;print input args number:\u0026#34; echo $# #输入参数个数 echo \u0026#34;print doller@:\u0026#34; echo $@ #所有传递参数的列表 echo \u0026#34;print doller*:\u0026#34; echo $* #所有传递参数的列表 echo \u0026#34;traverse doller@:\u0026#34; for arg in $@ do echo $arg done echo \u0026#34;traverse doller*:\u0026#34; for arg in $* do echo $arg done echo \u0026#34;traverse \u0026#39;doller@\u0026#39;:\u0026#34; for arg in \u0026#34;$@\u0026#34; do echo $arg done echo \u0026#34;traverse \u0026#39;doller*\u0026#39;:\u0026#34; for arg in \u0026#34;$*\u0026#34; do echo $arg done EOF sh arg.sh 1 2 3 输出： arg.sh 1 2 3 print input args number: 3 print doller@: 1 2 3 print doller*: 1 2 3 traverse doller@: #在不加引号时，$@和$@遍历的结果一样 1 2 3 traverse doller*: 1 2 3 traverse \u0026#39;doller@\u0026#39;: #加了引号以后,$@能遍历出每个参数，$*把所有参数当做一个整体 1 2 3 traverse \u0026#39;doller*\u0026#39;: 1 2 3 echo $? # $? 表示上一条命令的返回状态，返回值是0-255的数，一般0表示执行成功，非0表示出错 运算符 expre expr是linux的一个命令，接受参数并对他们进行计算\nexpr 1 + 2 expr 1 \\* 2 $+双大括号 a=$((1+2)) echo $a $+中括号 a=$[1+2] echo $a b=2 c=3 d=$[$b+$c] #中括号内也可以隔空格 echo $d 反引号 a=`expr 1 + 2` echo $a 条件判断 test test命令用于判断条件是否为真，为真返回0,为假返回1\na=hello test $a=hello echo $a #0 a=Hello test $a = hello echo $a #1 中括号 [ cond ]进行条件判断，中括号前后必须要有空格\na=hello [ $a = hello ] echo $? #0 a=Hello [ $a=Hello ] #报错，等号前后要有空格 [ $a ] echo $a #0 a= #赋空字符串 [ $a ] echo $a #1 整数比较符 -eq -ne -lt -le -gt -ge 文件比较符 -e:文件是否存在 -d:判断文件夹是否存在 -f:判断文件是否存在并且未普通文件 -r:文件是否可读 -w:文件是否可写 -x:文件是否可执行 多条件判断 [ hello ] \u0026amp;\u0026amp; echo ok || echo notok [ ] \u0026amp;\u0026amp; echo ok || echo notok num=10 [ $num -ge 10 ] \u0026amp;\u0026amp; echo \u0026#34;$num \u0026gt;= 10\u0026#34; || echo \u0026#34;$num \u0026lt; 10\u0026#34; if if [ 条件判断式 ];then fi if [ cond ] then fi if [ cond ] then elif [ cond ] then fi if (( cond )) #cond可以使用 \u0026gt; \u0026gt;= \u0026lt; \u0026lt;= ==等运算符 then fi 四种等效的写法：\ncat \u0026lt;\u0026lt;EOF \u0026gt; test.sh a=$1 b=$2 if [ $a -ge 10 ] \u0026amp;\u0026amp; [ $b -ge 10 ] then echo \u0026#34;a \u0026gt; 10 \u0026amp;\u0026amp; b \u0026gt; 10\u0026#34; else echo \u0026#34;a, b at least one less than 10\u0026#34; fi EOF cat \u0026lt;\u0026lt;EOF \u0026gt; test.sh a=$1 b=$2 if [ $a -ge 10 -a $b -ge 10 ] then echo \u0026#34;a \u0026gt; 10 \u0026amp;\u0026amp; b \u0026gt; 10\u0026#34; else echo \u0026#34;a, b at least one less than 10\u0026#34; fi EOF cat \u0026lt;\u0026lt;EOF \u0026gt; test.sh a=$1 b=$2 if [[ $a -ge 10 \u0026amp;\u0026amp; $b -ge 10 ]] then echo \u0026#34;a \u0026gt; 10 \u0026amp;\u0026amp; b \u0026gt; 10\u0026#34; else echo \u0026#34;a, b at least one less than 10\u0026#34; fi EOF cat \u0026lt;\u0026lt;EOF \u0026gt; test.sh a=$1 b=$2 if (( $a \u0026gt;= 10 \u0026amp;\u0026amp; $b \u0026gt;= 10 )) then echo \u0026#34;a \u0026gt;= 10 \u0026amp;\u0026amp; b \u0026gt;= 10\u0026#34; else echo \u0026#34;a, b at least one less than 10\u0026#34; fi EOF 下面四种写法等效：\ncat \u0026lt;\u0026lt;EOF \u0026gt; test.sh if [ $1 -lt 10 ];then echo \u0026#34;a \u0026lt; 10\u0026#34; elif [ $1 -lt 20 ];then echo \u0026#34;10 \u0026lt;= a \u0026lt; 20\u0026#34; else echo \u0026#34; a \u0026gt;= 20\u0026#34; fi EOF cat \u0026lt;\u0026lt;EOF \u0026gt; test.sh if [ $1 -lt 10 ] then echo \u0026#34;a \u0026lt; 10\u0026#34; elif [ $1 -lt 20 ] then echo \u0026#34;10 \u0026lt;= a \u0026lt; 20\u0026#34; else echo \u0026#34; a \u0026gt;= 20\u0026#34; fi EOF cat \u0026lt;\u0026lt;EOF \u0026gt; test.sh if [ $1 -lt 10 ];then echo \u0026#34;a \u0026lt; 10\u0026#34; elif [ $1 -lt 20 ] then echo \u0026#34;10 \u0026lt;= a \u0026lt; 20\u0026#34; else echo \u0026#34; a \u0026gt;= 20\u0026#34; fi EOF cat \u0026lt;\u0026lt;EOF \u0026gt; test.sh if (( $1 \u0026lt; 10 ));then echo \u0026#34;a \u0026lt; 10\u0026#34; elif (( $1 \u0026lt; 20 )) then echo \u0026#34;10 \u0026lt;= a \u0026lt; 20\u0026#34; else echo \u0026#34;a \u0026gt;= 20\u0026#34; fi EOF case case $arg_name in \u0026#34;val1\u0026#34;) block1 ;; \u0026#34;val2\u0026#34;) block2 ;; *) block3 esac cat \u0026lt;\u0026lt;EOF \u0026gt; test.sh case $1 in 1) echo \u0026#34;input 1\u0026#34; ;; \u0026#34;abc\u0026#34;) echo \u0026#34;input abc\u0026#34; ;; *) echo \u0026#34;input other\u0026#34; esac EOF for 1. for加双大括号 for (( 初始值; 循环控制条件; 变量变化 )) do ... done 2. for in for 变量 in 变量1 变量2 变量3 do ... done cat \u0026lt;\u0026lt;EOF \u0026gt; test.sh for e in 1 2 3 do echo \u0026#34;e is $e\u0026#34; done EOF cat \u0026lt;\u0026lt;EOF \u0026gt; test.sh for e in {1..3} do echo \u0026#34;e is $e\u0026#34; done EOF for e in $* 或 for e in $@ 没有区别 for e in \u0026#34;$*\u0026#34; 加了引号之后把所有参数当做一个整体 for e in \u0026#34;$@\u0026#34; 加了引号之后每个元素任然是单个参数 while while [ cond ] do done while (( cond )) do done read read命令读取控制台输入\n-p 参数指定提示信息 -t 参数指定等待退出时间 cat \u0026lt;\u0026lt;EOF \u0026gt; test.sh read -t 5 -p \u0026#34;input a number:\u0026#34; num echo \u0026#34;your input is $num\u0026#34; EOF 函数 系统函数 basename获取指定路径去除后缀的文件名\nbasename ./test.sh =\u0026gt; test.sh basename ./test.sh .sh =\u0026gt; test dirname获取路径的文件夹\ndirname ./test.sh =\u0026gt; . dirname /root/test.sh =\u0026gt; /root 自定义函数 [function] funcname(){ ... [return 0-255] } #申明函数无需指定参数，在函数内部可以通过 $0 $1 ... 来获取传入的参数，$0 为函数名 cat \u0026lt;\u0026lt;EOF \u0026gt; test.sh myfunc1(){ echo \u0026#34;$0 $1 $2\u0026#34; } myfunc1(1, 2) EOF 在shell函数中由于return语句只能返回0-255之间的数，所以像add这样的方法的返回值都无法用return返回\ncat \u0026lt;\u0026lt;EOF \u0026gt; test.sh add(){ return $[ $1 + $2 ] } add $1 $2 echo $? EOF sh test.sh 1 2 3 sh test.sh 100 200 44 #不正确 改为 cat \u0026lt;\u0026lt;EOF \u0026gt; test.sh add(){ echo $[ $1 + $2 ] } ret=$(add $1 $2) echo $ret EOF sh test.sh 1 2 3 sh test.sh 100 200 300 cat \u0026lt;\u0026lt;EOF \u0026gt; test.sh myfunc(){ echo $[ $1 + $2 ] $[ $1 - $2 ] } ret=$(myfunc $1 $2) echo \u0026#34;===$ret===\u0026#34; EOF sh test.sh 1 2 ===3 -1=== #会把输出当成一个整体 cat \u0026lt;\u0026lt;EOF \u0026gt; test.sh myfunc(){ addRet=$[ $1 + $2 ] #也可在函数内部把要返回在值赋值给一个变量，在函数调用后，直接从该变量取值 subRet=$[ $1 - $2 ] } myfunc 1 2 echo $addRet echo $subRet EOF sh test.sh 1 2 3 -1 备份文件案列 #!/bin/bash if [ $# -ne 2 ] then echo \u0026#34;plz input a file to backup.\u0026#34; exit fi if [ ! -d $2 ] then mkdir -p $2 fi file_name=$(basename $1) file_path=$(dirname $1) cd $file_path file_path=$(pwd) echo \u0026#34;file path: $file_path file name: $file_name\u0026#34; backup_src=\u0026#34;$file_path/$file_name\u0026#34; backup_path=$(dirname $2) cd $backup_path backup_path=\u0026#34;$(pwd)/$(basename $2)\u0026#34; echo \u0026#34;backup path: $backup_path\u0026#34; date_time=$(date +%s) backup_dst=\u0026#34;$backup_path/${file_name}_${date_time}_archive.tar.gz\u0026#34; echo \u0026#34;backup file name: $backup_dst\u0026#34; exit cd $file_path tar -zcf $backup_dst $file_name if [ $? -eq 0 ] then echo \u0026#34;backup success, write to $backup_dst\u0026#34; else echo \u0026#34;backup failed\u0026#34; fi 把该脚本加入到crontab中自动执行\ncrontab -e 添加 * * * * * sh /root/shell_t/test.sh /root/shell_t /root/backup2 # 第一个*表示分钟 # 第二个*表示小时 # 第三个*表示一个月的第几天 # 第四个*表示第几个月 # 第五个*表示星期几 或者直接编辑 /root/spool/cron/root 文件，添加以上内容\n要停止任务可以crontab -e删除执行的任务，或者直接vi /var/spool/cron/root删除\n正则 标准正则 匹配开头\n[root@centos72 shell_t]# cat /etc/passwd |grep ^a adm:x:3:4:adm:/var/adm:/sbin/nologin 匹配结尾\n[root@centos72 shell_t]# cat /etc/passwd |grep n$ bin:x:1:1:bin:/bin:/sbin/nologin daemon:x:2:2:daemon:/sbin:/sbin/nologin adm:x:3:4:adm:/var/adm:/sbin/nologin . 号,匹配任意一个字符\n[root@centos72 shell_t]# cat /etc/passwd |grep r..t root:x:0:0:root:/root:/bin/bash operator:x:11:0:operator:/root:/sbin/nologin ftp:x:14:50:FTP User:/var/ftp:/sbin/nologin dockerroot:x:991:988:Docker User:/var/lib/docker:/sbin/nologin * 号，不单独使用，表示匹配*号之前的字符0次或多次\n#ro*t 匹配 rot root roooot [root@centos72 shell_t]# cat /etc/passwd |grep ro*t root:x:0:0:root:/root:/bin/bash operator:x:11:0:operator:/root:/sbin/nologin dockerroot:x:991:988:Docker User:/var/lib/docker:/sbin/nologin .* 匹配任意一个字符任意次，即匹配任意字符串\n[root@centos72 shell_t]# cat /etc/passwd |grep r.*t root:x:0:0:root:/root:/bin/bash operator:x:11:0:operator:/root:/sbin/nologin ftp:x:14:50:FTP User:/var/ftp:/sbin/nologin [] 匹配字符区间\n[6,8] 匹配6或者8 [0-9] 匹配0-9的任意数字 [^0-9] 匹配任意非数字字符 [0-9]* 匹配任意数字串 [a-z] 匹配a-z的字符 [a-Z] 匹配a-Z的任意字符 [root@centos72 shell_t]# cat /etc/passwd |grep r[a-z]*t root:x:0:0:root:/root:/bin/bash operator:x:11:0:operator:/root:/sbin/nologin sshd:x:74:74:Privilege-separated SSH:/var/empty/sshd:/sbin/nologin rabbitmq:x:997:995:RabbitMQ messaging server:/var/lib/rabbitmq:/bin/bash gitlab-prometheus:x:992:989::/var/opt/gitlab/prometheus:/bin/sh dockerroot:x:991:988:Docker User:/var/lib/docker:/sbin/nologin \\转义\n#匹配$ grep \\$ test.sh 扩展正则 {}指定前一个字符出现几次\n{n}这种写法是扩展正则，grep使用扩展正则需要加 -E 参数 [root@centos72 shell_t]# grep -E ro{2}t /etc/passwd root:x:0:0:root:/root:/bin/bash operator:x:11:0:operator:/root:/sbin/nologin dockerroot:x:991:988:Docker User:/var/lib/docker:/sbin/nologin #{n,}匹配前一个字符至少n次 [root@centos72 shell_t]# grep -E \u0026#34;ro{0,}t\u0026#34; /etc/passwd root:x:0:0:root:/root:/bin/bash operator:x:11:0:operator:/root:/sbin/nologin dockerroot:x:991:988:Docker User:/var/lib/docker:/sbin/nologin #{,n}匹配前一个字符至多n次 [root@centos72 shell_t]# grep -E \u0026#34;ro{,2}t\u0026#34; /etc/passwd root:x:0:0:root:/root:/bin/bash operator:x:11:0:operator:/root:/sbin/nologin dockerroot:x:991:988:Docker User:/var/lib/docker:/sbin/nologin {n,m}匹配前一个字符n到m次 [root@centos72 shell_t]# grep -E \u0026#34;ro{1,2}t\u0026#34; /etc/passwd root:x:0:0:root:/root:/bin/bash operator:x:11:0:operator:/root:/sbin/nologin dockerroot:x:991:988:Docker User:/var/lib/docker:/sbin/nologin +号匹配前一个字符一次及以上\ncat \u0026lt;\u0026lt; EOF | grep -E \u0026#34;go+\u0026#34; g go goo goole EOF go goo goole ?号匹配前一个字符0次或一次\ncat \u0026lt;\u0026lt; EOF | grep -E \u0026#34;go?\u0026#34; g go goo goole EOF g #匹配到g go #匹配到go goo #匹配到go goole #匹配到go 匹配13开头的手机号码\ngrep -E \u0026#34;13[0-9]{9}\u0026#34; phone.txt cat cat命令用来查看一个文件的内容\ncat test.sh cat命令配合EOF加输出重定向可以向文件中写入内容\ncat \u0026lt;\u0026lt;EOF \u0026gt; test.sh name=\u0026#34;tom\u0026#34; echo \u0026#34;hello,\\${name}!\u0026#34; #在EOF中使用$需要加\\转移 EOF cat test.sh name=\u0026#34;tom\u0026#34; echo \u0026#34;hello, ${name}!\u0026#34; cut cut命令用于获取文件指定的列，并输出到标准输出\n#-d指定分隔符 -f指定列 cat \u0026lt;\u0026lt;EOF | cut -d \u0026#34; \u0026#34; -f 1 tom man 20 jerry female 18 jack man 25 EOF tom jerry jack cat \u0026lt;\u0026lt;EOF | cut -d \u0026#34; \u0026#34; -f 1,2 tom man 20 jerry female 18 jack man 25 EOF tom man jerry female jack man cat \u0026lt;\u0026lt;EOF | cut -d \u0026#34; \u0026#34; -f 1-2 tom man 20 jerry female 18 jack man 25 EOF tom man jerry female jack man cat \u0026lt;\u0026lt;EOF | cut -d \u0026#34; \u0026#34; -f -2 tom man 20 jerry female 18 jack man 25 EOF tom man jerry female jack man cat \u0026lt;\u0026lt;EOF | cut -d \u0026#34; \u0026#34; -f 2- tom man 20 jerry female 18 jack man 25 EOF man 20 female 18 man 25 获取ip地址\nifconfig ens33 |grep netmask |cut -d \u0026#34; \u0026#34; -f 10 192.168.37.131 grep grep用于配合正则按行过滤数据\ncat \u0026lt;\u0026lt;EOF | grep \u0026#39;go\u0026#39; g go goole EOF go goole # -E 指定使用扩展正则 cat \u0026lt;\u0026lt;EOF | grep -E \u0026#39;go+\u0026#39; g go goole EOF go #匹配到go goole #匹配到goo # -m 参数指定输出的最大行数 cat \u0026lt;\u0026lt;EOF | grep -m 1 -E \u0026#39;go+\u0026#39; g go goole EOF go # -c 参数指定输出匹配到的行数 cat \u0026lt;\u0026lt;EOF | grep -c -E \u0026#39;go+\u0026#39; g go goole EOF 2 # -i 参数指定忽略匹配正则的大小写 cat \u0026lt;\u0026lt;EOF | grep -i -E \u0026#39;go+\u0026#39; g go Go goole EOF go Go goole # -v 参数指定输出匹配到的行以外的行 cat \u0026lt;\u0026lt;EOF | grep -v -E \u0026#39;go+\u0026#39; g go Go goole EOF g Go # -w 参数指定正则要匹配整个单词 cat \u0026lt;\u0026lt;EOF | grep -w -E \u0026#39;go+\u0026#39; g go Go goole EOF go # -x 参数指定正则要匹配一整行的内容 cat \u0026lt;\u0026lt;EOF | grep -x -E \u0026#39;go+\u0026#39; g go go is good goole EOF go # -o 参数指定只显示匹配到的内容，对于同一行有多个匹配到的内容会隔行显示 cat \u0026lt;\u0026lt;EOF | grep -o -E \u0026#39;go+\u0026#39; g go go is good goole EOF go go goo goo sed sed针对文件的每一行进行处理，把一行读入放入模式空间，然后对模式空间的数据进行处理(增加/修改/删除)后输出到屏幕，直到处理完文件的每一行,处理完毕后并不会改变源文件，只会把处理后的结果输出到屏幕，改变源文件需要配合输出重定向\n-e 参数指定多次编辑(可以写多个规则) cat \u0026lt;\u0026lt;EOF \u0026gt; test.txt line1 name tom line2 age 20 line3 gender man EOF sed -e \u0026#34;1p\u0026#34; -n test.txt # p参数指定打印行为 -n参数取消默认打印，只输出匹配到的行 line1 name tom sed -e \u0026#34;/name/p\u0026#34; -n test.txt # 模糊匹配存在name的行 line1 name tom sed -e \u0026#34;/^line2/p\u0026#34; -n test.txt line2 age 20 sed -e \u0026#34;1,2p\u0026#34; -n test.txt # 1,2 指定第一行和第二行 line1 name tom line2 age 20 sed -e \u0026#34;2~1p\u0026#34; -n test.txt # 2~1 指定从第二行开始，已1步长匹配行 line2 age 20 line3 gender man sed -e \u0026#34;2~2p\u0026#34; -n test.txt line2 age 20 sed -e \u0026#34;2,+3p\u0026#34; -n test.txt # 2,+3 表示从第二行开始匹配向下三行(包括本行) line2 age 20 line3 gender man sed -e \u0026#34;2,\\$p\u0026#34; -n test.txt # 2,\\$ 表示匹配从第二行开始一直到结尾的行 line2 age 20 line3 gender man sed -e \u0026#34;1d\u0026#34; test.txt # d参数指定删除的行 line2 age 20 line3 gender man sed -e \u0026#34;1d\u0026#34; -e \u0026#34;s/age 20/age 30/g\u0026#34; test.txt # s参数指定进行替换，g是全局 line2 age 30 line3 gender man cat test.txt #源文件内容没有变 line1 name tom line2 age 20 line3 gender man sed -e \u0026#34;1a hight 170cm\u0026#34; test.txt # a参数指定在指定的行后添加一行/多行 line1 name tom hight 170cm line2 age 20 line3 gender man sed -e \u0026#34;1i weight 55kg\u0026#34; test.txt # i参数指定在指定的行前插入一行/多行 weight 55kg line1 name tom line2 age 20 line3 gender man #输出结果重定向 sed -e \u0026#34;1a hight 170cm\u0026#34; test.txt \u0026gt; test.txt -n 参数指定只输出匹配到的被处理的内容 sed -e \u0026#34;1p\u0026#34; -n test.txt # p参数指定打印行为 -n参数取消默认打印，只输出匹配到的行 line1 name tom -i 参数指定修改应用到源文件 cat test.txt line1 name tom line2 age 20 line3 gender man sed -i -e \u0026#34;s/age 20/age 30/g\u0026#34; test.txt cat test.txt line1 name tom line2 age 30 line3 gender man -r 参数指定开启扩展正则 cat \u0026lt;\u0026lt;EOF \u0026gt; test.txt go goo goole EOF sed -e \u0026#34;s/go+/x/g\u0026#34; test.txt # 不加-r参数由于+是扩展正则，所以不能匹配到任何的内容 go goo goole sed -r -e \u0026#34;s/go+/x/g\u0026#34; test.txt x x xle sed取ip地址 ifconfig ens33 | sed \u0026#39;2p\u0026#39; -n | sed \u0026#34;s/^.*inet//g\u0026#34; | sed \u0026#34;s/netmask.*$//g\u0026#34; 192.168.37.131 #前后有空格 ifconfig ens33 | sed -e \u0026#34;2s/^.*inet//\u0026#34; -n -e \u0026#34;s/netmask.*$//p\u0026#34; -n 192.168.37.131 awk awk通过正则过滤到匹配的行，然后对行进行切片(默认以空格)，然后对每个切片进行处理\n# -F 参数指定行分隔符 cat /etc/passwd | awk -F \u0026#34;:\u0026#34; \u0026#39;/^root/ {print $7}\u0026#39; /bin/bash cat /etc/passwd | awk -F \u0026#34;:\u0026#34; \u0026#39;/^root/ {print $1 \u0026#34;,\u0026#34; $7}\u0026#39; root,/bin/bash # BEGIN代码块在过滤之前执行 END代码块在过滤结束之后执行 cat /etc/passwd | awk -F \u0026#34;:\u0026#34; \u0026#39;BEGIN{print \u0026#34;start\u0026#34;}{print $1\u0026#34;=\u0026#34;$7}END{print \u0026#34;stop\u0026#34;}\u0026#39; start root=/bin/bash bin=/sbin/nologin daemon=/sbin/nologin stop cat /etc/passwd | awk -F \u0026#34;:\u0026#34; \u0026#39;{print $3+1}\u0026#39; 1 2 3 4 5 # 使用-v参数可以像awk中的变量赋值 cat /etc/passwd | awk -F \u0026#34;:\u0026#34; -v num=1 \u0026#39;{print $3+num}\u0026#39; # 内置变量 # FILENAME 文件名 # NR 行号 # NF 列号 cat /etc/passwd | awk -F \u0026#34;:\u0026#34; \u0026#39;{print \u0026#34;filename=\u0026#34;FILENAME, \u0026#34;row_number=\u0026#34;NR, \u0026#34;col_number\u0026#34;NF}\u0026#39; [root@centos72 shell_t]# cat /etc/passwd | awk -F \u0026#34;:\u0026#34; \u0026#39;{print \u0026#34;filename=\u0026#34;FILENAME, \u0026#34;row_number=\u0026#34;NR, \u0026#34;col_number\u0026#34;NF}\u0026#39; filename=- row_number=1 col_number7 filename=- row_number=2 col_number7 filename=- row_number=3 col_number7 awk截取ip\nifconfig | awk \u0026#39;/netmask/ {print $2}\u0026#39; 172.17.0.1 192.168.37.131 127.0.0.1 sort cat \u0026lt;\u0026lt;EOF \u0026gt; sort.txt aa:1:tom bb:0:jack dd:5:jarry cc:4:lucy ee:3:mike EOF sort sort.txt #按照字母序排序 aa:1:tom bb:0:jack cc:4:lucy dd:5:jarry ee:3:mike sort -r sort.txt #-r指定降序排序 ee:3:mike dd:5:jarry cc:4:lucy bb:0:jack aa:1:tom sort -t : -k 2 sort.txt #-t指定分隔符 -k指定对哪一列排序 bb:0:jack aa:1:tom ee:3:mike cc:4:lucy dd:5:jarry nohup nohup命令将程序以忽略挂起信号的方式后台运行，输出的结果不打印到终端而是保存在当前目录的nohup.out文件中，如果当前目录下的nohup.out文件无法写入会保存到$HOME/nohup.out文件中\nnohup ping baidu.com nohup: ignoring input and appending output to ‘nohup.out’ #进程会hang在这儿，不能执行其他命令，如果ctrl+c结束程序，那么执行的程序也会停止 nohup ping bilibili.com \u0026amp; nohup: ignoring input and appending output to ‘nohup.out’ #进程会hang在这儿,但是ctrl+c结束结束程序后，执行的程序不会停止 nohup ping baidu.com \u0026gt; ping.log \u0026amp; # 把程序的标准输出重定向到指定文件 nohup ping baidu.com \u0026gt;ping.log \u0026amp; # 标准输出 1 # 标准错误输出 2 nohup ping baidu.com \u0026gt; ping.log 2\u0026gt;\u0026amp;1 \u0026amp; # 把程序的标准输出及出错信息都写入到指定文件 nohup ping baidu.com \u0026gt; /dev/null 2\u0026gt;\u0026amp;1 \u0026amp; # 把程序的输出写入到linux的黑洞文件立即销毁 把程序的标准输出和标准错误输出写入文件\n# 把标准输出写入app.log,标准错误输出写入err.log nohup ping baidu.com \u0026gt; ping-app.log 2\u0026gt;ping-err.log \u0026amp; nohup ping baidu.com 1\u0026gt;ping-app.log 2\u0026gt;ping-err.log \u0026amp; # 把标准输出标准错误输出都写入app.log文件 nohup ping baidu.com \u0026gt; app.log 2\u0026gt;\u0026amp;1 \u0026amp; nohup ping baidu.com \u0026amp;\u0026gt;app.log \u0026amp; ","permalink":"https://moyuduo.github.io/posts/shell/","summary":"申明 在shell脚本中，第一行写#!/bin/bash申请使用bash执行该脚本，当使用./执行脚本文件时就会使用第一行申明的执行器执行，如果使用sh/bash/source/.执行脚本，那么文件申不申明#!/bin/bash都无所谓\n执行方式 加可执行权限执行：会解析到文件第一行申明的执行器，使用该执行器开启子shell执行脚本 sh/bash执行：会使用指定的shell执行器开启子shell执行脚本 source/.执行：会使用当前的shell(终端登录的shell)执行脚本，可以避免父子shell变量作用域问题 环境变量 全局环境变量：在当前shell以及子shell中都能够访问的环境变量 局部环境变量：仅在当前shell中可以访问的环境变量，子shell不可访问 env\\printenv查看所有全局环境变量\n[root@centos72 shell_t]# env XDG_SESSION_ID=1 HOSTNAME=centos72 SELINUX_ROLE_REQUESTED= [root@centos72 shell_t]# printenv XDG_SESSION_ID=1 HOSTNAME=centos72 SELINUX_ROLE_REQUESTED= printenv HOME /root 常用全局环境变量：$HOME $PWD $SHELL $USER\nset查看当前shell的所有环境变量(全局环境变量和局部环境变量)\n定义变量 定义局部变量 a=1 #等号前后不能有空格 b=\u0026#34;hello world\u0026#34; #变量的值不能用空格，如果用空格用引号 定义全局变量 a=1 export a #导出局部变量为全局环境变量 export b=\u0026#34;hello world\u0026#34; #直接申明为全局环境变量 在子shell中定义全局变量/修改父shell中的全局环境变量对父shell来说都是不可见的\n由于source/.执行脚本时都是在当前shell中执行，所以在脚本中导出的全局环境变量对当前终端是可见的，所以我们经常使用source /etc/profile导出全局环境变量，而不是sh /etc/profile\n一般局部环境变量用小写，全局环境变量用大写\n定义只读变量 # readonly定义只读变量,只读变量不可撤销 readonly pi=3.14 unset pi -bash: unset: pi: cannot unset: readonly variable 撤销变量 a=1 echo $a unset a echo $a 变量使用 使用$号取值: echo $a 使用${变量名}取值: echo ${a}_${b}_${c} a=1 b=2 c=3 echo $a_$b_$c #输出 3 3 echo ${a}_${b}_${c} #输出 1_2_3 1_2_3 特殊变量 特殊变量用于向脚本中传入参数","title":"shell"},{"content":"StringBuilder、StringBuffer源码分析 StringBuilder源码分析 类结构 public final class StringBuilder extends AbstractStringBuilder implements java.io.Serializable, CharSequence StringBuilder使用final关键字修饰，和String一样不可以被继承\nStringBuilder继承AbstractStringBuilder并实现了Serializable和CharSequence，可以被序列化\n方法 StringBuilder 的方法多是直接调用父类AbstractStringBuilder的方法，这里找几个典型的方法看一下\nStringBuilder append(Object obj)方法重写父类的方法，追加Object类型的元素 @Override public StringBuilder append(Object obj) { return append(String.valueOf(obj));//String.valueOf(obj)获取对象转换成的字符串 } public static String valueOf(Object obj) { return (obj == null) ? \u0026#34;null\u0026#34; : obj.toString(); } @Override public StringBuilder append(String str) { super.append(str); return this; } public AbstractStringBuilder append(String str) { if (str == null) return appendNull();//如果为null追加字符串“null” int len = str.length(); ensureCapacityInternal(count + len); //拷贝字符串到数组 str.getChars(0, len, value, count); count += len; return this; } StringBuilder delete(int start, int end)删除指定起点下标到指定结束下标的字符 @Override public StringBuilder delete(int start, int end) { super.delete(start, end); return this; } public AbstractStringBuilder delete(int start, int end) { if (start \u0026lt; 0) throw new StringIndexOutOfBoundsException(start); if (end \u0026gt; count)//如果结束下标\u0026gt;当前保存char的最大下标，直接赋值为最大下标 end = count; if (start \u0026gt; end) throw new StringIndexOutOfBoundsException(); int len = end - start; if (len \u0026gt; 0) { //把删除尾下标后的元素拷贝到删除起始下标后 System.arraycopy(value, start+len, value, start, count-end); count -= len; } return this; } StringBuilder replace(int start, int end, String str)使用字符串替换指定范围内的字符 @Override public StringBuilder replace(int start, int end, String str) { super.replace(start, end, str); return this; } public AbstractStringBuilder replace(int start, int end, String str) { if (start \u0026lt; 0) throw new StringIndexOutOfBoundsException(start); if (start \u0026gt; count) throw new StringIndexOutOfBoundsException(\u0026#34;start \u0026gt; length()\u0026#34;); if (start \u0026gt; end) throw new StringIndexOutOfBoundsException(\u0026#34;start \u0026gt; end\u0026#34;); if (end \u0026gt; count) end = count; int len = str.length(); //计算需要的容量 int newCount = count + len - (end - start); //扩容 ensureCapacityInternal(newCount); //删除指定范围的字符 System.arraycopy(value, end, value, start + len, count - end); //在删除的起始位置插入字符串 str.getChars(value, start); count = newCount; return this; } StringBuilder insert(int offset, Object obj)在指定位置插入对象 @Override public StringBuilder insert(int offset, Object obj) { super.insert(offset, obj); return this; } public AbstractStringBuilder insert(int offset, Object obj) { return insert(offset, String.valueOf(obj));//String.valueOf(obj)获取对象转换的字符串 } public static String valueOf(Object obj) { return (obj == null) ? \u0026#34;null\u0026#34; : obj.toString(); } @Override public StringBuilder insert(int offset, String str) { super.insert(offset, str); return this; } public AbstractStringBuilder insert(int offset, String str) { if ((offset \u0026lt; 0) || (offset \u0026gt; length())) throw new StringIndexOutOfBoundsException(offset); if (str == null) str = \u0026#34;null\u0026#34;; int len = str.length(); //扩容 ensureCapacityInternal(count + len); //把要插入位置后一定数量的字符（插入字符串长度）串移动后移一定距离（插入字符串长度） System.arraycopy(value, offset, value, offset + len, count - offset); //插入要插入的字符串 str.getChars(value, offset); count += len; return this; } 可以看到，StringBuilder的append、insert、replace、delete都是对父类的char数组进行的一些操作，并没有产生新的对象\nString toString() 最精髓的一个方法 @Override public String toString() { //把进过一些列修改后的最终char数组生成String return new String(value, 0, count); } 这里我们看到在toString的时候，把char数组生成了String，这也是为什么StringBuilder比String效率高的原因，String类没做一点修改都会生成新的对象，那么在频繁拼串和截取字符串时，效率当然不如StringBuilder\nStringBuffer源码分析 类结构 public final class StringBuffer extends AbstractStringBuilder implements java.io.Serializable, CharSequence StringBuffer的类结构和StringBuilder的一样\n方法 StringBuffer和StringBuilder一样，很多方法都是调用父类AbstractStringBuilder的方法,我们看几个最主要的方法\nStringBuffer append(Object obj)向StringBuffer中追加对象,和StringBuilder的追加对象一样的代码 @Override public synchronized StringBuffer append(Object obj) { toStringCache = null; super.append(String.valueOf(obj)); return this; } public AbstractStringBuilder append(String str) { if (str == null) return appendNull(); int len = str.length(); ensureCapacityInternal(count + len); str.getChars(0, len, value, count); count += len; return this; } public void getChars(int srcBegin, int srcEnd, char dst[], int dstBegin) { if (srcBegin \u0026lt; 0) { throw new StringIndexOutOfBoundsException(srcBegin); } if (srcEnd \u0026gt; value.length) { throw new StringIndexOutOfBoundsException(srcEnd); } if (srcBegin \u0026gt; srcEnd) { throw new StringIndexOutOfBoundsException(srcEnd - srcBegin); } System.arraycopy(value, srcBegin, dst, dstBegin, srcEnd - srcBegin); } StringBuffer delete(int start, int end)删除指定范围内的字符,和StringBuilder中delete方法代码一样 @Override public synchronized StringBuffer delete(int start, int end) { toStringCache = null; super.delete(start, end); return this; } public AbstractStringBuilder delete(int start, int end) { if (start \u0026lt; 0) throw new StringIndexOutOfBoundsException(start); if (end \u0026gt; count) end = count; if (start \u0026gt; end) throw new StringIndexOutOfBoundsException(); int len = end - start; if (len \u0026gt; 0) { System.arraycopy(value, start+len, value, start, count-end); count -= len; } return this; } StringBuffer replace(int start, int end, String str)方法使用字符串替换指定范围内的字符,和StringBuilder的replace方法代码一样 @Override public synchronized StringBuffer replace(int start, int end, String str) { toStringCache = null; super.replace(start, end, str); return this; } public AbstractStringBuilder replace(int start, int end, String str) { if (start \u0026lt; 0) throw new StringIndexOutOfBoundsException(start); if (start \u0026gt; count) throw new StringIndexOutOfBoundsException(\u0026#34;start \u0026gt; length()\u0026#34;); if (start \u0026gt; end) throw new StringIndexOutOfBoundsException(\u0026#34;start \u0026gt; end\u0026#34;); if (end \u0026gt; count) end = count; int len = str.length(); int newCount = count + len - (end - start); ensureCapacityInternal(newCount); System.arraycopy(value, end, value, start + len, count - end); str.getChars(value, start); count = newCount; return this; } StringBuffer insert(int offset, Object obj)在指定位置插入字符串，也是和StringBuilder的insert方法代码一样 @Override public synchronized StringBuffer insert(int offset, Object obj) { toStringCache = null; super.insert(offset, String.valueOf(obj)); return this; } public AbstractStringBuilder insert(int offset, String str) { if ((offset \u0026lt; 0) || (offset \u0026gt; length())) throw new StringIndexOutOfBoundsException(offset); if (str == null) str = \u0026#34;null\u0026#34;; int len = str.length(); ensureCapacityInternal(count + len); System.arraycopy(value, offset, value, offset + len, count - offset); str.getChars(value, offset); count += len; return this; } 通过分析这几个方法源码，我们可以看到，StringBuilder和StringBuffer在方法的实现上是一致的，唯一的区别是StringBuffer的所有方法都加了synchronized锁，所以是线程安全的\nString toString()把StringBuffer转换成字符串 @Override public synchronized String toString() { if (toStringCache == null) { toStringCache = Arrays.copyOfRange(value, 0, count); } return new String(toStringCache, true); } StringBuffer与StringBuilder都是在修改的时候并没有产生新的对象，只是在调用toString方法是才转换为字符串。\n总结 StringBuilder和StringBuffer的类结构是一致的，都是使用父类的char数组保存字符。 StringBuffer的所有方法都加了synchronized锁，所以是线程安全的，但是这也使得它的效率比StringBuilder低。 StringBuilder和StringBuffer的基本思想是一致的，对StringBuilder、StringBuffer的任何修改都不会产生新对象，这也使得StringBuilder、StringBuffer在进行大量拼串截取时比String的效率高。 ","permalink":"https://moyuduo.github.io/posts/stringbuilderstringbuffer%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/","summary":"StringBuilder、StringBuffer源码分析 StringBuilder源码分析 类结构 public final class StringBuilder extends AbstractStringBuilder implements java.io.Serializable, CharSequence StringBuilder使用final关键字修饰，和String一样不可以被继承\nStringBuilder继承AbstractStringBuilder并实现了Serializable和CharSequence，可以被序列化\n方法 StringBuilder 的方法多是直接调用父类AbstractStringBuilder的方法，这里找几个典型的方法看一下\nStringBuilder append(Object obj)方法重写父类的方法，追加Object类型的元素 @Override public StringBuilder append(Object obj) { return append(String.valueOf(obj));//String.valueOf(obj)获取对象转换成的字符串 } public static String valueOf(Object obj) { return (obj == null) ? \u0026#34;null\u0026#34; : obj.toString(); } @Override public StringBuilder append(String str) { super.append(str); return this; } public AbstractStringBuilder append(String str) { if (str == null) return appendNull();//如果为null追加字符串“null” int len = str.length(); ensureCapacityInternal(count + len); //拷贝字符串到数组 str.","title":"StringBuilder、StringBuffer源码分析"},{"content":"String源码分析 类结构 public final class String implements java.io.Serializable, Comparable\u0026lt;String\u0026gt;, CharSequence String类实现了Serializable可以被序列化\nString类实现了Comparable可以进行比较\nString类实现了CharSequence可以按下标进行相关操作\n并且String类使用final进行修饰，不可以被继承\n属性 //用来存储字符串的每一个字符 private final char value[]; //hash值 private int hash; // Default to 0 //序列化版本号 private static final long serialVersionUID = -6849794470754667710L; //从变量名大致可以看出和序列化有关，具体的不明白 private static final ObjectStreamField[] serialPersistentFields = new ObjectStreamField[0]; 构造方法 //无参，直接使用空字符串赋值，hash为0 public String() { this.value = \u0026#34;\u0026#34;.value; } //使用已有字符串初始化 public String(String original) { this.value = original.value; this.hash = original.hash; } //使用char数组初始化，hash为0 public String(char value[]) { this.value = Arrays.copyOf(value, value.length); } //使用字符数组，并指定偏移、字符个数初始化 public String(char value[], int offset, int count) { if (offset \u0026lt; 0) { throw new StringIndexOutOfBoundsException(offset); } if (count \u0026lt;= 0) { if (count \u0026lt; 0) { throw new StringIndexOutOfBoundsException(count); } if (offset \u0026lt;= value.length) { this.value = \u0026#34;\u0026#34;.value; return; } } // Note: offset or count might be near -1\u0026gt;\u0026gt;\u0026gt;1. if (offset \u0026gt; value.length - count) { throw new StringIndexOutOfBoundsException(offset + count); } this.value = Arrays.copyOfRange(value, offset, offset+count); } //使用unicode编码数组并指定偏移和数量进行初始化 public String(int[] codePoints, int offset, int count) { if (offset \u0026lt; 0) { throw new StringIndexOutOfBoundsException(offset); } if (count \u0026lt;= 0) { if (count \u0026lt; 0) { throw new StringIndexOutOfBoundsException(count); } if (offset \u0026lt;= codePoints.length) { this.value = \u0026#34;\u0026#34;.value; return; } } // Note: offset or count might be near -1\u0026gt;\u0026gt;\u0026gt;1. if (offset \u0026gt; codePoints.length - count) { throw new StringIndexOutOfBoundsException(offset + count); } final int end = offset + count; // Pass 1: Compute precise size of char[]\t计算char数组大小 int n = count; for (int i = offset; i \u0026lt; end; i++) { int c = codePoints[i]; if (Character.isBmpCodePoint(c))//判断编码是不是BMP（Basic Mutilingual Plane） continue; else if (Character.isValidCodePoint(c))//验证编码是否在unicode编码范围内 n++; else throw new IllegalArgumentException(Integer.toString(c)); } // Pass 2: Allocate and fill in char[] 申明char数组并填入编码对应char final char[] v = new char[n]; for (int i = offset, j = 0; i \u0026lt; end; i++, j++) { int c = codePoints[i]; if (Character.isBmpCodePoint(c))//如果编码是BMP直接一个字符就是接受 v[j] = (char)c; else Character.toSurrogates(c, v, j++);//转换成两个字符存储 } this.value = v; } //使用ascii码数组进行初始化 @Deprecated public String(byte ascii[], int hibyte, int offset, int count) { checkBounds(ascii, offset, count); char value[] = new char[count]; if (hibyte == 0) { for (int i = count; i-- \u0026gt; 0;) { value[i] = (char)(ascii[i + offset] \u0026amp; 0xff); } } else { hibyte \u0026lt;\u0026lt;= 8; for (int i = count; i-- \u0026gt; 0;) { value[i] = (char)(hibyte | (ascii[i + offset] \u0026amp; 0xff)); } } this.value = value; } @Deprecated public String(byte ascii[], int hibyte) { this(ascii, hibyte, 0, ascii.length); } //使用字节数组+字符集名初始化 public String(byte bytes[], int offset, int length, String charsetName) throws UnsupportedEncodingException { if (charsetName == null) throw new NullPointerException(\u0026#34;charsetName\u0026#34;); checkBounds(bytes, offset, length); this.value = StringCoding.decode(charsetName, bytes, offset, length); } //使用字节数组+字符集名初始化 public String(byte bytes[], int offset, int length, Charset charset) { if (charset == null) throw new NullPointerException(\u0026#34;charset\u0026#34;); checkBounds(bytes, offset, length); this.value = StringCoding.decode(charset, bytes, offset, length); } //使用字节数组+字符集名初始化 public String(byte bytes[], String charsetName) throws UnsupportedEncodingException { this(bytes, 0, bytes.length, charsetName); } //使用字节数组+字符集名初始化 public String(byte bytes[], Charset charset) { this(bytes, 0, bytes.length, charset); } //使用字节数组初始化 public String(byte bytes[], int offset, int length) { checkBounds(bytes, offset, length); this.value = StringCoding.decode(bytes, offset, length); } public String(byte bytes[]) { this(bytes, 0, bytes.length); } //使用StringBuffer初始化 public String(StringBuffer buffer) { synchronized(buffer) { this.value = Arrays.copyOf(buffer.getValue(), buffer.length()); } } //使用StringBuilder初始化 public String(StringBuilder builder) { this.value = Arrays.copyOf(builder.getValue(), builder.length()); } 方法 静态方法 join(CharSequence，CharSequence\u0026hellip;）使用分隔符拼接字符串 public static String join(CharSequence delimiter, CharSequence... elements) { Objects.requireNonNull(delimiter); Objects.requireNonNull(elements); // Number of elements not likely worth Arrays.stream overhead. StringJoiner joiner = new StringJoiner(delimiter); for (CharSequence cs: elements) { joiner.add(cs); } return joiner.toString(); } join(CharSequence，Iterable\u0026lt;? extends CharSequence\u0026gt;）使用分隔符拼接字符串 public static String join(CharSequence delimiter, Iterable\u0026lt;? extends CharSequence\u0026gt; elements) { Objects.requireNonNull(delimiter); Objects.requireNonNull(elements); StringJoiner joiner = new StringJoiner(delimiter); for (CharSequence cs: elements) { joiner.add(cs); } return joiner.toString(); } format(String，Object\u0026hellip;）使用字符串格式指定参数进行格式化生成字符串 public static String format(String format, Object... args) { return new Formatter().format(format, args).toString(); } format(Local，String，Object\u0026hellip;）根据环境使用字符串格式指定参数进行格式化生成字符串 public static String format(Locale l, String format, Object... args) { return new Formatter(l).format(format, args).toString(); } valueOf(Object）对象转换成字符串，如果对象为null转为为字符串“null” public static String valueOf(Object obj) { return (obj == null) ? \u0026#34;null\u0026#34; : obj.toString(); } valueOf(char[]）char数组转换成字符串 public static String valueOf(char data[]) { return new String(data); } valueOf（xxx）xxx数据类型转换为字符串 public static String valueOf(boolean b) { return b ? \u0026#34;true\u0026#34; : \u0026#34;false\u0026#34;; } public static String valueOf(char c) { char data[] = {c}; return new String(data, true); } public static String valueOf(int i) { return Integer.toString(i); } public static String valueOf(long l) { return Long.toString(l); } public static String valueOf(float f) { return Float.toString(f); } public static String valueOf(double d) { return Double.toString(d); } valueOf(char[],int,int）char数组按照偏移个指定字符格式转换为字符串 public static String valueOf(char data[], int offset, int count) { return new String(data, offset, count); } copyValueOf(char，int，int）使用指定字符数组根据偏移和字符个数拷贝一个新字符串，同valueOf public static String copyValueOf(char data[], int offset, int count) { return new String(data, offset, count); } copyValueOf(char[])使用指定字符数组拷贝新字符串 public static String copyValueOf(char data[]) { return new String(data); } 成员方法 char charAt(int index)获取指定下标的字符 public char charAt(int index) { if ((index \u0026lt; 0) || (index \u0026gt;= value.length)) { throw new StringIndexOutOfBoundsException(index); } return value[index]; } void getChars(int srcBegin, int srcEnd, char dst[], int dstBegin)把当前字符串的char数组的指定范围拷贝到目标char数组的指定位置 public void getChars(int srcBegin, int srcEnd, char dst[], int dstBegin) { if (srcBegin \u0026lt; 0) { throw new StringIndexOutOfBoundsException(srcBegin); } if (srcEnd \u0026gt; value.length) { throw new StringIndexOutOfBoundsException(srcEnd); } if (srcBegin \u0026gt; srcEnd) { throw new StringIndexOutOfBoundsException(srcEnd - srcBegin); } //System.arraycopy(Object src, int srcPos,Object dest, int destPos,int length) //src：要拷贝的源数组 //srcPos：源数组拷贝的起始位置 //dest：目标数组 //destPost：拷贝到目标数组的起始位置 //length：要拷贝元素的个数 System.arraycopy(value, srcBegin, dst, dstBegin, srcEnd - srcBegin); } byte[] getBytes(String charsetName)根据字符集获取字符串的编码后的字节数组 public byte[] getBytes(String charsetName) throws UnsupportedEncodingException { if (charsetName == null) throw new NullPointerException(); return StringCoding.encode(charsetName, value, 0, value.length); } boolean equals(Object anObject)方法比较两个字符串，重写的Object方法 public boolean equals(Object anObject) { if (this == anObject) {//地址相等两对象equals为true return true; } if (anObject instanceof String) { String anotherString = (String)anObject; int n = value.length; if (n == anotherString.value.length) {//判断两字符串的字符个数 char v1[] = value; char v2[] = anotherString.value; int i = 0; while (n-- != 0) { if (v1[i] != v2[i])//有一个字符不相等最直接为false return false; i++; } return true; } } return false; } contentEquals(CharSequence cs)判断当前String与其他字符序列是否相等，与equals不同的是，equals只有当两个对象都是String时equals才为true，contentEquals可以用来同其他StringBuffer、StringBuilder和其他字符序列进行比较 public boolean contentEquals(CharSequence cs) { // Argument is a StringBuffer, StringBuilder if (cs instanceof AbstractStringBuilder) { if (cs instanceof StringBuffer) { synchronized(cs) {//如果是StringBuffer那么进行上锁操作 return nonSyncContentEquals((AbstractStringBuilder)cs); } } else {//StringBuilder不上锁 return nonSyncContentEquals((AbstractStringBuilder)cs); } } // Argument is a String if (cs instanceof String) { return equals(cs); } // Argument is a generic CharSequence char v1[] = value; int n = v1.length; if (n != cs.length()) { return false; } for (int i = 0; i \u0026lt; n; i++) {//其他字符序列，一个一个字符进行比较 if (v1[i] != cs.charAt(i)) { return false; } } return true; } equalsIgnoreCase(String anotherString)两个字符串忽略大小写进行比较是否相等 public boolean equalsIgnoreCase(String anotherString) { return (this == anotherString) ? true : (anotherString != null)//不为空 \u0026amp;\u0026amp; (anotherString.value.length == value.length)//字符个数相等 \u0026amp;\u0026amp; regionMatches(true, 0, anotherString, 0, value.length);//忽略大小写比较 } public boolean regionMatches(boolean ignoreCase, int toffset, String other, int ooffset, int len) { char ta[] = value; int to = toffset; char pa[] = other.value; int po = ooffset; // Note: toffset, ooffset, or len might be near -1\u0026gt;\u0026gt;\u0026gt;1. if ((ooffset \u0026lt; 0) || (toffset \u0026lt; 0) || (toffset \u0026gt; (long)value.length - len) || (ooffset \u0026gt; (long)other.value.length - len)) { return false; } while (len-- \u0026gt; 0) { char c1 = ta[to++]; char c2 = pa[po++]; if (c1 == c2) { continue; } if (ignoreCase) { // If characters don\u0026#39;t match but case may be ignored, // try converting both characters to uppercase. // If the results match, then the comparison scan should // continue. //把两个字符转换成大写的 char u1 = Character.toUpperCase(c1); char u2 = Character.toUpperCase(c2); if (u1 == u2) { continue; } // Unfortunately, conversion to uppercase does not work properly // for the Georgian alphabet, which has strange rules about case // conversion. So we need to make one last check before // exiting. //转换成大写的不相等，在转换成小写的判断 if (Character.toLowerCase(u1) == Character.toLowerCase(u2)) { continue; } } return false; } return true; } int compareTo(String anotherString)进行字符串的比较 public int compareTo(String anotherString) { int len1 = value.length; int len2 = anotherString.value.length; int lim = Math.min(len1, len2); char v1[] = value; char v2[] = anotherString.value; int k = 0; while (k \u0026lt; lim) { char c1 = v1[k]; char c2 = v2[k]; if (c1 != c2) {//如果当前字符串的字符比参数的大返回正数，否则返回负数 return c1 - c2; } k++; } //如果两个字符串，长度小的字符串与长度大的前部分每个字符都相等，如果两字符串长度相等返回0，当前字符串长度大于参数字符串返回整数，当前字符串长度小于参数字符串返回负数 return len1 - len2; } compareToIgnoreCase(String str)字符串忽略大小写进行比较 public int compareToIgnoreCase(String str) { return CASE_INSENSITIVE_ORDER.compare(this, str); } public int compare(String s1, String s2) { int n1 = s1.length(); int n2 = s2.length(); int min = Math.min(n1, n2); for (int i = 0; i \u0026lt; min; i++) { char c1 = s1.charAt(i); char c2 = s2.charAt(i); if (c1 != c2) { c1 = Character.toUpperCase(c1); c2 = Character.toUpperCase(c2); if (c1 != c2) { c1 = Character.toLowerCase(c1); c2 = Character.toLowerCase(c2); if (c1 != c2) { //如果两字符不相等，最后是转换成小写的进行比较 return c1 - c2; } } } } return n1 - n2; } startsWith(String prefix)判断字符串是否以指定字符串开头 public boolean startsWith(String prefix) { return startsWith(prefix, 0); } public boolean startsWith(String prefix, int toffset) { char ta[] = value; int to = toffset; char pa[] = prefix.value; int po = 0; int pc = prefix.value.length; // Note: toffset might be near -1\u0026gt;\u0026gt;\u0026gt;1. if ((toffset \u0026lt; 0) || (toffset \u0026gt; value.length - pc)) { return false; } while (--pc \u0026gt;= 0) {//循环给定前缀字符串长度 if (ta[to++] != pa[po++]) {//前缀字符串字符和当前字符串字符比较 return false; } } return true; } boolean endsWith(String suffix)判断字符串是否以指定字符串结尾 public boolean endsWith(String suffix) { return startsWith(suffix, value.length - suffix.value.length); } int hashCode()获取字符串的hashCode public int hashCode() { //默认字符串hash为0，如果是用另一个字符串就等于另一个字符串的hash int h = hash; if (h == 0 \u0026amp;\u0026amp; value.length \u0026gt; 0) { char val[] = value; for (int i = 0; i \u0026lt; value.length; i++) {//一个一个字符的变量 //前面字符的hash*31+当前字符的ascii码 h = 31 * h + val[i]; } hash = h; } return h; } int indexOf(int ch)根据unicode编码获取下标 public int indexOf(int ch) { return indexOf(ch, 0); } public int indexOf(int ch, int fromIndex) { final int max = value.length; if (fromIndex \u0026lt; 0) { fromIndex = 0; } else if (fromIndex \u0026gt;= max) {//如果查找的起始位置超过了数组下标 // Note: fromIndex might be near -1\u0026gt;\u0026gt;\u0026gt;1. return -1; } if (ch \u0026lt; Character.MIN_SUPPLEMENTARY_CODE_POINT) { //编码是一个基本多语言编码 // handle most cases here (ch is a BMP code point or a // negative value (invalid code point)) final char[] value = this.value; for (int i = fromIndex; i \u0026lt; max; i++) { if (value[i] == ch) { return i; } } return -1; } else { //获取需要使用两个char存储的编码的下标 return indexOfSupplementary(ch, fromIndex); } } private int indexOfSupplementary(int ch, int fromIndex) { if (Character.isValidCodePoint(ch)) {//是一个合法的unicode编码 final char[] value = this.value; final char hi = Character.highSurrogate(ch); final char lo = Character.lowSurrogate(ch); final int max = value.length - 1; for (int i = fromIndex; i \u0026lt; max; i++) { if (value[i] == hi \u0026amp;\u0026amp; value[i + 1] == lo) { return i; } } } return -1; } int lastIndexOf(int ch)获取指定编码从后往前搜索的第一个下标 public int lastIndexOf(int ch) { return lastIndexOf(ch, value.length - 1); } public int lastIndexOf(int ch, int fromIndex) { if (ch \u0026lt; Character.MIN_SUPPLEMENTARY_CODE_POINT) {//编码是一个基本多语言unicode编码，使用一个char存储 // handle most cases here (ch is a BMP code point or a // negative value (invalid code point)) final char[] value = this.value; int i = Math.min(fromIndex, value.length - 1); for (; i \u0026gt;= 0; i--) { if (value[i] == ch) { return i; } } return -1; } else { //编码使用两个char存储 return lastIndexOfSupplementary(ch, fromIndex); } } private int lastIndexOfSupplementary(int ch, int fromIndex) { if (Character.isValidCodePoint(ch)) { final char[] value = this.value; char hi = Character.highSurrogate(ch); char lo = Character.lowSurrogate(ch); int i = Math.min(fromIndex, value.length - 2); for (; i \u0026gt;= 0; i--) { if (value[i] == hi \u0026amp;\u0026amp; value[i + 1] == lo) { return i; } } } return -1; } int indexOf(String str)获取指定字符串的的第一个字符在当前字符串的下标 public int indexOf(String str) { return indexOf(str, 0); } public int indexOf(String str, int fromIndex) { return indexOf(value, 0, value.length, str.value, 0, str.value.length, fromIndex); } static int indexOf(char[] source, int sourceOffset, int sourceCount, char[] target, int targetOffset, int targetCount, int fromIndex) { if (fromIndex \u0026gt;= sourceCount) { return (targetCount == 0 ? sourceCount : -1); } if (fromIndex \u0026lt; 0) { fromIndex = 0; } if (targetCount == 0) { return fromIndex; } char first = target[targetOffset]; int max = sourceOffset + (sourceCount - targetCount); for (int i = sourceOffset + fromIndex; i \u0026lt;= max; i++) { /* Look for first character. */ if (source[i] != first) { while (++i \u0026lt;= max \u0026amp;\u0026amp; source[i] != first); } /* Found first character, now look at the rest of v2 */ if (i \u0026lt;= max) { int j = i + 1; //计算终止下标 int end = j + targetCount - 1; for (int k = targetOffset + 1; j \u0026lt; end \u0026amp;\u0026amp; source[j] == target[k]; j++, k++); if (j == end) { /* Found whole string. */ return i - sourceOffset; } } } return -1; } String substring(int beginIndex)获取指定下标到最末下标的字符串 public String substring(int beginIndex) { if (beginIndex \u0026lt; 0) { throw new StringIndexOutOfBoundsException(beginIndex); } //计算长度 int subLen = value.length - beginIndex; if (subLen \u0026lt; 0) { throw new StringIndexOutOfBoundsException(subLen); } return (beginIndex == 0) ? this : new String(value, beginIndex, subLen); } String substring(int beginIndex, int endIndex)根据起始下标和结束下标获取字符串，包含起始下标字符，不包含结束下标字符 public String substring(int beginIndex, int endIndex) { if (beginIndex \u0026lt; 0) { throw new StringIndexOutOfBoundsException(beginIndex); } if (endIndex \u0026gt; value.length) { throw new StringIndexOutOfBoundsException(endIndex); } //计算字符个数 int subLen = endIndex - beginIndex; if (subLen \u0026lt; 0) { throw new StringIndexOutOfBoundsException(subLen); } return ((beginIndex == 0) \u0026amp;\u0026amp; (endIndex == value.length)) ? this : new String(value, beginIndex, subLen); } String concat(String str)把参数字符串拼接到当前字符串 public String concat(String str) { int otherLen = str.length(); if (otherLen == 0) { return this; } //获取拼接字符串的长度 int len = value.length; //把原字符串的字符拷贝到一个大小为原字符串大小+参数字符串大小的新数组中 char buf[] = Arrays.copyOf(value, len + otherLen); //把拼接字符串的字符拷贝到数组中 str.getChars(buf, len); return new String(buf, true); } String replace(char oldChar, char newChar)把指定字符替换为新字符 public String replace(char oldChar, char newChar) { if (oldChar != newChar) { int len = value.length; int i = -1; char[] val = value; /* avoid getfield opcode */ while (++i \u0026lt; len) { if (val[i] == oldChar) {//找到需要替换字符的位置 break; } } if (i \u0026lt; len) { char buf[] = new char[len]; for (int j = 0; j \u0026lt; i; j++) { buf[j] = val[j]; } while (i \u0026lt; len) { char c = val[i]; buf[i] = (c == oldChar) ? newChar : c;//把原字符替换为新字符 i++; } return new String(buf, true); } } return this; } boolean matches(String regex)判断正则表达式是否比配当前字符串 public boolean matches(String regex) { return Pattern.matches(regex, this); } boolean contains(CharSequence s)判断当前字符串是否包含另一个字符序列 public boolean contains(CharSequence s) { return indexOf(s.toString()) \u0026gt; -1; } String trim()去掉字符串前后的空格 public String trim() { int len = value.length; int st = 0; char[] val = value; /* avoid getfield opcode */ //找到字符串由前往后第一个不是空格的位置 while ((st \u0026lt; len) \u0026amp;\u0026amp; (val[st] \u0026lt;= \u0026#39; \u0026#39;)) { st++; } //找到字符串由后往前第一个不是空格的位置 while ((st \u0026lt; len) \u0026amp;\u0026amp; (val[len - 1] \u0026lt;= \u0026#39; \u0026#39;)) { len--; } return ((st \u0026gt; 0) || (len \u0026lt; value.length)) ? substring(st, len) : this; } char[] toCharArray()把字符串转换成字符数组 public char[] toCharArray() { // Cannot use Arrays.copyOf because of class initialization order issues char result[] = new char[value.length]; //使用System.arraycopy方法拷贝 System.arraycopy(value, 0, result, 0, value.length); return result; } 本地方法 native String intern();获取字符串所指向的字符串常量池中对象的地址 @Test public void test8() { String s1=\u0026#34;abc\u0026#34;; String s2=new String(\u0026#34;abc\u0026#34;); System.out.println(s1==s2);//false System.out.println(s1==s2.intern());//true } 使用s1=\u0026ldquo;abc\u0026quot;这种方式栈中变量s1直接指向字符串常量池中的常量“abc”，而s2=new String(\u0026ldquo;abc\u0026rdquo;)这种方式，栈中变量s2指向的是对中一个变量t，t指向字符串常量池中的“abc”，所以s1和s2指向的地址不相同\ns2.intern()获取的是字符串的常量池中的地址，也就是如果变量直接指向常量池，那么就是变量的地址，如果变量指向堆，那么会获取堆所指向字符串常量池中的地址\n","permalink":"https://moyuduo.github.io/posts/string%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/","summary":"String源码分析 类结构 public final class String implements java.io.Serializable, Comparable\u0026lt;String\u0026gt;, CharSequence String类实现了Serializable可以被序列化\nString类实现了Comparable可以进行比较\nString类实现了CharSequence可以按下标进行相关操作\n并且String类使用final进行修饰，不可以被继承\n属性 //用来存储字符串的每一个字符 private final char value[]; //hash值 private int hash; // Default to 0 //序列化版本号 private static final long serialVersionUID = -6849794470754667710L; //从变量名大致可以看出和序列化有关，具体的不明白 private static final ObjectStreamField[] serialPersistentFields = new ObjectStreamField[0]; 构造方法 //无参，直接使用空字符串赋值，hash为0 public String() { this.value = \u0026#34;\u0026#34;.value; } //使用已有字符串初始化 public String(String original) { this.value = original.value; this.hash = original.hash; } //使用char数组初始化，hash为0 public String(char value[]) { this.","title":"String源码分析"},{"content":"HTTP 协议 · 笔试面试知识整理 https://labuladong.gitbook.io/algo/ 开篇词 - labuladong的算法小抄 https://www.jianshu.com/p/96f1189b95fe IO多路复用机制详解 - 简书 https://www.cnblogs.com/tiancai/p/9024351.html 为什么MySQL数据库索引选择使用B+树？ - 甜菜波波 - 博客园 https://hit-alibaba.github.io/interview/basic/network/HTTP.html TCP 协议 · 笔试面试知识整理 https://hit-alibaba.github.io/interview/basic/network/TCP.html Golang相关：[审稿进度80%]Go语法、Go并发思想、Go与web开发、Go微服务设施等 https://github.com/overnote/over-golang go 内部、源码分析 https://github.com/cch123/golang-notes https://github.com/teh-cmc/go-internals ✅ Solutions to LeetCode by Go https://github.com/halfrost/LeetCode-Go 从问题切入，串连 Go 语言相关的所有知识，融会贯通 https://golang.design/go-questions/ C/C++ 技术面试基础知识总结，包括语言、程序库、数据结构、算法、系统、网络、链接装载库等知识及面试经验、招聘、内推等信息。 https://github.com/huihut/interview 技术面试必备基础知识、Leetcode、计算机操作系统、计算机网络、系统设计 （内含 Java） http://www.cyc2018.xyz/\n","permalink":"https://moyuduo.github.io/posts/temp/","summary":"HTTP 协议 · 笔试面试知识整理 https://labuladong.gitbook.io/algo/ 开篇词 - labuladong的算法小抄 https://www.jianshu.com/p/96f1189b95fe IO多路复用机制详解 - 简书 https://www.cnblogs.com/tiancai/p/9024351.html 为什么MySQL数据库索引选择使用B+树？ - 甜菜波波 - 博客园 https://hit-alibaba.github.io/interview/basic/network/HTTP.html TCP 协议 · 笔试面试知识整理 https://hit-alibaba.github.io/interview/basic/network/TCP.html Golang相关：[审稿进度80%]Go语法、Go并发思想、Go与web开发、Go微服务设施等 https://github.com/overnote/over-golang go 内部、源码分析 https://github.com/cch123/golang-notes https://github.com/teh-cmc/go-internals ✅ Solutions to LeetCode by Go https://github.com/halfrost/LeetCode-Go 从问题切入，串连 Go 语言相关的所有知识，融会贯通 https://golang.design/go-questions/ C/C++ 技术面试基础知识总结，包括语言、程序库、数据结构、算法、系统、网络、链接装载库等知识及面试经验、招聘、内推等信息。 https://github.com/huihut/interview 技术面试必备基础知识、Leetcode、计算机操作系统、计算机网络、系统设计 （内含 Java） http://www.cyc2018.xyz/","title":"temp"},{"content":"windows命令备忘录 端口转发 #需要管理员权限 #查看端口转发 netsh interface portproxy show all #添加端口转发 netsh interface portproxy add v4tov4 listenaddress=172.31.164.1 listenport=9309 connectaddress=192.168.37.131 connectport=9309 #删除端口转发 netsh interface portproxy delete v4tov4 listenaddress=172.31.164.1 listenport=9309 ","permalink":"https://moyuduo.github.io/posts/windows%E5%91%BD%E4%BB%A4%E5%A4%87%E5%BF%98%E5%BD%95/","summary":"windows命令备忘录 端口转发 #需要管理员权限 #查看端口转发 netsh interface portproxy show all #添加端口转发 netsh interface portproxy add v4tov4 listenaddress=172.31.164.1 listenport=9309 connectaddress=192.168.37.131 connectport=9309 #删除端口转发 netsh interface portproxy delete v4tov4 listenaddress=172.31.164.1 listenport=9309 ","title":"windows命令备忘录"},{"content":"yurt-device-controller和yurt-edgex-manager调研 openyurt架构：\nopenyurt云端通过各个controller同apiServer控制openyurt节点，如Yurt Controller Manager就是一个基于节点控制器开发的组件它能实现即使边端节点心跳丢失节点上的pod也不会被驱逐 openyurt 边端节点上通过yunrtHub代理k8s各个组件的请求同云端的apiServer通信 在云端部署Tunnel Server，边端部署Tunnel Agent，通过边端Tunnel Agent发起建立长连接到云端Tunnel Server，通过云端Tunnel Server来做代理实现云边运维通道 特点：\n从整个Openyurt的架构来看它只涉及到了云和边，它并不内置端的设备管理，仅仅只是专注于计算资源和业务容器的管理。 当使用 Kubernetes 来解决边缘计算场景的需求时，现有的解决方案要么改变系统架构（如将控制平面和 kubelet 打包在一起），要么重度修改核心组件（如kubelet 中糅合设备管理）。 受 Unix 哲学：“做一件事，做好它”（Do one thing and do it well）的启发，OpenYurt 社区认为 Kubernetes 应该专注于计算资源和业务容器的管理，而边缘设备管理可以通过采用现有的边缘计算平台来完成。 OpenYurt 社区定义了通用的 Kubernetes CRDs，它们充当 OpenYurt 和边缘平台之间的中介。通过为这些 CRDs 实现自定义控制器，任何现有的边缘平台(如 EdgeX Foundry)都可以集成到 OpenYurt 中。同时这些 CRDs 允许用户以声明式的方式管理边缘设备，这为用户提供了 Kubernetes-native 的边缘设备管理体验。 云原生iot模型 为管理现实世界中的设备，需要对设备管理相关的服务进行抽象，使用k8s的Customer Resource Definition(CRD)最终抽象出了3个CRD用于映射设备资源。\nDeviceProfile：描述了使用相同协议的一种设备类型，其中包括一些通用信息，如制造商名称、设备描述和设备型号，此外还定义了此类设备提供的资源类型（例如，温度、湿度）以及如何读取/写入这些资源。类似于Edgewize1.0中的设备数据模型 DeviceService：是与设备交互的边缘连接器在云端的映射，定义了如何将设备接入到边缘设备管理平台，包括设备的通信协议，通信地址等信息。类似Edgewize1.0中驱动的配置信息 Device：是现实世界中端设备的映射，如一个真实的温度传感器，它包括关联的DeviceProfile、DeviceService和一些设备特有的属性。 yurt-device-controller yurt-device-controller通过与边缘平台交互获取边缘平台所连接的真实设备，并将设备抽象为device、deviceService、deviceProfile，通过yurtHub上报到云端\nyurt-edgex-manager yurt-edgex-manager是部署在云端的edgex生命周期控制器，通过CR来对边端的edgex安装、卸载、升级\n","permalink":"https://moyuduo.github.io/posts/yurt-device-controller%E5%92%8Cyurt-edgex-manager%E8%B0%83%E7%A0%94/","summary":"yurt-device-controller和yurt-edgex-manager调研 openyurt架构：\nopenyurt云端通过各个controller同apiServer控制openyurt节点，如Yurt Controller Manager就是一个基于节点控制器开发的组件它能实现即使边端节点心跳丢失节点上的pod也不会被驱逐 openyurt 边端节点上通过yunrtHub代理k8s各个组件的请求同云端的apiServer通信 在云端部署Tunnel Server，边端部署Tunnel Agent，通过边端Tunnel Agent发起建立长连接到云端Tunnel Server，通过云端Tunnel Server来做代理实现云边运维通道 特点：\n从整个Openyurt的架构来看它只涉及到了云和边，它并不内置端的设备管理，仅仅只是专注于计算资源和业务容器的管理。 当使用 Kubernetes 来解决边缘计算场景的需求时，现有的解决方案要么改变系统架构（如将控制平面和 kubelet 打包在一起），要么重度修改核心组件（如kubelet 中糅合设备管理）。 受 Unix 哲学：“做一件事，做好它”（Do one thing and do it well）的启发，OpenYurt 社区认为 Kubernetes 应该专注于计算资源和业务容器的管理，而边缘设备管理可以通过采用现有的边缘计算平台来完成。 OpenYurt 社区定义了通用的 Kubernetes CRDs，它们充当 OpenYurt 和边缘平台之间的中介。通过为这些 CRDs 实现自定义控制器，任何现有的边缘平台(如 EdgeX Foundry)都可以集成到 OpenYurt 中。同时这些 CRDs 允许用户以声明式的方式管理边缘设备，这为用户提供了 Kubernetes-native 的边缘设备管理体验。 云原生iot模型 为管理现实世界中的设备，需要对设备管理相关的服务进行抽象，使用k8s的Customer Resource Definition(CRD)最终抽象出了3个CRD用于映射设备资源。\nDeviceProfile：描述了使用相同协议的一种设备类型，其中包括一些通用信息，如制造商名称、设备描述和设备型号，此外还定义了此类设备提供的资源类型（例如，温度、湿度）以及如何读取/写入这些资源。类似于Edgewize1.0中的设备数据模型 DeviceService：是与设备交互的边缘连接器在云端的映射，定义了如何将设备接入到边缘设备管理平台，包括设备的通信协议，通信地址等信息。类似Edgewize1.0中驱动的配置信息 Device：是现实世界中端设备的映射，如一个真实的温度传感器，它包括关联的DeviceProfile、DeviceService和一些设备特有的属性。 yurt-device-controller yurt-device-controller通过与边缘平台交互获取边缘平台所连接的真实设备，并将设备抽象为device、deviceService、deviceProfile，通过yurtHub上报到云端\nyurt-edgex-manager yurt-edgex-manager是部署在云端的edgex生命周期控制器，通过CR来对边端的edgex安装、卸载、升级","title":"yurt-device-controller和yurt-edgex-manager调研"},{"content":"交控项目备忘录 串口网口调试工具 终端设备主要和边端主要是通过串口或网口进行通信，串口就是使用物理接线的方式通过设备接线连接两个设备，网口就是在终端设备方启动一个tcp的server监听连接，边端驱动通过tcp连接到终端设备，然后通过tcp协议发送控制指令。\n通过串口接入的设备可以串口调试工具来模拟出多个串口(vistual serial port driver)对和进行串口数据的监听(XCOM V2.0.exe串口调试助手)。通过串口虚拟工具在主机windows上虚拟出多个串口对，然后通过虚拟机配置把一对串口中的一个网口映射到虚拟机中(vmware参考https://www.cnblogs.com/mjiu/p/9258459.html)，在windows主机中通过串口调试工具来接受指令\n通过网口接入的设备通过SocketTool来快速启动一个tcp server来接受指令\nvmware串口 通过设置使用物理串口接入虚拟机的，一般串口不一定是/dev/ttyS0，可以使用ls -l ttyS*来查看可用的串口，但是并不能断定接入的串口是哪一个，此时可以使用cat /proc/tty/driver/serial来查看\ncat /proc/tty/driver/serial serinfo:1.0 driver revision: 0: uart:16550A port:000003F8 irq:4 tx:82220847 rx:0 RTS|CTS|DTR|DSR|CD 1: uart:16550A port:000002F8 irq:3 tx:0 rx:0 2: uart:unknown port:000003E8 irq:4 3: uart:unknown port:000002E8 irq:3 可以看到前两个有内容，可能是可用的串口，0对应ttyS0,1对应ttyS1\n现在估计可能是虚拟机设置中的串行端口和虚拟机中的串口文件由对应关系，如串行端口1对应/dev/ttyS0,所以串行端口2就对应/dev/ttyS1\n串口的对应关系为：\nvm中配置的串行端口2使用的物理端口COM1对应要使用COM2来接收发送消息，由于是vm中串行端口2，所以对应/dev/ttyS1\nvm中串行端口n \u0026lt;=\u0026gt; /dev/ttyS(n-1)\tvm中串行端口n \u0026lt;=\u0026gt; 对应vm中配置的物理端口X 物理端口X \u0026lt;=\u0026gt; 物理端口(X+1)或物理端口(X-1)\n称台驱动粘包导致响应慢问题 {\u0026#34;level\u0026#34;:\u0026#34;debug\u0026#34;,\u0026#34;timestamp\u0026#34;:\u0026#34;2021-09-23T14:16:09.371+0800\u0026#34;,\u0026#34;content\u0026#34;:\u0026#34;！！！！！！！！！！！！！！！！recv:0xFF00001B07E50917\\n！！！！！！！！！！！！！！！！1111frameLength:27\\n!!!!!!!!!!!!!!!!!! frameLength:27\u0026#34;,\u0026#34;appID\u0026#34;:\u0026#34;3475ba9f-e2ed-11eb-92bd-52549e8f212b\u0026#34;,\u0026#34;source\u0026#34;:\u0026#34;EdgeWize\u0026#34;} {\u0026#34;level\u0026#34;:\u0026#34;debug\u0026#34;,\u0026#34;timestamp\u0026#34;:\u0026#34;2021-09-23T14:16:09.380+0800\u0026#34;,\u0026#34;content\u0026#34;:\u0026#34;！！！！！！！！！！！！！！！！recv:0x0C340B0000920002\\n！！！！！！！！！！！！！！！！1111frameLength:27\\n!!!!!!!!!!!!!!!!!! frameLength:27\u0026#34;,\u0026#34;appID\u0026#34;:\u0026#34;3475ba9f-e2ed-11eb-92bd-52549e8f212b\u0026#34;,\u0026#34;source\u0026#34;:\u0026#34;EdgeWize\u0026#34;} {\u0026#34;level\u0026#34;:\u0026#34;debug\u0026#34;,\u0026#34;timestamp\u0026#34;:\u0026#34;2021-09-23T14:16:09.388+0800\u0026#34;,\u0026#34;content\u0026#34;:\u0026#34;！！！！！！！！！！！！！！！！recv:0x02004E003C010101\\n！！！！！！！！！！！！！！！！1111frameLength:27\\n!!!!!!!!!!!!!!!!!! frameLength:27\u0026#34;,\u0026#34;appID\u0026#34;:\u0026#34;3475ba9f-e2ed-11eb-92bd-52549e8f212b\u0026#34;,\u0026#34;source\u0026#34;:\u0026#34;EdgeWize\u0026#34;} {\u0026#34;level\u0026#34;:\u0026#34;debug\u0026#34;,\u0026#34;timestamp\u0026#34;:\u0026#34;2021-09-23T14:16:13.990+0800\u0026#34;,\u0026#34;content\u0026#34;:\u0026#34;！！！！！！！！！！！！！！！！recv:0x21E26FFF00001B07E50917\\n！！！！！！！！！！！！！！！！1111frameLength:27\\n!!!!!!!!!!!!!!!!!! frameLength:27\\n！！！！！！！！！！！！！！！！dataBuf:0xFF00001B07E50917\\n！！！！！！！！！！！！！！！！33333333recv:0xFF00001B07E509170C340B000092000202004E003C01010121E26F\\n!!!!!!!!!!!!!AckWeight:0xFF0000004BA3 \\n！！！！！！！！！！！！！！！！report WeightWholeCar event\u0026#34;,\u0026#34;appID\u0026#34;:\u0026#34;3475ba9f-e2ed-11eb-92bd-52549e8f212b\u0026#34;,\u0026#34;source\u0026#34;:\u0026#34;EdgeWize\u0026#34;} {\u0026#34;level\u0026#34;:\u0026#34;debug\u0026#34;,\u0026#34;timestamp\u0026#34;:\u0026#34;2021-09-23T14:16:14.021+0800\u0026#34;,\u0026#34;content\u0026#34;:\u0026#34;!!!!!!! reportEvent param:{WeightTime:1632401531000 OverrunSign:1 Speed:14.6 Acceleration:0 AxisCount:2 AxisGroupCount:2 AxisGroupWeightList:[780 600] AxisGroupTypeList:[1 1] AxisGroupSpacingList:[2.8899999] Cmd:0}\\n!!!!!!! reportEvent ---- data:map[Acceleration:0 AxisCount:2 AxisGroupCount:2 AxisGroupSpacingList:[2.8899999] AxisGroupTypeList:[1 1] AxisGroupWeightList:[780 600] Cmd:0 OverrunSign:1 Speed:14.6 WeightTime:1632401531000]\\n！！！！！！！！！！！！！！！！1111frameLength:27\\n!!!!!!!!!!!!!!!!!! frameLength:27\\n！！！！！！！！！！！！！！！！recv:0x0C340B0000920002\\n！！！！！！！！！！！！！！！！1111frameLength:27\\n!!!!!!!!!!!!!!!!!! frameLength:27\\n！！！！！！！！！！！！！！！！recv:0x02004E003C010101\\n！！！！！！！！！！！！！！！！1111frameLength:27\\n!!!!!!!!!!!!!!!!!! frameLength:27\u0026#34;,\u0026#34;appID\u0026#34;:\u0026#34;3475ba9f-e2ed-11eb-92bd-52549e8f212b\u0026#34;,\u0026#34;source\u0026#34;:\u0026#34;EdgeWize\u0026#34;} 从日志来看的话主要是称台终端对称重信息的响应包分了四个包发送，前三个包都是一秒内就接收完毕，但是第四个包等到了下一条指令组了一个包才接收，由于没有ack所以5秒后才会重新发，就导致解析称重满了5秒\n经过检查主要是\noptions := serial.OpenOptions{ PortName: portName, BaudRate: baudRate, DataBits: dataBits, StopBits: stopBits, MinimumReadSize: 4, } log.Info(\u0026#34;new serial endpoint options:%+v\u0026#34;, options) client, err := endpoint.NewSerialEndpoint(s.ctx, v.Token, options) 打开串口的时候指定了MinimumReadSize为4，而分包发送的最后一个包只有三字节，所以等了下一个包一起接收，把MinimumReadSize改为1即解决问题\n停止边端驱动服务 #!/bin/bash DRIVER_NAME=$1 CNT=5 echo \u0026#34;stop edge driver $DRIVER_NAME ...\u0026#34; while(( CNT\u0026gt;0 )) do sudo docker stop $DRIVER_NAME sleep 1 done echo \u0026#34;stop edge driver $DRIVER_NAME success\u0026#34; 构建驱动 docker build -t 镜像名：版本号 -f Dockerfile文件地址 .\n最有一个 . 代表上下文路径，即在构建镜像的时候会把该目录下的文件拷贝到镜像中\n#创建Dockerfile文件 # build FROM golang AS build WORKDIR /qingcloud ADD . . ENV GOPROXY=https://goproxy.cn,direct ENV GOOS=linux RUN go mod download \u0026amp;\u0026amp; go build -o /gowork/driver-weighing-adapter #必须要指定基础镜像为centos，使用alpine:3.9、saratch运行容器时都会报错：standard_init_linux.go:228: exec user process caused: no such file or directory FROM centos MAINTAINER litao \u0026#34;taoli@yunify.com\u0026#34; WORKDIR /data COPY --from=build /qingcloud/driver-weighing-adapter . ENTRYPOINT [\u0026#34;/data/driver-weighing-adapter\u0026#34;,\u0026#34;serve\u0026#34;] 使用以上构建的话由于指定了基础镜像为centos所以构建出来的镜像会很大\n# # Qingcloud Dockerfile # FROM golang As build WORKDIR /gowork COPY . . ENV GOPROXY=https://goproxy.cn,direct ENV GOOS=linux #在编译项目的时候指定了\tCGO_ENABLED=0 那么就可以使用scratch.alpine:3.9这样的比较小的基础镜像，最后生成的镜像也会很小 RUN go mod download \u0026amp;\u0026amp; CGO_ENABLED=0 go build -o /gowork/driver-rsu-adapter FROM scratch MAINTAINER taoli \u0026#34;taoli@yunify.com\u0026#34; WORKDIR /data COPY --from=build /gowork/driver-rsu-adapter . ENTRYPOINT [\u0026#34;/data/driver-rsu-adapter\u0026#34;,\u0026#34;serve\u0026#34;] 构建镜像\n#构建镜像,注意版本号有v docker build --no-cache -f Dockerfile -t dockerhub.qingcloud.com/iot_demo/driver-weighing-adapter:v0.31 . 登录要推送的仓库\n#登录私有仓库 docker login -u hexing dockerhub.qingcloud.com hexing 推送到仓库,注意：构建镜像版本时指定版本号加了v所以推送的时候也要加\n#推送镜像到私有仓库 docker push dockerhub.qingcloud.com/iot_demo/driver-weighing-adapter:v0.31 ","permalink":"https://moyuduo.github.io/posts/%E4%BA%A4%E6%8E%A7%E9%A1%B9%E7%9B%AE%E5%A4%87%E5%BF%98%E5%BD%95/","summary":"交控项目备忘录 串口网口调试工具 终端设备主要和边端主要是通过串口或网口进行通信，串口就是使用物理接线的方式通过设备接线连接两个设备，网口就是在终端设备方启动一个tcp的server监听连接，边端驱动通过tcp连接到终端设备，然后通过tcp协议发送控制指令。\n通过串口接入的设备可以串口调试工具来模拟出多个串口(vistual serial port driver)对和进行串口数据的监听(XCOM V2.0.exe串口调试助手)。通过串口虚拟工具在主机windows上虚拟出多个串口对，然后通过虚拟机配置把一对串口中的一个网口映射到虚拟机中(vmware参考https://www.cnblogs.com/mjiu/p/9258459.html)，在windows主机中通过串口调试工具来接受指令\n通过网口接入的设备通过SocketTool来快速启动一个tcp server来接受指令\nvmware串口 通过设置使用物理串口接入虚拟机的，一般串口不一定是/dev/ttyS0，可以使用ls -l ttyS*来查看可用的串口，但是并不能断定接入的串口是哪一个，此时可以使用cat /proc/tty/driver/serial来查看\ncat /proc/tty/driver/serial serinfo:1.0 driver revision: 0: uart:16550A port:000003F8 irq:4 tx:82220847 rx:0 RTS|CTS|DTR|DSR|CD 1: uart:16550A port:000002F8 irq:3 tx:0 rx:0 2: uart:unknown port:000003E8 irq:4 3: uart:unknown port:000002E8 irq:3 可以看到前两个有内容，可能是可用的串口，0对应ttyS0,1对应ttyS1\n现在估计可能是虚拟机设置中的串行端口和虚拟机中的串口文件由对应关系，如串行端口1对应/dev/ttyS0,所以串行端口2就对应/dev/ttyS1\n串口的对应关系为：\nvm中配置的串行端口2使用的物理端口COM1对应要使用COM2来接收发送消息，由于是vm中串行端口2，所以对应/dev/ttyS1\nvm中串行端口n \u0026lt;=\u0026gt; /dev/ttyS(n-1)\tvm中串行端口n \u0026lt;=\u0026gt; 对应vm中配置的物理端口X 物理端口X \u0026lt;=\u0026gt; 物理端口(X+1)或物理端口(X-1)\n称台驱动粘包导致响应慢问题 {\u0026#34;level\u0026#34;:\u0026#34;debug\u0026#34;,\u0026#34;timestamp\u0026#34;:\u0026#34;2021-09-23T14:16:09.371+0800\u0026#34;,\u0026#34;content\u0026#34;:\u0026#34;！！！！！！！！！！！！！！！！recv:0xFF00001B07E50917\\n！！！！！！！！！！！！！！！！1111frameLength:27\\n!!!!!!!!!!!!!!!!!! frameLength:27\u0026#34;,\u0026#34;appID\u0026#34;:\u0026#34;3475ba9f-e2ed-11eb-92bd-52549e8f212b\u0026#34;,\u0026#34;source\u0026#34;:\u0026#34;EdgeWize\u0026#34;} {\u0026#34;level\u0026#34;:\u0026#34;debug\u0026#34;,\u0026#34;timestamp\u0026#34;:\u0026#34;2021-09-23T14:16:09.380+0800\u0026#34;,\u0026#34;content\u0026#34;:\u0026#34;！！！！！！！！！！！！！！！！recv:0x0C340B0000920002\\n！！！！！！！！！！！！！！！！1111frameLength:27\\n!!!!!!!!!!!!!!!!!! frameLength:27\u0026#34;,\u0026#34;appID\u0026#34;:\u0026#34;3475ba9f-e2ed-11eb-92bd-52549e8f212b\u0026#34;,\u0026#34;source\u0026#34;:\u0026#34;EdgeWize\u0026#34;} {\u0026#34;level\u0026#34;:\u0026#34;debug\u0026#34;,\u0026#34;timestamp\u0026#34;:\u0026#34;2021-09-23T14:16:09.388+0800\u0026#34;,\u0026#34;content\u0026#34;:\u0026#34;！！！！！！！！！！！！！！！！recv:0x02004E003C010101\\n！！！！！！！！！！！！！！！！1111frameLength:27\\n!!!!!!!!!!!!!!!!!! frameLength:27\u0026#34;,\u0026#34;appID\u0026#34;:\u0026#34;3475ba9f-e2ed-11eb-92bd-52549e8f212b\u0026#34;,\u0026#34;source\u0026#34;:\u0026#34;EdgeWize\u0026#34;} {\u0026#34;level\u0026#34;:\u0026#34;debug\u0026#34;,\u0026#34;timestamp\u0026#34;:\u0026#34;2021-09-23T14:16:13.990+0800\u0026#34;,\u0026#34;content\u0026#34;:\u0026#34;！！！！！！！！！！！！！！！！recv:0x21E26FFF00001B07E50917\\n！！！！！！！！！！！！！！！！1111frameLength:27\\n!!!!!!!!!!!!!!!!!! frameLength:27\\n！！！！！！！！！！！！！！！！dataBuf:0xFF00001B07E50917\\n！！！！！！！！！！！！！！！！33333333recv:0xFF00001B07E509170C340B000092000202004E003C01010121E26F\\n!!!!!!!!!!!!!AckWeight:0xFF0000004BA3 \\n！！！！！！！！！！！！！！！！report WeightWholeCar event\u0026#34;,\u0026#34;appID\u0026#34;:\u0026#34;3475ba9f-e2ed-11eb-92bd-52549e8f212b\u0026#34;,\u0026#34;source\u0026#34;:\u0026#34;EdgeWize\u0026#34;} {\u0026#34;level\u0026#34;:\u0026#34;debug\u0026#34;,\u0026#34;timestamp\u0026#34;:\u0026#34;2021-09-23T14:16:14.021+0800\u0026#34;,\u0026#34;content\u0026#34;:\u0026#34;!!!!!!! reportEvent param:{WeightTime:1632401531000 OverrunSign:1 Speed:14.","title":"交控备忘录"},{"content":"dlv install go install github.com/go-delve/delve/cmd/dlv@latest go install github.com/go-delve/delve/cmd/dlv@v1.7.3 use [root@centos72 k8s-dlv-debug]# dlv help Delve is a source level debugger for Go programs. Delve enables you to interact with your program by controlling the execution of the process, evaluating variables, and providing information of thread / goroutine state, CPU register state and more. The goal of this tool is to provide a simple yet powerful interface for debugging Go programs. Pass flags to the program you are debugging using `--`, for example: `dlv exec ./hello -- server --config conf/config.toml` Usage: dlv [command] Available Commands: attach Attach to running process and begin debugging. #使用pid调试程序:dlv attach pid connect Connect to a headless debug server. core Examine a core dump. dap [EXPERIMENTAL] Starts a headless TCP server communicating via Debug Adaptor Protocol (DAP). debug Compile and begin debugging main package in current directory, or the package specified. #debug一个程序，首先会编译文件生成__debug_bin可执行文件，执行后attach到该程序上，退出后__debug_bin文件会被删除 exec Execute a precompiled binary, and begin a debug session. #执行可执行文件并attach help Help about any command run Deprecated command. Use \u0026#39;debug\u0026#39; instead. test Compile test binary and begin debugging program. trace Compile and begin tracing program. version Prints version. Flags: --accept-multiclient Allows a headless server to accept multiple client connections. --allow-non-terminal-interactive Allows interactive sessions of Delve that don\u0026#39;t have a terminal as stdin, stdout and stderr --api-version int Selects API version when headless. New clients should use v2. Can be reset via RPCServer.SetApiVersion. See Documentation/api/json-rpc/README.md. (default 1) --backend string Backend selection (see \u0026#39;dlv help backend\u0026#39;). (default \u0026#34;default\u0026#34;) --build-flags string Build flags, to be passed to the compiler. For example: --build-flags=\u0026#34;-tags=integration -mod=vendor -cover -v\u0026#34; --check-go-version Checks that the version of Go in use is compatible with Delve. (default true) --disable-aslr Disables address space randomization --headless Run debug server only, in headless mode. -h, --help help for dlv --init string Init file, executed by the terminal client. -l, --listen string Debugging server listen address. (default \u0026#34;127.0.0.1:0\u0026#34;) --log Enable debugging server logging. --log-dest string Writes logs to the specified file or file descriptor (see \u0026#39;dlv help log\u0026#39;). --log-output string Comma separated list of components that should produce debug output (see \u0026#39;dlv help log\u0026#39;) --only-same-user Only connections from the same user that started this instance of Delve are allowed to connect. (default true) -r, --redirect stringArray Specifies redirect rules for target process (see \u0026#39;dlv help redirect\u0026#39;) --wd string Working directory for running the program. Additional help topics: dlv backend Help about the --backend flag. dlv log Help about logging flags. dlv redirect Help about file redirection. Use \u0026#34;dlv [command] --help\u0026#34; for more information about a command dlv debug main.go #执行一步 n / next #查看断点 bp #设置断点到hello方法 b main.hello #设置断点到指定行 b main.go:20 #放行 c #看变量 locals p arg1 #判断表达式 p name == \u0026#34;abc\u0026#34; #清除断点 clear 1 #清除所有断点 clearall #进入方法 s / step #跳出方法 so / stepout windows下vscode远程dlv调试 在远程机器上/storehouse/k8s-dlv-debug目录下执行dlv debug main.go --listen=:19999 --headless --api-version=2,必须使用debug命令，如果使用exec/attach都会导致变量值不可见 在windows下机器上创建launch.json并配置 { \u0026#34;version\u0026#34;: \u0026#34;0.2.0\u0026#34;, \u0026#34;configurations\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;remote debug\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;go\u0026#34;, \u0026#34;request\u0026#34;: \u0026#34;attach\u0026#34;, \u0026#34;mode\u0026#34;: \u0026#34;remote\u0026#34;, \u0026#34;host\u0026#34;: \u0026#34;192.168.37.131\u0026#34;, \u0026#34;port\u0026#34;: 19999, \u0026#34;showLog\u0026#34;: true } ] } 在windows下vscode的进行debug在代码中设置断点,注意调试时windows下项目的代码要和远程执行的一致 windows下调试k8s中pod中的container中运行的go 编写要调试程序的Dockerfile FROM golang:1.17 WORKDIR /work COPY . /work/ ENV CGO_ENABLED=0 GOPROXY=https://goproxy.cn,direct RUN go get github.com/go-delve/delve/cmd/dlv EXPOSE 9999 19999 ENTRYPOINT [ \u0026#34;dlv\u0026#34;, \u0026#34;debug\u0026#34;, \u0026#34;.\u0026#34;, \u0026#34;--listen=:19999\u0026#34;, \u0026#34;--headless\u0026#34;, \u0026#34;--api-version=2\u0026#34; ] 构建容器docker build -t moyuduo/k8s-dlv-debug . 登录后docker login -u moyuduo 推送镜像docker push moyuduo/k8s-dlv-debug 编写在k8s集群中部署的yaml文件 apiVersion: v1 kind: Pod metadata: name: k8s-dlv-debug namespace: moyuduo labels: app: k8s-dlv-debug spec: containers: - name: debug image: moyuduo/k8s-dlv-debug imagePullPolicy: IfNotPresent ports: - name: web containerPort: 9999 protocol: TCP - name: dlv containerPort: 19999 protocol: TCP --- apiVersion: v1 kind: Service metadata: name: k8s-dlv-debug-service namespace: moyuduo spec: type: NodePort #暴露nodeport供windows调试时连接 selector: app: k8s-dlv-debug ports: - name: web port: 9999 targetPort: 9999 protocol: TCP - name: dlv port: 19999 targetPort: 19999 protocol: TCP 部署yaml文件 k apply -f pod.yaml k apply -f service.yaml 查看集群中service的nodePort hello,myd[root@centos72 manifest]# k get svc -n moyuduo NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE ingress-svc-nginx-demo NodePort 10.96.37.49 \u0026lt;none\u0026gt; 80:30633/TCP 2d k8s-dlv-debug-service NodePort 10.96.120.143 \u0026lt;none\u0026gt; 9999:31122/TCP,19999:30449/TCP 11m 在windows下使用使用vscode连接远程，首先创建launch.json文件并修改 { \u0026#34;version\u0026#34;: \u0026#34;0.2.0\u0026#34;, \u0026#34;configurations\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;remote debug\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;go\u0026#34;, \u0026#34;request\u0026#34;: \u0026#34;attach\u0026#34;, \u0026#34;mode\u0026#34;: \u0026#34;remote\u0026#34;, \u0026#34;host\u0026#34;: \u0026#34;172.18.2.2\u0026#34;, \u0026#34;port\u0026#34;: 30449, \u0026#34;showLog\u0026#34;: true } ] } 完成调试后一定要删除k8s中的资源 k delete -f service.yaml k delete -f pod.yaml ","permalink":"https://moyuduo.github.io/posts/%E4%BD%BF%E7%94%A8dlv%E8%B0%83%E8%AF%95k8s%E4%B8%AD%E8%BF%90%E8%A1%8C%E7%9A%84go%E7%A8%8B%E5%BA%8F/","summary":"dlv install go install github.com/go-delve/delve/cmd/dlv@latest go install github.com/go-delve/delve/cmd/dlv@v1.7.3 use [root@centos72 k8s-dlv-debug]# dlv help Delve is a source level debugger for Go programs. Delve enables you to interact with your program by controlling the execution of the process, evaluating variables, and providing information of thread / goroutine state, CPU register state and more. The goal of this tool is to provide a simple yet powerful interface for debugging Go programs. Pass flags to the program you are debugging using `--`, for example: `dlv exec .","title":"使用dlv调试k8s中运行的go程序"},{"content":"饿汉式 静态变量方式 public class Singleton1 { private final static Singleton1 instance=new Singleton1(); private Singleton1() {} public static Singleton1 getInstance() { return instance; } } 静态代码块方式 public class Singleton2 { private static Singleton2 instance; static { instance=new Singleton2(); } private Singleton2() {} public static Singleton2 getInstance() { return instance; } } 懒汉式 线程不安全式 public class Singleton3 { private static Singleton3 instance; private Singleton3() {} public static Singleton3 getInstance() { if(instance==null) { instance=new Singleton3(); } return instance; } } 线程安全式 public class Singleton4 { private static Singleton4 instance; private Singleton4() {} public synchronized static Singleton4 getInstance() { if(instance==null) { instance=new Singleton4(); } return instance; } } 双重检查方式 public class Singleton5 { private static volatile Singleton5 instance; private Singleton5() {} public static Singleton5 getInstance() { if(instance==null) { synchronized (Singleton5.class) { if(instance==null) { instance=new Singleton5(); } } } return instance; } } 为什么需要双重检查？\n加入有两个线程A、B都执行到了if(instance==null)这个语句，而A线程先拿到了锁，生成了对象，如果A线程是否了锁，B线程此时拿到锁，如果不在执行一次判断if(instance==null)的话，那么就又会生成一个实例，那么就不是严格的单例模式\n静态内部类方式 public class Singleton6 { private static class SingletonInstance{ private static final Singleton6 INSTANCE=new Singleton6(); } private Singleton6() {} public static Singleton6 getInstance() { return SingletonInstance.INSTANCE; } } 外部类的加载不会导致内部类的加载，只有当内部类别使用时才会导致加载，并且类加载的时候JVM保证线程安全，所以利用这种方式即能保证线程安全又能保证懒加载\n枚举方式 public enum Singleton7 { INSTANCE; public void method() { System.out.println(\u0026#34;method\u0026#34;); } } 利用枚举的特性，得到的实例都是单例的。\n","permalink":"https://moyuduo.github.io/posts/%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F/","summary":"饿汉式 静态变量方式 public class Singleton1 { private final static Singleton1 instance=new Singleton1(); private Singleton1() {} public static Singleton1 getInstance() { return instance; } } 静态代码块方式 public class Singleton2 { private static Singleton2 instance; static { instance=new Singleton2(); } private Singleton2() {} public static Singleton2 getInstance() { return instance; } } 懒汉式 线程不安全式 public class Singleton3 { private static Singleton3 instance; private Singleton3() {} public static Singleton3 getInstance() { if(instance==null) { instance=new Singleton3(); } return instance; } } 线程安全式 public class Singleton4 { private static Singleton4 instance; private Singleton4() {} public synchronized static Singleton4 getInstance() { if(instance==null) { instance=new Singleton4(); } return instance; } } 双重检查方式 public class Singleton5 { private static volatile Singleton5 instance; private Singleton5() {} public static Singleton5 getInstance() { if(instance==null) { synchronized (Singleton5.","title":"单例模式"},{"content":"多线程 创建 public static void main(String[] args) { new Thread(new Runnable() { @Override public void run() { for(int i=0;i\u0026lt;100;i++) { System.out.println(\u0026#34;A:\u0026#34;+i); } } }).start(); new Thread(new Runnable() { @Override public void run() { for(int i=0;i\u0026lt;100;i++) { System.out.println(\u0026#34;B:\u0026#34;+i); } } }).start(); } ","permalink":"https://moyuduo.github.io/posts/%E5%A4%9A%E7%BA%BF%E7%A8%8B/","summary":"多线程 创建 public static void main(String[] args) { new Thread(new Runnable() { @Override public void run() { for(int i=0;i\u0026lt;100;i++) { System.out.println(\u0026#34;A:\u0026#34;+i); } } }).start(); new Thread(new Runnable() { @Override public void run() { for(int i=0;i\u0026lt;100;i++) { System.out.println(\u0026#34;B:\u0026#34;+i); } } }).start(); } ","title":"多线程"},{"content":"分享的问题： TCP本来就具有数据包校验功能，那么为什么基于TCP的上层协议还需要自定义数据校验？ TCP具有Keepalive机制为什么需要应用层使用心跳包来探测对方是否存活？ 为什么要分享这几个问题： 不知道有没有伙伴和我一样有这些问题，比如：\nTCP不是可靠的网络传输协议吗，TCP的超时重传、拥塞控制、CheckSum校验难道还不能保证数据的可靠性？ TCP具有开启keepalive的选项，为什么应用层去发送心跳包？ 在TCP网络编程中，客户端服务器建立了连接，但是没有发送数据连接会不会断开？多久断开？为什么断开？ 最近在看交控的一些设备驱动代码，终端设备的接入方式基本为网口接入和串口接入使用自定义的通信协议封装数据来传送数据帧，对于网口接入的设备往往会使用goroutine的方式去发送心跳数据包，并且自定义的通信协议也有数据校验的过程\n百度百科定义：\n传输控制协议（TCP，Transmission Control Protocol）是一种面向连接的、可靠的、基于字节流的传输层通信协议\nTCP本来就具有数据包校验功能，那么为什么基于TCP的上层协议还需要自定义数据校验 回顾一下网络模型：\n各层数据包的封装就像俄罗斯套娃一样\n以太网帧：\n以太网帧的校验码FCS采用32位循环冗余码(CRC);不但需要检验MAC帧的数据部分，还要检验目的地址、源地址和类型字段，但是不校验前导码\nIP数据包：\nIP数据包也包含校验码，但是它只对IP数据报的头部信息计算校验码并不包含数据区域，而且计算校验和的算法为将IP数据包头按16位划分为一个单元，对各个单元采取反码加法运算(对每个单元取反码相加，高位溢出位会加到低位，所有单元计算完后将得到的和填入校验和字段)\nTCP数据包：\nTCP数据包也包含了校验和，生成校验和的算法和IP数据包的一样，但是不同的是TCP的校验和是把数据区域也加入了计算的校验和的范围内而IP数据包不是\n所以：\n虽然在Mac帧层使用了Crc32位进行校验但是还是可能会有出错的概率，导致错误的数据包传递给了上层，我们都知道数据在物理层上传输是使用电信号、光信号但是这些信号在传输过程中是很容易出错的，比如电信号，它在物理层上的传输是通过规定阈值来区分01的，比如1伏一下表示0，一伏以上表示1，但是数据在物理上传输是会受到磁场等干扰，所容易原来的0可能变成1,1也可能变成0，这里的核心思想是，距离数据的发源地越近的地方，将错误的数据丢弃，避免错误的数据奔袭万里贻害网络资源 如果一个错误的数据包在数据链路层没有被检查到，那么在上传的IP层、TCP层有没有可能也没有检测到？当然有可能！所以我们为了保证万无一失还可以在应用层使用复杂的检测算法来检测数据的完整性 TCP具有KeepAlive机制为什么需要应用层使用心跳包来探测对方是否存活 不知道有没有同事试过或者想过建立好的连接如果遇到断网、断电等情况会怎么样？\n在说明TCP KeepAlive机制之前，聊一聊内网主机一般如何上外网：我们的绝大多数主机，不管是公司电脑还是家庭电脑的ip都是运营商提供的内网IP，内网IP可以和本局域网的其他主机直接通信，但是要和外部网络的主机通信就需要借助网关，一般使用的NAT网络地址转换协议\n比如一台主机它的内网ip为172.31.164.1端口10000的程序要去访问外网ip110.242.68.4端口80的程序，它是没办法直接访问的，于是它把数据包发送给它的网关172.31.165.254端口8000，网关会把ip数据报里的源地址修改为自己的ip172.31.165.254源端口修改为8000，并生成一张端口转换表：\n内网主机IP 内网主机端口 网关转发端口 外网主机IP 外网主机端口 172.31.164.1 10000 8000 110.242.68.4 80 当网关8000端口接收到主机110.242.68.4回复的数据时，会查询端口映射表，把ip数据报里的目的IP修改为内网主机172.31.164.1并把目的端口修改为10000，通过这个过程内网IP就完成了和外网IP的通信\n但是我们知道一台设备它的端口最多为65536个(0-65535),当内网中的主机特别多或主机上特别多进程要访问外部ip时，网关上的端口可能就不够用了，所以网关会监控端口的状况，如果网关上的端口很久没有转发数据了，那么就会把该端口释放掉，供其他需要和外部通信的内部主机使用，并且不会进行通知\n**TCP KeepAlive是用来干嘛的：**使用TCP连接的C/S模式的应用中，当TCP连接建立后，如果一方发生宕机、断网、路由器故障等情况时，另一方是没有办法感知到连接失效的，导致它一直维护着这个连接，如果是服务端，那么维护过多的半开连接还会造成系统资源的浪费。所以不管是客户端还是服务端都需要快速感知到对方还是否存活，这就有了TCP层面的KeepAlive机制。TCP KeepAlive机制是指不管是客户端还是服务端都可以在建立连接的时候指定是否开启KeepAlive，开启之后(TCP协议层面默认不开启)如果连接没有发送数据达到一定时间(TCP_KeepAlive_Idle 参数Linux下默认7200s也就是2h)，会向对方发送TCP KeepAlive数据包，对方收到数据包之后必须ACK，如果对方应该特殊情况收不到这个KeepAlive包那么就没办法回复ACK，这是会定时(TCP_KeepAlive_Interval参数，Linux下默认75s)发送KeepAlive包，当这些KeepAlive包未被应答累计到了一定的数量(TCP_KeepAlive_Probes参数，linux下默认为9)之后，TCP就会返回错误。\n**心跳包HeartBeat:**HeartBeat和TCP的KeepAlive机制类似，都是通过发送数据来检验对方是否存活，不同的是应用层面的HeartBeat不用要求另一方应用层面回复数据，可以通过TCP层面的数据包是否被ACK来检验对方是否存活。\n所以已经有KeepAlive机制了为什么还要应用层HeartBeat呢？\nTCP的KeepAlive是传输层面的，TCP协议层面是规定默认不开启的，而且不同操作系统（windows、linux）去实现TCP协议时参数设置还有差异 TCP层面的KeepAlive和应用层的HeartBeat并不冲突，是不同层在进行控制，可以达到更好的效果 TCP的KeepAlive机制是传输层协议在发送接收数据包，发送接收的内容不可控制，对于一些要监听设备状态IM应用，HeartBeat就是必须的 参考资料： https://www.zhihu.com/question/370717865?utm_source=wechat_session\nhttps://my.oschina.net/zhongwcool/blog/4617109\nhttps://www.cnblogs.com/fhefh/archive/2011/10/18/2216885.html\nhttps://www.bilibili.com/read/cv10935452?from=search\n","permalink":"https://moyuduo.github.io/posts/%E5%BA%94%E7%94%A8%E5%B1%82%E6%95%B0%E6%8D%AE%E6%A0%A1%E9%AA%8C%E5%92%8C%E5%BF%83%E8%B7%B3%E5%8C%85%E7%9A%84%E5%BF%85%E8%A6%81%E6%80%A7/","summary":"分享的问题： TCP本来就具有数据包校验功能，那么为什么基于TCP的上层协议还需要自定义数据校验？ TCP具有Keepalive机制为什么需要应用层使用心跳包来探测对方是否存活？ 为什么要分享这几个问题： 不知道有没有伙伴和我一样有这些问题，比如：\nTCP不是可靠的网络传输协议吗，TCP的超时重传、拥塞控制、CheckSum校验难道还不能保证数据的可靠性？ TCP具有开启keepalive的选项，为什么应用层去发送心跳包？ 在TCP网络编程中，客户端服务器建立了连接，但是没有发送数据连接会不会断开？多久断开？为什么断开？ 最近在看交控的一些设备驱动代码，终端设备的接入方式基本为网口接入和串口接入使用自定义的通信协议封装数据来传送数据帧，对于网口接入的设备往往会使用goroutine的方式去发送心跳数据包，并且自定义的通信协议也有数据校验的过程\n百度百科定义：\n传输控制协议（TCP，Transmission Control Protocol）是一种面向连接的、可靠的、基于字节流的传输层通信协议\nTCP本来就具有数据包校验功能，那么为什么基于TCP的上层协议还需要自定义数据校验 回顾一下网络模型：\n各层数据包的封装就像俄罗斯套娃一样\n以太网帧：\n以太网帧的校验码FCS采用32位循环冗余码(CRC);不但需要检验MAC帧的数据部分，还要检验目的地址、源地址和类型字段，但是不校验前导码\nIP数据包：\nIP数据包也包含校验码，但是它只对IP数据报的头部信息计算校验码并不包含数据区域，而且计算校验和的算法为将IP数据包头按16位划分为一个单元，对各个单元采取反码加法运算(对每个单元取反码相加，高位溢出位会加到低位，所有单元计算完后将得到的和填入校验和字段)\nTCP数据包：\nTCP数据包也包含了校验和，生成校验和的算法和IP数据包的一样，但是不同的是TCP的校验和是把数据区域也加入了计算的校验和的范围内而IP数据包不是\n所以：\n虽然在Mac帧层使用了Crc32位进行校验但是还是可能会有出错的概率，导致错误的数据包传递给了上层，我们都知道数据在物理层上传输是使用电信号、光信号但是这些信号在传输过程中是很容易出错的，比如电信号，它在物理层上的传输是通过规定阈值来区分01的，比如1伏一下表示0，一伏以上表示1，但是数据在物理上传输是会受到磁场等干扰，所容易原来的0可能变成1,1也可能变成0，这里的核心思想是，距离数据的发源地越近的地方，将错误的数据丢弃，避免错误的数据奔袭万里贻害网络资源 如果一个错误的数据包在数据链路层没有被检查到，那么在上传的IP层、TCP层有没有可能也没有检测到？当然有可能！所以我们为了保证万无一失还可以在应用层使用复杂的检测算法来检测数据的完整性 TCP具有KeepAlive机制为什么需要应用层使用心跳包来探测对方是否存活 不知道有没有同事试过或者想过建立好的连接如果遇到断网、断电等情况会怎么样？\n在说明TCP KeepAlive机制之前，聊一聊内网主机一般如何上外网：我们的绝大多数主机，不管是公司电脑还是家庭电脑的ip都是运营商提供的内网IP，内网IP可以和本局域网的其他主机直接通信，但是要和外部网络的主机通信就需要借助网关，一般使用的NAT网络地址转换协议\n比如一台主机它的内网ip为172.31.164.1端口10000的程序要去访问外网ip110.242.68.4端口80的程序，它是没办法直接访问的，于是它把数据包发送给它的网关172.31.165.254端口8000，网关会把ip数据报里的源地址修改为自己的ip172.31.165.254源端口修改为8000，并生成一张端口转换表：\n内网主机IP 内网主机端口 网关转发端口 外网主机IP 外网主机端口 172.31.164.1 10000 8000 110.242.68.4 80 当网关8000端口接收到主机110.242.68.4回复的数据时，会查询端口映射表，把ip数据报里的目的IP修改为内网主机172.31.164.1并把目的端口修改为10000，通过这个过程内网IP就完成了和外网IP的通信\n但是我们知道一台设备它的端口最多为65536个(0-65535),当内网中的主机特别多或主机上特别多进程要访问外部ip时，网关上的端口可能就不够用了，所以网关会监控端口的状况，如果网关上的端口很久没有转发数据了，那么就会把该端口释放掉，供其他需要和外部通信的内部主机使用，并且不会进行通知\n**TCP KeepAlive是用来干嘛的：**使用TCP连接的C/S模式的应用中，当TCP连接建立后，如果一方发生宕机、断网、路由器故障等情况时，另一方是没有办法感知到连接失效的，导致它一直维护着这个连接，如果是服务端，那么维护过多的半开连接还会造成系统资源的浪费。所以不管是客户端还是服务端都需要快速感知到对方还是否存活，这就有了TCP层面的KeepAlive机制。TCP KeepAlive机制是指不管是客户端还是服务端都可以在建立连接的时候指定是否开启KeepAlive，开启之后(TCP协议层面默认不开启)如果连接没有发送数据达到一定时间(TCP_KeepAlive_Idle 参数Linux下默认7200s也就是2h)，会向对方发送TCP KeepAlive数据包，对方收到数据包之后必须ACK，如果对方应该特殊情况收不到这个KeepAlive包那么就没办法回复ACK，这是会定时(TCP_KeepAlive_Interval参数，Linux下默认75s)发送KeepAlive包，当这些KeepAlive包未被应答累计到了一定的数量(TCP_KeepAlive_Probes参数，linux下默认为9)之后，TCP就会返回错误。\n**心跳包HeartBeat:**HeartBeat和TCP的KeepAlive机制类似，都是通过发送数据来检验对方是否存活，不同的是应用层面的HeartBeat不用要求另一方应用层面回复数据，可以通过TCP层面的数据包是否被ACK来检验对方是否存活。\n所以已经有KeepAlive机制了为什么还要应用层HeartBeat呢？\nTCP的KeepAlive是传输层面的，TCP协议层面是规定默认不开启的，而且不同操作系统（windows、linux）去实现TCP协议时参数设置还有差异 TCP层面的KeepAlive和应用层的HeartBeat并不冲突，是不同层在进行控制，可以达到更好的效果 TCP的KeepAlive机制是传输层协议在发送接收数据包，发送接收的内容不可控制，对于一些要监听设备状态IM应用，HeartBeat就是必须的 参考资料： https://www.zhihu.com/question/370717865?utm_source=wechat_session\nhttps://my.oschina.net/zhongwcool/blog/4617109\nhttps://www.cnblogs.com/fhefh/archive/2011/10/18/2216885.html\nhttps://www.bilibili.com/read/cv10935452?from=search","title":"应用层数据校验和心跳包的必要性"},{"content":"数据库隔离级别 如果没有隔离级别会出现的问题 脏读 意思是读取到了事务正在修改的数据，如果事务回滚，那么拿到的数据就是错误的\n时间 事务A 事务B 1 开始事务 2 读取quantity为5 3 修改quantity为4 4 开始事务 5 读取到quantity为4 6 发生错误，回滚，quantity为5 7 提交事务 在按照正常逻辑quantity应该为5\n不可重复读 时间 事务A 事务B 1 开始事务 2 读取quantity为5 3 开始事务 4 修改quantity为4 5 提交事务 6 读取quantity为4 7 提交事务 在同一个事务内，两次读取同一个数据产生不一致\n幻读 时间 事务A 事务B 1 开始事务 2 更新所有行的quantity为100 3 开始事务 4 插入一行quantity为5 5 提交事务 6 查询所有行的quantity 7 提交事务 当一个事务内更新所有行后，另一个事务插入了新行，当再次查看记录时，发现有未更新的记录，好像幻觉一样\n丢失更新 第一种情况：\n时间 事务A 事务B 1 开始事务 2 查询到quantity为10 3 开始事务 4 查询到quantity为10 5 更新quantity为11 6 提交事务 7 更新quantity为9 8 事务回滚，quantity为10 可以看到，回滚的事务把正常事务的数据覆盖了，正常事务的数据丢失了\n第二种情况：\n时间 事务A 事务B 1 开始事务 2 查询到quantity为10 3 开始事务 4 查询到quantity为10 5 更新quantity为9 6 提交事务 7 更新quantity为11 8 提交事务 这种情况是事务在执行期间，其他事务对数据进行了修改，那么当前事务拿到的数据就是错的，对错的数据进行更新，那也就没有意义了\n解决方法 对于脏读、不可重复读、幻读 我们可以使用数据库提供的隔离级别来避免以上情况\n隔离级别 脏读 不可重复读 幻读 Read-Uncommitted(读取未提交的内容) √ √ √ Read-Committed(读取已提交的内容) × √ √ Repeatable-Read(可重读) × × √ Serializable(串行化) × × × Mysql的默认隔离级别为Repeatable-Read,可以通过以下命令查看\nSELECT @@global.tx_isolation;--查看全局隔离级别 SELECT @@session.tx_isolation;--查看当前连接的隔离级别 修改隔离级别\nSET @@global.tx_isolation=\u0026#39;Read-Committed\u0026#39; SET @@session.tx_isolation=\u0026#39;Read-Committed\u0026#39; --或 SET GLOBAL TRANSACTION ISOLATION LEVEL SERIALIZABLE 对于丢失更新 使用悲观锁 悲观锁主要有共享锁（读锁）和排他锁（写锁）\n共享锁是指多个事务可以共享一个一把锁，都可以读取到数据，但是不能修改 排他锁就是一个事务获得了排他锁，那么其他事务就不能获得锁（包括共享锁和排他锁），获取排他锁的事务可以对数据进行访问和修改 Mysql默认开启了自动事务提交，可以使用以下命令关闭\nSET autocommit=0\t--关闭自动事务提交 这里必须要强调一下锁的概念，不管是共享锁还是排他锁，都是我们给每一个数据元素加的，如果一个数据元素已经有了排他锁，那么久不能再给它加任何锁，如果一个数据元素有共享锁，那么还可以给它加共享锁，Mysql的InnoDB引擎默认给insert、update、delete都加了排他锁，而select未加任何锁\n新建一个查询窗口，开始事务，但是没有提交，因为update默认给数据元素加排他锁，所以这个时候我们去更新该数据元素就会出现\n上一个事务还没有提交，数据元素还有排他锁，这个update语句要给数据元素加排他锁，所以只有等待，这也验证了update语句默认会给相关的数据元素加排他锁\n如果使用select语句加共享锁进行查询一样会阻塞\n但是使用select语句不加任何锁是可以查出数据的，但是数据是更新之前的\n所以，使用悲观锁在高并发情况下，对于减库存这样的操作，首先要使用排他锁的select语句拿到库存，如果已经有事务对这个数据元素上了锁，那么只有等待该事务释放锁，只有这样拿到的库存才是正确的\nBEGIN; DECLARE @now_quantity INT; SELECT quantity INTO @now_quantity FROM item WHERE id=1 FOR UPDATE;//一定要加排他锁 UPDATE item SET quantity=@now_quantity-1 WHERE id=1; COMMIT; 而且需要注意，MySQL InnoDB默认行级锁。行级锁都是基于索引的，如果一条SQL语句用不到索引是不会使用行级锁的，会使用表级锁把整张表锁住\n使用悲观锁的方式解决丢失更新很简单，但是也会带来效率上的问题，如果一个事务上了锁，那么其他的都只有等待\n使用乐观锁 我们可以给表中加上一个version自增的版本字段，查询的时候拿到版本字段和库存，当需要去更新的时候，如果版本不一致，那么需要重新查询，重复上述步骤，知道拿到的版本和数据库中的版本一致时，才进行更新，这样就不需要等待，效率更高\n","permalink":"https://moyuduo.github.io/posts/%E6%95%B0%E6%8D%AE%E5%BA%93%E9%9A%94%E7%A6%BB%E7%BA%A7%E5%88%AB/","summary":"数据库隔离级别 如果没有隔离级别会出现的问题 脏读 意思是读取到了事务正在修改的数据，如果事务回滚，那么拿到的数据就是错误的\n时间 事务A 事务B 1 开始事务 2 读取quantity为5 3 修改quantity为4 4 开始事务 5 读取到quantity为4 6 发生错误，回滚，quantity为5 7 提交事务 在按照正常逻辑quantity应该为5\n不可重复读 时间 事务A 事务B 1 开始事务 2 读取quantity为5 3 开始事务 4 修改quantity为4 5 提交事务 6 读取quantity为4 7 提交事务 在同一个事务内，两次读取同一个数据产生不一致\n幻读 时间 事务A 事务B 1 开始事务 2 更新所有行的quantity为100 3 开始事务 4 插入一行quantity为5 5 提交事务 6 查询所有行的quantity 7 提交事务 当一个事务内更新所有行后，另一个事务插入了新行，当再次查看记录时，发现有未更新的记录，好像幻觉一样\n丢失更新 第一种情况：\n时间 事务A 事务B 1 开始事务 2 查询到quantity为10 3 开始事务 4 查询到quantity为10 5 更新quantity为11 6 提交事务 7 更新quantity为9 8 事务回滚，quantity为10 可以看到，回滚的事务把正常事务的数据覆盖了，正常事务的数据丢失了","title":"数据库隔离级别"},{"content":"经典数据结构和算法 目录 两种数据结构\n线性结构 非线性结构 稀疏数组\n队列\n链表\n介绍 单链表 双链表 单向循环链表 栈\n介绍 中缀表达式 逆波兰表达式 中缀表达式转后缀表达式 递归\n介绍 迷宫问题 回溯算法 排序算法\n介绍 冒泡排序 选择排序 插入排序 希尔排序 快速排序 归并排序 基数排序 排序算法的比较 查找算法\n介绍 二分查找 插值查找 斐波拉契查找 哈希表\n介绍 应用 树\n二叉树 介绍 二叉树三种遍历方式 查找指定节点 删除节点 顺序存储二叉树 介绍 遍历 线索化二叉树 介绍 遍历 树的应用\n堆排序 哈夫曼树 哈夫曼编码 二叉排序树 平衡二叉树AVL树 图\n介绍 图的临接矩阵表示法 图的临接表表示法 图的深度优先遍历 图的广度优先遍历 深度优先和广度优先的比较 算法\n分治算法 动态规划 KMP算法 贪心算法 普利姆算法 克鲁斯卡尔算法 迪杰斯特拉算法 弗洛伊德算法 1. 两种数据结构 线性数据结构 线性数据结构是最常用的数据结构，特点是数据元素之间存在一一对应的线性关系。\n线性结构具有顺序存储和链式存储两种存储方式。\n非线性数据结构 非线性数据结构包括：二维数组，多维数组，广义表，树结构，图结构。\n2. 稀疏数组 介绍 当我们在处理如五子棋这类棋盘问题时，只有棋盘中的黑子和白字位置对于我们来说是由具体意义的，当一个二维数组中的绝大多数值都是某一个值时，我们选定位默认值，我们可以使用稀疏数组来保存，以达到节约空间的目的\n处理过程 创建一个n+1行3列的二维数组（n为待压缩数组中不同于选定默认值的个数） 在第一行分别保存待压缩数组的行数、列数、n 对每一个不同于默认值的值按照行号、列号、值记录一行 把一个二维数组压缩为稀疏数组 public class SparseArray { public int[][] array2SparseArray(int[][] res){ int n=0; for(int i=0;i\u0026lt;res.length;i++) { for(int j=0;j\u0026lt;res[i].length;j++) { if(res[i][j]!=0) { n++; } } } int[][] tar=new int[n+1][3]; tar[0][0]=res.length; tar[0][1]=res[0].length; tar[0][2]=n; int row=1; for(int i=0;i\u0026lt;res.length;i++) { for(int j=0;j\u0026lt;res[i].length;j++) { if(res[i][j]!=0) { tar[row][0]=i; tar[row][1]=j; tar[row][2]=res[i][j]; row++; } } } return tar; } public static void main(String[] args) { int[][] res=new int[4][5]; res[1][2]=1; res[0][3]=2; res[2][0]=1; res[2][2]=1; SparseArray sa=new SparseArray(); sa.print(res); int[][] tar = sa.array2SparseArray(res); sa.print(tar); } public void print(int[][] res) { for(int i=0;i\u0026lt;res.length;i++) { for(int j=0;j\u0026lt;res[i].length;j++) { System.out.print(res[i][j]+\u0026#34; \u0026#34;); } System.out.println(); } } } 输出： 0 0 0 2 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 4 5 4 0 3 2 1 2 1 2 0 1 2 2 1 把稀疏数组还原 public class SparseArray { public int[][] array2SparseArray(int[][] res){ int n=0; for(int i=0;i\u0026lt;res.length;i++) { for(int j=0;j\u0026lt;res[i].length;j++) { if(res[i][j]!=0) { n++; } } } int[][] tar=new int[n+1][3]; tar[0][0]=res.length; tar[0][1]=res[0].length; tar[0][2]=n; int row=1; for(int i=0;i\u0026lt;res.length;i++) { for(int j=0;j\u0026lt;res[i].length;j++) { if(res[i][j]!=0) { tar[row][0]=i; tar[row][1]=j; tar[row][2]=res[i][j]; row++; } } } return tar; } public int[][] sparseArray2Array(int[][] res){ int rows=res[0][0]; int cols=res[0][1]; int n=res[0][2]; int[][] tar=new int[rows][cols]; for(int i=1;i\u0026lt;=n;i++) { int row=res[i][0]; int col=res[i][1]; int val=res[i][2]; tar[row][col]=val; } return tar; } public static void main(String[] args) { int[][] res=new int[4][5]; res[1][2]=1; res[0][3]=2; res[2][0]=1; res[2][2]=1; SparseArray sa=new SparseArray(); sa.print(res); int[][] tar = sa.array2SparseArray(res); sa.print(tar); int[][] res2 = sa.sparseArray2Array(tar); sa.print(res2); } public void print(int[][] res) { for(int i=0;i\u0026lt;res.length;i++) { for(int j=0;j\u0026lt;res[i].length;j++) { System.out.print(res[i][j]+\u0026#34; \u0026#34;); } System.out.println(); } } } 输出： 0 0 0 2 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 4 5 4 0 3 2 1 2 1 2 0 1 2 2 1 0 0 0 2 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 3.队列 队列是用数组或链表实现的，遵循先进先出规则的一个有序列表\n使用数组模拟队列 public class ArrayQueue\u0026lt;T\u0026gt; { private Object[] arr; private int front; private int rear; private int capacity; public ArrayQueue() { this.capacity=10; this.front=-1; this.rear=-1; this.arr=new Object[this.capacity]; } public ArrayQueue(int capacity) { this.capacity=capacity; this.front=-1; this.rear=-1; this.arr=new Object[this.capacity]; } public boolean add(T t) { if(this.rear\u0026lt;this.capacity-1) { this.arr[++rear]=t; return true; } throw new RuntimeException(\u0026#34;队列已满！\u0026#34;); } public T remove() { if(this.rear==this.front) { throw new RuntimeException(\u0026#34;队列为空，不能出队列！\u0026#34;); } return (T)this.arr[++front]; } public T poll() { if(this.rear==this.front) { return null; } return (T)this.arr[++front]; } public T peek() { if(this.rear==this.front) { return null; } return (T)this.arr[++front]; } @Override public String toString() { String str= \u0026#34;ArrayQueue [\u0026#34;; for(int i=front+1;i\u0026lt;=rear;i++) { str+=this.arr[i]+\u0026#34; \u0026#34;; } return str+=\u0026#34;]\u0026#34;; } public static void main(String[] args) { ArrayQueue\u0026lt;Integer\u0026gt; queue=new ArrayQueue\u0026lt;\u0026gt;(4); queue.add(1); queue.add(2); queue.add(3); queue.add(4); System.out.println(queue); Integer remove1 = queue.remove(); System.out.println(remove1); Integer remove2 = queue.remove(); System.out.println(remove2); Integer remove3 = queue.remove(); System.out.println(remove3); Integer remove4 = queue.remove(); System.out.println(remove4); queue.add(5); } } 输出： ArrayQueue [1 2 3 4 ] 1 2 3 4 Exception in thread \u0026#34;main\u0026#34; java.lang.RuntimeException: 队列已满！ 分析：虽然队列中的元素已经全部出队，但是由于我们的队列是使用数组模拟的，而且每次入队的时候，头指定都后移，当我们入队次数增加，总有一时刻，头指针指向数组最大下标，尽管我们有出队，但是任然不能入队元素，我们可以使用数组模拟循环队列来解决这个问题\n使用数组模拟循环队列 分析 我们可以做这样一个约定，在数组中空一个位置，当**（rear+1）%capacity==front来表示队满，当front==rear**时表示队空\n这个时候，那么计算队列中元素个数公式为：size=(rear+capacity-front)%capacity\npublic class CircleArrayQueue\u0026lt;T\u0026gt; { private Object[] arr; private int front; private int rear; private int capacity; public CircleArrayQueue() { this.capacity=10; this.front=0; this.rear=0; this.arr=new Object[this.capacity]; } public CircleArrayQueue(int capacity) { this.capacity=capacity; this.front=0; this.rear=0; this.arr=new Object[this.capacity]; } public boolean add(T t) { if((rear+1)%capacity==front) {//队列已满 throw new RuntimeException(\u0026#34;队列已满！\u0026#34;); } //rear下标超出最大下标，那么取模 rear=(rear+1)%capacity; this.arr[rear]=t; return true; } public T remove() { if(this.rear==this.front) { throw new RuntimeException(\u0026#34;队列为空，不能出队列！\u0026#34;); } return (T)this.arr[++front]; } public T poll() { if(this.rear==this.front) { return null; } return (T)this.arr[++front]; } public T peek() { if(this.rear==this.front) { return null; } return (T)this.arr[++front]; } public int size() { return (rear+capacity-front)%capacity; } @Override public String toString() { String str= \u0026#34;ArrayQueue [\u0026#34;; int total=size(); int index=front+1; for(int i=0;i\u0026lt;total;i++) { str+=arr[index]+\u0026#34; \u0026#34;; index=(index+1)%capacity; } return str+=\u0026#34;]\u0026#34;; } public static void main(String[] args) { CircleArrayQueue\u0026lt;Integer\u0026gt; queue=new CircleArrayQueue\u0026lt;\u0026gt;(4); //由于需要空一个，capacity为4也只能存放三个元素 queue.add(1); queue.add(2); queue.add(3); System.out.println(queue); Integer remove = queue.remove(); System.out.println(remove); queue.add(4); System.out.println(queue); } } 输出： ArrayQueue [1 2 3 ] 1 ArrayQueue [2 3 4 ] 链队列 使用节点来包装值，好处是使用链表可以不用考虑大小的问题，队列永远不可能满\npublic class LinkedQueue\u0026lt;T\u0026gt; { static class Node\u0026lt;T\u0026gt;{ T val; Node next; public Node(T val, Node next) { super(); this.val = val; this.next = next; } public Node(T val) { this.val=val; } } private int size; private Node\u0026lt;T\u0026gt; front; private Node\u0026lt;T\u0026gt; rear; public LinkedQueue() { this.size=0; } public void add(T t) { Node\u0026lt;T\u0026gt; node=new Node\u0026lt;T\u0026gt;(t); this.size++; if(rear==null) { rear=node; front=node; } rear.next=node; rear=node; } public T remove() { if(size\u0026lt;=0) { throw new RuntimeException(\u0026#34;队列为空,不能出队！\u0026#34;); } size--; Node\u0026lt;T\u0026gt; n=front; if(size==0) { front=null; rear=null; return n.val; } front=front.next; return n.val; } public T poll() { if(size\u0026lt;=0) { return null; } size--; Node\u0026lt;T\u0026gt; n=front; if(size==0) { front=null; rear=null; return n.val; } front=front.next; return n.val; } public T peek() { if(this.size\u0026lt;=0) { return null; } return front.val; } public int size() { return size; } @Override public String toString() { String str= \u0026#34;LinkedQueue [\u0026#34;; Node\u0026lt;T\u0026gt; n=front; while(n!=null) { str+=n.val+\u0026#34; \u0026#34;; n=n.next; } str+=\u0026#34;]\u0026#34;; return str; } public static void main(String[] args) { LinkedQueue\u0026lt;Integer\u0026gt; queue =new LinkedQueue\u0026lt;\u0026gt;(); queue.add(1); queue.add(2); queue.add(3); System.out.println(queue); Integer remove1 = queue.remove(); System.out.println(remove1); Integer remove2 = queue.remove(); System.out.println(remove2); Integer remove3 = queue.remove(); System.out.println(remove3); queue.remove(); } } 输出： LinkedQueue [1 2 3 ] 1 2 3 Exception in thread \u0026#34;main\u0026#34; java.lang.RuntimeException: 队列为空,不能出队！ 4.链表 链表是一个以节点存储的有序列表，每个节点包括data域和next域，data域是用来保存值的，next域是保存下一个节点的地址，根据有无头节点，链表可分为带头节点的链表和不带头节点的链表\n单链表 不带头节点的单链表 public class SingleLinkedList\u0026lt;E\u0026gt; { static class Node\u0026lt;E\u0026gt;{ E data; Node\u0026lt;E\u0026gt; next; public Node(E e) { this.data=e; } } private Node\u0026lt;E\u0026gt; head; public SingleLinkedList() { } //向链表这中添加数据 public void add(E e) { Node\u0026lt;E\u0026gt; node=new Node(e); if(head==null) { head=node; return; } Node\u0026lt;E\u0026gt; t=head; head=node; head.next=t; } //从链表中查找数据，使用equals判断两个对象是否相等 public E search(E e) { Node\u0026lt;E\u0026gt; node=head; while(node!=null) { if(e.equals(node.data)) { return node.data; } node=node.next; } return null; } //从链表中删除数据，使用equals判断是否相等 public E delete(E e) { if(head==null) { return null; } Node\u0026lt;E\u0026gt; node=head; //如果头节点就是要删除的数据 if(e.equals(head.data)) { head=node.next; return node.data; } //遍历找到要删除的数据 while(node.next!=null) { if(e.equals(node.next.data)) { E val=node.next.data; node.next=node.next.next; return val; } node=node.next; } return null; } @Override public String toString() { String str= \u0026#34;SingleLinkedList [\u0026#34;; Node\u0026lt;E\u0026gt; node=head; while(node!=null) { str+=node.data.toString()+\u0026#34;,\u0026#34;; node=node.next; } if(head!=null) { str=str.substring(0, str.length()-1); } return str+\u0026#34;]\u0026#34;; } public static void main(String[] args) { SingleLinkedList\u0026lt;Stu\u0026gt; list=new SingleLinkedList\u0026lt;\u0026gt;(); list.add(new Stu(1,\u0026#34;张三\u0026#34;,20)); list.add(new Stu(2,\u0026#34;李四\u0026#34;,21)); list.add(new Stu(3,\u0026#34;王五\u0026#34;,22)); System.out.println(list); Stu query=new Stu(2); Stu search = list.search(query); System.out.println(search); list.delete(new Stu(2)); System.out.println(list); list.delete(new Stu(1)); System.out.println(list); list.delete(new Stu(3)); System.out.println(list); } } class Stu{ private Integer idcard; private String name; private Integer age; public Stu(Integer idcard) { super(); this.idcard = idcard; } public Stu(Integer idcard, String name, Integer age) { super(); this.idcard = idcard; this.name = name; this.age = age; } public Integer getIdcard() { return idcard; } public void setIdcard(Integer idcard) { this.idcard = idcard; } public String getName() { return name; } public void setName(String name) { this.name = name; } public Integer getAge() { return age; } public void setAge(Integer age) { this.age = age; } @Override public String toString() { return \u0026#34;Stu [idcard=\u0026#34; + idcard + \u0026#34;, name=\u0026#34; + name + \u0026#34;, age=\u0026#34; + age + \u0026#34;]\u0026#34;; } @Override public boolean equals(Object obj) { if(obj==null) { return false; } if(obj instanceof Stu) { Stu o=(Stu)obj; return this.idcard==o.idcard; } return false; } } 输出： SingleLinkedList [Stu [idcard=3, name=王五, age=22],Stu [idcard=2, name=李四, age=21],Stu [idcard=1, name=张三, age=20]] Stu [idcard=2, name=李四, age=21] SingleLinkedList [Stu [idcard=3, name=王五, age=22],Stu [idcard=1, name=张三, age=20]] SingleLinkedList [Stu [idcard=3, name=王五, age=22]] SingleLinkedList [] 带头节点的单链表 public class SingleLinkedList2\u0026lt;E\u0026gt; { static class Node\u0026lt;E\u0026gt;{ E data; Node\u0026lt;E\u0026gt; next; public Node(E e) { this.data=e; } public Node() {} } private Node\u0026lt;E\u0026gt; head; public SingleLinkedList2() { head=new Node\u0026lt;E\u0026gt;(); } //向链表这中添加数据 public void add(E e) { Node\u0026lt;E\u0026gt; newNode=new Node\u0026lt;E\u0026gt;(e); newNode.next=head.next; head.next=newNode; } //从链表中查找数据，使用equals判断两个对象是否相等 public E search(E e) { Node\u0026lt;E\u0026gt; node=head.next; while(node!=null) { if(e.equals(node.data)) { return node.data; } node=node.next; } return null; } //从链表中删除数据，使用equals判断是否相等 public E delete(E e) { //使用pre来保存要删除节点的前一个节点，以便在删除时断链 Node\u0026lt;E\u0026gt; pre=head; while(pre.next!=null) { if(e.equals(pre.next.data)) { E val=pre.next.data; pre.next=pre.next.next; return val; } pre=pre.next; } return null; } @Override public String toString() { String str= \u0026#34;SingleLinkedList2 [\u0026#34;; Node\u0026lt;E\u0026gt; node=head.next; while(node!=null) { str+=node.data.toString()+\u0026#34;,\u0026#34;; node=node.next; } if(head.next!=null) { str=str.substring(0, str.length()-1); } return str+\u0026#34;]\u0026#34;; } public static void main(String[] args) { SingleLinkedList2\u0026lt;Stu2\u0026gt; list=new SingleLinkedList2\u0026lt;\u0026gt;(); list.add(new Stu2(1,\u0026#34;张三\u0026#34;,20)); list.add(new Stu2(2,\u0026#34;李四\u0026#34;,21)); list.add(new Stu2(3,\u0026#34;王五\u0026#34;,22)); System.out.println(list); Stu2 query=new Stu2(2); Stu2 search = list.search(query); System.out.println(search); list.delete(new Stu2(2)); System.out.println(list); list.delete(new Stu2(1)); System.out.println(list); list.delete(new Stu2(3)); System.out.println(list); } } class Stu2{ private Integer idcard; private String name; private Integer age; public Stu2(Integer idcard) { super(); this.idcard = idcard; } public Stu2(Integer idcard, String name, Integer age) { super(); this.idcard = idcard; this.name = name; this.age = age; } public Integer getIdcard() { return idcard; } public void setIdcard(Integer idcard) { this.idcard = idcard; } public String getName() { return name; } public void setName(String name) { this.name = name; } public Integer getAge() { return age; } public void setAge(Integer age) { this.age = age; } @Override public String toString() { return \u0026#34;Stu2 [idcard=\u0026#34; + idcard + \u0026#34;, name=\u0026#34; + name + \u0026#34;, age=\u0026#34; + age + \u0026#34;]\u0026#34;; } @Override public boolean equals(Object obj) { if(obj==null) { return false; } if(obj instanceof Stu2) { Stu2 o=(Stu2)obj; return this.idcard==o.idcard; } return false; } } 输出： SingleLinkedList2 [Stu2 [idcard=3, name=王五, age=22],Stu2 [idcard=2, name=李四, age=21],Stu2 [idcard=1, name=张三, age=20]] Stu2 [idcard=2, name=李四, age=21] SingleLinkedList2 [Stu2 [idcard=3, name=王五, age=22],Stu2 [idcard=1, name=张三, age=20]] SingleLinkedList2 [Stu2 [idcard=3, name=王五, age=22]] SingleLinkedList2 [] 双链表 分析为什么要双链表 单链表每个节点只保存了后继节点，只能单向遍历，使用双链表可以双向遍历 单链表在删除时需要找到删除节点的前一个节点，然后删除，双链表可以实现自删除 不带头节点的双链表 public class DoubleLinkedList\u0026lt;E\u0026gt; { static class Node\u0026lt;E\u0026gt;{ E data; Node\u0026lt;E\u0026gt; pre; Node\u0026lt;E\u0026gt; next; public Node(E e) { this.data=e; } } private Node\u0026lt;E\u0026gt; head; public DoubleLinkedList() { } //头插法向链表这中添加数据 public void add(E e) { Node\u0026lt;E\u0026gt; newNode=new Node\u0026lt;E\u0026gt;(e); if(head==null) { head=newNode; return; } //新节点的next指向head newNode.next=head; //head的pre更新为新节点 head.pre=newNode; //把head指向添加的新节点 head=newNode; } //从链表中查找数据，使用equals判断两个对象是否相等 public E search(E e) { Node\u0026lt;E\u0026gt; node=head; while(node!=null) { if(e.equals(node.data)) { return node.data; } node=node.next; } return null; } //从链表中删除数据，使用equals判断是否相等 public E delete(E e) { Node\u0026lt;E\u0026gt; node=head; while(node!=null) { if(e.equals(node.data)) {//找到要删除的节点 if(node.pre==null\u0026amp;\u0026amp;node.next==null) {//如果链表只有一个节点且为删除节点 head=null; return node.data; } if(node.pre==null) {//如果链表不止一个节点，且删除节点是头节点 head=head.next; head.pre=null; return node.data; } if(node.next==null) {//如果链表不止一个节点，且删除节点是尾节点 node.pre.next=null; return node.data; } //删除中间节点 node.pre.next=node.next; node.next.pre=node.pre; return node.data; } node=node.next; } return null; } @Override public String toString() { String str= \u0026#34;DoubleLinkedList [\u0026#34;; Node\u0026lt;E\u0026gt; node=head; while(node!=null) { str+=node.data+\u0026#34;,\u0026#34;; node=node.next; } if(head!=null) { str=str.substring(0,str.length()-1); } return str+\u0026#34;]\u0026#34;; } public static void main(String[] args) { DoubleLinkedList\u0026lt;Stu\u0026gt; list=new DoubleLinkedList\u0026lt;\u0026gt;(); list.add(new Stu(1,\u0026#34;张三\u0026#34;,20)); list.add(new Stu(2,\u0026#34;李四\u0026#34;,21)); list.add(new Stu(3,\u0026#34;王五\u0026#34;,22)); System.out.println(list); Stu query=new Stu(2); Stu search = list.search(query); System.out.println(search); list.delete(new Stu(2)); System.out.println(list); list.delete(new Stu(1)); System.out.println(list); list.delete(new Stu(3)); System.out.println(list); } } 输出： DoubleLinkedList [Stu [idcard=3, name=王五, age=22],Stu [idcard=2, name=李四, age=21],Stu [idcard=1, name=张三, age=20]] Stu [idcard=2, name=李四, age=21] DoubleLinkedList [Stu [idcard=3, name=王五, age=22],Stu [idcard=1, name=张三, age=20]] DoubleLinkedList [Stu [idcard=3, name=王五, age=22]] DoubleLinkedList [] 带头节点的双链表 public class DoubleLinkedList\u0026lt;E\u0026gt; { static class Node\u0026lt;E\u0026gt;{ E data; Node\u0026lt;E\u0026gt; pre; Node\u0026lt;E\u0026gt; next; public Node(E e) { this.data=e; } } private Node\u0026lt;E\u0026gt; head; public DoubleLinkedList() { } //头插法向链表这中添加数据 public void add(E e) { Node\u0026lt;E\u0026gt; newNode=new Node\u0026lt;E\u0026gt;(e); if(head==null) { head=newNode; return; } //新节点的next指向head newNode.next=head; //head的pre更新为新节点 head.pre=newNode; //把head指向添加的新节点 head=newNode; } //从链表中查找数据，使用equals判断两个对象是否相等 public E search(E e) { Node\u0026lt;E\u0026gt; node=head; while(node!=null) { if(e.equals(node.data)) { return node.data; } node=node.next; } return null; } //从链表中删除数据，使用equals判断是否相等 public E delete(E e) { Node\u0026lt;E\u0026gt; node=head; while(node!=null) { if(e.equals(node.data)) {//找到要删除的节点 if(node.pre==null\u0026amp;\u0026amp;node.next==null) {//如果链表只有一个节点且为删除节点 head=null; return node.data; } if(node.pre==null) {//如果链表不止一个节点，且删除节点是头节点 head=head.next; head.pre=null; return node.data; } if(node.next==null) {//如果链表不止一个节点，且删除节点是尾节点 node.pre.next=null; return node.data; } //删除中间节点 node.pre.next=node.next; node.next.pre=node.pre; return node.data; } node=node.next; } return null; } @Override public String toString() { String str= \u0026#34;DoubleLinkedList [\u0026#34;; Node\u0026lt;E\u0026gt; node=head; while(node!=null) { str+=node.data+\u0026#34;,\u0026#34;; node=node.next; } if(head!=null) { str=str.substring(0,str.length()-1); } return str+\u0026#34;]\u0026#34;; } public static void main(String[] args) { DoubleLinkedList\u0026lt;Stu\u0026gt; list=new DoubleLinkedList\u0026lt;\u0026gt;(); list.add(new Stu(1,\u0026#34;张三\u0026#34;,20)); list.add(new Stu(2,\u0026#34;李四\u0026#34;,21)); list.add(new Stu(3,\u0026#34;王五\u0026#34;,22)); System.out.println(list); Stu query=new Stu(2); Stu search = list.search(query); System.out.println(search); list.delete(new Stu(2)); System.out.println(list); list.delete(new Stu(1)); System.out.println(list); list.delete(new Stu(3)); System.out.println(list); } } 输出： DoubleLinkedList [Stu [idcard=3, name=王五, age=22],Stu [idcard=2, name=李四, age=21],Stu [idcard=1, name=张三, age=20]] Stu [idcard=2, name=李四, age=21] DoubleLinkedList [Stu [idcard=3, name=王五, age=22],Stu [idcard=1, name=张三, age=20]] DoubleLinkedList [Stu [idcard=3, name=王五, age=22]] DoubleLinkedList [] ","permalink":"https://moyuduo.github.io/posts/%E7%BB%8F%E5%85%B8%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E7%AE%97%E6%B3%95/","summary":"经典数据结构和算法 目录 两种数据结构\n线性结构 非线性结构 稀疏数组\n队列\n链表\n介绍 单链表 双链表 单向循环链表 栈\n介绍 中缀表达式 逆波兰表达式 中缀表达式转后缀表达式 递归\n介绍 迷宫问题 回溯算法 排序算法\n介绍 冒泡排序 选择排序 插入排序 希尔排序 快速排序 归并排序 基数排序 排序算法的比较 查找算法\n介绍 二分查找 插值查找 斐波拉契查找 哈希表\n介绍 应用 树\n二叉树 介绍 二叉树三种遍历方式 查找指定节点 删除节点 顺序存储二叉树 介绍 遍历 线索化二叉树 介绍 遍历 树的应用\n堆排序 哈夫曼树 哈夫曼编码 二叉排序树 平衡二叉树AVL树 图\n介绍 图的临接矩阵表示法 图的临接表表示法 图的深度优先遍历 图的广度优先遍历 深度优先和广度优先的比较 算法\n分治算法 动态规划 KMP算法 贪心算法 普利姆算法 克鲁斯卡尔算法 迪杰斯特拉算法 弗洛伊德算法 1.","title":"数据结构和算法"},{"content":"面试题答案 ==可以用来比较基本数据类型和引用数据类型，当比较基本数据类型时，比较的是值，比较引用数据类型时，比较的是对象的地址。equals是Object定义的方法，默认比较的是对象的地址，编写类时重写equals方法，逻辑上相等的对象调用equals应该为true。\nequals是Object的方法，默认比较的是对象地址，重写用来判断对象是否相等。hashCode也是Object的方法，是用来生成散列码的函数，默认返回的是对象地址。当不使用散列集合存储对象时，可以只重写equals，当需要使用散列集合存储对象时，一定要重写equals和hashCode，因为散列集合底层是通过hashCode生成的hash计算存储下标，使用equals判断对象是否相等。\n首先31这个数是一个素数，即只能被1和自身整除，那么当计算hash时，就能减少hash碰撞的次数，其次任何n*31可以被JVM转换为(n\u0026laquo;5)-n只有移位和减法的操作，速度更快。\n输出的结果是： false false false ============== false true true 当使用new关键字创建字符串时，首先会去对空间创建对象，然后去字符串常量池中找有没有该字符串，如果有就把堆空间对象指向字符串常量池中对象，如果没有，就在字符串常量池中添加该字符串常量，然后把堆空间对象指向字符串常量，所以，使用new方法的变量实际是指向堆空间地址。而使用=“abc”这种方式是直接去字符创常量池中找有没有该字符串常量，没有就加入，然后变量指向字符串常量池中对象。\nString类的intern方法是获取字符串常量池中的对象，即如果是=“abc”这种方式就直接可以去到对象，如果是new出来的，那么会通过栈然后拿到常量池中的对象。\n输出： true false false 任何字符串变量类型和变量类型（s5+s6）或和常量类型（\u0026ldquo;ja\u0026rdquo;+s6）操作，都会在堆空间生成对象，然后执行常量池。所以不推荐使用String s=s1+\u0026ldquo;hello\u0026rdquo;；这样的方法式来生成字符串，会消耗堆内存，推荐使用StringBuilder的append方法进行字符串拼接。\n10 10 jack abc 可以简单的理解为java中8种基本数据类型及其包装类型和String是引用传值，所以这里只有change3是引用传值方法。但是实际上java使用的是值传递。\nFather Static代码块 Son Static代码块 Father普通代码块 Father构造器 Son普通代码块 Son构造器 Father普通代码块 Father构造器 Father普通代码块 Father构造器 Son普通代码块 Son构造器 类的加载顺序为从父类到子类，先加载器静态代码块，且静态代码块只加载一次，然后后父类到子类，加载普通代码块和构造器，普通代码块先于构造器\n负载因子是用来计算阈值的，可以指定，负载因子的设计是用来减少hash碰撞的次数的，如果HashMap元素个数要达到数组大小才扩容的话，可能会造成链表的长度过长，查询效率低。\n阈值是判断HashMap扩容的条件，是通过capacity*loadFactor计算得到的，当HashMap中节点的个数达到阈值就要进行扩容。\nHashMap的默认容量是16，默认负载因子是0.75\nHashMap在put的时候会根据key的hashCode计算一个hash值，并通过这个hash值计算存储下标，如果数组 的下标位置为空，就直接添加，如果不空的话，该节点的next可能是链表或红黑树，如果是链表通过为插法添加，是红黑树就按照红黑树的规则添加，添加完元素后如果size到达阈值，那么进行扩容。\nget的时候也是通过key的hashCode计算hash值在计算下标，然后进行判断，共有三种情况：①数组下标元素就是查找的节点②数组下标节点是next是链表，那么遍历链表查找③数组下标节点是next是红黑树，那么按照红黑树规则查找。\nresize方法会把数组的容量扩大为原容量的二倍，然后把所有的元素进行重新计算元素下标进行添加，这个过程也是使用的尾插法，所以节点添加的相对顺序不会变。\n","permalink":"https://moyuduo.github.io/posts/%E7%AC%94%E8%AF%95%E9%A2%98%E7%AD%94%E6%A1%88/","summary":"面试题答案 ==可以用来比较基本数据类型和引用数据类型，当比较基本数据类型时，比较的是值，比较引用数据类型时，比较的是对象的地址。equals是Object定义的方法，默认比较的是对象的地址，编写类时重写equals方法，逻辑上相等的对象调用equals应该为true。\nequals是Object的方法，默认比较的是对象地址，重写用来判断对象是否相等。hashCode也是Object的方法，是用来生成散列码的函数，默认返回的是对象地址。当不使用散列集合存储对象时，可以只重写equals，当需要使用散列集合存储对象时，一定要重写equals和hashCode，因为散列集合底层是通过hashCode生成的hash计算存储下标，使用equals判断对象是否相等。\n首先31这个数是一个素数，即只能被1和自身整除，那么当计算hash时，就能减少hash碰撞的次数，其次任何n*31可以被JVM转换为(n\u0026laquo;5)-n只有移位和减法的操作，速度更快。\n输出的结果是： false false false ============== false true true 当使用new关键字创建字符串时，首先会去对空间创建对象，然后去字符串常量池中找有没有该字符串，如果有就把堆空间对象指向字符串常量池中对象，如果没有，就在字符串常量池中添加该字符串常量，然后把堆空间对象指向字符串常量，所以，使用new方法的变量实际是指向堆空间地址。而使用=“abc”这种方式是直接去字符创常量池中找有没有该字符串常量，没有就加入，然后变量指向字符串常量池中对象。\nString类的intern方法是获取字符串常量池中的对象，即如果是=“abc”这种方式就直接可以去到对象，如果是new出来的，那么会通过栈然后拿到常量池中的对象。\n输出： true false false 任何字符串变量类型和变量类型（s5+s6）或和常量类型（\u0026ldquo;ja\u0026rdquo;+s6）操作，都会在堆空间生成对象，然后执行常量池。所以不推荐使用String s=s1+\u0026ldquo;hello\u0026rdquo;；这样的方法式来生成字符串，会消耗堆内存，推荐使用StringBuilder的append方法进行字符串拼接。\n10 10 jack abc 可以简单的理解为java中8种基本数据类型及其包装类型和String是引用传值，所以这里只有change3是引用传值方法。但是实际上java使用的是值传递。\nFather Static代码块 Son Static代码块 Father普通代码块 Father构造器 Son普通代码块 Son构造器 Father普通代码块 Father构造器 Father普通代码块 Father构造器 Son普通代码块 Son构造器 类的加载顺序为从父类到子类，先加载器静态代码块，且静态代码块只加载一次，然后后父类到子类，加载普通代码块和构造器，普通代码块先于构造器\n负载因子是用来计算阈值的，可以指定，负载因子的设计是用来减少hash碰撞的次数的，如果HashMap元素个数要达到数组大小才扩容的话，可能会造成链表的长度过长，查询效率低。\n阈值是判断HashMap扩容的条件，是通过capacity*loadFactor计算得到的，当HashMap中节点的个数达到阈值就要进行扩容。\nHashMap的默认容量是16，默认负载因子是0.75\nHashMap在put的时候会根据key的hashCode计算一个hash值，并通过这个hash值计算存储下标，如果数组 的下标位置为空，就直接添加，如果不空的话，该节点的next可能是链表或红黑树，如果是链表通过为插法添加，是红黑树就按照红黑树的规则添加，添加完元素后如果size到达阈值，那么进行扩容。\nget的时候也是通过key的hashCode计算hash值在计算下标，然后进行判断，共有三种情况：①数组下标元素就是查找的节点②数组下标节点是next是链表，那么遍历链表查找③数组下标节点是next是红黑树，那么按照红黑树规则查找。\nresize方法会把数组的容量扩大为原容量的二倍，然后把所有的元素进行重新计算元素下标进行添加，这个过程也是使用的尾插法，所以节点添加的相对顺序不会变。","title":"笔试题"},{"content":"TCP/IP协议 模型图：\n三次握手 客户端向服务器发送一个包，请求建立连接 服务器接受到这个包，同意建立连接的请求，返回一个包给客户端表示服务器同意建立连接 客户端接受到这个同意建立连接的包，但是客户端得告诉服务器它收到了这个包，再次回复个确认包 四次挥手 客户端告诉服务器我不传输数据了，请求关闭连接 服务器接收到这个包，会一个包告诉客户端表示收到了断开连接的请求，由于客户端可能还有往客户端传输的数据没传完，所以此时不能断开连接 服务器端往客户端传输的数据传完了，此时可以断开连接，服务器端发送一个包给客户端告诉客户端我也数据传完了，可以断开连接 客户端接受到这个包后回复一个确认包，双方断开连接 Http协议 Http工作原理 HTTP协议定义Web客户端如何从Web服务器请求Web页面，以及服务器如何把Web页面传送给客户端。HTTP协议采用了请求/响应模型。客户端向服务器发送一个请求报文，请求报文包含请求的方法、URL、协议版本、请求头部和请求数据。服务器以一个状态行作为响应，响应的内容包括协议的版本、成功或者错误代码、服务器信息、响应头部和响应数据。\nHTTP 请求/响应的步骤：\n客户端连接到web服务器：一个Http客户端，通常是浏览器，与web服务器的Http端口（默认80）建立一个TCP套接字连接 发送HTTP请求：通过TCP套接字，客户端向web服务器发送一个文本的请求报文（请求行、请求头、空行、请求数据） 服务器接受请求返回Http响应：web服务器解析请求，定位请求资源，服务器将资源副本写到TCP套接字，由客户端读取，包括状态行、响应头、空行、响应数据。 释放TCP连接：若connection模式为close，则服务器主动关闭TCP连接；若connection模式为keepalive，则连接会保持一段时间，在该时间内可以继续接受请求。 客户端解析内容：客户端浏览器首先解析状态行，查看表明是否成功的状态码，然后解析每一个响应头，判断返回内容的格式（html、jpg、json）和字符集，然后客户端浏览器根据响应的规则渲染。 请求 请求行 请求行又分为三部分\n请求方法 GET POST PUT DELETE HEAD:和GET方法基本一致，只是不返回内容 TRACE：使用代理上网访问网站，你想看看代理有没有修改你的HTTp请求 OPTIONS：返回服务器可用的请求方法 请求路径 /\t根路径\n所用协议 HTTP/1.1\n请求头信息 key：value\nReferer防盗链 在Http协议中，头信息有一个重要的选项：Referer，这个选项指明是请求是从哪儿网站过来的\n如何实现防盗链？\n原理：在web服务器层面，根据Http协议的referer头信息，判断请求来自于哪个网站，如果是站外请求，重写到另一个url\n请求主体信息 主体信息内容是可选的。为发送的内容。\n响应 响应行 响应行由协议、状态码、状态文字三部分组成。\n状态码：\n状态码 定义 说明 1xx 信息 接受到请求，继续处理 2xx 成功 操作成功 3xx 重定向 为了完成求情，必须采取进一步措施 4xx 客户端错误 请求语法有错误或请求不能满足 5xx 服务端错误 服务器无法完成请求 200\t服务器成功返回页面\n301/2\t永久/临时重定向\n304\tNot Modified\n307\t重定向中保护原有数据\n404\t请求的网页不存在\n500\t服务器内部错误\n响应头 响应主体 Http缓存 图片的下载往往是：\n第一次请求时200 ok\n第二次请求时304 Not Modified 未修改\n解释：\n在网络上有一些缓存服务器，浏览器自身也具有缓存功能，当我们第一次请求某个图片，返回200，基于图片不会频繁修改这样一个前提，服务器在返回200时，同时会返回该图片的“签名”Etag，当浏览器再次访问该图片时，会校验这个“签名”Etag，如果图片没有发生变化，直接使用缓存中的图片，这样就减轻了服务器的负担\n第一次请求图片：\n请求头：\nHost: www.zzrbl.com User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:75.0) Gecko/20100101 Firefox/75.0 Accept: image/webp,/ Accept-Language: zh-CN,zh;q=0.8,zh-TW;q=0.7,zh-HK;q=0.5,en-US;q=0.3,en;q=0.2 Accept-Encoding: gzip, deflate Connection: keep-alive Referer: http://www.zzrbl.com/wordpress/\n响应头：\nHTTP/1.1 200 OK Date: Tue, 09 Jun 2020 23:32:33 GMT Server: Apache X-Frame-Options: SAMEORIGIN Vary: Cookie Last-Modified: Tue, 14 Apr 2020 02:09:55 GMT ETag: \u0026ldquo;258b6-5a336b218b5b2\u0026rdquo; Accept-Ranges: bytes Content-Length: 153782 Keep-Alive: timeout=5, max=99 Connection: Keep-Alive Content-Type: image/jpeg\n第二次请求图片：\n请求头：\nHost: www.zzrbl.com User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:75.0) Gecko/20100101 Firefox/75.0 Accept: image/webp,/ Accept-Language: zh-CN,zh;q=0.8,zh-TW;q=0.7,zh-HK;q=0.5,en-US;q=0.3,en;q=0.2 Accept-Encoding: gzip, deflate Connection: keep-alive Referer: http://www.zzrbl.com/wordpress/ If-Modified-Since: Tue, 14 Apr 2020 02:09:55 GMT If-None-Match: \u0026ldquo;258b6-5a336b218b5b2\u0026rdquo; Cache-Control: max-age=0\n响应头：\nHTTP/1.1 304 Not Modified Date: Tue, 09 Jun 2020 23:28:37 GMT Server: Apache Connection: Keep-Alive Keep-Alive: timeout=5, max=85 ETag: \u0026ldquo;258b6-5a336b218b5b2\u0026rdquo; Vary: Cookie\nHttp压缩 请求：\nHost: www.163.com User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:75.0) Gecko/20100101 Firefox/75.0 Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,/;q=0.8 Accept-Language: zh-CN,zh;q=0.8,zh-TW;q=0.7,zh-HK;q=0.5,en-US;q=0.3,en;q=0.2 Accept-Encoding: gzip, deflate, br Referer: http://www.163.com/ Connection: keep-alive Cookie: _ntes_nuid=0f8c8d6cb50a32bb51add4cab7248168; _antanalysis_s_id=1591832409086; ChannelCookieUserLoalIp=%E5%AE%9C%E5%AE%BE%7C%E5%9B%9B%E5%B7%9D; NTES_hp_textlink1=old; _ntes_nnid=2e787180750ae52da42b15e48908dcb8,1591832409923; NNSSPID=9e5a7a9797824ee9ab635a6f0cbb1935; neteaseAD120611channelcookies137851003711591693840220971=2; UM_distinctid=172a09b00a278-0fd029816d92f48-4c302e7f-144000-172a09b00a3120; CNZZDATA1254828714=1553223004-1591828245-null%7C1591828245 Upgrade-Insecure-Requests: 1 Cache-Control: max-age=0 TE: Trailers\n响应：\nHTTP/2 200 OK date: Wed, 10 Jun 2020 23:40:38 GMT content-type: text/html; charset=GBK expires: Wed, 10 Jun 2020 23:41:58 GMT server: nginx cache-control: no-cache,no-store,private content-encoding: gzip vary: Accept-Encoding x-ser: BC51_dx-lt-yd-shandong-jinan-5-cache-6, BC49_dx-lt-yd-shandong-jinan-5-cache-6, BC19_yd-guangdong-huizhou-3-cache-1 cdn-user-ip: 2409:8a62:5b2d:fe30:5959:ac0d:11af:23bc cdn-ip: 2409:8c54:3810:2:0:2:1:10 x-cache-remote: HIT cdn-source: baishan X-Firefox-Spdy: h2\n在请求头中有一个Accept-Encoding: gzip, deflate, br这样一个属性表示浏览器客户端支持的解压方式，在请求服务器后，如果服务器要对页面进行压缩，并且这个压缩是浏览器支持的，那么返回的响应主体信息就是压缩后的，客户端必须进过解压后才能进行渲染，这样做可以减少在网络上传输的开销\n","permalink":"https://moyuduo.github.io/posts/%E5%8D%8F%E8%AE%AE/","summary":"TCP/IP协议 模型图：\n三次握手 客户端向服务器发送一个包，请求建立连接 服务器接受到这个包，同意建立连接的请求，返回一个包给客户端表示服务器同意建立连接 客户端接受到这个同意建立连接的包，但是客户端得告诉服务器它收到了这个包，再次回复个确认包 四次挥手 客户端告诉服务器我不传输数据了，请求关闭连接 服务器接收到这个包，会一个包告诉客户端表示收到了断开连接的请求，由于客户端可能还有往客户端传输的数据没传完，所以此时不能断开连接 服务器端往客户端传输的数据传完了，此时可以断开连接，服务器端发送一个包给客户端告诉客户端我也数据传完了，可以断开连接 客户端接受到这个包后回复一个确认包，双方断开连接 Http协议 Http工作原理 HTTP协议定义Web客户端如何从Web服务器请求Web页面，以及服务器如何把Web页面传送给客户端。HTTP协议采用了请求/响应模型。客户端向服务器发送一个请求报文，请求报文包含请求的方法、URL、协议版本、请求头部和请求数据。服务器以一个状态行作为响应，响应的内容包括协议的版本、成功或者错误代码、服务器信息、响应头部和响应数据。\nHTTP 请求/响应的步骤：\n客户端连接到web服务器：一个Http客户端，通常是浏览器，与web服务器的Http端口（默认80）建立一个TCP套接字连接 发送HTTP请求：通过TCP套接字，客户端向web服务器发送一个文本的请求报文（请求行、请求头、空行、请求数据） 服务器接受请求返回Http响应：web服务器解析请求，定位请求资源，服务器将资源副本写到TCP套接字，由客户端读取，包括状态行、响应头、空行、响应数据。 释放TCP连接：若connection模式为close，则服务器主动关闭TCP连接；若connection模式为keepalive，则连接会保持一段时间，在该时间内可以继续接受请求。 客户端解析内容：客户端浏览器首先解析状态行，查看表明是否成功的状态码，然后解析每一个响应头，判断返回内容的格式（html、jpg、json）和字符集，然后客户端浏览器根据响应的规则渲染。 请求 请求行 请求行又分为三部分\n请求方法 GET POST PUT DELETE HEAD:和GET方法基本一致，只是不返回内容 TRACE：使用代理上网访问网站，你想看看代理有没有修改你的HTTp请求 OPTIONS：返回服务器可用的请求方法 请求路径 /\t根路径\n所用协议 HTTP/1.1\n请求头信息 key：value\nReferer防盗链 在Http协议中，头信息有一个重要的选项：Referer，这个选项指明是请求是从哪儿网站过来的\n如何实现防盗链？\n原理：在web服务器层面，根据Http协议的referer头信息，判断请求来自于哪个网站，如果是站外请求，重写到另一个url\n请求主体信息 主体信息内容是可选的。为发送的内容。\n响应 响应行 响应行由协议、状态码、状态文字三部分组成。\n状态码：\n状态码 定义 说明 1xx 信息 接受到请求，继续处理 2xx 成功 操作成功 3xx 重定向 为了完成求情，必须采取进一步措施 4xx 客户端错误 请求语法有错误或请求不能满足 5xx 服务端错误 服务器无法完成请求 200\t服务器成功返回页面\n301/2\t永久/临时重定向","title":"网络协议"},{"content":"脚本执行前需要检查的点 脚本依赖的环境是否都已经安装了 如果是批量 增/删/改 的脚本一定要写一个只影响一条数据的版本，然后执行脚本，验证对业务的影响!!! 脚本中每个阶段都必须有输出，特别是循环中，一定要打印信息给脚本执行者，不要脚本一执行一片黑，只有最后才有结果输出!!! ","permalink":"https://moyuduo.github.io/posts/%E8%84%9A%E6%9C%AC%E5%86%9B%E8%A7%84/","summary":"脚本执行前需要检查的点 脚本依赖的环境是否都已经安装了 如果是批量 增/删/改 的脚本一定要写一个只影响一条数据的版本，然后执行脚本，验证对业务的影响!!! 脚本中每个阶段都必须有输出，特别是循环中，一定要打印信息给脚本执行者，不要脚本一执行一片黑，只有最后才有结果输出!!! ","title":"脚本军规"},{"content":"解决staging环境下edgewize无法上线问题 修改edgewize安装目录/services/scheduler/scheduler.yml文件中cloud_addr、iot_addr的地址为192.168.14.94 linux同步时间\nyum install -y ntpdate ntpdate time.nist.gov 安装lzo组件\ncd ~ curl -O http://www.oberhumer.com/opensource/lzo/download/lzo-2.10.tar.gz tar zxvf lzo-2.10.tar.gz -C /usr/src/ cd /usr/src/lzo-2.10/ ./configure --enable-shared make \u0026amp;\u0026amp; make install 安装openvpn的依赖\nyum install -y epel-release openssl lzo pam openssl-devel lzo-devel pam-devel easy-rsa 安装openvpn\ncd ~ curl -O https://swupdate.openvpn.org/community/releases/openvpn-2.4.6.tar.gz tar zxvf openvpn-2.4.6.tar.gz -C /usr/src/ cd /usr/src/openvpn-2.4.6/ ./configure --prefix=/usr/local/openvpn make \u0026amp;\u0026amp; make install 创建配置文件目录\nmkdir /usr/local/openvpn/etc #把windows下配置office vpn时的配置文件上传到该目录 #windows下配置vpn参考https://cwiki.yunify.com/pages/viewpage.action?pageId=3539103 #上传后etc目录下有以下文件 [root@localhost etc]# pwd /usr/local/openvpn/etc [root@localhost etc]# ls -l total 16 -rw-r--r--. 1 root root 244 Sep 2 05:38 office.ovpn -rw-r--r--. 1 root root 30 Sep 2 05:11 pass.txt -rw-r--r--. 1 root root 4481 Sep 2 05:11 yunify-ca.crt #修改office.ovpn中的ca、auth-user-pass为绝对路径 ca /usr/local/openvpn/etc/yunify-ca.crt auth-user-pass /usr/local/openvpn/etc/pass.txt 启动openvpn\ncd /usr/local/openvpn/sbin ./openvpn --config /usr/local/openvpn/etc/office.ovpn --daemon #查看是否启动成功 ps -ef|grep openvpn 重启启动edgewize\nsystemctl restart edge_hub scheduler edge_log ota monitor ","permalink":"https://moyuduo.github.io/posts/%E8%A7%A3%E5%86%B3staging%E7%8E%AF%E5%A2%83%E4%B8%8Bedgewize%E6%97%A0%E6%B3%95%E4%B8%8A%E7%BA%BF%E9%97%AE%E9%A2%98/","summary":"解决staging环境下edgewize无法上线问题 修改edgewize安装目录/services/scheduler/scheduler.yml文件中cloud_addr、iot_addr的地址为192.168.14.94 linux同步时间\nyum install -y ntpdate ntpdate time.nist.gov 安装lzo组件\ncd ~ curl -O http://www.oberhumer.com/opensource/lzo/download/lzo-2.10.tar.gz tar zxvf lzo-2.10.tar.gz -C /usr/src/ cd /usr/src/lzo-2.10/ ./configure --enable-shared make \u0026amp;\u0026amp; make install 安装openvpn的依赖\nyum install -y epel-release openssl lzo pam openssl-devel lzo-devel pam-devel easy-rsa 安装openvpn\ncd ~ curl -O https://swupdate.openvpn.org/community/releases/openvpn-2.4.6.tar.gz tar zxvf openvpn-2.4.6.tar.gz -C /usr/src/ cd /usr/src/openvpn-2.4.6/ ./configure --prefix=/usr/local/openvpn make \u0026amp;\u0026amp; make install 创建配置文件目录\nmkdir /usr/local/openvpn/etc #把windows下配置office vpn时的配置文件上传到该目录 #windows下配置vpn参考https://cwiki.yunify.com/pages/viewpage.action?pageId=3539103 #上传后etc目录下有以下文件 [root@localhost etc]# pwd /usr/local/openvpn/etc [root@localhost etc]# ls -l total 16 -rw-r--r--.","title":"解决staging环境下edgewize无法上线问题"},{"content":"静态代理 为某个对象提供一个代理，以控制对这个对象的访问。 代理类和被代理类有共同的父类或父接口，这样在任何使用被代理类对象的地方都可以用代理对象替代。代理类负责请求的预处理、过滤、将请求分派给被代理对象处理、以及被代理对象执行完请求后的后续处理。\n代理类是手动编写的代码，在编译期代理类和被代理类的关系就确定了。\npublic class StaticProxy { public static void main(String[] args) { Sell mall=new ClothMall(new NikeFactory()); double price = mall.sell(); System.out.println(\u0026#34;商场卖出商品的价格：\u0026#34;+price); } } interface Sell{ double sell(); } //被代理对象 class NikeFactory implements Sell{ @Override public double sell() { return 100; } } //代理对象 class ClothMall implements Sell{ //被代理对象 private Sell target; public ClothMall(Sell target) { this.target=target; } @Override public double sell() { double originalPrice = target.sell(); //提价 return originalPrice+50; } } 动态代理 动态代理类的源码是在程序运行期间由JVM根据反射等机制动态的生成，所以不存在代理类的字节码文件。代理类和被代理类的关系是在程序运行时确定。\npublic class DynamicProxy { public static void main(String[] args) { ProxyFactory proxyFactory=new ProxyFactory(new HouseOwner()); RentHouse proxy = (RentHouse)proxyFactory.getProxyInstance(); double price = proxy.rentHouse(); System.out.println(\u0026#34;代理出租房子价格：\u0026#34;+price); ProxyFactory proxyFactory2=new ProxyFactory(new NikeFactory()); Sell proxy2 = (Sell)proxyFactory2.getProxyInstance(); double price2 = proxy2.sell(); System.out.println(\u0026#34;代理出售Nike服装价格：\u0026#34;+price2); } } interface RentHouse { double rentHouse(); } //被代理对象 class HouseOwner implements RentHouse { @Override public double rentHouse() { return 1500; } } class ProxyFactory implements InvocationHandler { //被代理对象 private Object target; public ProxyFactory(Object target) { this.target=target; } @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { double originalPrice = (double)method.invoke(target, args); //后置操作，提价 return originalPrice+100; } //返回代理类对象 public Object getProxyInstance() { return Proxy.newProxyInstance(target.getClass().getClassLoader(), target.getClass().getInterfaces(), this); } } 在动态代理中，不用去手动编写代理类，可以根据代理工厂为每个被代理类生成一个代理类，在被代理类较多时，可以减少代理类的编写。\n","permalink":"https://moyuduo.github.io/posts/%E9%9D%99%E6%80%81%E4%BB%A3%E7%90%86%E5%92%8C%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86/","summary":"静态代理 为某个对象提供一个代理，以控制对这个对象的访问。 代理类和被代理类有共同的父类或父接口，这样在任何使用被代理类对象的地方都可以用代理对象替代。代理类负责请求的预处理、过滤、将请求分派给被代理对象处理、以及被代理对象执行完请求后的后续处理。\n代理类是手动编写的代码，在编译期代理类和被代理类的关系就确定了。\npublic class StaticProxy { public static void main(String[] args) { Sell mall=new ClothMall(new NikeFactory()); double price = mall.sell(); System.out.println(\u0026#34;商场卖出商品的价格：\u0026#34;+price); } } interface Sell{ double sell(); } //被代理对象 class NikeFactory implements Sell{ @Override public double sell() { return 100; } } //代理对象 class ClothMall implements Sell{ //被代理对象 private Sell target; public ClothMall(Sell target) { this.target=target; } @Override public double sell() { double originalPrice = target.sell(); //提价 return originalPrice+50; } } 动态代理 动态代理类的源码是在程序运行期间由JVM根据反射等机制动态的生成，所以不存在代理类的字节码文件。代理类和被代理类的关系是在程序运行时确定。","title":"静态代理和动态代理"},{"content":"面试相关知识储备 你觉得java研发岗位需要什么能力？ 要成为java研发工程师，我觉得首先要具备很好的代码能力，能够使用技术完成需求，其次需要有良好的沟通能力，因为我们是一个团队进行开发，每个人都不是独立的一个单位，需要彼此合作，才能完成项目。然后还需要有学习的能力，作为互联网从业者，我们都知道技术的更替是很快的，有不断的新技术出现，作为一个开发者，快速学习新技术是很有必要的。\n你觉得你有什么缺点？ 我是一个不太愿意去麻烦别人的人，如果遇到了什么问题，必须要寻求别人的帮助，那么我也一定会在物质和态度上去感谢对方，这就导致我也不喜欢别人轻易麻烦我，这可能算是我很大一个缺点。\n你还有什么要问的？ 加入我有幸加入贵公司，那在入职之前还有什么需要去学习和准备的吗？入职之后公司有没有相关培训？\n你的职业规划是怎么样的？ 作为一个一个应届毕业生，刚刚工作，在工作经验和技术上面还有很多需要积累的，我准备在未来2-3年主要提升自己的技术实力，达到能在团队内独挡一面，然后再经过 几年的学习，能够带领团队，进行项目开发，当自己技术具备一定广度，我准备往架构师方向发展。\n集合 ArrayList ArrayList底层使用Object数组来保存元素，默认初始化大小为10，当需要扩容时，新容量是原容量的1.5倍，modCount属性与集合遍历时的快速失败机制有关，ArrayList不是线程安全的\nVector Vector底层使用Object数组来保存元素，默认初始化大小是10，具有一个capacityIncrement属性，可以指定扩容时的增长因子，在进行扩容时，如果指定了增长因子，那么新容量为原容量+增长因子，否则新容量为原容量的2倍，Vector的所有方法都加了锁，所以是线程安全的\nLinkedList LinkedList底层使用的是一个不带头结点的双向链表来保存元素的，在插入元素的时候进行的是尾插法，LinkedList实现了Deque接口，可以在链表的两端进行入队和出队的操作，所以可以把LinkedList当做栈和队列使用，LinkedList不是线程安全的\nHashMap 在jdk1.7以前HashMap使用的是数组+链表的结构来存储元素的，由于添加元素过多后，hash碰撞的次数增加，导致链表的长度过长，访问的时候有效率的问题，jdk1.8为了解决这个问题采用数组+链表+红黑树的结构存储元素，当添加元素后，链表的长度达到8（还需要满足最少有64个元素的一条件）就会把链表转化为红黑树，HashMap默认的初始化大小是16，加载因子是0.75，添加元素如果对应节点是链表，进行的是尾插法，添加元素后到达阈值，需要进行扩容时，数组的新容量扩大为原来的2倍，并将所有元素进行rehash操作，HashMap的所有方法都没有加锁，所以不是线程安全的\nHashSet HashSet底层维护了一个HashMap，把添加的元素当做key来存储，利用HashMap中key不能重复的特性了保证HashSet中的元素不重复，不是线程安全的\nHashtable Hashtable底层采用数组+链表结构存储，默认初始化大小为11，加载因子为0.75，当元素个数达到阈值进行扩容时，新容量为原容量的2倍+1，并且使用头插法进行rehash，Hashtable的所有方法都加了锁，所以是线程安全的\nLinkedHashMap LinkedHashMap是HashMap的子类，节点新增了before和after两个属性保存前驱了后继，LinkedHashMap保证了遍历时按照添加/访问的顺序,LinkedHashMap不是线程安全的\n项目遇到的问题 主键问题 在在线学习项目中，数据库的主键使用的是mybatisPlus的生成策略，默认生成的是一个19位字符长度，js只能解析16位长度整数，发现这个问题户我们把主键生成策略改成了生成字符串，解决了这个问题\n413错误 在视频上传的时候，刚开始测试是没有问题，配置了nginx请求转发后报出了413异常，我们直接判断是nginx出了问题，后来查阅资料发现是nginx的上传问题默认不能超过1M，通过配置client_max_body_size解决了这个问题\nJVM 类加载器有什么好处？ 可以确保java核心类库的安全：如果java类库中的类是由自定义的加载器去加载的，那么可能在会在JVM中存在多个版本类，而且这些类是不兼容的，项目不可见的，借助双亲委派机制，java核心类库都由启动类加载器来统一加载，所以他们是类型兼容的。 确保java的核心类库不会被自定义类替换，每个加载器都有自己的加载路径，即使和java核心类同名，也会去加载java自己的类。 不同类的加载器可以为同名的类创建额外的命名空间，使得相同名称的类可以并存在java虚拟机中，并且他们 是不兼容的，相当于在java虚拟机中创建了一个个隔离的类空间，这种技术在很多框架中都有使用。 mybatis中#和$有什么区别 #{}意味着预编译语句，sql语句中的#{}参数会使用jdbc的PreparedStatement替换为？占位符，这种方式可以防止sql注入,替换后的每个参数都有单引号\n${}是直接将参数的字符串取值拼接sql后再去编译，这样就带来了sql注入的风险，当然${}并不是一无是处，在进行动态排序时，就需要使用\nmybatis中嵌套查询和嵌套结果有什么区别 嵌套查询是对单表的查询后拿到关联的列再对关联对象进行查询，特点是简单但是需要执行多条sql语句效率低\n嵌套结果是对多表的连接查询，一条sql查出所有的信息，然后再进行对象封装\nmysql中如何实现分页 可以使用limit来进行分页，如果要查询pageNum页时，就使用limit （pageNum-1）*pageSize,pageSize\nservlet的生命周期 servlet的生命周期主要包括四个阶段：①加载和实例化 ②初始化 ③处理请求 ④服务终止\n当客户端第一次向web服务器发起一个servlet请求时，web服务器会创建一个该servlet的实例，并调用servlet的init方法；如果web服务器已经存在该servlet实例，那么就直接使用该实例；然后调用service方法；当web服务器reload或关闭tocat时，web服务器将调用servlet的destroy方法释放资源，然后将servlet从服务器内存中删除。\nhttp和https区别 http采用的是明文传输，信息在网络上有可能被拦截\nhttps采用ssl证书，运用对称加密+非对称加密+CA第三方对传输的数据进行加密，即使传输的数据在网络上被劫持了也不能被破译\nTCP/IP几次握手，为什么 三次握手。第一次握手是客户端向服务器发送一个syn包包含一个seq标志位，第二次握手是服务器收到了客户端连接的请求，同意建议连接，回复一个包，包含syn+ack，ack为seq+1表示收到了请求包，并且也有一个同步标志seq，第三次握手是客户端收到这个syn+ack包，此时客户端就知道服务器同意连接，并且准备就绪。如果只是两次握手，由于包在网络上传输是有延迟的，tcp是具有超时重传的，如果第一个请求建立连接的包在网络上阻塞了，客户端发送了第二个请求建立连接的包后，服务器收到了第一个延迟的包，给客户端回了一个确认包就建立连接的话。由于服务器是以延迟包的seq为标志，而客户端以为是新的请求连接的seq，导致后续客户端发送数据包时以客户端的seq的准，这些数据包发送到服务器都被丢弃了。如果是四次握手的话，也能保证建立连接，但是并不能显著增加可靠性，没有必要。\nTCP和UDP有什么区别 TCP是面向连接的，在建立逻辑连接之前需要三次握手建立连接，并且TCP协议具有超时重传，数据包去重，所以TCP是保证可靠性的协议。\nUDP是面向无连接的，不需要建立连接，发送端不保证数据包能被接收端收到，可能存在丢包的情况，是不保证数据可靠性的连接。\n有哪些状态码 200 500 404 401 413 302 304\n401是访问一些需要权限页面时，如果直接使用url访问，会返回状态码401表示没有权限访问\n413请求体大小超过了nginx的默认1m大小，可以配置client_max_body_size解决了这个问题\n302重定向，浏览器会从响应头中取出Location值的地址，然后去请求这个地址\n304是请求资源未修改，直接使用缓存，常用于图片的缓存\njava堆为什么要分代 由于java中对象的生命周期是不一样的，有的对象的生命周期很长，有的对象被创建后马上就不再使用，所有JVM堆的设计者为了提高垃圾回收的效率，设计了堆的分代，如果不进行分代，那么不同生命周期的对象被放在一个空间中，GC需要去判断每个对象是否需要被回收，其实很多生命周期长的对象并不需要被回收，不分代那么这些对象也需要进行判断，增加了开销。\n为什么要有TLAB（Thread Local Allocation Buffer） 堆区是线程共享区域，当多个线程同时操作同一地址时，需要进行加锁，影响并发效率，为了解决这个问题，在Eden区内每个线程创建一个私有的缓存区域TLAB，当需要创建对象时，先在线程的TLAB中创建，由于TLAB是线程私有的，这个过程可以多个线程同时进行，不需要加锁，如果空间不够再在Eden中创建对象，由于堆中创建的对象绝大多数都是小对象，所以都使用TLAB，这样就提高了效率。\n堆是分配对象存储的唯一选择吗 不是。在java虚拟机中，有这种特殊的情况，如果经过逃逸分析后发现一个对象没有逃逸出方法，那么就可以被优化为栈上分配。但是由于进行逃逸分析消耗的性能可能比把对象存放在堆上消耗的性能还多，所以在HotSpot虚拟机中并没有运用逃逸分析，也就是说针对HotSpot虚拟机而言，对象都是分配在堆上的。\n逃逸分析：如果一个对象是在方法内new的，如果在方法外不能使用该对象，那么就说该对象没能逃逸出方法。\n//对象只在方法内使用，没能逃逸出方法 public void test(){ User u=new User(\u0026#34;tom\u0026#34;); //use u u=null; } //对象逃逸出方法,对象可能在方法外被使用 public User createUser(){ User u=new User(\u0026#34;tom\u0026#34;); return u; } 为什么要使用元空间替换永久代 因为永久代的空间大小很难确定，在某些情况下，我们的类加载过多（使用到很多jar包、tomcat下部署了很多war包），容易导致永久代OOM，而使用元空间就不会存在这个问题，因为元空间并不在虚拟机中，它是直接使用的本地内存，默认情况下，元空间大小仅受本地内存大小限制。\n我们公司业务慢，请你从数据库的角度分析下原因 首先判断是应急性的慢还是持续性的慢。如果是应急性的慢，先使用show processlist;查看导致慢的执行语句，再使用explain/desc分析执行的SQL的执行计划，有没有走索引，索引的类型，分析出原因后根据原因建索引或改语句。如果是持续性的慢，先查看slowlog查看哪些SQL执行慢，再使用explain/desc分析SQL执行计划找到原因。\nMysql数据引擎InnoDB和MyISAM有什么区别 InnoDB是Mysql的默认存储引擎，InnoDB支持事务，MyISAM不支持事务；InnoDB的锁粒度为行级锁，MyISAM为表级锁；InnoDB支持文件，MyISAM不支持外键；除此之外，InnoDB还具有自动故障恢复、热备份等优点。\n说说Mysql脏读、不可重复读、幻读的区别，Mysql默认的隔离级别是什么，不同隔离级别下会出现什么问题 脏读是一个事务读取了另一个事务未提交的事务，然后这个事务回滚了，这个数据就是脏数据。不可重复读是一个事务第一次读取一个数据，这时第二个事务修改了这个数据，当第一个事务再次读取这个数据时，就发现两次读同一个数据不一致。幻读是一个事务在前后两次查询同一范围的时候，后一次查询看到了前一次查询没有看到的行。\nmysql的默认事务隔离级别是可重复读，一共有读取未提交、读取已提交、可重复读和串行化四种隔离级别。在读取未提交隔离级别下，脏读、不可重复读、幻读都有可能出现。读取已提交不会出现脏读但是任然有不可重复读和幻读现象。可重复读解决了脏读和不可重复读，但是还是有幻读现象。串行化隔离模式下，脏读、不可重复读、幻读都不会出现。\n静态代理和动态代理有何不同 静态代理类需要手动实现，并且每个代理类只能代理一个目标对象，如果目标对象过多，那么就会生成大量的代理类。动态代理是在执行过程中，使用jdk的反射来创建代理类对象，并动态的指定要代理的目标对象。\n为什么要把字符串常量池从方法区移动到堆 jdk1.7中把字符串常量池从永久代移动到堆的原因是，永久代的GC频率很低，只有当老年代或永久代的空间不足时，才会触发Full GC，而我们开发中往往会创建大量的字符串，放在永久代回收效率低，放在堆中，GC更加频繁，更能即时回收空间。\n垃圾回收是否会涉及到java虚拟机栈 不会。虚拟机栈中的每个栈帧对应着每一个调用的方法，当方法执行结束，栈帧也就出栈了，栈帧中的局部变量表、操作数栈、动态链接等也就销毁了，所以不存在垃圾回收。\n方法中定义的局部变量是否线程安全 方法中定义的局部变量是线程安全的，因为方法中的局部变量是保存在java虚拟机栈中的局部变量表中的，而java虚拟机栈是线程私有的。\n什么是垃圾回收 垃圾是指运行的程序中没有任何指针指向的对象，如果不及时对内存进行垃圾清理，那么这些垃圾对象所占的内存空降会一致保留到程序结束，这些空间无法被其他对象使用，甚至可能导致内存溢出。\n为什么需要GC 对于高级语言来说，如果不进行垃圾会输，内存迟早都会被消耗完，因为不断的分配内存空间而不进行回收，就好像不停生成生活垃圾而不进行打扫。除了释放没用的对象，垃圾回收也可以清除内存碎片，碎片整理将所占的堆内存移动到堆的一端，方便后续给对象分配空间。随着程序的业务逐渐扩大，用户增多，如果没有垃圾回收就不能保证程序正常运行。\n哪些内存需要回收 从GC Root无法访问的对象，即没有对象引用该对象，这些对象在内存中不能被访问到，需要被回收\n什么时候进行垃圾回收 怎么进行垃圾回收 ParNew收集器是并行回收，那么是否可以断定ParNew收集器一定比Serial收集器的效率高 ParNew收集器运行在多CPU环境下，可以充分利用多CPU、多核心的硬件优势，可以更快的进行垃圾收集。但是在单CPU环境下，ParNew收集器的效率不比Serial收集器高，因为Serial收集器是基于单线程的，不需要CPU频繁的进行垃圾收集线程切换，避免了多线程切换过程中的一些额外开销。\nCMS收集器采用的是标记-清除算法，会产生内存碎片，那为什么不换成标记-压缩算法，解决内存碎片问题呢 CMS收集器是一款并发的垃圾收集器，它追求的是低延迟，如果把垃圾清除算法，换成标记-压缩算法的话，由于标记压缩算法需要移动对象，这个阶段必须“Stop The World”，如果采用这种算法的话，势必会增加延迟，这个这个垃圾收集器的设计初衷是相悖的。\n","permalink":"https://moyuduo.github.io/posts/%E9%9D%A2%E8%AF%95%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86%E5%82%A8%E5%A4%87/","summary":"面试相关知识储备 你觉得java研发岗位需要什么能力？ 要成为java研发工程师，我觉得首先要具备很好的代码能力，能够使用技术完成需求，其次需要有良好的沟通能力，因为我们是一个团队进行开发，每个人都不是独立的一个单位，需要彼此合作，才能完成项目。然后还需要有学习的能力，作为互联网从业者，我们都知道技术的更替是很快的，有不断的新技术出现，作为一个开发者，快速学习新技术是很有必要的。\n你觉得你有什么缺点？ 我是一个不太愿意去麻烦别人的人，如果遇到了什么问题，必须要寻求别人的帮助，那么我也一定会在物质和态度上去感谢对方，这就导致我也不喜欢别人轻易麻烦我，这可能算是我很大一个缺点。\n你还有什么要问的？ 加入我有幸加入贵公司，那在入职之前还有什么需要去学习和准备的吗？入职之后公司有没有相关培训？\n你的职业规划是怎么样的？ 作为一个一个应届毕业生，刚刚工作，在工作经验和技术上面还有很多需要积累的，我准备在未来2-3年主要提升自己的技术实力，达到能在团队内独挡一面，然后再经过 几年的学习，能够带领团队，进行项目开发，当自己技术具备一定广度，我准备往架构师方向发展。\n集合 ArrayList ArrayList底层使用Object数组来保存元素，默认初始化大小为10，当需要扩容时，新容量是原容量的1.5倍，modCount属性与集合遍历时的快速失败机制有关，ArrayList不是线程安全的\nVector Vector底层使用Object数组来保存元素，默认初始化大小是10，具有一个capacityIncrement属性，可以指定扩容时的增长因子，在进行扩容时，如果指定了增长因子，那么新容量为原容量+增长因子，否则新容量为原容量的2倍，Vector的所有方法都加了锁，所以是线程安全的\nLinkedList LinkedList底层使用的是一个不带头结点的双向链表来保存元素的，在插入元素的时候进行的是尾插法，LinkedList实现了Deque接口，可以在链表的两端进行入队和出队的操作，所以可以把LinkedList当做栈和队列使用，LinkedList不是线程安全的\nHashMap 在jdk1.7以前HashMap使用的是数组+链表的结构来存储元素的，由于添加元素过多后，hash碰撞的次数增加，导致链表的长度过长，访问的时候有效率的问题，jdk1.8为了解决这个问题采用数组+链表+红黑树的结构存储元素，当添加元素后，链表的长度达到8（还需要满足最少有64个元素的一条件）就会把链表转化为红黑树，HashMap默认的初始化大小是16，加载因子是0.75，添加元素如果对应节点是链表，进行的是尾插法，添加元素后到达阈值，需要进行扩容时，数组的新容量扩大为原来的2倍，并将所有元素进行rehash操作，HashMap的所有方法都没有加锁，所以不是线程安全的\nHashSet HashSet底层维护了一个HashMap，把添加的元素当做key来存储，利用HashMap中key不能重复的特性了保证HashSet中的元素不重复，不是线程安全的\nHashtable Hashtable底层采用数组+链表结构存储，默认初始化大小为11，加载因子为0.75，当元素个数达到阈值进行扩容时，新容量为原容量的2倍+1，并且使用头插法进行rehash，Hashtable的所有方法都加了锁，所以是线程安全的\nLinkedHashMap LinkedHashMap是HashMap的子类，节点新增了before和after两个属性保存前驱了后继，LinkedHashMap保证了遍历时按照添加/访问的顺序,LinkedHashMap不是线程安全的\n项目遇到的问题 主键问题 在在线学习项目中，数据库的主键使用的是mybatisPlus的生成策略，默认生成的是一个19位字符长度，js只能解析16位长度整数，发现这个问题户我们把主键生成策略改成了生成字符串，解决了这个问题\n413错误 在视频上传的时候，刚开始测试是没有问题，配置了nginx请求转发后报出了413异常，我们直接判断是nginx出了问题，后来查阅资料发现是nginx的上传问题默认不能超过1M，通过配置client_max_body_size解决了这个问题\nJVM 类加载器有什么好处？ 可以确保java核心类库的安全：如果java类库中的类是由自定义的加载器去加载的，那么可能在会在JVM中存在多个版本类，而且这些类是不兼容的，项目不可见的，借助双亲委派机制，java核心类库都由启动类加载器来统一加载，所以他们是类型兼容的。 确保java的核心类库不会被自定义类替换，每个加载器都有自己的加载路径，即使和java核心类同名，也会去加载java自己的类。 不同类的加载器可以为同名的类创建额外的命名空间，使得相同名称的类可以并存在java虚拟机中，并且他们 是不兼容的，相当于在java虚拟机中创建了一个个隔离的类空间，这种技术在很多框架中都有使用。 mybatis中#和$有什么区别 #{}意味着预编译语句，sql语句中的#{}参数会使用jdbc的PreparedStatement替换为？占位符，这种方式可以防止sql注入,替换后的每个参数都有单引号\n${}是直接将参数的字符串取值拼接sql后再去编译，这样就带来了sql注入的风险，当然${}并不是一无是处，在进行动态排序时，就需要使用\nmybatis中嵌套查询和嵌套结果有什么区别 嵌套查询是对单表的查询后拿到关联的列再对关联对象进行查询，特点是简单但是需要执行多条sql语句效率低\n嵌套结果是对多表的连接查询，一条sql查出所有的信息，然后再进行对象封装\nmysql中如何实现分页 可以使用limit来进行分页，如果要查询pageNum页时，就使用limit （pageNum-1）*pageSize,pageSize\nservlet的生命周期 servlet的生命周期主要包括四个阶段：①加载和实例化 ②初始化 ③处理请求 ④服务终止\n当客户端第一次向web服务器发起一个servlet请求时，web服务器会创建一个该servlet的实例，并调用servlet的init方法；如果web服务器已经存在该servlet实例，那么就直接使用该实例；然后调用service方法；当web服务器reload或关闭tocat时，web服务器将调用servlet的destroy方法释放资源，然后将servlet从服务器内存中删除。\nhttp和https区别 http采用的是明文传输，信息在网络上有可能被拦截\nhttps采用ssl证书，运用对称加密+非对称加密+CA第三方对传输的数据进行加密，即使传输的数据在网络上被劫持了也不能被破译\nTCP/IP几次握手，为什么 三次握手。第一次握手是客户端向服务器发送一个syn包包含一个seq标志位，第二次握手是服务器收到了客户端连接的请求，同意建议连接，回复一个包，包含syn+ack，ack为seq+1表示收到了请求包，并且也有一个同步标志seq，第三次握手是客户端收到这个syn+ack包，此时客户端就知道服务器同意连接，并且准备就绪。如果只是两次握手，由于包在网络上传输是有延迟的，tcp是具有超时重传的，如果第一个请求建立连接的包在网络上阻塞了，客户端发送了第二个请求建立连接的包后，服务器收到了第一个延迟的包，给客户端回了一个确认包就建立连接的话。由于服务器是以延迟包的seq为标志，而客户端以为是新的请求连接的seq，导致后续客户端发送数据包时以客户端的seq的准，这些数据包发送到服务器都被丢弃了。如果是四次握手的话，也能保证建立连接，但是并不能显著增加可靠性，没有必要。\nTCP和UDP有什么区别 TCP是面向连接的，在建立逻辑连接之前需要三次握手建立连接，并且TCP协议具有超时重传，数据包去重，所以TCP是保证可靠性的协议。\nUDP是面向无连接的，不需要建立连接，发送端不保证数据包能被接收端收到，可能存在丢包的情况，是不保证数据可靠性的连接。\n有哪些状态码 200 500 404 401 413 302 304\n401是访问一些需要权限页面时，如果直接使用url访问，会返回状态码401表示没有权限访问\n413请求体大小超过了nginx的默认1m大小，可以配置client_max_body_size解决了这个问题\n302重定向，浏览器会从响应头中取出Location值的地址，然后去请求这个地址","title":"面试储备"},{"content":"面试题 ==和equals的区别\n说说equals和hashCode\n为什么eclipse重写hashCode会有31这个数\nString s1=new String(\u0026#34;abc\u0026#34;); String s2=\u0026#34;abc\u0026#34;; String s3=new String(\u0026#34;abc\u0026#34;); System.out.println(s1==s2); System.out.println(s1==s3); System.out.println(s2==s3); System.out.println(\u0026#34;==============\u0026#34;); System.out.println(s1==s1.intern()); System.out.println(s2==s2.intern()); System.out.println(s1.intern()==s2.intern()); 输出结果是什么？为什么？ String s4=\u0026#34;java\u0026#34;; String s5=\u0026#34;ja\u0026#34;; String s6=\u0026#34;va\u0026#34;; System.out.println(s4==\u0026#34;java\u0026#34;); System.out.println(s4==(s5+s6)); System.out.println(s4==\u0026#34;ja\u0026#34;+s6); 输出什么，为什么？ class Person{ String name; public Person(String name) { this.name=name; } public String getName() { return name; } public void setName(String name) { this.name = name; } } public void change1(int x) { x=20; } public void change2(Integer x) { x=20; } public void change3(Person p) { p.setName(\u0026#34;jack\u0026#34;); } public void change4(String s) { s=\u0026#34;ABC\u0026#34;; } @Test public void test4() { int a=10; change1(a); System.out.println(a); Integer b=10; change2(b); System.out.println(b); Person p=new Person(\u0026#34;tom\u0026#34;); change3(p); System.out.println(p.getName()); String s=\u0026#34;abc\u0026#34;; change4(s); System.out.println(s); } 输出是什么？ class Father{ public Father() { System.out.println(\u0026#34;Father构造器\u0026#34;); } { System.out.println(\u0026#34;Father普通代码块\u0026#34;); } static{ System.out.println(\u0026#34;Father Static代码块\u0026#34;); } } class Son extends Father{ public Son() { System.out.println(\u0026#34;Son构造器\u0026#34;); } { System.out.println(\u0026#34;Son普通代码块\u0026#34;); } static{ System.out.println(\u0026#34;Son Static代码块\u0026#34;); } } @Test public void test1() { new Son(); new Father(); new Son(); } 输出结果是什么？为什么？ 什么是HashMap的负载因子，什么是阈值，HashMap默认的容量和负载因子是多少？说说HashMap的put/get/resize方法，modCount属性是用来干嘛的？\n什么是进程什么是线程？\n","permalink":"https://moyuduo.github.io/posts/%E7%AC%94%E8%AF%95%E9%A2%98/","summary":"面试题 ==和equals的区别\n说说equals和hashCode\n为什么eclipse重写hashCode会有31这个数\nString s1=new String(\u0026#34;abc\u0026#34;); String s2=\u0026#34;abc\u0026#34;; String s3=new String(\u0026#34;abc\u0026#34;); System.out.println(s1==s2); System.out.println(s1==s3); System.out.println(s2==s3); System.out.println(\u0026#34;==============\u0026#34;); System.out.println(s1==s1.intern()); System.out.println(s2==s2.intern()); System.out.println(s1.intern()==s2.intern()); 输出结果是什么？为什么？ String s4=\u0026#34;java\u0026#34;; String s5=\u0026#34;ja\u0026#34;; String s6=\u0026#34;va\u0026#34;; System.out.println(s4==\u0026#34;java\u0026#34;); System.out.println(s4==(s5+s6)); System.out.println(s4==\u0026#34;ja\u0026#34;+s6); 输出什么，为什么？ class Person{ String name; public Person(String name) { this.name=name; } public String getName() { return name; } public void setName(String name) { this.name = name; } } public void change1(int x) { x=20; } public void change2(Integer x) { x=20; } public void change3(Person p) { p.","title":"面试题"},{"content":"Docker相关 为什么要使用Docker？ 想想在分布式项目中，Nginx后会有很多的服务器提供服务，并且当一些特殊的情况下我们需要对服务器进行扩容，假如我们要新增100台服务器，我们需要一个一个服务器都去装tomcat吗？每台都去进行相关配置吗？再想想我们学习开源项目，很多情况下都需要安装Mysql、Redis、MongoDB、Tomcat等，这时候一个一个去装，一个个去配置是不是很麻烦，Docker就为我们提供了一个简洁的方式完成这些工作。\n简介 Docker是一个开源的应用容器引擎；是一个轻量级容器技术；\nDocker支持将软件编译成一个镜像；然后在镜像中各种软件做好配置，将镜像发布出去，其他使用者可以直接使用这个镜像；\n运行中的这个镜像称为容器，容器启动是非常快速的。\n核心概念 docker主机(Host)：安装了Docker程序的机器（Docker直接安装在操作系统之上）；\ndocker客户端(Client)：连接docker主机进行操作；\ndocker仓库(Registry)：用来保存各种打包好的软件镜像；\ndocker镜像(Images)：软件打包好的镜像；放在docker仓库中；\ndocker容器(Container)：镜像启动后的实例称为一个容器；容器是独立运行的一个或一组应用；\n安装Docker 1）可以使用VmWare或VirtualBox\n2）安装好centos，内核版本必须是3.1以上，可以使用uname -r查看\n3）配置好网络，保证能连上外网\n4）使用yum命令安装docker\nyum install docker yum list installed|grep docker #卸载原有的docker yum remove -y docker-ce docker-ce-cli docker-ce-rootless-extras docker-scan-plugin containerd.io #删除镜像、容器、配置文件等内容 rm -rf /var/lib/docker #查询docker可按照版本 yum list docker-ce --showduplicates | sort -r # !!!亲测centos7.2下安装这个版本不会有问题 yum install -y docker-ce-17.06.2.ce-1.el7.centos 20.10.7-3 yum install -y docker-ce-20.10.7-3.el7.x86_64 containerd.io systemctl start docker docker run hello-world 5)安装的过程中会提示是否继续？[y/N]：y\t输入y即可\t最后出现完毕!即完成\n启动Docker #启动docker [root@localhost yum.repos.d]# systemctl start docker #查看docker版本 [root@localhost yum.repos.d]# docker -v Docker version 1.13.1, build cccb291/1.13.1 #设置docker开机自启动 [root@localhost yum.repos.d]# systemctl enable docker Created symlink from /etc/systemd/system/multi-user.target.wants/docker.service to /usr/lib/systemd/system/docker.service. #停止docker [root@localhost yum.repos.d]# systemctl stop docker Docker常用命令 参考docs.docker.com\nDocker镜像命令 #镜像搜索命令 [root@localhost /]# docker search mysql INDEX NAME DESCRIPTION STARS OFFICIAL AUTOMATED docker.io docker.io/mysql MySQL is a widely used, open-source relati... 9286 [OK] docker.io docker.io/mariadb MariaDB is a community-developed fork of M... 3315 [OK] docker.io docker.io/mysql/mysql-server Optimized MySQL Server Docker images. Crea... 682 [OK] docker.io docker.io/centos/mysql-57-centos7 MySQL 5.7 SQL database server 71 docker.io docker.io/mysql/mysql-cluster Experimental MySQL Cluster Docker images. ... 66 docker.io docker.io/centurylink/mysql Image containing mysql. Optimized to be li... 61 [OK] docker.io docker.io/deitch/mysql-backup REPLACED! Please use http://hub.docker.com... 41 [OK] docker.io docker.io/bitnami/mysql Bitnami MySQL Docker Image 36 [OK] #在搜索容器时可以加上--no-trunc --automated\t--limit --filter或-f -s 参数\t--no-trunc是值显示完整的镜像描述\t--automated是搜索自动构建的项目 -s 10 表示搜索出的项目star大于等于10 #--no-trunc [root@localhost ~]# docker search mysql --no-trunc INDEX NAME DESCRIPTION STARS OFFICIAL AUTOMATED docker.io docker.io/mysql MySQL is a widely used, open-source relational database management system (RDBMS). 9289 [OK] docker.io docker.io/mariadb MariaDB is a community-developed fork of MySQL intended to remain free under the GNU GPL. 3316 [OK] #--automated [root@localhost ~]# docker search mysql --automated Flag --automated has been deprecated, use --filter=automated=true instead INDEX NAME DESCRIPTION STARS OFFICIAL AUTOMATED docker.io docker.io/mysql/mysql-server Optimized MySQL Server Docker images. Crea... 683 [OK] docker.io docker.io/centurylink/mysql Image containing mysql. Optimized to be li... 61 [OK] #limit限制搜索出的结果条数 [root@localhost ~]# docker search --limit 3 mysql INDEX NAME DESCRIPTION STARS OFFICIAL AUTOMATED docker.io docker.io/mysql MySQL is a widely used, open-source relati... 9289 [OK] docker.io docker.io/mysql/mysql-server Optimized MySQL Server Docker images. Crea... 683 [OK] docker.io docker.io/circleci/mysql MySQL is a widely used, open-source relati... 19 #--filter限制IS-AUTOMATED或IS-OFFICIAL [root@localhost ~]# docker search --filter is-automated=false --filter is-official=false mysql INDEX NAME DESCRIPTION STARS OFFICIAL AUTOMATED docker.io docker.io/centos/mysql-57-centos7 MySQL 5.7 SQL database server 71 docker.io docker.io/mysql/mysql-cluster Experimental MySQL Cluster Docker images. ... 66 docker.io docker.io/tutum/mysql Base docker image to run a MySQL database ... 34 docker.io docker.io/linuxserver/mysql A Mysql container, brought to you by Linux... 24 docker.io docker.io/centos/mysql-56-centos7 MySQL 5.6 SQL database server 19 docker.io docker.io/circleci/mysql MySQL is a widely used, open-source relati... 19 docker.io docker.io/mysql/mysql-router MySQL Router provides transparent routing ... 14 docker.io docker.io/databack/mysql-backup Back up mysql databases to... anywhere! 13 docker.io docker.io/openshift/mysql-55-centos7 DEPRECATED: A Centos7 based MySQL v5.5 ima... 6 docker.io docker.io/devilbox/mysql Retagged MySQL, MariaDB and PerconaDB offi... 2 docker.io docker.io/jelastic/mysql An image of the MySQL database server main... 1 docker.io docker.io/monasca/mysql-init A minimal decoupled init container for mysql 0 #-s限制star数 [root@localhost ~]# docker search mysql -s 5000 Flag --stars has been deprecated, use --filter=stars=3 instead INDEX NAME DESCRIPTION STARS OFFICIAL AUTOMATED docker.io docker.io/mysql MySQL is a widely used, open-source relati... 9289 [OK] #拉取镜像命令,镜像名:版本号\t如果不加版本号默认最新版本 [root@localhost /]# docker pull mysql Using default tag: latest Trying to pull repository docker.io/library/mysql ... Get https://registry-1.docker.io/v2/: net/http: request canceled (Client.Timeout exceeded while awaiting headers) #docker的默认源在国外，响应时间过长，拉取被取消 #可以修改docker的镜像源，文件位置在 /etc/docker/daemon.json #修改为使用网易的docker镜像源 { \u0026#34;registry-mirrors\u0026#34;: [\u0026#34;http://hub-mirror.c.163.com\u0026#34;] } #修改后再次拉取，不加版本默认lastest版本 [root@localhost /]# docker pull mysql Using default tag: latest Trying to pull repository docker.io/library/mysql ... latest: Pulling from docker.io/library/mysql 68ced04f60ab: Pull complete f9748e016a5c: Pull complete da54b038fed1: Pull complete 6895ec5eb2c0: Pull complete 111ba0647b87: Pull complete c1dce60f2f1a: Pull complete 702ec598d0af: Pull complete 4aba2fcbe869: Pull complete b26bbbd533e6: Pull complete 7bd100a66c55: Pull complete 74149336419a: Pull complete 145ea1f01648: Pull complete Digest: sha256:4a30434ce03d2fa396d0414f075ad9ca9b0b578f14ea5685e24dcbf789450a2c Status: Downloaded newer image for docker.io/mysql:latest #查看本地镜像,默认显示隐藏中间镜像,可带参数 -a --digests --no-trunc -q\t-q表示显示镜像id [root@localhost /]# docker images REPOSITORY TAG IMAGE ID CREATED SIZE docker.io/mysql latest 9b51d9275906 2 weeks ago 547 MB [root@localhost ~]# docker images -q 9b51d9275906 #删除镜像docker rmi -f 镜像ID或docker rmi -f 镜像ID：TAG或docker rmi -f 镜像ID：TAG 镜像ID：TAG [root@localhost ~]# docker rmi -f 9b51d9275906 Untagged: docker.io/mysql:latest Untagged: docker.io/mysql@sha256:4a30434ce03d2fa396d0414f075ad9ca9b0b578f14ea5685e24dcbf789450a2c Deleted: sha256:9b51d9275906910446e03bb86e16a0fe0051d6518ba7ae39c8780fc2323fd637 Deleted: sha256:3b5f20d41feb31513164dab347e9f5bea57dc9c644819aeea2dd5cbb7c7213bf Deleted: sha256:0c9402cadbef6d34b3c8db27a0d793011c2de41cabc14354734752ec7bd325c1 Deleted: sha256:177c77529402c2687f69bb1cb16c1d6c82351e9f0ab5e7729d48ffab311b85be Deleted: sha256:67ef0899247f5e0163e7592aeff6a5ecfe644a67e465c207234153ff8ffc5be0 Deleted: sha256:85437a1ff817195eff1881a5b2d12bc0e17fa299cbba52cc6e2bb23f27d160bd Deleted: sha256:1dc77e60e1b82d40abf76f305b0854f0e3ad0352f7e18372344b955b84dfe9f5 Deleted: sha256:f145e1f715e622fbdb1677a24ca723e52a4bd921ad656faab61f537d3f326c4a Deleted: sha256:b1dbb44d9f303b7b24defc06cc8b6c58a38a0c3ed7e917adc309d5a75926dace Deleted: sha256:c92180bc575fea05e5dd83cbad7d2fd1852732f162b00818b101b2baabda04ac Deleted: sha256:c8420ebfba3078cd14bed76ee7d244b6ce4abad47f4f4843682eea6f03bd575e Deleted: sha256:bbb9cccab59a16cb6da78f8879e9d07a19e3a8d49010ab9c98a2c348fa116c87 Deleted: sha256:f2cb0ecef392f2a630fa1205b874ab2e2aedf96de04d0b8838e4e728e28142da #使用docker rmi -f $(docker images -q) $(docker images -q)即查出所用镜像ID，再进行删除 [root@localhost ~]# docker rmi -f $(docker images -q) Untagged: docker.io/tomcat:latest Untagged: docker.io/tomcat@sha256:b707d3b8b4f40951ca2f387c24ab9f78800c69c90740f0cca937a1b95204b3a4 Deleted: sha256:a7fa4ac97be4e70160f145599507a72b1ce91c4ceeb7ba164b757a631419b0d6 Deleted: sha256:76b28be2f8143a7c6a2e157cdf2b35130910f17aa8a4acfbea7c8a7d14c89d72 Deleted: sha256:17581028ef98984e5ce75b03ddc1ff4cb39d3378fe5d11a4eca94af3f998ff93 Deleted: sha256:e92ef8cef8f8f4531a678cee9d5cfda64cd2da64306d1c35e1611a7b0141d38b Deleted: sha256:5f7dc856e7f86af866f8248c928085fa93378d31ad8cc2af5f979874d2eec86a Deleted: sha256:ac3fa431f3550b5e1fc12ff79543a6426eff374fbf83917a038e7ec9a4f5eb2c Deleted: sha256:3072865e3a6e7586b8d1b4f30a1e610d1ac6d073d24728ca8043add4e9cd220f Deleted: sha256:9fdf9669f254a9165f7bbcaf4b4bd7b2b13f330e9ba24c44196a8864515fe8f1 Deleted: sha256:a7b99d1f9971254f00f4260842ca6280291150f3e181a045447f1dfc82b028cb Deleted: sha256:e26c0a912839cb72ad7ee298a3b850e8b80bf10d7f9236ca418aee240270fde1 Deleted: sha256:1c76bd0dc3255e65f07a8a5f12cecc85b2a9866bb5b33528462c83e1c1e48ab4 Docker容器命令 #使用镜像新建并启动容器docker run [OPTIONS] IMAGE [COMMAND] [ARG] OPTIONSkex可选参数，有--name为容器命名，-d以后台进程方式启动，-i以交互式方式启动容器，-t为容器分配一个伪终端，-p指定端口映射形式为hostPort：containerPort, -e指定容器启动后容器内的环境变量， --network可以指定启动的容器使用哪个docker network会自动分配ip，并且设置了容器名和ip的映射关系 #使用docker run -v指定挂载时，不能用相对目录，如 docker run -v config.xml:/etc/config.xml xxx 会报错 改为：docker run -v $PWD/config.xml:/etc/config.xml xxx [root@localhost ~]# docker run -it centos /bin/bash #退出容器exit为直接退出，退出后容器停止，使用ctrl+P+Q退出会容器会在后台运行 [root@12133e6bd7f1 /]# exit exit #对于foreground容器，由于其只是在开发调试过程中短期运行，其用户数据并无保留的必要，因而可以在容器启动时设置--rm选项，这样在容器退出时就能够自动清理容器内部的文件系统 #docker run -w path -w参数用于指定工作目录 [root@localhost ~]# docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES [root@localhost ~]# [root@238d3fc941cb /]# [root@localhost ~]# [root@localhost ~]# docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 238d3fc941cb centos \u0026#34;/bin/bash\u0026#34; 13 seconds ago Up 11 seconds romantic_davinci #启动停止的容器 [root@localhost ~]# docker start 12133e6bd7f1 12133e6bd7f1 [root@localhost ~]# #停止容器 [root@localhost ~]# docker stop 12133e6bd7f1 12133e6bd7f1 #重启容器 [root@localhost ~]# docker restart 12133e6bd7f1 12133e6bd7f1 #强制停止容器 [root@localhost ~]# docker kill 12133e6bd7f1 12133e6bd7f1 #删除镜像docker rm -f 镜像ID或docker -rm -f $(docker ps -qa)删除所有镜像 [root@localhost ~]# docker rm -f $(docker ps -qa) 238d3fc941cb 12133e6bd7f1 #查看容器日志docker logs 容器ID -t -f --tail -t表示打印时间戳，-f表示跟随打印最新消息，--tail表示显示多少行 [root@localhost ~]# docker logs -f 6ec5b1ff99b8 25-Mar-2020 07:07:16.350 INFO [main] org.apache.catalina.startup.VersionLoggerListener.log Server version name: Apache Tomcat/8.5.53 25-Mar-2020 07:07:16.361 INFO [main] org.apache.catalina.startup.VersionLoggerListener.log Server built: Mar 11 2020 10:01:39 UTC 25-Mar-2020 07:07:16.361 INFO [main] org.apache.catalina.startup.VersionLoggerListener.log Server version number: 8.5.53.0 25-Mar-2020 07:07:16.361 INFO [main] org.apache.catalina.startup.VersionLoggerListener.log OS Name: Linux 25-Mar-2020 07:07:16.361 INFO [main] org.apache.catalina.startup.VersionLoggerListener.log OS Version: 3.10.0-1062.el7.x86_64 #--since指定查询指定时间之后的日志 --until指定查询时间之前的日志 时间戳必须是 2021-12-15T12:56:30.309227015Z 这种格式 docker logs --since=2021-12-15T12:56:30.309227015Z --until=2021-12-15T12:56:30.309227015Z xxx #如果你使用 grep 会发现根本不起作用，因为 docker logs 命令并没有将日志打印到标准输出，这里我们需要先重定向下。 docker logs \u0026lt;container-id\u0026gt; 2\u0026gt;\u0026amp;1 | grep \u0026#39;grep thing\u0026#39; #以命令交互的方式进入正在运行的容器docker exec -it 容器ID /bin/bash或docker attach 容器ID [root@localhost ~]# docker attach 61872b9e7bb5 [root@61872b9e7bb5 /]# [root@localhost ~]# docker exec -it 61872b9e7bb5 /bin/bash [root@61872b9e7bb5 /]# 使用别名访问容器\ndocker run -it --name centos-1 docker.io/centos:latest docker run -it --name centos-2 --link centos-1:centos-1 docker.io/centos:latest --link：参数中第一个centos-1是容器名，第二个centos-1是定义的容器别名（使用别名访问容器），为了方便使用，一般别名默认容器名。 设置docker容器自启动\n#这种方式设置的自启动是docker restart/start 之后容器自启动，不是docker stop之后 #开启容器自启动 docker update cf877cb5ea48 9120211fed93 --restart=always #关闭容器自启动 docker update cf877cb5ea48 9120211fed93 --restart=no 删除所有已经停止运行的容器\n#查找出所有已经停止运行容器的ID,awk是linux下的一个文本分析工具，print $1 是打印安装tab分割每一行后的第一个参数 docker ps -a|grep Exited|awk \u0026#39;{print $1}\u0026#39; #删除 docker rm -f `docker ps -a|grep Exited|awk \u0026#39;{print $1}\u0026#39;` docker构建镜像 docker build -t 镜像名：版本号 -f Dockerfile文件地址 .\n最有一个 . 代表上下文路径，即在构建镜像的时候会把该目录下的文件拷贝到镜像中\n#创建Dockerfile文件 # build FROM golang AS build WORKDIR /gowork ADD . . ENV GOPROXY=https://goproxy.cn,direct ENV GOOS=linux #要使用alpine运行二进制必须指定 CGO_ENABLED=0 RUN CGO_ENABLED=0 go build -mod=mod -o /gowork/driver-weighing-adapter FROM alpine:3.9 # Define maintainer directories. MAINTAINER litao \u0026#34;taoli@yunify.com\u0026#34; # Define working directory. WORKDIR /data COPY --from=build /gowork/driver-weighing-adapter . # Define default command. ENTRYPOINT [\u0026#34;/data/driver-weighing-adapter\u0026#34;,\u0026#34;serve\u0026#34;] #构建镜像,注意版本号有v docker build -f Dockerfile -t dockerhub.qingcloud.com/iot_demo/driver-weighing-adapter:v0.31 . #登录私有仓库 docker login -u hexing dockerhub.qingcloud.com hexing #推送镜像到私有仓库 docker push dockerhub.qingcloud.com/iot_demo/driver-weighing-adapter:v0.31 network 在docker中程序都使用docker来部署，一个程序可能要使用mysql、redis、es等，那么如何使部署在docker中的程序能够连接到mysql、redis、es呢，这就需要使用到网络了，使用docker network ls可以查看已经创建好的docker网络，最常使用的bridge模式，该模式的工作原理是建立一个docker0网桥，给这个网桥分配一段私有ip地址，在启动容器时如果使用该docker网络，那么会创建一对网口，一个网口位于docker容器内部为eth0，另一个网口在网桥上为vthxxx，在这一对网口的任一口通信另一个都能收到，所以当多个容器都使用同一个docker network那么就可以进行通信了\n#查看docker网络 docker network ls #创建docker网络，其中-d用于指定网络的类型，可以省略默认为bridge docker network create -d bridge networkname #删除docker网络 docker network rm networkname #查看docker网络细节，如有哪些容器使用了该网络，他们分配到的ip是多少 docker network inspect dnetworkname #删除所有未使用的docker 网络 docker network prune volume #查看存在的数据卷 docker volume ls #查看volume细节 docker volume inspect volumename #创建volume,会在/var/lib/docker/volumes/volumename/_data创建挂载点用于和容器内部连接 docker volume create volumename #删除volume docker volume rm volumename #删除未使用的volume docker volume prune 配置docker镜像仓库加速 cd /etc/docker vim /etc/docker/daemon.json { \u0026#34;registry-mirrors\u0026#34;: [\u0026#34;https://docker.mirrors.ustc.edu.cn\u0026#34;,\u0026#34;http://hub-mirror.c.163.com\u0026#34;,\u0026#34;https://registry.docker-cn.com\u0026#34;] } :wq systemctl daemon-reload systemctl restart docker Dockerfile FROM 指定构建的镜像是基于哪个镜像\nRUN 用于执行命令，主要有两种格式：RUN command，相当于./command; RUN [\u0026quot;./command.sh\u0026quot;, \u0026ldquo;arg1\u0026rdquo;, \u0026ldquo;arg2\u0026rdquo;],相当于 ./command.sh arg1 arg2，每执行一条RUN docker在构建时都会构建一层镜像，所以过多无意义的层会导致最终构建的镜像庞大，所以有必要将多条RUN压缩成一条\nRUN ./command1.sh arg1 \\ \u0026amp;\u0026amp; ./command2.sh arg1 arg2 COPY 从上下文路径中把文件或目录复制到容器中的指定路径，如果COPY的文件不在上下文中，在docker build的时候会构建失败COPY failed: file not found in build context or excluded by .dockerignore\nCOPY中源路径不可使用绝对路径，如要把当前上下文中的某个子文件拷贝进容器，使用COPY ./xxx/yyy/ /root 、 COPY xxx/yyy/ /root、COPY xxx/yyy /root都可以,但是不可以使用COPY xxx/yyy .该命令会把yyy文件夹下的文件拷贝到WORKDIR而不是把yyy文件夹拷贝到WORKDIR\n注意文件是不是在 .dockerignore 文件中申明了\nCOPY [--chown=\u0026lt;user\u0026gt;:\u0026lt;group\u0026gt;] \u0026lt;源路径\u0026gt; \u0026lt;目标路径\u0026gt; --chown可选参数可以改变拷贝到容器中文件的所有者和所属组 文件路径支持通配符 ADD 和COPY命令类似，不同的是ADD会把tar压缩文件解压后复制到容器中的指定路径\nCMD 和RUN一样都是用来运行命令，但不同的是RUN是在docker build 的时候执行，而CMD是docker run的时候执行，当Dockerfile中有多个CMD命令时，仅最后一个生效，CMD命令会被docker run时指定的参数所覆盖\nENTRYPOINT\nENTRYPOINT [\u0026#34;\u0026lt;executeable\u0026gt;\u0026#34;, \u0026#34;\u0026lt;param1\u0026gt;\u0026#34;, \u0026#34;\u0026lt;param2\u0026gt;\u0026#34;] FROM nginx ENTRYPOINT [\u0026#34;nginx\u0026#34;, \u0026#34;-c\u0026#34;] # 定参 CMD [\u0026#34;/etc/nginx/nginx.conf\u0026#34;] # 变参,会被 docker run -it -p 80:80 nginx -c /root/nginx.conf 覆盖 #该Dockerfile写法有问题，定义ENTRYPOINT、CMD会破坏父镜像nginx中的ENTRYPOINT、CMD导致nginx无法启动 ENV 设置环境变量,设置的环境变量可以通过$key 在Dockerfile中引用\nENV \u0026lt;key\u0026gt; \u0026lt;val\u0026gt; ENV \u0026lt;key1\u0026gt;=\u0026lt;val1\u0026gt; \u0026lt;key2\u0026gt;=\u0026lt;val2\u0026gt; ... ARG 和ENV类似，不过ARG的作用域仅为Dockerfile，构建好的容器中并不会有该环境变量\nFROM busybox ARG arg1 arg2 ARG user docker build --build-arg user=what_user --build-arg arg1=value1 --build-arg arg2=value2 . 应用案例：通过 --build-arg 在构建镜像时传递参数使得二进制中包含版本信息\nFROM golang:1.17 as builder ARG VERSION GIT_DIR GIT_COMMIT GIT_BRANCH BUILD_DATE WORKDIR /workspace # Copy the Go Modules manifests COPY go.mod go.mod COPY go.sum go.sum # cache deps before building and copying source so that we don\u0026#39;t need to re-download as much # and so that source changes don\u0026#39;t invalidate our downloaded layer ENV GO111MODULE=on CGO_ENABLED=0 GOOS=linux GOARCH=amd64 GOPROXY=https://goproxy.cn,direct RUN go mod download # Copy the go source COPY main.go main.go COPY pkg/ pkg/ # Build RUN go build -gcflags \u0026#34;all=-N -l\u0026#34; -ldflags \u0026#34;-X $GIT_DIR/pkg/version.Version=$VERSION -X $GIT_DIR/pkg/version.BuildDate=$BUILD_DATE -X $GIT_DIR/pkg/version.GitCommit=$GIT_COMMIT -X $GIT_DIR/pkg/version.GitBranch=$GIT_BRANCH\u0026#34; -a -o manager main.go 构建镜像的时候传递版本信息\ndocker build -t ${IMG} --build-arg VERSION=${VERSION} --build-arg GIT_DIR=${GIT_DIR} --build-arg GIT_COMMIT=${GIT_COMMIT} --build-arg GIT_BRANCH=${GIT_BRANCH} --build-arg BUILD_DATE=${BUILD_DATE} . VOLUME 定义匿名数据卷，避免容器重启数据丢失，避免容器过大,用过这种方式指定的都是容器内的挂载点，无法指定宿主机的源目录，所以在构建成功启动容器后要使用docker inspect去查看挂在目录的Source\nVOLUME [\u0026#34;\u0026lt;path1\u0026gt;\u0026#34;, \u0026#34;\u0026lt;path2\u0026gt;\u0026#34;] EXPOSE 申明容器内部端口，用于在docker run -P 时会随机选用宿主机端口映射到这些容器内什么的端口 EXPOSE \u0026lt;port1\u0026gt; \u0026lt;port2\u0026gt; WORKDIR 指定工作目录，当docker容器启动时就在该目录下 docker compose 在https://github.com/docker/compose/releases去下载 赋予执行权限 移动到/usr/bin下 使用docker-compose verison验证 编写docker-compose文件\nvim docker-compose.yml 1 version: \u0026#34;3.0\u0026#34; 2 3 services: 4 tomcat: container_name: tomcat1 #相当于docker run 的 --name，指定了container_name后在同一个网桥中的容器可以使用 container_name代替ip 5 image: tomcat 6 ports: 7 - 8080:8080 volumes: #相当于docker run 的 -v - /root/webapps:/usr/local/tomcat/webapps networks: #相当于docker run的--network - hello #代表当前服务使用那么网桥 command: \u0026#34;xxxx\u0026#34; #覆盖容器默认命令 networks： #定义服务使用的网桥 hello： #创建网桥，默认为bridge，默认名称为项目名_网桥名 external: true #使用外部网桥，但是网桥必须存在，docker network -d bridge hello :wq portainer #安装 docker pull portainer/portainer #创建volume用于保存portainer的数据 docker volume create portainer_data #运行,-p 9000:9000用于映射portainer内部web访问页面，-v portainer_data:/data用于保存portainer数据，-v /var/run/docker.sock:/var/run/docker.sock用于映射docker的管理套接字到portainer内部来获取docker信息 docker run -d -p 9000:9000 -v portainer_data:/data -v /var/run/docker.sock:/var/run/docker.sock --name docker_portainer portainer/portainer namespace #lsns命令可以查看指定类型的namespace下的进程 lsns -t \u0026lt;namespace_type\u0026gt; #查看容器的pid号 docker inpsect xxx |grep -i pid #nsenter进入到指定pid号的进程的指定namespace中执行命令 nsenter -t \u0026lt;pid\u0026gt; --mount --uts --ipc --net --pid -user ip addr 使用阿里云代理拉取gcr docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/{group}-{project} docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/{group}-{project} gcr.io/{group}/{project} docker rmi registry.cn-hangzhou.aliyuncs.com/google_containers/{group}-{project} ","permalink":"https://moyuduo.github.io/posts/docker%E7%AE%80%E4%BB%8B%E5%8F%8A%E4%BD%BF%E7%94%A8/","summary":"Docker相关 为什么要使用Docker？ 想想在分布式项目中，Nginx后会有很多的服务器提供服务，并且当一些特殊的情况下我们需要对服务器进行扩容，假如我们要新增100台服务器，我们需要一个一个服务器都去装tomcat吗？每台都去进行相关配置吗？再想想我们学习开源项目，很多情况下都需要安装Mysql、Redis、MongoDB、Tomcat等，这时候一个一个去装，一个个去配置是不是很麻烦，Docker就为我们提供了一个简洁的方式完成这些工作。\n简介 Docker是一个开源的应用容器引擎；是一个轻量级容器技术；\nDocker支持将软件编译成一个镜像；然后在镜像中各种软件做好配置，将镜像发布出去，其他使用者可以直接使用这个镜像；\n运行中的这个镜像称为容器，容器启动是非常快速的。\n核心概念 docker主机(Host)：安装了Docker程序的机器（Docker直接安装在操作系统之上）；\ndocker客户端(Client)：连接docker主机进行操作；\ndocker仓库(Registry)：用来保存各种打包好的软件镜像；\ndocker镜像(Images)：软件打包好的镜像；放在docker仓库中；\ndocker容器(Container)：镜像启动后的实例称为一个容器；容器是独立运行的一个或一组应用；\n安装Docker 1）可以使用VmWare或VirtualBox\n2）安装好centos，内核版本必须是3.1以上，可以使用uname -r查看\n3）配置好网络，保证能连上外网\n4）使用yum命令安装docker\nyum install docker yum list installed|grep docker #卸载原有的docker yum remove -y docker-ce docker-ce-cli docker-ce-rootless-extras docker-scan-plugin containerd.io #删除镜像、容器、配置文件等内容 rm -rf /var/lib/docker #查询docker可按照版本 yum list docker-ce --showduplicates | sort -r # !!!亲测centos7.2下安装这个版本不会有问题 yum install -y docker-ce-17.06.2.ce-1.el7.centos 20.10.7-3 yum install -y docker-ce-20.10.7-3.el7.x86_64 containerd.io systemctl start docker docker run hello-world 5)安装的过程中会提示是否继续？[y/N]：y\t输入y即可\t最后出现完毕!即完成\n启动Docker #启动docker [root@localhost yum.","title":"Docker简介及使用"},{"content":"linux命令自查 查看cpu和内存 cpu个数 cat /proc/cpuinfo | grep \u0026#34;physical id\u0026#34; | uniq | wc -l cpu核数 cat /proc/cpuinfo | grep \u0026#34;cpu cores\u0026#34; | uniq cpu型号 cat /proc/cpuinfo | grep \u0026#39;model name\u0026#39; |uniq 内存大小 cat /proc/meminfo | grep MemTotal 设置linux开机自启动 linux文件/etc/rc.local文件中的内容会linux启动完成后执行，所以可以用来做开机自启动，/etc/rc.local默认是lrwxrwxrwx权限，但是由于它是/etc/rc.d/rc.local的一个软连接，所以/etc/rc.d/rc.local这个文件必须要有执行权限才能开机自启动，而这个人间默认是-rw-rw-rw-权限，所以必须要修改添加执行权限,注意在这个文件中添加开机执行死循环脚本时必须使用\u0026amp;后台执行。\n秒级检测脚本 #!/bin/bash while true do count=`ps -ef|grep etcd|grep -v grep|wc -l` if [ $count -eq 0 ]; then cd /opt/etcd-v3.5.0-linux-amd64 ./etcd -listen-client-urls=\u0026#34;http://0.0.0.0:2379\u0026#34; --advertise-client-urls=\u0026#34;http://0.0.0.0:2379\u0026#34; echo \u0026#34;restart etcd at $(date)\u0026#34; \u0026gt;\u0026gt; /opt/etcd-v3.5.0-linux-amd64/record fi sleep 1 done 原理是通过ps -ef|grep按照条件过滤执行的进程，再通过wc -l转换为进程个数，最后通过shell进行判断。\n这种方式本质上是通过循环来进行判断，相比于crontab而言，时间可以精确到秒，而crontab的最小单位是分钟\n单行命令直接增加cpu占有率到100% for i in `seq 1 $(cat /proc/cpuinfo |grep \u0026#34;physical id\u0026#34; |wc -l)`; do dd if=/dev/zero of=/dev/null \u0026amp; done 说明: cat /proc/cpuinfo |grep \u0026#34;physical id\u0026#34; | wc -l 可以获得CPU的个数,　我们将其表示为N。 seq 1 N 用来生成１到Ｎ之间的数字 for i in `seq 1 N`; 就是循环执行命令,从１到Ｎ dd if=/dev/zero of=/dev/null 执行dd命令,　输出到/dev/null, 实际上只占用CPU,　没有IO操作. 由于连续执行Ｎ个(Ｎ是ＣＰＵ个数)的dd 命令, 且使用率为100%,　这时调度器会调度每个dd命令在不同的CPU上处理. 最终就实现所有ＣＰＵ占用率100% 测试完毕后，必须使用top命令查看cpu使用率，并kill掉脚本的进程\nfind find path -option name option常用的有 name 按照名字查找文件，支持通配符 type 按照类型查找，d为目录、c为字节型文件、f一般文件、s为socket size ssh远程免密登录 #生成rsa秘钥 ssh-keygen #把id_rsa.pub文件拷贝打要远程登录的目标机器,并改名为authorized_keys #在拷贝前一定要保证有/root/.ssh这个目录，可以是用ssh-keygen生成秘钥对来创建该目录，也可以手动创建该目录 scp id_rsa.pub root@192.168.37.152:/root/authorized_keys #配置完成后测试 ssh root@192.168.37.152 \u0026#34;ls -l /root\u0026#34; #或 ssh 192.168.37.152 \u0026#34;ls -l /root\u0026#34; 配置hosts本地DNS vim /etc/hosts #添加 ip\t域名 防火墙操作 #开放端口 firewall-cmd --add-port=9092/tcp --permanent #重新加载防火墙配置 firewall-cmd --reload #查询端口释放开放 firewall-cmd --query-port=9092/tcp #关闭端口 firewall-cmd --remove-port=9092/tcp --permanent shell脚本中使用其他用户执行脚本 #切换用户执行命令 su - user -c command #切换用户执行一个shell脚本 su - user -s /bin/bash xxx.sh #参考：https://www.cnblogs.com/bigben0123/archive/2013/05/07/3064843.html 配置yum源 cd /etc/yum.repos.d/ curl -O http://mirrors.aliyun.com/repo/Centos-7.repo #备份原来的yum源 mv CentOS-Base.repo CentOS-Base.repo.bak #修改yum源为下载的yum源 mv Centos-7.repo CentOS-Base.repo yum clean all yum makecache yum update wsl下ubuntu设置密码找回密码 cmd打开powershell 输入ubuntu按tab选择要重置的虚拟机 ubuntu.exe conifg \u0026ndash;default-user root 打开ubuntu,会切换指定用户登录且不需要密码，passwd修改密码 ubuntu更新apt源 在https://opsx.alibaba.com/mirror找到对应的ubuntu版本 sudo mv /etc/apt/sources.list /etc/apt/sources.list_backup 将 sources.list 文件备份 sudo vim /etc/apt/sources.list写入配置 sudo apt-get update 更新apt软件源 vim vim模式：\n普通默认：使用vim进来默认就是 view模式：按v进入，可以使用HJKL来移动光标选择文本 view line模式：按V进入，使用JK可上下移动光标来按行选择文本 插入默认：按i、a、o都可进入，可以插入文本 在vim的普通模式中可以使用HJKL四个键来控制光标的上下左右移动，H是光标左移、J是光标下移、K是光标上移、L是光标右移\n在普通模式下，按b键会跳转到单词的开头或上一个单词开头(当前以及处于单词开头),按w键会跳转到下一个单词的开头\n在普通模式下可以使用f+字符来对当前行光标之后进行查找包含当前查找字符的下一处，查找到会把光标移动到下一处对应的查找字符，并且可以使用；键来继续在当前行向后查找，使用，键来在当前行向前查找\n在普通模式下使用F+字符来对当前行光标之前查找包含当前查找字符的上一处\n可以使用:set nu来设置vim显示行号，但是这种方式退出后再次进入就失效了，可以在当前用户的家目录下建立.vimrc文件来设置当前用户的个人vim设置，也可建立/etc/vimrc来配置系统级别的vim设置\n使用:set nonu来取消vim行号显示\n在view模式下，按iw可以选中当前单词，按aw可以选中当前单词及后面的所有空格\n在普通模式下按d、c、y、v都可以进入对应的待决模式\nd是删除模式，例如要删除一个单词就可以使用diw或者daw\nc是修改模式，也是用于删除，例如：ciw或caw就可删除一个单词，它与删除模式不同的是，删除模式删除之后还是在普通模式，而修改模式删除之后就进入插入模式\ny是复制模式，可以使用yiw或yaw来复制一个单词，然后使用p来粘贴\n使用m + 符号来设置一个标记，然后可以使用` + 符号 来快速跳转到标记的位置\n普通模式下按V进入view line模式使用，JK来选择一个范围的内容，按y进行赋值，然后可以p进行粘贴\n在普通模式下可以使用ctl + b向上翻页，ctl + f向下翻页，ctl + u向上翻半页，ctl + d向下翻半页\n在普通模式下输入:/pattern 来进行查找，查找到的单词会高亮显示，可以按n来进行跳转，可以使用:/xxx来搜索一个不存在的关键词或：noh来取消高亮显示\n在普通模式下输入:%s/pattern/string/g 来进行全局的替换，其中pattern是待替换的词，string是替换后的词\n在普通模式下可以使用gg来跳转到首行第一个字符，使用G可以跳转到最后一行最后一个字符，使用：n可以跳转到指定行，n为行号\n在普通模式下按0可以跳转当前行的行首，按$即ctl + 4可以跳转到行末\n使用:e! 来退出文档编辑并重新打开文档\n使用ngg或nG或:n 来跳转到指定的行，n为行号\n用户管理 #添加用户 useradd [options] \u0026lt;user_name\u0026gt; options: -d 指定家目录，默认会在/home目录下创建和用户名同名的家目录，如果给用户指定的家目录不存在可以使用-m参数指定不存在就创建 -g 指定用户所属的组，如果指定的组不存在则创建失败，一个用户只能所属与一个组 #删除用户 userdel [options] \u0026lt;user_name\u0026gt; options: -r 会把用户的家目录一并删除 #修改用户，主要是修改用户相关组合家目录，并不是修改名字 usermod [options] \u0026lt;user_name\u0026gt; 参数options和useradd的类似,但是可以使用-l参数来修改用户名,ex：usermod -l new_name old_name #添加组 groupadd [options] \u0026lt;group_name\u0026gt; options: -g 指定组编号 #删除分组 groupdel \u0026lt;group_name\u0026gt; #修改组 groupmod [options] \u0026lt;group_name\u0026gt; options:和groupadd类似但是可以使用-n参数来修改组名,ex：groupmod -n new_group_name old_group_name #用户密码管理 passwd [options] \u0026lt;user_name\u0026gt; 如果不指定参数的话那么可以给用户设置密码，如果指定参数的话则用户下次登录就要相关限制 options: -d 删除密码，以后该用户登录就没有密码了 -l 锁定账户 -u 解锁账户 -f 强制执行 tail 查看文件末内容\n#默认显示文件的最后10行 tail /filename #-f参数可使循环读取，在读取日志文件时可以实时查看日志 tail -f xxx.log #-n参数可以指定显示文件末的行数，默认为10 tail -n 20 -f xxx.log linux链接 硬连接：多个文件的副本，会随任意文件的修改而修改，但是删除其中的文件，并不会影响其他文件\n软连接：软连接相当于创建了一个快捷方式，删除软连接不影响源文件\necho \u0026#34;init\u0026#34; \u0026gt; f1.txt #对f1.txt创建名为f2.txt的硬连接 ln f1.txt f2.txt # -s参数指定创建软连接 ln -s [链接指向的目标] [软链接名称] ln -s f1.txt f3.txt ls -li 1094956 -rw-rw-r-- 2 aiiqh aiiqh 5 Oct 13 12:01 f1.txt 1094956 -rw-rw-r-- 2 aiiqh aiiqh 5 Oct 13 12:01 f2.txt #inode号相同 1094958 lrwxrwxrwx 1 aiiqh aiiqh 6 Oct 13 12:01 f3.txt -\u0026gt; f1.txt rm -f f1.txt cat f2.txt #init cat f3.txt #cat: f3.txt: No such file or directory 查看文件夹内文件大小 cd / du -h --max-depth=1 nc 用于快速启动一个tcp或udp服务器\n#安装 yum install -y nc #使用-l xxx参数用于启动一个在指定端口上的tcp(默认)服务 nc -l 5000 #使用-w xxx参数指定建立连接的超时时间 nc -l 5000 -w 5 #使用nc ip 端口号 来与外部tcp服务建立连接 nc 127.0.0.1 22 #使用-k参数来指定允许多个连接，不指定该参数默认只允许建立一个链接 nc -l 5000 -k #使用-v参数来显示详细信息 nc -l 5000 -v #使用-u参数来指定使用udp，不使用该参数默认使用tcp nc -l 5000 -uv nc -u 127.0.0.1 5000 #使用-p参数来指定使用的源端口 nc -u -p 8888 127.0.0.1 5000 lsns lsns用于查看linux下的namespace\nlsns -t {namespace} lsns -t pid lsns -t net brctl [root@centos72 ~]# brctl -bash: brctl: command not found yum install -y bridge-utils #创建虚拟网桥 brctl addbr br0 #查看 ip a 11: br0: \u0026lt;BROADCAST,MULTICAST\u0026gt; mtu 1500 qdisc noop state DOWN group default qlen 1000 link/ether 92:47:2a:9f:bf:3f brd ff:ff:ff:ff:ff:ff #关闭STP(生成树协议)因为我们只有一个路由器，是绝对不可能形成一个环的 brctl stp br0 off #添加以太物理接口 brctl addif br0 ens33 #删除网桥物理接口 brctl delif br0 ens33 #给网桥分配一个ip地址 ifconfig br0 172.18.0.1 #启用网桥 ifconfig br0 up #关闭网桥 ifconfig br0 down #删除网桥 brctl delbr b grep grep用于过滤字符，适用于进行日志查询，grep不会一次把所有内容加载到内存，而是一次加载一部分进行匹配后继续向下匹配，相较于cat、vim、more更适用于大量日志分析。\n-C 参数用于指定显示匹配内容上下文的行数，即匹配内容的上下n行都会输出 grep -C 5 \u0026#39;aaa\u0026#39; text -B参数指定显示匹配内容及前n行 -A参数指定显示匹配内容及后n行 -I 忽略大小写 -o 只显示匹配的内容 -c 统计过滤到的内容的行数 -n 显示行号 -v 剔除匹配到的内容 - w 精确 #基础正则，直接用grep就可以使用 . 表示任意字符 grep \u0026#39;A.C\u0026#39; text #可匹配ABC A1C A+C ... ^ 匹配行开头 $ 匹配行结尾 ^$ 匹配空行 * 表示前一个字符出现0次或0次以上 .* 表示匹配任意字符，包括空行 0* 会匹配到任意字符，因为*表示0个或0个以上字符，所以可以匹配到空字符，而每个行都有空字符 [] 中括号表示匹配中括号的内的任一字符，中括号内如果有特殊字符，那么这些字符都被去除特殊含义 grep \u0026#39;[abc]123\u0026#39; #可以匹配 a123 b123 c123 grep \u0026#39;[a-c]123\u0026#39; #同上 grep \u0026#39;[abc|.,]123\u0026#39; #中括号内的 | . , 都被去除特殊含义，可以匹配到 |123 .123 ,123 #扩展正则，使用grep -E 或 egrep + 前一个字符出现了0次以上 | 表示或者 grep -E \u0026#39;abc|123\u0026#39; #匹配abc 或 123 () 作为一个整体，可看做一个字符 grep -E \u0026#39;a(b|c)d\u0026#39; #匹配 abd 或 acd {m,n} 表示前一次字符出现几次 grep -E \u0026#39;abc{1,3}\u0026#39; #c出现1次以上3次即一下 匹配 abc abcc abccc grep -E \u0026#39;abc{1,}\u0026#39; #只指定最少出现几次，而不指定上界 grep -E \u0026#39;abc{,3}\u0026#39; #只指定上界，而不指定下界 grep -E \u0026#39;abc{1}\u0026#39; #恰好出现几次 ，匹配abc grep -E \u0026#39;(a{1,}b{1,}c{1,}){1,}\u0026#39; #匹配 abc aabbcc aabbccc ? 指定前一个字符出现0次或一次 grep -E \u0026#39;abc?\u0026#39; #匹配ab 或 abc EOF 向文件test.sh里输入内容\n[root@slave-server opt]# cat \u0026lt;\u0026lt; EOF \u0026gt;test.sh 123123123 3452354345 asdfasdfs EOF cat \u0026lt;\u0026lt; EOF \u0026gt; test.go package main import ( \u0026#34;fmt\u0026#34; \u0026#34;runtime\u0026#34; ) func main() { fmt.Println(\u0026#34;cpu:\u0026#34;, runtime.NumCPU()) } EOF alias 设置别名:\nalias k=\u0026#39;kubectl\u0026#39; 查看已经设置的别名：\nalias -p 删除别名：\nunalias k 设置别名每次登陆可用：\n默认使用 alias 设置的别名仅本次登陆有效，如果想每次登陆都能使用别名，可以把alias设置别名的命令放在~/.bashrc文件中。\n清空文件内容 使用vi/vim打开文件，输入%d即清空,:wq保存即可 使用cat /dev/null \u0026gt; file 使用echo \u0026quot;\u0026quot; \u0026gt; file shell脚本中路径问题 在shell中如果通过$PWD获取路径，那么获取到的值是指向shell脚本时的路径,如test.sh脚本在/etc路径下，但是执行的时候是在/root路径下执行./etc/test.sh那么$PWD获取到的值就是/root\nbase64 base64加密 base64 \u0026lt;file_name\u0026gt; echo \u0026#34;abc\u0026#34; | base64 base64解码 base64 -d \u0026lt;file_name\u0026gt; echo \u0026#34;YWJjCg==\u0026#34; | base64 -d 环境变量 KUBECONFIG=config.yaml k get ns #暴露的环境变量仅改行命令有效 export KUBECONFIG=config.yaml #暴露的环境变量当前终端有效，新开的终端对该环境变量不可见 k get ns 常用快捷键 #清屏 ctrl + l #跳转到上一条历史命令,相当于 ↑键 ctrl + p #跳转到下一条命令,相当于 ↓键 ctrl + n #删除光标指向字符 ctrl + d #命令行中向前移动一个字符 ctrl + b #命令行中向后移动一个字符 ctrl + f #命令行中向前移动一个单词 alt + b #命令行中向后移动一个单词 alt + f #移动到命令行最前端 ctrl + a #移动到命令行最后端 ctrl + e #停止记录命令行输入 ctrl + s #回复记录命令行输入 ctrl + q #根据关键字搜索历史命令，如果有多条命令被匹配到可以ctrl + r 进行切换选择，然后按tab可以把该命令显示到命令行，或者直接enter直接执行该命令 ctrl + r 查看端口占用 # -a 参数列出所有状态的端口占用，监听的端口、已建立连接的端口 # -n 参数不进行name解析显示ip地址 # -p 参数显示端口相关程序的pid # -t 参数显示tcp相关的端口占用 # -u 参数显示udp相关的端口占用 netstat -anp 脚本后台运行 使用\u0026amp;在终端断连之后继续执行:sh test.sh \u0026gt; test.log \u0026amp; 使用nohup加\u0026amp;可以在终端断连之后继续执行：nohup sh test.sh \u0026gt; test.log \u0026amp; linux运行级别 # 0 关机 # 1 单用户 # 2 多用户，无网络模式 # 3 完全多用户模式 # 4 用户自定义级别 # 5 图形化界面多用户 # 6 重启 runlevel N 3 init 命令加对应的级别可以切换到不同的级别 init 6 正则 标准正则 匹配开头\n[root@centos72 shell_t]# cat /etc/passwd |grep ^a adm:x:3:4:adm:/var/adm:/sbin/nologin 匹配结尾\n[root@centos72 shell_t]# cat /etc/passwd |grep n$ bin:x:1:1:bin:/bin:/sbin/nologin daemon:x:2:2:daemon:/sbin:/sbin/nologin adm:x:3:4:adm:/var/adm:/sbin/nologin . 号,匹配任意一个字符\n[root@centos72 shell_t]# cat /etc/passwd |grep r..t root:x:0:0:root:/root:/bin/bash operator:x:11:0:operator:/root:/sbin/nologin ftp:x:14:50:FTP User:/var/ftp:/sbin/nologin dockerroot:x:991:988:Docker User:/var/lib/docker:/sbin/nologin * 号，不单独使用，表示匹配*号之前的字符0次或多次\n#ro*t 匹配 rot root roooot [root@centos72 shell_t]# cat /etc/passwd |grep ro*t root:x:0:0:root:/root:/bin/bash operator:x:11:0:operator:/root:/sbin/nologin dockerroot:x:991:988:Docker User:/var/lib/docker:/sbin/nologin .* 匹配任意一个字符任意次，即匹配任意字符串\n[root@centos72 shell_t]# cat /etc/passwd |grep r.*t root:x:0:0:root:/root:/bin/bash operator:x:11:0:operator:/root:/sbin/nologin ftp:x:14:50:FTP User:/var/ftp:/sbin/nologin [] 匹配字符区间\n[6,8] 匹配6或者8 [0-9] 匹配0-9的任意数字 [^0-9] 匹配任意非数字字符 [0-9]* 匹配任意数字串 [a-z] 匹配a-z的字符 [a-Z] 匹配a-Z的任意字符 [root@centos72 shell_t]# cat /etc/passwd |grep r[a-z]*t root:x:0:0:root:/root:/bin/bash operator:x:11:0:operator:/root:/sbin/nologin sshd:x:74:74:Privilege-separated SSH:/var/empty/sshd:/sbin/nologin rabbitmq:x:997:995:RabbitMQ messaging server:/var/lib/rabbitmq:/bin/bash gitlab-prometheus:x:992:989::/var/opt/gitlab/prometheus:/bin/sh dockerroot:x:991:988:Docker User:/var/lib/docker:/sbin/nologin \\转义\n#匹配$ grep \\$ test.sh 扩展正则 {}指定前一个字符出现几次\n{n}这种写法是扩展正则，grep使用扩展正则需要加 -E 参数 [root@centos72 shell_t]# grep -E ro{2}t /etc/passwd root:x:0:0:root:/root:/bin/bash operator:x:11:0:operator:/root:/sbin/nologin dockerroot:x:991:988:Docker User:/var/lib/docker:/sbin/nologin #{n,}匹配前一个字符至少n次 [root@centos72 shell_t]# grep -E \u0026#34;ro{0,}t\u0026#34; /etc/passwd root:x:0:0:root:/root:/bin/bash operator:x:11:0:operator:/root:/sbin/nologin dockerroot:x:991:988:Docker User:/var/lib/docker:/sbin/nologin #{,n}匹配前一个字符至多n次 [root@centos72 shell_t]# grep -E \u0026#34;ro{,2}t\u0026#34; /etc/passwd root:x:0:0:root:/root:/bin/bash operator:x:11:0:operator:/root:/sbin/nologin dockerroot:x:991:988:Docker User:/var/lib/docker:/sbin/nologin {n,m}匹配前一个字符n到m次 [root@centos72 shell_t]# grep -E \u0026#34;ro{1,2}t\u0026#34; /etc/passwd root:x:0:0:root:/root:/bin/bash operator:x:11:0:operator:/root:/sbin/nologin dockerroot:x:991:988:Docker User:/var/lib/docker:/sbin/nologin +号匹配前一个字符一次及以上\ncat \u0026lt;\u0026lt; EOF | grep -E \u0026#34;go+\u0026#34; g go goo goole EOF go goo goole ?号匹配前一个字符0次或一次\ncat \u0026lt;\u0026lt; EOF | grep -E \u0026#34;go?\u0026#34; g go goo goole EOF g #匹配到g go #匹配到go goo #匹配到go goole #匹配到go 匹配13开头的手机号码\ngrep -E \u0026#34;13[0-9]{9}\u0026#34; phone.txt cat cat命令用来查看一个文件的内容\ncat test.sh cat命令配合EOF加输出重定向可以向文件中写入内容\ncat \u0026lt;\u0026lt;EOF \u0026gt; test.sh name=\u0026#34;tom\u0026#34; echo \u0026#34;hello,\\${name}!\u0026#34; #在EOF中使用$需要加\\转移 EOF cat test.sh name=\u0026#34;tom\u0026#34; echo \u0026#34;hello, ${name}!\u0026#34; cut cut命令用于获取文件指定的列，并输出到标准输出\n#-d指定分隔符 -f指定列 cat \u0026lt;\u0026lt;EOF | cut -d \u0026#34; \u0026#34; -f 1 tom man 20 jerry female 18 jack man 25 EOF tom jerry jack cat \u0026lt;\u0026lt;EOF | cut -d \u0026#34; \u0026#34; -f 1,2 tom man 20 jerry female 18 jack man 25 EOF tom man jerry female jack man cat \u0026lt;\u0026lt;EOF | cut -d \u0026#34; \u0026#34; -f 1-2 tom man 20 jerry female 18 jack man 25 EOF tom man jerry female jack man cat \u0026lt;\u0026lt;EOF | cut -d \u0026#34; \u0026#34; -f -2 tom man 20 jerry female 18 jack man 25 EOF tom man jerry female jack man cat \u0026lt;\u0026lt;EOF | cut -d \u0026#34; \u0026#34; -f 2- tom man 20 jerry female 18 jack man 25 EOF man 20 female 18 man 25 获取ip地址\nifconfig ens33 |grep netmask |cut -d \u0026#34; \u0026#34; -f 10 192.168.37.131 grep grep用于配合正则按行过滤数据\ncat \u0026lt;\u0026lt;EOF | grep \u0026#39;go\u0026#39; g go goole EOF go goole # -E 指定使用扩展正则 cat \u0026lt;\u0026lt;EOF | grep -E \u0026#39;go+\u0026#39; g go goole EOF go #匹配到go goole #匹配到goo # -m 参数指定输出的最大行数 cat \u0026lt;\u0026lt;EOF | grep -m 1 -E \u0026#39;go+\u0026#39; g go goole EOF go # -c 参数指定输出匹配到的行数 cat \u0026lt;\u0026lt;EOF | grep -c -E \u0026#39;go+\u0026#39; g go goole EOF 2 # -i 参数指定忽略匹配正则的大小写 cat \u0026lt;\u0026lt;EOF | grep -i -E \u0026#39;go+\u0026#39; g go Go goole EOF go Go goole # -v 参数指定输出匹配到的行以外的行 cat \u0026lt;\u0026lt;EOF | grep -v -E \u0026#39;go+\u0026#39; g go Go goole EOF g Go # -w 参数指定正则要匹配整个单词 cat \u0026lt;\u0026lt;EOF | grep -w -E \u0026#39;go+\u0026#39; g go Go goole EOF go # -x 参数指定正则要匹配一整行的内容 cat \u0026lt;\u0026lt;EOF | grep -x -E \u0026#39;go+\u0026#39; g go go is good goole EOF go # -o 参数指定只显示匹配到的内容，对于同一行有多个匹配到的内容会隔行显示 cat \u0026lt;\u0026lt;EOF | grep -o -E \u0026#39;go+\u0026#39; g go go is good goole EOF go go goo goo sed sed针对文件的每一行进行处理，把一行读入放入模式空间，然后对模式空间的数据进行处理(增加/修改/删除)后输出到屏幕，直到处理完文件的每一行,处理完毕后并不会改变源文件，只会把处理后的结果输出到屏幕，改变源文件需要配合输出重定向\n-e 参数指定多次编辑(可以写多个规则) cat \u0026lt;\u0026lt;EOF \u0026gt; test.txt line1 name tom line2 age 20 line3 gender man EOF sed -e \u0026#34;1p\u0026#34; -n test.txt # p参数指定打印行为 -n参数取消默认打印，只输出匹配到的行 line1 name tom sed -e \u0026#34;/name/p\u0026#34; -n test.txt # 模糊匹配存在name的行 line1 name tom sed -e \u0026#34;/^line2/p\u0026#34; -n test.txt line2 age 20 sed -e \u0026#34;1,2p\u0026#34; -n test.txt # 1,2 指定第一行和第二行 line1 name tom line2 age 20 sed -e \u0026#34;2~1p\u0026#34; -n test.txt # 2~1 指定从第二行开始，已1步长匹配行 line2 age 20 line3 gender man sed -e \u0026#34;2~2p\u0026#34; -n test.txt line2 age 20 sed -e \u0026#34;2,+3p\u0026#34; -n test.txt # 2,+3 表示从第二行开始匹配向下三行(包括本行) line2 age 20 line3 gender man sed -e \u0026#34;2,\\$p\u0026#34; -n test.txt # 2,\\$ 表示匹配从第二行开始一直到结尾的行 line2 age 20 line3 gender man sed -e \u0026#34;1d\u0026#34; test.txt # d参数指定删除的行 line2 age 20 line3 gender man sed -e \u0026#34;1d\u0026#34; -e \u0026#34;s/age 20/age 30/g\u0026#34; test.txt # s参数指定进行替换，g是全局 line2 age 30 line3 gender man cat test.txt #源文件内容没有变 line1 name tom line2 age 20 line3 gender man sed -e \u0026#34;1a hight 170cm\u0026#34; test.txt # a参数指定在指定的行后添加一行/多行 line1 name tom hight 170cm line2 age 20 line3 gender man sed -e \u0026#34;1i weight 55kg\u0026#34; test.txt # i参数指定在指定的行前插入一行/多行 weight 55kg line1 name tom line2 age 20 line3 gender man #输出结果重定向 sed -e \u0026#34;1a hight 170cm\u0026#34; test.txt \u0026gt; test.txt -n 参数指定只输出匹配到的被处理的内容 sed -e \u0026#34;1p\u0026#34; -n test.txt # p参数指定打印行为 -n参数取消默认打印，只输出匹配到的行 line1 name tom -i 参数指定修改应用到源文件 cat test.txt line1 name tom line2 age 20 line3 gender man sed -i -e \u0026#34;s/age 20/age 30/g\u0026#34; test.txt cat test.txt line1 name tom line2 age 30 line3 gender man -r 参数指定开启扩展正则 cat \u0026lt;\u0026lt;EOF \u0026gt; test.txt go goo goole EOF sed -e \u0026#34;s/go+/x/g\u0026#34; test.txt # 不加-r参数由于+是扩展正则，所以不能匹配到任何的内容 go goo goole sed -r -e \u0026#34;s/go+/x/g\u0026#34; test.txt x x xle sed取ip地址 ifconfig ens33 | sed \u0026#39;2p\u0026#39; -n | sed \u0026#34;s/^.*inet//g\u0026#34; | sed \u0026#34;s/netmask.*$//g\u0026#34; 192.168.37.131 #前后有空格 ifconfig ens33 | sed -e \u0026#34;2s/^.*inet//\u0026#34; -n -e \u0026#34;s/netmask.*$//p\u0026#34; -n 192.168.37.131 awk awk通过正则过滤到匹配的行，然后对行进行切片(默认以空格)，然后对每个切片进行处理\n# -F 参数指定行分隔符 cat /etc/passwd | awk -F \u0026#34;:\u0026#34; \u0026#39;/^root/ {print $7}\u0026#39; /bin/bash cat /etc/passwd | awk -F \u0026#34;:\u0026#34; \u0026#39;/^root/ {print $1 \u0026#34;,\u0026#34; $7}\u0026#39; root,/bin/bash # BEGIN代码块在过滤之前执行 END代码块在过滤结束之后执行 cat /etc/passwd | awk -F \u0026#34;:\u0026#34; \u0026#39;BEGIN{print \u0026#34;start\u0026#34;}{print $1\u0026#34;=\u0026#34;$7}END{print \u0026#34;stop\u0026#34;}\u0026#39; start root=/bin/bash bin=/sbin/nologin daemon=/sbin/nologin stop cat /etc/passwd | awk -F \u0026#34;:\u0026#34; \u0026#39;{print $3+1}\u0026#39; 1 2 3 4 5 # 使用-v参数可以像awk中的变量赋值 cat /etc/passwd | awk -F \u0026#34;:\u0026#34; -v num=1 \u0026#39;{print $3+num}\u0026#39; # 内置变量 # FILENAME 文件名 # NR 行号 # NF 列号 cat /etc/passwd | awk -F \u0026#34;:\u0026#34; \u0026#39;{print \u0026#34;filename=\u0026#34;FILENAME, \u0026#34;row_number=\u0026#34;NR, \u0026#34;col_number\u0026#34;NF}\u0026#39; [root@centos72 shell_t]# cat /etc/passwd | awk -F \u0026#34;:\u0026#34; \u0026#39;{print \u0026#34;filename=\u0026#34;FILENAME, \u0026#34;row_number=\u0026#34;NR, \u0026#34;col_number\u0026#34;NF}\u0026#39; filename=- row_number=1 col_number7 filename=- row_number=2 col_number7 filename=- row_number=3 col_number7 awk截取ip\nifconfig | awk \u0026#39;/netmask/ {print $2}\u0026#39; 172.17.0.1 192.168.37.131 127.0.0.1 sort cat \u0026lt;\u0026lt;EOF \u0026gt; sort.txt aa:1:tom bb:0:jack dd:5:jarry cc:4:lucy ee:3:mike EOF sort sort.txt #按照字母序排序 aa:1:tom bb:0:jack cc:4:lucy dd:5:jarry ee:3:mike sort -r sort.txt #-r指定降序排序 ee:3:mike dd:5:jarry cc:4:lucy bb:0:jack aa:1:tom sort -t : -k 2 sort.txt #-t指定分隔符 -k指定对哪一列排序 bb:0:jack aa:1:tom ee:3:mike cc:4:lucy dd:5:jarry nohup nohup命令将程序以忽略挂起信号的方式后台运行，输出的结果不打印到终端而是保存在当前目录的nohup.out文件中，如果当前目录下的nohup.out文件无法写入会保存到$HOME/nohup.out文件中\nnohup ping baidu.com nohup: ignoring input and appending output to ‘nohup.out’ #进程会hang在这儿，不能执行其他命令，如果ctrl+c结束程序，那么执行的程序也会停止 nohup ping bilibili.com \u0026amp; nohup: ignoring input and appending output to ‘nohup.out’ #进程会hang在这儿,但是ctrl+c结束结束程序后，执行的程序不会停止 nohup ping baidu.com \u0026gt; ping.log \u0026amp; # 把程序的标准输出重定向到指定文件 nohup ping baidu.com \u0026gt;ping.log \u0026amp; # 标准输出 1 # 标准错误输出 2 nohup ping baidu.com \u0026gt; ping.log 2\u0026gt;\u0026amp;1 \u0026amp; # 把程序的标准输出及出错信息都写入到指定文件 nohup ping baidu.com \u0026gt; /dev/null 2\u0026gt;\u0026amp;1 \u0026amp; # 把程序的输出写入到linux的黑洞文件立即销毁 把程序的标准输出和标准错误输出写入文件\n# 把标准输出写入app.log,标准错误输出写入err.log nohup ping baidu.com \u0026gt; ping-app.log 2\u0026gt;ping-err.log \u0026amp; nohup ping baidu.com 1\u0026gt;ping-app.log 2\u0026gt;ping-err.log \u0026amp; # 把标准输出标准错误输出都写入app.log文件 nohup ping baidu.com \u0026gt; app.log 2\u0026gt;\u0026amp;1 \u0026amp; nohup ping baidu.com \u0026amp;\u0026gt;app.log \u0026amp; nohup 执行的命令后如果要结束程序就需要取查进程号kill\nps -ef|grep stdout UID PID PPID C STIME TTY TIME CMD aiiqh 798370 798026 0 09:26 pts/0 00:00:00 python3 stdout_stderr.py aiiqh 799200 798026 0 09:59 pts/0 00:00:00 grep --color=auto stdout kill 798370 定时任务 at at命令可用于执行定时任务，但是只执行一次，at定时任务的执行依赖atd后台服务，所以需要确保atd在后台运行\nat定时任务也只能精确到分钟\n[root@centos72 shell_t]# at 09:40 at\u0026gt; echo \u0026#34;$(date +%H:%M:%S)\u0026#34; \u0026gt; at.log at\u0026gt; \u0026lt;EOT\u0026gt; job 9 at Thu Oct 6 09:40:00 2022 batch batch命令用于在指定时间，当系统不繁忙时执行任务，用法与at相似\nbatch at\u0026gt; echo \u0026#34;$(date +%H:%M:%S)\u0026#34; \u0026gt; batch.log crontab crontab依赖crond后台进程每分钟检查一次定时任务进行执行 crond检查/var/spool/cron文件夹下的文件进行解析执行里面的定时任务，除此之外还会检查 /etc/cron.d目录以及 /etc/anaccrontab里面存放的是每小时、每天、每周、每月需要执行的定时任务\ncrontab -e * * * * * sh test.sh #第一个*是分钟 #第二个*是小时 #第三个*是天 #第四个*是月 #第五个*是星期几 # Example of job definition: # .---------------- minute (0 - 59) # | .------------- hour (0 - 23) # | | .---------- day of month (1 - 31) # | | | .------- month (1 - 12) OR jan,feb,mar,apr ... # | | | | .---- day of week (0 - 6) (Sunday=0 or 7) OR sun,mon,tue,wed,thu,fri,sat # | | | | | # * * * * * user-name command to be executed #特殊符号 # * 代表每的意思 * * * * * 代表每分钟执行一次 # - 代表范围的意思 1-10 * * * * 代表每小时的0到10分钟之内都执行意思 # , 代表分割 1,3,5 * * * * 代表每小时的第一、三、五分钟执行 # /n 每隔n执行 */5 * * * * 每五分钟执行一次 0 7-11/2 * * * 每天7点到11点每隔2小时执行一次 30 10/2 * * * 从10点30分开始每2小时执行一次 或者直接编辑 /var/spool/cron/root 要删除定时任务也可以 crontab -e 或者编辑 /var/spool/cron/root 删除 定时任务执行后会发送一个邮件给linux用户，使用(postfix服务),会提示you have mail in /var/spool/mail/root\nsu myd [myd@centos72 root]$ mailx -s \u0026#34;test\u0026#34; root hello, i am myd! . EOT exit [root@centos72 ~]# mail Heirloom Mail version 12.5 7/5/10. Type ? for help. \u0026#34;/var/spool/mail/root\u0026#34;: 1363 messages 1 new 1338 unread U1361 (Cron Daemon) Sun Oct 2 18:15 29/1053 \u0026#34;Cron \u0026lt;root@centos72\u0026gt; sh /root/shell_t/test.sh /root/shell_t /root/backup2\u0026#34; U1362 (Cron Daemon) Sun Oct 2 18:16 29/1053 \u0026#34;Cron \u0026lt;root@centos72\u0026gt; sh /root/shell_t/test.sh /root/shell_t /root/backup2\u0026#34; \u0026gt;N1363 myd@centos72.localdo Thu Oct 6 09:23 18/601 \u0026#34;test\u0026#34; \u0026amp; 1363 Message 1363: From myd@centos72.localdomain Thu Oct 6 09:23:49 2022 Return-Path: \u0026lt;myd@centos72.localdomain\u0026gt; X-Original-To: root Delivered-To: root@centos72.localdomain Date: Thu, 06 Oct 2022 09:23:49 +0800 To: root@centos72.localdomain Subject: test User-Agent: Heirloom mailx 12.5 7/5/10 Content-Type: text/plain; charset=us-ascii From: myd@centos72.localdomain Status: R hello, i am myd! \u0026amp; #发送文件夹中的内容 mailx -s \u0026#34;test\u0026#34; root \u0026lt; test.mail exit [root@centos72 ~]# mail Heirloom Mail version 12.5 7/5/10. Type ? for help. \u0026#34;/var/spool/mail/root\u0026#34;: 1366 messages 3 new 1340 unread U1361 (Cron Daemon) Sun Oct 2 18:15 29/1053 \u0026#34;Cron \u0026lt;root@centos72\u0026gt; sh /root/shell_t/test.sh /root/shell_t /root/backup2\u0026#34; U1362 (Cron Daemon) Sun Oct 2 18:16 29/1053 \u0026#34;Cron \u0026lt;root@centos72\u0026gt; sh /root/shell_t/test.sh /root/shell_t /root/backup2\u0026#34; 1363 myd@centos72.localdo Thu Oct 6 09:23 19/612 \u0026#34;test\u0026#34; \u0026gt;N1364 myd@centos72.localdo Thu Oct 6 09:26 16/637 \u0026#34;*** SECURITY information for centos72 ***\u0026#34; N1365 myd@centos72.localdo Thu Oct 6 09:27 16/637 \u0026#34;*** SECURITY information for centos72 ***\u0026#34; N1366 myd@centos72.localdo Thu Oct 6 09:28 18/606 \u0026#34;test\u0026#34; \u0026amp; 1366 Message 1366: From myd@centos72.localdomain Thu Oct 6 09:28:46 2022 Return-Path: \u0026lt;myd@centos72.localdomain\u0026gt; X-Original-To: root Delivered-To: root@centos72.localdomain Date: Thu, 06 Oct 2022 09:28:46 +0800 To: root@centos72.localdomain Subject: test User-Agent: Heirloom mailx 12.5 7/5/10 Content-Type: text/plain; charset=us-ascii From: myd@centos72.localdomain Status: R content from txt file \u0026amp; 向指定登陆的终端发送信息 ps -ef|grep ssh aiiqh 798025 797922 0 09:07 ? 00:00:00 sshd: aiiqh@pts/0 echo \u0026#34;msg\u0026#34; \u0026gt;\u0026gt; /dev/pts/0 获取后台执行程序的输出 参考链接：https://juejin.cn/post/7089818727524335630\n在linux的/proc/{pid}/fd目录下存在三个文件\n标准输入，描述符为 0，默认就是键盘输入 标准输出，描述符为 1，默认就是输出到屏幕 标准输出，描述符为 2，默认还是输出到屏幕 使用测试程序进行测试 stdout_stderr.py:\nimport time import sys while True: ts = int(time.time()) if ts % 2 == 0: print(f\u0026#34;stdout now time is {ts}\u0026#34;, file=sys.stdout) sys.stdout.flush() #不缓存 else: print(f\u0026#34;stderr now time is {ts}\u0026#34;, file=sys.stderr) sys.stderr.flush() #不缓存 time.sleep(1) 后台运行\n#使用nohup命令后台运行程序，程序运行输出会被nohup进行接管 nohup python3 stdout_stderr.py \u0026amp; #或者 #必须要指定日志输出文件才行，/dev/null 这种都不会生效 python3 stdout_stderr.py \u0026amp;\u0026gt;stdout_stderr.log \u0026amp; ps -ef|grep stdout aiiqh 798370 798026 0 09:26 pts/0 00:00:00 python3 stdout_stderr.py aiiqh 799007 798026 0 09:49 pts/0 00:00:00 grep --color=auto std pid 798370 是nohup程序 pid 798026 是python3程序 #由于python3的输出被nohup接管了，所以取nohup里查看 cd /proc/798370/fd ls -la total 0 dr-x------ 2 aiiqh aiiqh 0 Oct 22 09:44 . dr-xr-xr-x 9 aiiqh aiiqh 0 Oct 22 09:26 .. l-wx------ 1 aiiqh aiiqh 64 Oct 22 09:44 0 -\u0026gt; /dev/null l-wx------ 1 aiiqh aiiqh 64 Oct 22 09:44 1 -\u0026gt; /home/aiiqh/python_proj/script/nohup.out l-wx------ 1 aiiqh aiiqh 64 Oct 22 09:44 2 -\u0026gt; /home/aiiqh/python_proj/script/nohup.out #查看标准输出 tail -f 1 #查看标准错误输出 tail -f 2 head head 命令用于查看文件的头部信息\ncat \u0026lt;\u0026lt;EOF \u0026gt; test-head.txt this is line 1 this is line 2 this is line 3 this is line 4 this is line 5 this is line 6 this is line 7 this is line 8 this is line 9 this is line 10 this is line 11 this is line 12 EOF #默认显示十行 head test-head.txt this is line 1 this is line 2 ... this is line 9 this is line 10 #-n参数指定显示几行 head -n 5 test-head.txt this is line 1 this is line 2 this is line 3 this is line 4 this is line 5 #-c参数指定显示几字节 head -c 50 test-head.txt this is line 1 this is line 2 this is line 3 this tail tail 命令用于查看文件的末端内容\n#默认显示文件的最后10行 tail test-head.txt this is line 3 this is line 4 this is line 5 this is line 6 this is line 7 this is line 8 this is line 9 this is line 10 this is line 11 this is line 12 #-n参数用于指定查看文件的最后几行 tail -n 5 test-head.txt this is line 8 this is line 9 this is line 10 this is line 11 this is line 12 #-c参数用于指定查看文件的最后几字节 tail -c 50 test-head.txt 9 this is line 10 this is line 11 this is line 12 #-f参数用于指定循环读取，文件有新内容追加会进行打印 tail -f test-head.txt this is line 3 this is line 4 this is line 5 this is line 6 this is line 7 this is line 8 this is line 9 this is line 10 this is line 11 this is line 12 more more 与 cat命令类似，以分页的形式查看文件\n#-{num}参数指定一页显示几行 #+{num}参数指定从第几行开始 #enter 用于显示下一行 #space 用于显示下一页 #b 用于回到上一页 #q 用于退出 #v 用于调期vi指令并指向当前行,退出后还是more命令 more -3 +2 test-head.txt this is line 2 this is line 3 this is line 4 --More--(32%) netstat netstat 用于显示linux网络状态\n#-a 参数用于所有socket #-n或--numeric 直接使用IP地址，而不显示域名 #-p或--programs 显示正在使用Socket的程序识别码和程序名称 #-t或--tcp 显示TCP传输协议的连线状况 #-u或--udp 显示UDP传输协议的连线状况 netstat -anp (Not all processes could be identified, non-owned process info will not be shown, you would have to be root to see it all.) Active Internet connections (servers and established) Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp 0 0 127.0.0.1:33491 0.0.0.0:* LISTEN - tcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN - tcp 0 0 127.0.0.1:45227 0.0.0.0:* LISTEN 3761/node tcp 0 0 127.0.0.53:53 0.0.0.0:* LISTEN - tcp 0 0 127.0.0.1:45227 127.0.0.1:46626 ESTABLISHED 4224/node tcp 0 0 127.0.0.1:50826 127.0.0.1:45227 ESTABLISHED - tcp 0 0 127.0.0.1:45227 127.0.0.1:58744 ESTABLISHED 5070/node ... udp 0 0 127.0.0.53:53 0.0.0.0:* - udp 0 0 192.168.52.128:68 0.0.0.0:* - raw6 0 0 :::58 :::* 7 - Active UNIX domain sockets (servers and established) Proto RefCnt Flags Type State I-Node PID/Program name Path unix 2 [ ACC ] STREAM LISTENING 32724 - /run/dbus/system_bus_socket unix 2 [ ACC ] STREAM LISTENING 32726 - /run/docker.sock unix 2 [ ACC ] STREAM LISTENING 14730 - /run/snapd.socket unix 2 [ ACC ] STREAM LISTENING 14732 - /run/snapd-snap.socket unix 2 [ ACC ] STREAM LISTENING 14734 - /run/uuidd/request ","permalink":"https://moyuduo.github.io/posts/linux/","summary":"linux命令自查 查看cpu和内存 cpu个数 cat /proc/cpuinfo | grep \u0026#34;physical id\u0026#34; | uniq | wc -l cpu核数 cat /proc/cpuinfo | grep \u0026#34;cpu cores\u0026#34; | uniq cpu型号 cat /proc/cpuinfo | grep \u0026#39;model name\u0026#39; |uniq 内存大小 cat /proc/meminfo | grep MemTotal 设置linux开机自启动 linux文件/etc/rc.local文件中的内容会linux启动完成后执行，所以可以用来做开机自启动，/etc/rc.local默认是lrwxrwxrwx权限，但是由于它是/etc/rc.d/rc.local的一个软连接，所以/etc/rc.d/rc.local这个文件必须要有执行权限才能开机自启动，而这个人间默认是-rw-rw-rw-权限，所以必须要修改添加执行权限,注意在这个文件中添加开机执行死循环脚本时必须使用\u0026amp;后台执行。\n秒级检测脚本 #!/bin/bash while true do count=`ps -ef|grep etcd|grep -v grep|wc -l` if [ $count -eq 0 ]; then cd /opt/etcd-v3.5.0-linux-amd64 ./etcd -listen-client-urls=\u0026#34;http://0.0.0.0:2379\u0026#34; --advertise-client-urls=\u0026#34;http://0.0.0.0:2379\u0026#34; echo \u0026#34;restart etcd at $(date)\u0026#34; \u0026gt;\u0026gt; /opt/etcd-v3.5.0-linux-amd64/record fi sleep 1 done 原理是通过ps -ef|grep按照条件过滤执行的进程，再通过wc -l转换为进程个数，最后通过shell进行判断。","title":"Linux"},{"content":"Introduction This is bold text, and this is emphasized text.\nVisit the Hugo website!\n","permalink":"https://moyuduo.github.io/posts/my-first-post/","summary":"Introduction This is bold text, and this is emphasized text.\nVisit the Hugo website!","title":"My First Post"}]