<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>kafka相关 | Moyuduo's Blog</title><meta name=keywords content><meta name=description content="kafka相关 安装 安装JDK1.8
yum install -y java-1.8.0* #使用java -version出现以下命令说明安装成功 openjdk version &#34;1.8.0_302&#34; OpenJDK Runtime Environment (build 1.8.0_302-b08) OpenJDK 64-Bit Server VM (build 25.302-b08, mixed mode) 安装zookeeper
#创建zookeeper安装目录 mkdir -p /opt/zookeeper #进入目录 cd /opt/zookeeper #下载安装包 wget https://mirrors.aliyun.com/apache/zookeeper/zookeeper-3.6.3/apache-zookeeper-3.6.3-bin.tar.gz #解压 tar -zxvf apache-zookeeper-3.6.3-bin.tar.gz #进入配置文件目录 cd /opt/zookeeper/apache-zookeeper-3.6.3-bin/conf #复制配置文件 cp zoo_sample.cfg zoo.cfg #修改配置 #客户端会话超时时间 tickTime=2000 #客户端初始化可接受多少个心跳监测，默认10，即10*tickTime(默认2000)，表示20s没有连接上集群的配置则连接失败 initLimit=10 #Leader和follwer之间，允许多少个请求应答长度，默认5，即5*tickTime(默认2000)，表示默认10sLeader和Follwer之间如果消息5次没有发送成功就不尝试了 syncLimit=5 #存储快照文件的目录 dataDir=/opt/zookeeper/zoodata #事务日志存储的目录 dataLogDir=/opt/zookeeper/zoodatalog #服务端口 clientPort=2181 #server.X=A:B:C	X是一个数字，表示这是第几号server	A是该server所在的IP地址	B配置该server和集群中的leader交换消息所使用的端口	C配置选举leader时所使用的端口 server.1=127.0.0.1:2888:3888 #集群配置 server.1=192.168.37.151:2888:3888 server.2=192.168.37.152:2888:3888 server.3=192.168.37.153:2888:3888 #创建dataDir目录 mkdir -p /opt/zookeeper/zoodata #进入dataDir目录 cd /opt/zookeeper/zoodata #把节点号写入myid文件，不同节点各自配置 echo 1 > myid #配置防火墙 firewall-cmd --zone=public --add-port=2181/tcp --permanent firewall-cmd --zone=public --add-port=2888/tcp --permanent firewall-cmd --zone=public --add-port=3888/tcp --permanent firewall-cmd --reload #进入zookeeper执行目录 cd /opt/zookeeper/apache-zookeeper-3."><meta name=author content="Me"><link rel=canonical href=https://moyuduo.github.io/posts/kafka%E7%9B%B8%E5%85%B3/><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.bc1149f4a72aa4858d3a9f71462f75e5884ffe8073ea9d6d5761d5663d651e20.css integrity="sha256-vBFJ9KcqpIWNOp9xRi915YhP/oBz6p1tV2HVZj1lHiA=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://moyuduo.github.io/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=https://moyuduo.github.io/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=https://moyuduo.github.io/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=https://moyuduo.github.io/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=https://moyuduo.github.io/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script type=application/javascript>var doNotTrack=!1;doNotTrack||(function(e,t,n,s,o,i,a){e.GoogleAnalyticsObject=o,e[o]=e[o]||function(){(e[o].q=e[o].q||[]).push(arguments)},e[o].l=1*new Date,i=t.createElement(n),a=t.getElementsByTagName(n)[0],i.async=1,i.src=s,a.parentNode.insertBefore(i,a)}(window,document,"script","https://www.google-analytics.com/analytics.js","ga"),ga("create","UA-123-45","auto"),ga("send","pageview"))</script><meta property="og:title" content="kafka相关"><meta property="og:description" content="kafka相关 安装 安装JDK1.8
yum install -y java-1.8.0* #使用java -version出现以下命令说明安装成功 openjdk version &#34;1.8.0_302&#34; OpenJDK Runtime Environment (build 1.8.0_302-b08) OpenJDK 64-Bit Server VM (build 25.302-b08, mixed mode) 安装zookeeper
#创建zookeeper安装目录 mkdir -p /opt/zookeeper #进入目录 cd /opt/zookeeper #下载安装包 wget https://mirrors.aliyun.com/apache/zookeeper/zookeeper-3.6.3/apache-zookeeper-3.6.3-bin.tar.gz #解压 tar -zxvf apache-zookeeper-3.6.3-bin.tar.gz #进入配置文件目录 cd /opt/zookeeper/apache-zookeeper-3.6.3-bin/conf #复制配置文件 cp zoo_sample.cfg zoo.cfg #修改配置 #客户端会话超时时间 tickTime=2000 #客户端初始化可接受多少个心跳监测，默认10，即10*tickTime(默认2000)，表示20s没有连接上集群的配置则连接失败 initLimit=10 #Leader和follwer之间，允许多少个请求应答长度，默认5，即5*tickTime(默认2000)，表示默认10sLeader和Follwer之间如果消息5次没有发送成功就不尝试了 syncLimit=5 #存储快照文件的目录 dataDir=/opt/zookeeper/zoodata #事务日志存储的目录 dataLogDir=/opt/zookeeper/zoodatalog #服务端口 clientPort=2181 #server.X=A:B:C	X是一个数字，表示这是第几号server	A是该server所在的IP地址	B配置该server和集群中的leader交换消息所使用的端口	C配置选举leader时所使用的端口 server.1=127.0.0.1:2888:3888 #集群配置 server.1=192.168.37.151:2888:3888 server.2=192.168.37.152:2888:3888 server.3=192.168.37.153:2888:3888 #创建dataDir目录 mkdir -p /opt/zookeeper/zoodata #进入dataDir目录 cd /opt/zookeeper/zoodata #把节点号写入myid文件，不同节点各自配置 echo 1 > myid #配置防火墙 firewall-cmd --zone=public --add-port=2181/tcp --permanent firewall-cmd --zone=public --add-port=2888/tcp --permanent firewall-cmd --zone=public --add-port=3888/tcp --permanent firewall-cmd --reload #进入zookeeper执行目录 cd /opt/zookeeper/apache-zookeeper-3."><meta property="og:type" content="article"><meta property="og:url" content="https://moyuduo.github.io/posts/kafka%E7%9B%B8%E5%85%B3/"><meta property="og:image" content="https://moyuduo.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="article:section" content="posts"><meta property="article:published_time" content="2022-11-27T16:16:14+08:00"><meta property="article:modified_time" content="2022-11-27T16:16:14+08:00"><meta property="og:site_name" content="Moyuduo's Blog"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://moyuduo.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="kafka相关"><meta name=twitter:description content="kafka相关 安装 安装JDK1.8
yum install -y java-1.8.0* #使用java -version出现以下命令说明安装成功 openjdk version &#34;1.8.0_302&#34; OpenJDK Runtime Environment (build 1.8.0_302-b08) OpenJDK 64-Bit Server VM (build 25.302-b08, mixed mode) 安装zookeeper
#创建zookeeper安装目录 mkdir -p /opt/zookeeper #进入目录 cd /opt/zookeeper #下载安装包 wget https://mirrors.aliyun.com/apache/zookeeper/zookeeper-3.6.3/apache-zookeeper-3.6.3-bin.tar.gz #解压 tar -zxvf apache-zookeeper-3.6.3-bin.tar.gz #进入配置文件目录 cd /opt/zookeeper/apache-zookeeper-3.6.3-bin/conf #复制配置文件 cp zoo_sample.cfg zoo.cfg #修改配置 #客户端会话超时时间 tickTime=2000 #客户端初始化可接受多少个心跳监测，默认10，即10*tickTime(默认2000)，表示20s没有连接上集群的配置则连接失败 initLimit=10 #Leader和follwer之间，允许多少个请求应答长度，默认5，即5*tickTime(默认2000)，表示默认10sLeader和Follwer之间如果消息5次没有发送成功就不尝试了 syncLimit=5 #存储快照文件的目录 dataDir=/opt/zookeeper/zoodata #事务日志存储的目录 dataLogDir=/opt/zookeeper/zoodatalog #服务端口 clientPort=2181 #server.X=A:B:C	X是一个数字，表示这是第几号server	A是该server所在的IP地址	B配置该server和集群中的leader交换消息所使用的端口	C配置选举leader时所使用的端口 server.1=127.0.0.1:2888:3888 #集群配置 server.1=192.168.37.151:2888:3888 server.2=192.168.37.152:2888:3888 server.3=192.168.37.153:2888:3888 #创建dataDir目录 mkdir -p /opt/zookeeper/zoodata #进入dataDir目录 cd /opt/zookeeper/zoodata #把节点号写入myid文件，不同节点各自配置 echo 1 > myid #配置防火墙 firewall-cmd --zone=public --add-port=2181/tcp --permanent firewall-cmd --zone=public --add-port=2888/tcp --permanent firewall-cmd --zone=public --add-port=3888/tcp --permanent firewall-cmd --reload #进入zookeeper执行目录 cd /opt/zookeeper/apache-zookeeper-3."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://moyuduo.github.io/posts/"},{"@type":"ListItem","position":2,"name":"kafka相关","item":"https://moyuduo.github.io/posts/kafka%E7%9B%B8%E5%85%B3/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"kafka相关","name":"kafka相关","description":"kafka相关 安装 安装JDK1.8\nyum install -y java-1.8.0* #使用java -version出现以下命令说明安装成功 openjdk version \u0026#34;1.8.0_302\u0026#34; OpenJDK Runtime Environment (build 1.8.0_302-b08) OpenJDK 64-Bit Server VM (build 25.302-b08, mixed mode) 安装zookeeper\n#创建zookeeper安装目录 mkdir -p /opt/zookeeper #进入目录 cd /opt/zookeeper #下载安装包 wget https://mirrors.aliyun.com/apache/zookeeper/zookeeper-3.6.3/apache-zookeeper-3.6.3-bin.tar.gz #解压 tar -zxvf apache-zookeeper-3.6.3-bin.tar.gz #进入配置文件目录 cd /opt/zookeeper/apache-zookeeper-3.6.3-bin/conf #复制配置文件 cp zoo_sample.cfg zoo.cfg #修改配置 #客户端会话超时时间 tickTime=2000 #客户端初始化可接受多少个心跳监测，默认10，即10*tickTime(默认2000)，表示20s没有连接上集群的配置则连接失败 initLimit=10 #Leader和follwer之间，允许多少个请求应答长度，默认5，即5*tickTime(默认2000)，表示默认10sLeader和Follwer之间如果消息5次没有发送成功就不尝试了 syncLimit=5 #存储快照文件的目录 dataDir=/opt/zookeeper/zoodata #事务日志存储的目录 dataLogDir=/opt/zookeeper/zoodatalog #服务端口 clientPort=2181 #server.X=A:B:C\tX是一个数字，表示这是第几号server\tA是该server所在的IP地址\tB配置该server和集群中的leader交换消息所使用的端口\tC配置选举leader时所使用的端口 server.1=127.0.0.1:2888:3888 #集群配置 server.1=192.168.37.151:2888:3888 server.2=192.168.37.152:2888:3888 server.3=192.168.37.153:2888:3888 #创建dataDir目录 mkdir -p /opt/zookeeper/zoodata #进入dataDir目录 cd /opt/zookeeper/zoodata #把节点号写入myid文件，不同节点各自配置 echo 1 \u0026gt; myid #配置防火墙 firewall-cmd --zone=public --add-port=2181/tcp --permanent firewall-cmd --zone=public --add-port=2888/tcp --permanent firewall-cmd --zone=public --add-port=3888/tcp --permanent firewall-cmd --reload #进入zookeeper执行目录 cd /opt/zookeeper/apache-zookeeper-3.","keywords":[],"articleBody":"kafka相关 安装 安装JDK1.8\nyum install -y java-1.8.0* #使用java -version出现以下命令说明安装成功 openjdk version \"1.8.0_302\" OpenJDK Runtime Environment (build 1.8.0_302-b08) OpenJDK 64-Bit Server VM (build 25.302-b08, mixed mode) 安装zookeeper\n#创建zookeeper安装目录 mkdir -p /opt/zookeeper #进入目录 cd /opt/zookeeper #下载安装包 wget https://mirrors.aliyun.com/apache/zookeeper/zookeeper-3.6.3/apache-zookeeper-3.6.3-bin.tar.gz #解压 tar -zxvf apache-zookeeper-3.6.3-bin.tar.gz #进入配置文件目录 cd /opt/zookeeper/apache-zookeeper-3.6.3-bin/conf #复制配置文件 cp zoo_sample.cfg zoo.cfg #修改配置 #客户端会话超时时间 tickTime=2000 #客户端初始化可接受多少个心跳监测，默认10，即10*tickTime(默认2000)，表示20s没有连接上集群的配置则连接失败 initLimit=10 #Leader和follwer之间，允许多少个请求应答长度，默认5，即5*tickTime(默认2000)，表示默认10sLeader和Follwer之间如果消息5次没有发送成功就不尝试了 syncLimit=5 #存储快照文件的目录 dataDir=/opt/zookeeper/zoodata #事务日志存储的目录 dataLogDir=/opt/zookeeper/zoodatalog #服务端口 clientPort=2181 #server.X=A:B:C\tX是一个数字，表示这是第几号server\tA是该server所在的IP地址\tB配置该server和集群中的leader交换消息所使用的端口\tC配置选举leader时所使用的端口 server.1=127.0.0.1:2888:3888 #集群配置 server.1=192.168.37.151:2888:3888 server.2=192.168.37.152:2888:3888 server.3=192.168.37.153:2888:3888 #创建dataDir目录 mkdir -p /opt/zookeeper/zoodata #进入dataDir目录 cd /opt/zookeeper/zoodata #把节点号写入myid文件，不同节点各自配置 echo 1 \u003e myid #配置防火墙 firewall-cmd --zone=public --add-port=2181/tcp --permanent firewall-cmd --zone=public --add-port=2888/tcp --permanent firewall-cmd --zone=public --add-port=3888/tcp --permanent firewall-cmd --reload #进入zookeeper执行目录 cd /opt/zookeeper/apache-zookeeper-3.6.3-bin/bin #启动zookeeper ./zkServer.sh start #重启 ./zkServer.sh restart #关闭 ./zkServer.sh stop #查看状态 ./zkServer.sh status #客户端连接zookeeper ./zkCli.sh 参考：https://ken.io/note/zookeeper-cluster-deploy-guide\n3.kafka安装\n#创建安装目录 mkdir -p /opt/kafka #进入安装目录 cd /opt/kafka #下载kafka安装 wget https://mirrors.aliyun.com/apache/kafka/2.7.1/kafka_2.13-2.7.1.tgz #解压 tar -zxvf kafka_2.13-2.7.1.tgz #进入配置文件目录 cd kafka_2.13-2.7.1/config/ #备份配置文件 cp server.properties server.properties.bak #修改配置文件 vim server.properties #当前节点在集群中的唯一标识 broker.id=1 #服务监听端口 listeners=PLAINTEXT://127.0.0.1:9092 #提供给生产者、消费者的端口 advertised.listeners=PLAINTEXT://127.0.0.1:9092 #连接地址，如有集群需配置 zookeeper.connect=127.0.0.1:2181 #连接超时时间 zookeeper.connection.timeout.ms=18000 :wq #开放端口 firewall-cmd --add-port=9092/tcp --permanent #重新加载防火墙配置 firewall-cmd --reload #进入kafka执行目录 cd /opt/kafka/kafka_2.13-2.7.1/bin #后台启动kafka内置的zookeeper ./bin/zookeeper-server-start.sh -daemon config/zookeeper.properties #关闭zookeeper ./bin/zookeeper-server-stop.sh -daemon config/zookeeper.properties cd /opt/kafka/kafka_2.13-2.7.1 #启动kafka,如果在去启动时报错 The Cluster ID 4cffC36ERj6MTJ_mZkKafA doesn't match stored clusterId 可能是之前使用的 zookeeper 和现在的不是同一个，解决办法是删除 server.properties 中配置的 logDir 下的 meta.properties 文件 ./bin/kafka-server-start.sh -daemon config/server.properties #关闭kafka ./bin/kafka-server-stop.sh config/server.properties #创建topic #partitions表示在几个分区上创建topic #replication-factor表示在每个分区上副本的数量 ./kafka-topics.sh --create --zookeeper 127.0.0.1:2181 --replication-factor 1 --partitions 1 --topic topic1 #查看topic信息 ./kafka-topics.sh --describe --zookeeper 127.0.0.1:2181 --topic topic1 #启动控制台生产者 ./kafka-console-producer.sh --broker-list 127.0.0.1:9092 --topic topic1 #启动控制台消费者 ./kafka-console-consumer.sh --bootstrap-server 127.0.0.1:9092 --topic topic1 --from-beginning #3个broker情况下创建topic指定4个副本会报错，原因是replication的数量不能大于broker数，可以想象的是replication是针对每一个分区来说的，如果一个分区的副本数等于broker数的话那个意味着每个broker上都有一个该分区的副本，如果大于broker数，那么该分区在某些broker上会存在多个副本，没有必要 ./kafka-topics.sh --create --topic myd4 --partitions 3 -replication-factor 4 --zookeeper kafka1:2181 Error while executing topic command : Replication factor: 4 larger than available brokers: 3. 参考：https://www.cnblogs.com/kentalk/p/kafka-cluster-deploy-guide.html\n配置远程访问 cd kafka安装路径/config/server.properties 修改对应位置为 listeners=PLAINTEXT://:9092 advertised.listeners=PLAINTEXT://服务器ip:9092 基准测试 ./kafka-topics.sh --zookeeper 139.198.11.13:2181 --create --topic benchmark --partitions 1 --replication-factor 1 ./kafka-producer-perf-test.sh --topic benchmark --num-records 500000 --throughput -1 --record-size 1000 --producer-props bootstrap.servers=139.198.11.13:9092 acks=1 ./kafka-consumer-perf-test.sh --broker-list 139.198.11.13:9092 --topic benchmark --fetch-seze 1048576 --messages 500000 kafka-eagle管理工具 去官网https://www.kafka-eagle.org/下载tar安装包\n#上传tar包到kafka-eagle安装目录 tar -zxvf kafka-eagle-bin-2.0.6.tar.gz cd kafka-eagle-bin-2.0.6.tar tar -zxvf kafka-eagle-web-2.0.6-bin.tar.gz 设置环境变量\nvim /etc/profile #kafka-eagle export KE_HOME= xxx PATH=$PATH:$KE_HOME/bin #java export JAVA_HOME= xxx PATH=$PATH:$JAVA_HOME/bin :wq #更新环境变量 source /etc/profile 修改kafka-eagle配置文件\ncd $KE_HOME/conf vim system-config.properties ###################################### # multi zookeeper\u0026kafka cluster list # zookeeper和kafka集群配置 ###################################### kafka.eagle.zk.cluster.alias=cluster1 cluster1.zk.list=192.168.37.151:2181,192.168.37.152:2182,192.168.37.153:2183 ###################################### # kafka eagle webui port # web页面访问端口号 ###################################### kafka.eagle.webui.port=8048 ###################################### # kafka jdbc driver address # kafka默认使用sqlite数据库，Centos自带，注意配置下数据库存放路径就行 ###################################### kafka.eagle.driver=org.sqlite.JDBC kafka.eagle.url=jdbc:sqlite:/opt/kafka-eagle/db/ke.db kafka.eagle.username=root kafka.eagle.password=www.kafka-eagle.org 开放端口供外部访问\nfirewall-cmd --add-port=8048/tcp --permanent firewall-cmd --reload 启动kafka-eagle\ncd $KE_HOME/bin ./ke.sh start #出现以下内容则成功 Welcome to __ __ ___ ____ __ __ ___ ______ ___ ______ __ ______ / //_/ / | / __/ / //_/ / | / ____/ / | / ____/ / / / ____/ / ,\u003c / /| | / /_ / ,\u003c / /| | / __/ / /| | / / __ / / / __/ / /| | / ___ | / __/ / /| | / ___ | / /___ / ___ |/ /_/ / / /___ / /___ /_/ |_| /_/ |_|/_/ /_/ |_| /_/ |_| /_____/ /_/ |_|\\____/ /_____//_____/ Version 2.0.6 -- Copyright 2016-2021 ******************************************************************* * Kafka Eagle Service has started success. * Welcome, Now you can visit 'http://127.0.0.1:8048' * Account:admin ,Password:123456 kafka架构 Producer: 消息的生产者，像 broker 中发送消息 Consumer: 消息的消费者，从 broker 中消费消息 Broker：一台 kafka 服务器就是一个 broker，一个 kafka 集群由多个 broker 组成，一个 broker 包含多个 topic Topic：理解成一个队列，Producer 和 Consumer 都是面向 topic 的 ConsumerGroup: 多个对同一个 topic 进行消费的 Consumer 组成一个组，一个消费者组内的一个消费者只能消费一个分区，不同的分区由不同的消费者进行消费，消费者组内的消费者的消费能保证分区有序性，但是不能保证全局有序。 Partition: 为了实现扩展性，一个 topic 可以分布到多个 broker 上，一个 topic 可以分为多个 partition，每个 partition 是一个有序队列 Replica：副本，为了保证某一个 broker 故障后，分布在该节点上的 topic 的 partition 中的数据不会丢失，一个 topic 的每个 partition 都可以有若干 replica 分布在其他 broker上，replica 又分为 leader 和 follower Leader：每个 topic 的 partition 有多个 replica，其中一个为 leader，Producer 生产数据、Consumer 消费数据都是从 leader 上 Follower：topic 的 partition 的 follower，负责从 leader 处同步数据，并在 leader 发生故障后竞选为 leader kafka工作流程 在 kafka 中生产者生产消息和消费者消费消息都是面向 topic 的 topic 是一个逻辑上的概念，partition 是物理上的概念，每个 partition 对应一个.log文件，该文件中保存的就是生成者生产的数据。生产者生产的数据会被不断的追加到这个文件中，并且对于每个.log文件都有一个.index文件来保存当前.log文件的 offset 以便快速定位到数据 消费者组中的每一个消费者都会实时记录自己消费到哪个 offset 了，以便在出错回复时能从上次消费的地方消费和不会重复消费数据 kafka文件存储机制 由于生产者生产消息会不断追加到.log文件中，为了防止.log文件过大导致定位效率低下，kafka 采用分片和索引机制提高检索效率，将每个 partition 分为多个 segment。每个 segment 对应两个文件.log文件和.index文件，所有 segment 的文件位于一个topic_name + partition_number命名的文件夹下，当每个.log文件的大小大于 server.properties文件中定义的log.segment.bytes值(默认为1G)时，会新增一个 segment,并且文件名为 offset,当 segment 创建的时间大于server.properties中定义的log.retention.hours的值(默认为7天)该 segment 会被删除 00000000000000000000.indexindex 文件的格式为 offset 命名，最多可保存 20 位 .log 文件和 .index 文件 创建topic时的分区策略 创建topic时的副本分配策略 生产者分区写入策略 当生产者向一个 topic 中写入数据时，由于 topic 只是一个逻辑上的概念，而 partition 是物理上的概念，所以数据必然是写入到一个 partition 上，而一个 topic 由多个 partition 组成，那么生产者在发送消息时是具体将消息写入到了那个 partition 中呢?\n指定分区策略，消费者在发送消息时指定发送到哪个 partition 随机策略，随机发送到一个 partition ，会导致数据倾斜 轮询策略，生产者在发送消息时首先生成一个 random_number ，然后使用random_number % partition_number 作为第一个发送到的分区，以后的消息就轮流发送到每个分区上 按 key 分区策略，这种策略是在发送消息时指定一个 key，使用 key.hash % partition_number选择发送到的分区，这种策略能够保证相同的 key 的所有消息都能发送打同一个 partition，缺点是会造成数据倾斜 自定义策略，实现 Partitioner 接口 乱序问题 不管生产者使用 随机策略、轮询策略虽然消息在同一个分区中是局部有序的，但是不同分区之间由于消费者的消费速度一同，所以从整体上来看是乱序的，虽然按 key 分区策略能保证有序，但是有会造成数据的倾斜，除此之外把 topic 的分区设置成1也能保证有序，但是这样就失去了 kafka 的分布式特性和可扩展性\nkafka生产者生产消息的可靠性 幂等性 一个相同的操作进行两次会得到同样的结果，如发送两次相同的 http 请求，在 kafka 中生产者发送了生产消息到 topic 上，那么如何保证收到了这个消息？如果 server 收到了消息会进行ack的话，如何保证生产者这没有收到这个 ack 之前有发送了一遍上一次的消息后，server 收到了不会重复保存？\n消息可靠性 为了保证数据的可靠性，kafka 在收到了生产者发送的消息后会进行 ack，如果生产者在指定的时间内没有收到 ack，那么会重新发送上一次的消息。生产者在发送消息时会携带一个 pid(Producer Id)和一个 seqid(自增Id), kafka 在收到消息后会保存生产者发送过来的 pid 和 seqid,如果 kafka 接受到一条消息，消息的 seqid 小于等于 kafka 保存的对应 pid 对应 sqlid，即这条消息已经被 kafka保存，kafka 不会重复保存这条消息\nacks设置 acks=0: 生产者不等待分区返回 ack，存在丢数据风险 acks=1：生产者等待分区 leader 同步完成之后返回 ack，如果分区 follower 在 leader 返回 ack 之后故障，而此时 follower 还没同步数据将导致数据丢失 acks=-1：消费者分区的 leader 和 follower(ISR 中的 follower) 都同步完数据之后返回 ack。但是如在在 follower 同步完成后，leader 返回 ack 前 leader 故障那么会导致数据重复。如果 ISR 中当前只有 leader，那么 leader 同步完后就返回 ack 了但是 follower 还没同步完成，也可能导致丢失数据 kafka 对消息进行 ack 有两种方案 分区半数以上的 replica 同步成功后进行 ack，优点是延时低，缺点是选举新的 leader 时，如果要容忍 n台节点故障需要部署 2n+1 台\n所有 replica 同步完成后进行 ack，优点是选举新的 leader 时容忍 n 台故障，只需要 n+1 个节点，缺点是延时高\nkafka 选择第二种方案对消息进行 ack\n高延时怎么解决？ 每个分区维护一个动态的ISR(in-sync replica set)即和 leader 保持同步的 follower 的集合，当 ISR 中的 follower 同步完数据后会对消息进行 ack，如果 ISR 中的 follower 同 leader 进行同步的时间过长，那么该 follower 会被踢出 ISR该时间阈值由replica.lag.time.max.ms指定，如果在 ISR 之外的 follower 同 ISR 同步的时间较短，那么该 follower 能够加入 ISR，leader 故障后从 ISR 中选择新的 leader\n故障恢复 LEO(Log End Offset):指的是每个副本最大的 offset\nHW(High Watermark):指的是消费者能见到的最大的 offset，ISR 队列中最小的 LEO。\nleader故障 leader 发生故障后会从 ISR 中选择一个 follower 作为 leader，为保证数据一致性，其余的 follower 会把 log 文件中高于 HW 的一部分截取掉，重新从 leader 中同步\nfollower故障 follower 发生故障后会被临时踢出 ISR，待该 follower 恢复后，follower 会读取本地磁盘 记录的上次的 HW，并将 log 文件高于 HW 的部分截取掉，从 HW 开始向 leader 进行同步。 等该 follower 的 LEO 大于等于该 Partition 的 HW，即 follower 追上 leader 之后，就可以重 新加入 ISR 了\nExactly Onece 消费者分区消费策略 分区的物理存储 生产者消息不丢失 ack\n消费者消息不丢失 控制offset\n默认的自动提交offset会出现消息丢失\n即使控制消息保存成功，也有可能出现消息重复消费\n##kafka事务\n","wordCount":"875","inLanguage":"en","datePublished":"2022-11-27T16:16:14+08:00","dateModified":"2022-11-27T16:16:14+08:00","author":{"@type":"Person","name":"Me"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://moyuduo.github.io/posts/kafka%E7%9B%B8%E5%85%B3/"},"publisher":{"@type":"Organization","name":"Moyuduo's Blog","logo":{"@type":"ImageObject","url":"https://moyuduo.github.io/%3Clink%20/%20abs%20url%3E"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://moyuduo.github.io/ accesskey=h title="Moyuduo's Blog (Alt + H)"><img src=https://moyuduo.github.io/apple-touch-icon.png alt aria-label=logo height=35>Moyuduo's Blog</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://moyuduo.github.io/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=https://moyuduo.github.io/archives title=Archive><span>Archive</span></a></li><li><a href=https://moyuduo.github.io/categories/ title=Categories><span>Categories</span></a></li><li><a href=https://moyuduo.github.io/tags/ title=Tags><span>Tags</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class=post-title>kafka相关</h1></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ul><li><a href=#安装>安装</a></li><li><a href=#配置远程访问>配置远程访问</a></li><li><a href=#基准测试>基准测试</a></li><li><a href=#kafka-eagle管理工具>kafka-eagle管理工具</a></li><li><a href=#kafka架构>kafka架构</a></li><li><a href=#kafka工作流程>kafka工作流程</a></li><li><a href=#kafka文件存储机制>kafka文件存储机制</a><ul><li><a href=#log-文件和-index-文件>.log 文件和 .index 文件</a></li></ul></li><li><a href=#创建topic时的分区策略>创建topic时的分区策略</a></li><li><a href=#创建topic时的副本分配策略>创建topic时的副本分配策略</a></li><li><a href=#生产者分区写入策略>生产者分区写入策略</a></li><li><a href=#乱序问题>乱序问题</a></li><li><a href=#kafka生产者生产消息的可靠性>kafka生产者生产消息的可靠性</a><ul><li><a href=#幂等性>幂等性</a></li><li><a href=#消息可靠性>消息可靠性</a></li><li><a href=#acks设置>acks设置</a></li><li><a href=#故障恢复>故障恢复</a></li><li><a href=#exactly-onece>Exactly Onece</a></li></ul></li><li><a href=#消费者分区消费策略>消费者分区消费策略</a></li><li><a href=#分区的物理存储>分区的物理存储</a></li><li><a href=#生产者消息不丢失>生产者消息不丢失</a></li><li><a href=#消费者消息不丢失>消费者消息不丢失</a></li></ul></nav></div></details></div><div class=post-content><h1 id=kafka相关>kafka相关<a hidden class=anchor aria-hidden=true href=#kafka相关>#</a></h1><h2 id=安装>安装<a hidden class=anchor aria-hidden=true href=#安装>#</a></h2><ol><li><p>安装JDK1.8</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>yum install -y java-1.8.0*
</span></span><span class=line><span class=cl><span class=c1>#使用java -version出现以下命令说明安装成功</span>
</span></span><span class=line><span class=cl>openjdk version <span class=s2>&#34;1.8.0_302&#34;</span>
</span></span><span class=line><span class=cl>OpenJDK Runtime Environment <span class=o>(</span>build 1.8.0_302-b08<span class=o>)</span>
</span></span><span class=line><span class=cl>OpenJDK 64-Bit Server VM <span class=o>(</span>build 25.302-b08, mixed mode<span class=o>)</span>
</span></span></code></pre></div></li><li><p>安装zookeeper</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl><span class=c1>#创建zookeeper安装目录</span>
</span></span><span class=line><span class=cl>mkdir -p /opt/zookeeper
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>#进入目录</span>
</span></span><span class=line><span class=cl><span class=nb>cd</span> /opt/zookeeper
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>#下载安装包</span>
</span></span><span class=line><span class=cl>wget https://mirrors.aliyun.com/apache/zookeeper/zookeeper-3.6.3/apache-zookeeper-3.6.3-bin.tar.gz
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>#解压</span>
</span></span><span class=line><span class=cl>tar -zxvf apache-zookeeper-3.6.3-bin.tar.gz
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>#进入配置文件目录</span>
</span></span><span class=line><span class=cl><span class=nb>cd</span> /opt/zookeeper/apache-zookeeper-3.6.3-bin/conf
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>#复制配置文件</span>
</span></span><span class=line><span class=cl>cp zoo_sample.cfg zoo.cfg
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>#修改配置</span>
</span></span><span class=line><span class=cl><span class=c1>#客户端会话超时时间</span>
</span></span><span class=line><span class=cl><span class=nv>tickTime</span><span class=o>=</span><span class=m>2000</span> 
</span></span><span class=line><span class=cl><span class=c1>#客户端初始化可接受多少个心跳监测，默认10，即10*tickTime(默认2000)，表示20s没有连接上集群的配置则连接失败</span>
</span></span><span class=line><span class=cl><span class=nv>initLimit</span><span class=o>=</span><span class=m>10</span>
</span></span><span class=line><span class=cl><span class=c1>#Leader和follwer之间，允许多少个请求应答长度，默认5，即5*tickTime(默认2000)，表示默认10sLeader和Follwer之间如果消息5次没有发送成功就不尝试了</span>
</span></span><span class=line><span class=cl><span class=nv>syncLimit</span><span class=o>=</span><span class=m>5</span>
</span></span><span class=line><span class=cl><span class=c1>#存储快照文件的目录</span>
</span></span><span class=line><span class=cl><span class=nv>dataDir</span><span class=o>=</span>/opt/zookeeper/zoodata
</span></span><span class=line><span class=cl><span class=c1>#事务日志存储的目录</span>
</span></span><span class=line><span class=cl><span class=nv>dataLogDir</span><span class=o>=</span>/opt/zookeeper/zoodatalog
</span></span><span class=line><span class=cl><span class=c1>#服务端口</span>
</span></span><span class=line><span class=cl><span class=nv>clientPort</span><span class=o>=</span><span class=m>2181</span>
</span></span><span class=line><span class=cl><span class=c1>#server.X=A:B:C	X是一个数字，表示这是第几号server	A是该server所在的IP地址	B配置该server和集群中的leader交换消息所使用的端口	C配置选举leader时所使用的端口</span>
</span></span><span class=line><span class=cl>server.1<span class=o>=</span>127.0.0.1:2888:3888
</span></span><span class=line><span class=cl><span class=c1>#集群配置</span>
</span></span><span class=line><span class=cl>server.1<span class=o>=</span>192.168.37.151:2888:3888
</span></span><span class=line><span class=cl>server.2<span class=o>=</span>192.168.37.152:2888:3888
</span></span><span class=line><span class=cl>server.3<span class=o>=</span>192.168.37.153:2888:3888
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>#创建dataDir目录</span>
</span></span><span class=line><span class=cl>mkdir -p /opt/zookeeper/zoodata
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>#进入dataDir目录</span>
</span></span><span class=line><span class=cl><span class=nb>cd</span> /opt/zookeeper/zoodata
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>#把节点号写入myid文件，不同节点各自配置</span>
</span></span><span class=line><span class=cl><span class=nb>echo</span> <span class=m>1</span> &gt; myid
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>#配置防火墙</span>
</span></span><span class=line><span class=cl>firewall-cmd --zone<span class=o>=</span>public --add-port<span class=o>=</span>2181/tcp --permanent
</span></span><span class=line><span class=cl>firewall-cmd --zone<span class=o>=</span>public --add-port<span class=o>=</span>2888/tcp --permanent
</span></span><span class=line><span class=cl>firewall-cmd --zone<span class=o>=</span>public --add-port<span class=o>=</span>3888/tcp --permanent
</span></span><span class=line><span class=cl>firewall-cmd --reload
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>#进入zookeeper执行目录</span>
</span></span><span class=line><span class=cl><span class=nb>cd</span> /opt/zookeeper/apache-zookeeper-3.6.3-bin/bin
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>#启动zookeeper</span>
</span></span><span class=line><span class=cl>./zkServer.sh start
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>#重启</span>
</span></span><span class=line><span class=cl>./zkServer.sh restart
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>#关闭</span>
</span></span><span class=line><span class=cl>./zkServer.sh stop
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>#查看状态</span>
</span></span><span class=line><span class=cl>./zkServer.sh status
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>#客户端连接zookeeper</span>
</span></span><span class=line><span class=cl>./zkCli.sh
</span></span></code></pre></div><p>参考：https://ken.io/note/zookeeper-cluster-deploy-guide</p></li></ol><p>3.kafka安装</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl><span class=c1>#创建安装目录</span>
</span></span><span class=line><span class=cl>mkdir -p /opt/kafka
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>#进入安装目录</span>
</span></span><span class=line><span class=cl><span class=nb>cd</span> /opt/kafka
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>#下载kafka安装</span>
</span></span><span class=line><span class=cl>wget https://mirrors.aliyun.com/apache/kafka/2.7.1/kafka_2.13-2.7.1.tgz
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>#解压</span>
</span></span><span class=line><span class=cl>tar -zxvf kafka_2.13-2.7.1.tgz
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>#进入配置文件目录</span>
</span></span><span class=line><span class=cl><span class=nb>cd</span> kafka_2.13-2.7.1/config/
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>#备份配置文件</span>
</span></span><span class=line><span class=cl>cp server.properties server.properties.bak
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>#修改配置文件</span>
</span></span><span class=line><span class=cl>vim server.properties
</span></span><span class=line><span class=cl><span class=c1>#当前节点在集群中的唯一标识</span>
</span></span><span class=line><span class=cl>broker.id<span class=o>=</span><span class=m>1</span>
</span></span><span class=line><span class=cl><span class=c1>#服务监听端口</span>
</span></span><span class=line><span class=cl><span class=nv>listeners</span><span class=o>=</span>PLAINTEXT://127.0.0.1:9092
</span></span><span class=line><span class=cl><span class=c1>#提供给生产者、消费者的端口</span>
</span></span><span class=line><span class=cl>advertised.listeners<span class=o>=</span>PLAINTEXT://127.0.0.1:9092
</span></span><span class=line><span class=cl><span class=c1>#连接地址，如有集群需配置</span>
</span></span><span class=line><span class=cl>zookeeper.connect<span class=o>=</span>127.0.0.1:2181
</span></span><span class=line><span class=cl><span class=c1>#连接超时时间</span>
</span></span><span class=line><span class=cl>zookeeper.connection.timeout.ms<span class=o>=</span><span class=m>18000</span>
</span></span><span class=line><span class=cl>:wq
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>#开放端口</span>
</span></span><span class=line><span class=cl>firewall-cmd --add-port<span class=o>=</span>9092/tcp --permanent
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>#重新加载防火墙配置</span>
</span></span><span class=line><span class=cl>firewall-cmd --reload
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>#进入kafka执行目录</span>
</span></span><span class=line><span class=cl><span class=nb>cd</span> /opt/kafka/kafka_2.13-2.7.1/bin
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>#后台启动kafka内置的zookeeper</span>
</span></span><span class=line><span class=cl>./bin/zookeeper-server-start.sh -daemon config/zookeeper.properties
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>#关闭zookeeper</span>
</span></span><span class=line><span class=cl>./bin/zookeeper-server-stop.sh -daemon config/zookeeper.properties
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>cd</span> /opt/kafka/kafka_2.13-2.7.1
</span></span><span class=line><span class=cl><span class=c1>#启动kafka,如果在去启动时报错 The Cluster ID 4cffC36ERj6MTJ_mZkKafA doesn&#39;t match stored clusterId 可能是之前使用的 zookeeper 和现在的不是同一个，解决办法是删除 server.properties 中配置的 logDir 下的 meta.properties 文件</span>
</span></span><span class=line><span class=cl>./bin/kafka-server-start.sh -daemon config/server.properties
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>#关闭kafka</span>
</span></span><span class=line><span class=cl>./bin/kafka-server-stop.sh config/server.properties
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>#创建topic</span>
</span></span><span class=line><span class=cl><span class=c1>#partitions表示在几个分区上创建topic</span>
</span></span><span class=line><span class=cl><span class=c1>#replication-factor表示在每个分区上副本的数量</span>
</span></span><span class=line><span class=cl>./kafka-topics.sh --create --zookeeper 127.0.0.1:2181 --replication-factor <span class=m>1</span> --partitions <span class=m>1</span> --topic topic1
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>#查看topic信息</span>
</span></span><span class=line><span class=cl>./kafka-topics.sh --describe --zookeeper 127.0.0.1:2181 --topic topic1
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>#启动控制台生产者</span>
</span></span><span class=line><span class=cl>./kafka-console-producer.sh --broker-list 127.0.0.1:9092 --topic topic1
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>#启动控制台消费者</span>
</span></span><span class=line><span class=cl>./kafka-console-consumer.sh --bootstrap-server 127.0.0.1:9092 --topic topic1 --from-beginning
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>#3个broker情况下创建topic指定4个副本会报错，原因是replication的数量不能大于broker数，可以想象的是replication是针对每一个分区来说的，如果一个分区的副本数等于broker数的话那个意味着每个broker上都有一个该分区的副本，如果大于broker数，那么该分区在某些broker上会存在多个副本，没有必要</span>
</span></span><span class=line><span class=cl>./kafka-topics.sh --create --topic myd4 --partitions <span class=m>3</span> -replication-factor <span class=m>4</span> --zookeeper kafka1:2181
</span></span><span class=line><span class=cl>Error <span class=k>while</span> executing topic <span class=nb>command</span> : Replication factor: <span class=m>4</span> larger than available brokers: 3.
</span></span></code></pre></div><p>参考：https://www.cnblogs.com/kentalk/p/kafka-cluster-deploy-guide.html</p><h2 id=配置远程访问>配置远程访问<a hidden class=anchor aria-hidden=true href=#配置远程访问>#</a></h2><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl><span class=nb>cd</span> kafka安装路径/config/server.properties
</span></span><span class=line><span class=cl>修改对应位置为
</span></span><span class=line><span class=cl><span class=nv>listeners</span><span class=o>=</span>PLAINTEXT://:9092
</span></span><span class=line><span class=cl>advertised.listeners<span class=o>=</span>PLAINTEXT://服务器ip:9092
</span></span></code></pre></div><h2 id=基准测试>基准测试<a hidden class=anchor aria-hidden=true href=#基准测试>#</a></h2><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>./kafka-topics.sh --zookeeper 139.198.11.13:2181 --create --topic benchmark --partitions <span class=m>1</span> --replication-factor <span class=m>1</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>./kafka-producer-perf-test.sh --topic benchmark --num-records <span class=m>500000</span> --throughput -1 --record-size <span class=m>1000</span> --producer-props bootstrap.servers<span class=o>=</span>139.198.11.13:9092 <span class=nv>acks</span><span class=o>=</span><span class=m>1</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>./kafka-consumer-perf-test.sh --broker-list 139.198.11.13:9092 --topic benchmark --fetch-seze <span class=m>1048576</span> --messages <span class=m>500000</span>
</span></span></code></pre></div><h2 id=kafka-eagle管理工具>kafka-eagle管理工具<a hidden class=anchor aria-hidden=true href=#kafka-eagle管理工具>#</a></h2><ol><li><p>去官网https://www.kafka-eagle.org/下载tar安装包</p></li><li><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl><span class=c1>#上传tar包到kafka-eagle安装目录</span>
</span></span><span class=line><span class=cl>tar -zxvf kafka-eagle-bin-2.0.6.tar.gz
</span></span><span class=line><span class=cl><span class=nb>cd</span> kafka-eagle-bin-2.0.6.tar
</span></span><span class=line><span class=cl>tar -zxvf kafka-eagle-web-2.0.6-bin.tar.gz
</span></span></code></pre></div></li><li><p>设置环境变量</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>vim /etc/profile
</span></span><span class=line><span class=cl><span class=c1>#kafka-eagle</span>
</span></span><span class=line><span class=cl><span class=nb>export</span> <span class=nv>KE_HOME</span><span class=o>=</span> xxx
</span></span><span class=line><span class=cl><span class=nv>PATH</span><span class=o>=</span><span class=nv>$PATH</span>:<span class=nv>$KE_HOME</span>/bin
</span></span><span class=line><span class=cl><span class=c1>#java</span>
</span></span><span class=line><span class=cl><span class=nb>export</span> <span class=nv>JAVA_HOME</span><span class=o>=</span> xxx
</span></span><span class=line><span class=cl><span class=nv>PATH</span><span class=o>=</span><span class=nv>$PATH</span>:<span class=nv>$JAVA_HOME</span>/bin
</span></span><span class=line><span class=cl>:wq
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>#更新环境变量</span>
</span></span><span class=line><span class=cl><span class=nb>source</span> /etc/profile
</span></span></code></pre></div></li><li><p>修改kafka-eagle配置文件</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl><span class=nb>cd</span> <span class=nv>$KE_HOME</span>/conf
</span></span><span class=line><span class=cl>vim system-config.properties
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>######################################</span>
</span></span><span class=line><span class=cl><span class=c1># multi zookeeper&amp;kafka cluster list</span>
</span></span><span class=line><span class=cl><span class=c1># zookeeper和kafka集群配置</span>
</span></span><span class=line><span class=cl><span class=c1>######################################</span>
</span></span><span class=line><span class=cl>kafka.eagle.zk.cluster.alias<span class=o>=</span>cluster1
</span></span><span class=line><span class=cl>cluster1.zk.list<span class=o>=</span>192.168.37.151:2181,192.168.37.152:2182,192.168.37.153:2183
</span></span><span class=line><span class=cl><span class=c1>######################################</span>
</span></span><span class=line><span class=cl><span class=c1># kafka eagle webui port </span>
</span></span><span class=line><span class=cl><span class=c1># web页面访问端口号</span>
</span></span><span class=line><span class=cl><span class=c1>######################################</span>
</span></span><span class=line><span class=cl>kafka.eagle.webui.port<span class=o>=</span><span class=m>8048</span>
</span></span><span class=line><span class=cl><span class=c1>######################################</span>
</span></span><span class=line><span class=cl><span class=c1># kafka jdbc driver address</span>
</span></span><span class=line><span class=cl><span class=c1># kafka默认使用sqlite数据库，Centos自带，注意配置下数据库存放路径就行</span>
</span></span><span class=line><span class=cl><span class=c1>######################################</span>
</span></span><span class=line><span class=cl>kafka.eagle.driver<span class=o>=</span>org.sqlite.JDBC
</span></span><span class=line><span class=cl>kafka.eagle.url<span class=o>=</span>jdbc:sqlite:/opt/kafka-eagle/db/ke.db
</span></span><span class=line><span class=cl>kafka.eagle.username<span class=o>=</span>root
</span></span><span class=line><span class=cl>kafka.eagle.password<span class=o>=</span>www.kafka-eagle.org
</span></span></code></pre></div></li><li><p>开放端口供外部访问</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>firewall-cmd --add-port<span class=o>=</span>8048/tcp --permanent
</span></span><span class=line><span class=cl>firewall-cmd --reload
</span></span></code></pre></div></li><li><p>启动kafka-eagle</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl><span class=nb>cd</span> <span class=nv>$KE_HOME</span>/bin
</span></span><span class=line><span class=cl>./ke.sh start
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>#出现以下内容则成功</span>
</span></span><span class=line><span class=cl>Welcome to
</span></span><span class=line><span class=cl>    __ __    ___     ____    __ __    ___            ______    ___    ______    __     ______
</span></span><span class=line><span class=cl>   / //_/   /   <span class=p>|</span>   / __/   / //_/   /   <span class=p>|</span>          / ____/   /   <span class=p>|</span>  / ____/   / /    / ____/
</span></span><span class=line><span class=cl>  / ,&lt;     / /<span class=p>|</span> <span class=p>|</span>  / /_    / ,&lt;     / /<span class=p>|</span> <span class=p>|</span>         / __/     / /<span class=p>|</span> <span class=p>|</span> / / __    / /    / __/   
</span></span><span class=line><span class=cl> / /<span class=p>|</span> <span class=p>|</span>   / ___ <span class=p>|</span> / __/   / /<span class=p>|</span> <span class=p>|</span>   / ___ <span class=p>|</span>        / /___    / ___ <span class=p>|</span>/ /_/ /   / /___ / /___   
</span></span><span class=line><span class=cl>/_/ <span class=p>|</span>_<span class=p>|</span>  /_/  <span class=p>|</span>_<span class=p>|</span>/_/     /_/ <span class=p>|</span>_<span class=p>|</span>  /_/  <span class=p>|</span>_<span class=p>|</span>       /_____/   /_/  <span class=p>|</span>_<span class=p>|</span><span class=se>\_</span>___/   /_____//_____/   
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>Version 2.0.6 -- Copyright 2016-2021
</span></span><span class=line><span class=cl>*******************************************************************
</span></span><span class=line><span class=cl>* Kafka Eagle Service has started success.
</span></span><span class=line><span class=cl>* Welcome, Now you can visit <span class=s1>&#39;http://127.0.0.1:8048&#39;</span>
</span></span><span class=line><span class=cl>* Account:admin ,Password:123456
</span></span></code></pre></div></li></ol><h2 id=kafka架构>kafka架构<a hidden class=anchor aria-hidden=true href=#kafka架构>#</a></h2><p><img loading=lazy src=./images/Snipaste_2022-03-08_20-53-12.jpg alt></p><ul><li>Producer: 消息的生产者，像 broker 中发送消息</li><li>Consumer: 消息的消费者，从 broker 中消费消息</li><li>Broker：一台 kafka 服务器就是一个 broker，一个 kafka 集群由多个 broker 组成，一个 broker 包含多个 topic</li><li>Topic：理解成一个队列，Producer 和 Consumer 都是面向 topic 的</li><li>ConsumerGroup: 多个对同一个 topic 进行消费的 Consumer 组成一个组，一个消费者组内的一个消费者只能消费一个分区，不同的分区由不同的消费者进行消费，消费者组内的消费者的消费能保证分区有序性，但是不能保证全局有序。</li><li>Partition: 为了实现扩展性，一个 topic 可以分布到多个 broker 上，一个 topic 可以分为多个 partition，每个 partition 是一个有序队列</li><li>Replica：副本，为了保证某一个 broker 故障后，分布在该节点上的 topic 的 partition 中的数据不会丢失，一个 topic 的每个 partition 都可以有若干 replica 分布在其他 broker上，replica 又分为 leader 和 follower</li><li>Leader：每个 topic 的 partition 有多个 replica，其中一个为 leader，Producer 生产数据、Consumer 消费数据都是从 leader 上</li><li>Follower：topic 的 partition 的 follower，负责从 leader 处同步数据，并在 leader 发生故障后竞选为 leader</li></ul><h2 id=kafka工作流程>kafka工作流程<a hidden class=anchor aria-hidden=true href=#kafka工作流程>#</a></h2><p><img loading=lazy src=./images/Snipaste_2022-03-08_21-13-45.jpg alt></p><ol><li>在 kafka 中生产者生产消息和消费者消费消息都是面向 topic 的</li><li>topic 是一个逻辑上的概念，partition 是物理上的概念，每个 partition 对应一个<code>.log</code>文件，该文件中保存的就是生成者生产的数据。生产者生产的数据会被不断的追加到这个文件中，并且对于每个<code>.log</code>文件都有一个<code>.index</code>文件来保存当前<code>.log</code>文件的 offset 以便快速定位到数据</li><li>消费者组中的每一个消费者都会实时记录自己消费到哪个 offset 了，以便在出错回复时能从上次消费的地方消费和不会重复消费数据</li></ol><h2 id=kafka文件存储机制>kafka文件存储机制<a hidden class=anchor aria-hidden=true href=#kafka文件存储机制>#</a></h2><p><img loading=lazy src=./images/Snipaste_2022-03-08_21-21-16.jpg alt></p><ol><li>由于生产者生产消息会不断追加到<code>.log</code>文件中，为了防止<code>.log</code>文件过大导致定位效率低下，kafka 采用<strong>分片</strong>和<strong>索引</strong>机制提高检索效率，将每个 partition 分为多个 segment。每个 segment 对应两个文件<code>.log</code>文件和<code>.index</code>文件，所有 segment 的文件位于一个<code>topic_name + partition_number</code>命名的文件夹下，当每个<code>.log</code>文件的大小大于 <code>server.properties</code>文件中定义的<code>log.segment.bytes</code>值(默认为1G)时，会新增一个 segment,并且文件名为 offset,当 segment 创建的时间大于<code>server.properties</code>中定义的<code>log.retention.hours</code>的值(默认为7天)该 segment 会被删除</li><li><code>00000000000000000000.index</code>index 文件的格式为 offset 命名，最多可保存 20 位</li></ol><h3 id=log-文件和-index-文件>.log 文件和 .index 文件<a hidden class=anchor aria-hidden=true href=#log-文件和-index-文件>#</a></h3><p><img loading=lazy src=./images/Snipaste_2022-03-08_21-47-21.jpg alt></p><h2 id=创建topic时的分区策略>创建topic时的分区策略<a hidden class=anchor aria-hidden=true href=#创建topic时的分区策略>#</a></h2><h2 id=创建topic时的副本分配策略>创建topic时的副本分配策略<a hidden class=anchor aria-hidden=true href=#创建topic时的副本分配策略>#</a></h2><h2 id=生产者分区写入策略>生产者分区写入策略<a hidden class=anchor aria-hidden=true href=#生产者分区写入策略>#</a></h2><p>当生产者向一个 topic 中写入数据时，由于 topic 只是一个逻辑上的概念，而 partition 是物理上的概念，所以数据必然是写入到一个 partition 上，而一个 topic 由多个 partition 组成，那么生产者在发送消息时是具体将消息写入到了那个 partition 中呢?</p><ol><li>指定分区策略，消费者在发送消息时指定发送到哪个 partition</li><li>随机策略，随机发送到一个 partition ，会导致数据倾斜</li><li>轮询策略，生产者在发送消息时首先生成一个 random_number ，然后使用<code>random_number % partition_number</code> 作为第一个发送到的分区，以后的消息就轮流发送到每个分区上</li><li>按 key 分区策略，这种策略是在发送消息时指定一个 key，使用 <code>key.hash % partition_number</code>选择发送到的分区，这种策略能够保证相同的 key 的所有消息都能发送打同一个 partition，缺点是会造成数据倾斜</li><li>自定义策略，实现 Partitioner 接口</li></ol><h2 id=乱序问题>乱序问题<a hidden class=anchor aria-hidden=true href=#乱序问题>#</a></h2><p>不管生产者使用 随机策略、轮询策略虽然消息在同一个分区中是局部有序的，但是不同分区之间由于消费者的消费速度一同，所以从整体上来看是乱序的，虽然按 key 分区策略能保证有序，但是有会造成数据的倾斜，除此之外把 topic 的分区设置成1也能保证有序，但是这样就失去了 kafka 的分布式特性和可扩展性</p><h2 id=kafka生产者生产消息的可靠性>kafka生产者生产消息的可靠性<a hidden class=anchor aria-hidden=true href=#kafka生产者生产消息的可靠性>#</a></h2><h3 id=幂等性>幂等性<a hidden class=anchor aria-hidden=true href=#幂等性>#</a></h3><p>一个相同的操作进行两次会得到同样的结果，如发送两次相同的 http 请求，在 kafka 中生产者发送了生产消息到 topic 上，那么如何保证收到了这个消息？如果 server 收到了消息会进行ack的话，如何保证生产者这没有收到这个 ack 之前有发送了一遍上一次的消息后，server 收到了不会重复保存？</p><h3 id=消息可靠性>消息可靠性<a hidden class=anchor aria-hidden=true href=#消息可靠性>#</a></h3><p>为了保证数据的可靠性，kafka 在收到了生产者发送的消息后会进行 ack，如果生产者在指定的时间内没有收到 ack，那么会重新发送上一次的消息。生产者在发送消息时会携带一个 pid(Producer Id)和一个 seqid(自增Id), kafka 在收到消息后会保存生产者发送过来的 pid 和 seqid,如果 kafka 接受到一条消息，消息的 seqid 小于等于 kafka 保存的对应 pid 对应 sqlid，即这条消息已经被 kafka保存，kafka 不会重复保存这条消息</p><h3 id=acks设置>acks设置<a hidden class=anchor aria-hidden=true href=#acks设置>#</a></h3><ol><li>acks=0: 生产者不等待分区返回 ack，存在丢数据风险</li><li>acks=1：生产者等待分区 leader 同步完成之后返回 ack，如果分区 follower 在 leader 返回 ack 之后故障，而此时 follower 还没同步数据将导致数据丢失</li><li>acks=-1：消费者分区的 leader 和 follower(ISR 中的 follower) 都同步完数据之后返回 ack。但是如在在 follower 同步完成后，leader 返回 ack 前 leader 故障那么会导致数据重复。如果 ISR 中当前只有 leader，那么 leader 同步完后就返回 ack 了但是 follower 还没同步完成，也可能导致丢失数据
<img loading=lazy src=./images/Snipaste_2022-03-09_21-46-04.jpg alt>
<del>kafka 对消息进行 ack 有两种方案</del></li></ol><p><del>分区半数以上的 replica 同步成功后进行 ack，优点是延时低，缺点是选举新的 leader 时，如果要容忍 n台节点故障需要部署 2n+1 台</del></p><p><del>所有 replica 同步完成后进行 ack，优点是选举新的 leader 时容忍 n 台故障，只需要 n+1 个节点，缺点是延时高</del></p><p><del><strong>kafka 选择第二种方案对消息进行 ack</strong></del></p><p><strong>高延时怎么解决？</strong>
每个分区维护一个动态的ISR(in-sync replica set)即和 leader 保持同步的 follower 的集合，当 ISR 中的 follower 同步完数据后会对消息进行 ack，如果 ISR 中的 follower 同 leader 进行同步的时间过长，那么该 follower 会被踢出 ISR该时间阈值由<code>replica.lag.time.max.ms</code>指定，如果在 ISR 之外的 follower 同 ISR 同步的时间较短，那么该 follower 能够加入 ISR，leader 故障后从 ISR 中选择新的 leader</p><h3 id=故障恢复>故障恢复<a hidden class=anchor aria-hidden=true href=#故障恢复>#</a></h3><p><img loading=lazy src=./images/Snipaste_2022-03-09_22-34-24.jpg alt>
LEO(Log End Offset):指的是每个副本最大的 offset</p><p>HW(High Watermark):指的是消费者能见到的最大的 offset，ISR 队列中最小的 LEO。</p><h4 id=leader故障>leader故障<a hidden class=anchor aria-hidden=true href=#leader故障>#</a></h4><p>leader 发生故障后会从 ISR 中选择一个 follower 作为 leader，为保证数据一致性，其余的 follower 会把 log 文件中高于 HW 的一部分截取掉，重新从 leader 中同步</p><h4 id=follower故障>follower故障<a hidden class=anchor aria-hidden=true href=#follower故障>#</a></h4><p>follower 发生故障后会被临时踢出 ISR，待该 follower 恢复后，follower 会读取本地磁盘
记录的上次的 HW，并将 log 文件高于 HW 的部分截取掉，从 HW 开始向 leader 进行同步。
等该 follower 的 LEO 大于等于该 Partition 的 HW，即 follower 追上 leader 之后，就可以重
新加入 ISR 了</p><h3 id=exactly-onece>Exactly Onece<a hidden class=anchor aria-hidden=true href=#exactly-onece>#</a></h3><h2 id=消费者分区消费策略>消费者分区消费策略<a hidden class=anchor aria-hidden=true href=#消费者分区消费策略>#</a></h2><h2 id=分区的物理存储>分区的物理存储<a hidden class=anchor aria-hidden=true href=#分区的物理存储>#</a></h2><h2 id=生产者消息不丢失>生产者消息不丢失<a hidden class=anchor aria-hidden=true href=#生产者消息不丢失>#</a></h2><p>ack</p><h2 id=消费者消息不丢失>消费者消息不丢失<a hidden class=anchor aria-hidden=true href=#消费者消息不丢失>#</a></h2><p>控制offset</p><p>默认的自动提交offset会出现消息丢失</p><p>即使控制消息保存成功，也有可能出现消息重复消费</p><p>##kafka事务</p></div><footer class=post-footer><ul class=post-tags></ul></footer></article></main><footer class=footer><span>&copy; 2022 <a href=https://moyuduo.github.io/>Moyuduo's Blog</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>